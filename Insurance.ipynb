{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron VS Dense Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medical Cost Personal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>37</td>\n",
       "      <td>male</td>\n",
       "      <td>29.640</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>5028.14660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>54</td>\n",
       "      <td>male</td>\n",
       "      <td>33.630</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10825.25370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>471</td>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>30.115</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2203.47185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>745</td>\n",
       "      <td>50</td>\n",
       "      <td>female</td>\n",
       "      <td>30.115</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>9910.35985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>20.425</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>1625.43375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1295</td>\n",
       "      <td>20</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>1964.78000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1157</td>\n",
       "      <td>23</td>\n",
       "      <td>female</td>\n",
       "      <td>23.180</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>14426.07385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>574</td>\n",
       "      <td>57</td>\n",
       "      <td>female</td>\n",
       "      <td>34.295</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>13224.05705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>491</td>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>25.080</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>24513.09126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>883</td>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>37.050</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>northeast</td>\n",
       "      <td>46255.11250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "164    37    male  29.640         0     no  northwest   5028.14660\n",
       "110    54    male  33.630         1     no  northwest  10825.25370\n",
       "471    18  female  30.115         0     no  northeast   2203.47185\n",
       "745    50  female  30.115         1     no  northwest   9910.35985\n",
       "35     19    male  20.425         0     no  northwest   1625.43375\n",
       "1295   20    male  22.000         1     no  southwest   1964.78000\n",
       "1157   23  female  23.180         2     no  northwest  14426.07385\n",
       "574    57  female  34.295         2     no  northeast  13224.05705\n",
       "491    61  female  25.080         0     no  southeast  24513.09126\n",
       "883    51  female  37.050         3    yes  northeast  46255.11250"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/insurance.csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "attachments": {
    "Insurance%20MLP.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAABQAAAALQCAIAAABAH0oBAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAP+lSURBVHhe7J0NfBxVvfchtCWlBQsUKKKlclFjr2B6RcyDV1svKhEEVkTZwi0EKxqFYgCByFuBCqFA2b6S0gKB8pLSAhGhFgSpWqFQXkIrUF68lMtzsT4XaN6Tltru882ew7qdfcns7uxmdvf3/ZxPuzOZnTlz5syZ/3fOmdldwkIIIYQQQgghRAkgARZCCCGEEEIIURJIgIUQQgghhBBClAQSYCGEEEIIIYQQJYEEWAghhBBCCCFESSABFkIIIYQQQghREkiAhRBCCCGEEEKUBBJgIYQQQgghhBAlgQRYCCGEL/jg8glKuU62rIUQQohSRQIshBDCFzhUTSkXyZa1EEIIUapIgIUQQvgCh6op5SLZshZCCCFKFQmwEEIIX+BQNaVcJFvWQgghRKkiARZCCOELHKqmlItky1oIIYQoVSTAQgghfIFD1ZRykWxZCyGEEKWKBFgIIYQvcKiaUi6SLWshhBCiVJEACyGE8AUOVVPKRbJlLYQQQpQqEmAhhBC+wKFqSrlItqyFEEKIUkUCLIQQwhc4VE0pF8mWtRBCCFGqSICFEEL4AoeqKeUi2bIWQgghShUJsBBCCF/gULXSTO1zvrv52omOmR4mW9ZCCCFEqSIBFkII4QscqpZGuvLILS89whq2vd3q/FMkdd9/2T/+31/NVsLb//Hhm0/HS6abZWLT5hlH7ejevGPb1rYbv+34E6n3yYWsZssLv3bMT5267j2fbyVbpycpsntCCCFE6SIBFkII4QscquYytc//flRcEwqwcVGcdtvGFz584887Puzrn9r8P7F+62YZR8qdAO+03SuP3PZ//0LGOu/+eXSxbFL/bgohhBAljARYCCGEL3CompsUFVeslf/jBbjj5snYLJraeftZdqZRyhg7dbNMfMqFACdIEmAhhBDCUyTAQgghfIFD1QZMRkE//K+1m6+daPpO4wV46/pHme8QUWO80Y5WN8vEJwmwEEIIUYhIgIUQQvgCh6q5SR2La8yHxAKcxB6Nu9r5bpaJmR9NaQmw0Wkm2+d/f+urT0Z2N7y9/e+OlZvFonthzNxBz8pZ5q/pPrRskl1eCCGEKFUkwEIIIXyBQ9XSSgkFOKmjxkivm2V2mv9RykCAt218gX/7ZfWNP/9j0+v9+7zz+h0CjOJGH0g2Dyd/+NofzThts7983cxnbamfWI6m/m8JIYQQJYwEWAghhC9wqFpaKaEAG59MKreR3lQ3y+w0/6OUgQCbHEY11SwTm2eHAPenhB4+kJynSGxRCCGEKGUkwEIIIXyBQ9XSSikEOGHXqBldHBXg1Ms45puUgQA7thI/UwIshBBC5BoJsBBCCF/gULW0Uno9wHECnHoZx3yTMhkCvXP2zBoyEeCYIdAfvvl0R+OpsX9Knfq/JYQQQpQwEmAhhBC+wKFqaaWEApzUUWOs0s0yO83/KA2uAJNiX4LV/z6t6G84pUxmeSGEEKJkkQALIYTwBQ5VSyulEOB4e4x1VzfLxM6PpmRfNMnRe5wLATapfc53t7z0SH/xJV8mNvUvKYQQQpQwEmAhhBC+wKFqaaWEAkxKOIzZLBw1TzfLJEzmi9Fu3miKd+PcCbBJpsM52Wjt2MRiQgghRCkjARZCCOELHKqWVkomwGb+Th25RiljdNHNMgmT+SJ22vv4vOjM9vnfN9+NzUzmApzIz/nitndfjR3znNDhE6b+DAshhBAljARYCCGEL3CompvU96em/l/H/ehndbd3vmcmt6xdHl3GyCGa2v+TuX9dg2EylVAyUy+TMJmuV8M/Pnhne9u75rOj6zgbAbab+OjXg7Fc28PMFt/b2D8z8iRw6s7qaOpflRBCCFHCSICFEEL4AoeqDZw+6qeNZycbvPJIPNk4bf+fOt+L7bBNY5kkqf9lVBH9NpjvOlw0GwEm2ad8I93UZix0+/zvb331STOz343ffNqN/ZLsV4QQQohSRQIshBDCFzhUTSkXyZa1EEIIUapIgIUQQvgCh6op5SLZshZCCCFKFQmwEEIIX+BQNaVcJFvWQgghRKkiARZCCOELHKqmlItky1oIIYQoVSTAQgghfIFD1ZRykWxZCyGEEKWKBFgIIYQvcKiaUi6SLWshhBCiVJEACyGE8AUOVVPKRbJlLYQQQpQqEmAhhBC+wKFqSrlItqyFEEKIUkUCLIQQwhc4VE0pF8mWtRBCCFGqSICFEEL4AoeqKeUi2bIWQgghShUJsBBCCF/gUDWlXCRb1kIIIUSpIgEWQgjhCxyqppSLZMtaCCGEKFUkwEIIIYQQQgghSgIJsBBCCCGEEEKIkkACLIQQQgghhBCiJJAACyGEEEIIIYQoCSTAQgghhBBCCCFKAgmwEEIIIYQQQoiSQAIshBBCDMS2tnDbqvB7LeGN0/vTS/8RfvGofyYz8/819y/Tt9F+RQghhBD+QwIshBBCJAGbfbexX3dX7xlee1j4+S+HXzyhP71SF371wn8mM/P5r/Qv89SY8Nrx4f9uCPdssCsRQgghhG+QAAshhBA7g/disHgsNvvC0eFXfh7+r8VppA1XhF88NrxmbPjpg8JvTpMJCyGEEP5BAiyEEEJ8xNZN4TfP6fdeDBaP/evirNJr14VbTwk/PTa8/lgNjRZCCCH8gARYCCGEiDzl+9Zl4acPDL8UDP91kcfpLz/rl+rXpvYLthBCCCEGDwmwEEKIkuedWeGnPx5uDYTfXOB0Vw/Tuin9go1mb++z2xVCCCFEfpEACyGEKGG2tYVbvx5+sTr8xmynr+YiIdho9nOVGhEthBBCDAoSYCGEEKUKFvrcF/pf6fzXW/KaNlwWXvv5cMcamw0hhBBC5AsJsBBCiJKkbVX4mU+HN1zltNP8pNdvCK89PPy3xTYzQgghhMgLEmAhhBClx//MCz/3xfAbIaeX5jO9OT/8wtfDb/zMZkkIIYQQuUcCLIQQosTAfjHPN+eF/7pw8NNLJ4dfO9NmTAghhBA5RgIshBCilGhbFen7nRd+c6Ff0ovf7HdyIYQQQuQeCbAQQoiSoW9j/3O/r98UfrPRR+mNuf1OjpkLIYQQIsdIgIUQQpQG29r63/m8YbrTP/2QcHLMXL+NJIQQQuQYCbAQQojSoPXr4ZfPDb95s0/ThivCz1aEt/fZ3AohhBAiB0iAhRBClADvzAq/+K3wGzf7OrX+IPzGOTbDQgghhMgBEmAhhBDFztZN4acODL8+O/zGAr+nNYeEu1pttoUQQgjhNRJgIYQQxc4b54Rbv+9UTX+m9T8Orz/WZlsIIYQQXiMBFkIIUdT0d/+OCb8eCr8xvzDSM58Nd6yxmRdCCCGEp0iAhRBCFDWvTQ23Tg6/Pr9g0sv14bXjbeaFEEII4SkSYCGEEMVLV2v/U7WvzyuwtPaI8HstdheEEEII4R0SYCGEEMXLf10YfuFEp176P63/af+PNgkhhBDCayTAQgghipdnDgm/cplTL/2fXrspvHpP/SawEEII4TkSYCGEEEVKz4bw058Mvz63IJNGQQshhBA5QAIshBCiSHn7mvAL1U6xLJTUelr41dPsjgghhBDCIyTAQgghipTnJ4T/cr5TLAslbfhV+M+j7Y4IIYQQwiMkwEIIIYqRrZvCf94n/PqcAk76QWAhhBDCayTAQgghipH3Wvofo31tTgGn548O/9+Q3R0hhBBCeIEEWAghRDHybmP4+Ynh12YXcHr+O+G3Lra7I4QQQggvkAALIYQoRjZODz9f7VTKwkqtp+o9WEIIIYS3SICFEEIUI6hj6+Twa6ECTuvPDr/wf+zuCCGEEMILJMBCCCEKm8rKymAw2Nzc3NfXZ2dB69fDL/0kvCFUwOkvvww/c4jdHSGEEEJ4gQRYCCFEYVNdXb1LhPLycmPCbW1t4bWfC//lgvCGmwo4vXpNePWedieFEEII4QUSYCGEEAXMxo0bjf06+Pi+Zeef8X+cSlloaeX1u7S0tNhdFUIIIUTWSICFEEIUHm1tbatWrWpqarr44ouHDRtmrXdnTjtufHjDrAJOr85cecOQUaNGhUL6MSQhhBDCGyTAQggh/A6u29LSMn369GAwOGnSpPIIfGDy0ksv3Wuvvazy7swfbw84lbKw0suXhp8+aMOGDRUVFezpTk84CyGEECIjJMBCCCF8RGtr68qVK3Hd2tpaFHfUqFGobFVVVXV1NTObmpqQ4f5HfD+ChffZZx9jvA7a/nhSeMONBZzW/dS8BZr9ZfcrKys3bdpk9loIIYQQmSEBFkIIMThs2LABm21oaKirq8N1x40bh7VWVFTwGdcNhUL8NZnyMZ8v8hXc+LTTTjPGG0v57kPCzx8b3nBDAafW08Ivn2R3OBymlMaMGbNmzRo7LYQQQoj0kQALIYTIOfgqNtvY2IjZ4reVlZU4KvrKZ7wOleWv+LBdOiUrV64MBoOjRo2qra3lK6y5urp6xIgRxnujjP/0AeHnJzmVsrDSCyeE35xmdztCc3MzO97U1GSnhRBCCJEmEmAhhBBe0tfXh80iabhuIBCoqqpCR9E2XLempoaZGGwG3ZixXb6s3DwQy4cxY8bMmDEDJXa8CmvK978aXntkeMP1BZyePzr83w1m96NQdOxyXV2dnRZCCCFEOkiAhRBCZA6u63g9FfLJByaZ2dzczAJ20UxxdPmamXxgK9XV1evWrePfb33rW/vtt9/w4cN33XVXI8ANV50bXvOp8KvXF3Ba+2/h9xL8BtKmTZuqqqrY/dhnoYUQQgjhBgmwEEIIV7S2tmKzaK15PdWYMWPwzOjrqRobG/mrh0qWsMvXwHy2zkyWqaysPPXUU/n3a1/72pQpUx5//PHPfe5zeDjuHX764+G/1IdfnVmQ6ZVrwqtHhrcnfvMzpREMBisqKlyOGxdCCCGEQQIshBDCycaNG7FZPLO+vh7XjX09FXPM66lYxi7tNabLF8VlWw7BY9IoN+pLBsjYpZdeymQgEOBzVJJff/31/uy9OS38/HfCr15XkOmlH4Zbv252JxkciFGjRrW0JOglFkIIIURCJMBCCFHSYJLYrHk9FSZpXk+FfOK6dXV1zOSv+elmjHb5ko3+/tudQW7NX5sir4BqbW01r4Oqra1leTKc4LnitlXhZ8Y7xbJQ0nP/Hn630e5IclauXEk5YMJ2WgghhBApkQALIUSpgENis7glWhsIBFBcXDf29VQtLS2D8is7sV2+CTuWyVVFRQWZNEOsjfWRW5S4qqrq+OOPJ/NmSSer9wy/Mj38akPhpacOCPe56mPfsGEDhUMBxo4SF0IIIURCJMDCA7a9s37L+kd7n1zYcftZHYvOSJj465YXH/rwrefsd4QQOQZpNK+nwhtR3OjrqVBfZprXUw2uMqXu8jWQQ6wYN0Z6zRzz5mdj8nx35syZOHDSHXn11PALJ4dfvbbA0vpp4bWfs7vggra2NtN7T5HaWUIIIYRIhARYZMj2rvcR2s4l0zZfeWT77EBn45TO287uXv6r7gcaEib+2rHwzPa5J39w+QQ8uW/t8u1t79p1CSGyI/p6qrq6OhQXP8R10SGkiJnm9VS+UqMBu3wNjo5fCIVCSC/7y5/4+ooVK0aNGpXqaeQPVoafPcypl/5Pz08KvzPL7oJrOPqUyaD04QshhBCFggRYpMc/3tvY9/Td7TcH266ZiNB23ze99/E7+n5/V1qpe/mMzkVTN1/3jfa53+v9feO2v71m1y6EGAhkD5vFA1FHXBc/jH09VUNDA39NJYSDipsuXwPGi/eyX+yOnRURPOawd4DpPfbYY+YF0fbPyVj7ufD6c8KvXlMw6eX68NMHJnv/c2ooVfNotJ0WQgghxM5IgIVbtr76ZPus77RdX9256Mc9D17f98Rd2aeeX8/qvP2cyGqP6Xv2PrslIUQEJBD9S/h6qtraWmby19bWVru0v3HZ5WtgYbNkdGAzH/BhSoAyATQYx6MEAoGAWSAVXa3hNeOckunnlFH3bxTTN15XV2enhRBCCBGDBFgMzIdvPdd+c7Bjwak9D8/pe2JJLlLvI/M7F/0IE0az7VaFKCUQPGy2OfJ6KkQRxcV1y8vL+YD4MbOlpSW2L7RQcN/la0BuTcdv7DheCoevAx/A9HVTGmie23Hd674dbj0t/OqvCiCtPzutp38TQrFUVVVRUJSnnSWEEEKICBJgkYp/vLexc8k57XNO7nlwpkNZc5EQbDS7Y9EZ295Zb3MgRDGC3a1cuRKtRfawlFGjRqG7GIt5PVVTUxN2h+nZpQsTjN19l6/BvNQqtuMXULjKykoKykyyTmAmS0ZfizUwthM4zjZ9mNZOCL/nwe/6UoYUVEVFRX5+wkoIIYQoFCTAIjHbu97vabmy7fpjupde4dDUXKfu+69pD52IeOstWaIIQD+wWbTW8XoqPjPTh6+nyhJcF4NlN112+RooAZavqqpy2BprM0psJikxyg21w4fTHuL72pnhFwLhV2f4Or30w/ALVTbDXhAKhczvRdlpIYQQouSRAIsEbPvba+3zTu6868K+x+8crNTdfHl76AT9bJIoILA1bBblMJ5WEXk9Ff7GZ2zNvJ6qiLvj0F0kNq0uX4P5WSPKx05/RGtrK/MbGxvNJItRmG1tbWyIsk27h3xbW/iZz4TXnx9+5WqfppcvCT/zLy5/+9c9KyO/mUy1tNNCCCFEaSMBFk62rPtt++zv9j4yz2Gkg5BWLmqf873eP99pcyaEb0DDsFnzHibTdYnrohm4rnk9FdZRKK+nypLMunwNfDdhxy+Y92BFV0hpM8nymzZt4kOGZdvV2u/AL18efuUqP6ZnDwu//4jNqqdQvBUVFcFgsNDH1QshhBDZIwEWO9H7+PzOxim9j97W97s7fJI6b63teXD6jm1bbRaFyDvYFyaG1qIQKG55BD4wycwCfT1V9mTc5WtoaGjgu02JfrCHNfOn6CO++BuT5rVYFHt8X3Ea/O/9/Q/ZOszTD+mFb4Q3XmUzmQPa2to4WJWVlcU03l4IIYTIAAmwsGCYnXee3dU0zeGffkhdd1/UcevUHX2dNq9C5Izo66lqa2txrejrqZAHZprXU+ESdumSJJsuXwNCa4o0oYw1Njay8mgfr3nfldkQ6stBMfMzB8/ENl+50kfpxR+E/+Li95yypq6uLnorQQghhChNJMCin+1t77YvOKX/fVe/a/Jn6l42o312QK/FEh6ChmGzOJV5PRWWhetWVFTwGdcNhUL8Vd1lsWTZ5WtI0fELrJkDEV15X18fqmy6fM0jwd4cEWzzhZPCr0z3RVr3k/Bzh4e352lwMgdx1KhRycpfCCGEKHokwKK/7xf77Xnweodz+i31Pjynfd7J27vet/kWwjVYEzYbfT1VZWVl7OupmMlf4x9DFYbsu3wNa9asoeSDwWAyia2pqWGB2A72QCBgfgAJE66oqMhm6zuBba47JvzCsU4XzX968Qf99rstr2MKOBAczbRfoy2EEEIUBRJgEe4f+dx8Re9jTf5P3csbOhZO0fPAIgWxr6dCn2JfT4VKMXPlypUaAuoST7p8AX01Ch19rNcBC7AhiLVfvsIc894mbC36U8Ce8de68Noj+t+9/MoVg5NeOLq/Lzpffb+xbNq0iVODk6LEx/MLIYQoQSTApU7vb2/svPPnvY/dXiip855Luu493+ZelDy4bktLC1obfT0VussH83oq/I0F7KLCNV51+RrWrFlTUVGBviZzLeYjYyxgXNfQ2NjIt8xX0GbzA0jmT17y97vDz3w6/Jfzwq9cntf08oXhtZU5fevVgFDanCYUssY+CCGEKCkkwCXNlnW/7bx5isMw/Z/6jf23N9p9ECVDa2tr7Oup0LPY11PhS7iuurOyxKsuXwOHw7x1KVnHL7AVHMwxHJfl+ZbJwKbI7x7lsNO+/7eRDg2/8IP+n0fKT2r9YfjZz/a/j9oHhEKhUaNGtbS02GkhhBCi2JEAly7b3lnfPvfknt8u7n309oJLeDv2bvdEFB2YDzbb0NCAhuG6sa+nYo55PVX2eiaiUJgedvkajMSy2th+XQetra0cXA6onY5gXnYVNd5AIDB9+nTzOVds3RReVx1+5rPh1jPDL1+Ww7TunPCzXwg/Vxnu8VGnK0cKB3YcBSGEEKJYkQCXKNu73m+fd3LPQ7MdYlkoCW/H3nF4uz+iYDGvp2psbERy8Fvzeir8h8/R11NFfxFHeI63Xb6Gtra2mpqaioqK1N22HFm263gdMfUBJY52SPLXqqqqFArtJW2r+tUUQUVTHeKafVpfF37u38NPfzz8nh/7Wjds2MDxCgaDeSpqIYQQYvCQAJcoXct+2XnXRb2P3la4qfv+69rnnmT3RxQCxNY4T/T1VCiu4/VUaI9eT5UfctHla3DT8Qscaw69Y2g0X6msrIx2RWJlLJPvJ1QRVDR17ZfDL/0o/PKlHqR1teHnvh5eMzb8ziy7CV/S1tZGZaD8k72jWwghhCgOJMClyLa/vdY+67jelbcVeuqYP3nrq0/avRI+A5U1r6dCblHc6OupzIhWpAsZVndT/slFl68BcWLNVVVVA97FaGpqwmzjO/b5em1trflM3WBVjY2NZjLfvNsYfrYi/Oe9+034hZPDf7mo/2XRaaXW08Jr/0+/Sz/zqfBbl+b5h44yxjyzrftQQgghihgJcCnSueScrnsudchkIaaeX4fabjxOv4o06GAy2CxaG/t6qsrKSnyGmeb1VOpWGlyiXb7BYNDR7+oJOC0rb2hosNPJoUqMGzcu3r1RLyqMnYgsFggE7MRgsXVTvwmvqw6vHhl+9vDw2q+Gn/tGv9mSHEpsZj5f3b/M2iPCfxoRfqEq/H9DvnrW1yXNzc2jRo1yDE0XQgghigYJcMmx9dUnO+ZP7l15a3Gkjlt+1PfUErtvIvfgLdhs9PVUFRUVuC4+w2fmMJ+/etuvKLLEdPlyjDg6ubgNEe34dTNWuaamJuEg21AoxPzoiIA1a9ag0z66abK9r39o9Mbp4TfPCb/w5f70x2HhP+zyz2Rmvja1f5lNTYXS35sMU/6OV3MLIYQQxYEEuORon3tS9/Lren97a3Gknofmbp75TXUC54K2tjZs1ryeCsPBT6Kvp6qtrWUmf9XrqXxLrrt8DYiry45f5NY8+B3/U1UtLS2xfcIswGTu8izcsGnTpqqqqoTHSwghhChoJMClReSHf//T4ZCFnjpvO7v38fl2D0VGICfYbHNzsxl3StSL65aXl/Mh+noqFrBLC3+T6y5fw4YNGxAkNuRmE0gUdSnhS4ZbW1sdzwNT5aJPAotBhIPFIauoqMj3e8iEEEKIXCIBLi02z/xWT8tNvb9dXEyp55GFm2d8RZ3A7nG8ngr9QHeRGfN6qqamJlw3XlSEz8lPl68BtWZDLh8TJWOVlZUJnZY/sZ7Y3GLvGJeqn38IhUI0EbQYdloIIYQocCTAJcS2d9a3h05w2GNxpM4Fp21Z/6jdTxHDhg0bsFm0tq6uDtdFNszrqfjMTL2eqjjIT5evobW11X3HL1ADTcbsdAxtbW1Uxdj3PLNOqqjG1fuNlStX4sDRn6cSQgghChoJcAnR+/vGzkU/6V2xqPhS5x3ndy+/xO5nqbIx8noqgtT411NhvxgIf9VQxmKCo1lbW4uZ5KHLF/r6+kwPM75tZw3EmjVryF7CjmLWhkU7XrNEXU2oymLQobLRpCQcxC6EEEIUFhLgEqL/9VfLrnWoY5Gk38zbPOMrdj9LgLbI66nwiumR11NVVVXhupgG/mBeT4UOqRutWMFAOPQc9Px0+RpQWfynpqbG/SuRTLdhMjOnojp+5SgUClGB7YTwHxx6WpvKRC/xFkIIIQoICXCpsL3t3c0NRzu9sYhS++yTPnzrObu3xQWua15PFQwGMYTo66mYZKZeT1U65LnL1xDt+E1riyg6+USb7fTO4O14VGxfYmtrK5uIvgha+Ja6ujqOVLIjK4QQQvgfCXCp0Pf03R2NP+x95JZiTZ23nt3zyEy7twULYSWagdY6Xk9VXV3NTKQC13XfBSeKg0Hp8jVQG9ko1p1WrSOTfCvZePvm5mb+GrsX7GBFRYX7kdVicOFI0TRRJ+20EEIIUVBIgEuFjltO77p3ukMaiyn1PHDj5pnfsntbCKAH2CyqYF5PhRLgumgAn3HdUCjEXzXUsMQZlC5fA8ZbU1NDhUy3r48MV1ZWJuvLZW1jxoxxuDGnANuyE6IQMMfR8Qi3EEIIURBIgEuCHX2dbddM7PnNgt5HFhZxapv5rX+858chlHgsNovTYrb4LVIR+3oqZvLXZN1logQZxC5fA7KN3tTX18eOUh4QFkbUyXay7uL4Hz0CKj+7qXENBQfVkmNNI6ZjJ4QQorCQAJcE295Z33bTCT0PLyzu1DH/1EH/MSRiQQJ67AWtdbyeqqamhplE/3p8TiRjELt8DVgNm86g45eaT4UPBALJnJkFWK1j3CybQ4k5Zey0KCjMLQ8Oq+7fCSGEKCAkwCVB39rlHTef0fNwo1fplVtnjBq5B2p3x4VTHX8axNSx6Ce9j82x+5wXCNxbWlrQWqJAFLe8vJwy4QOTzGxublZkL9ww6F2+BvKAjpKBtDp+gQxXVlamGMbMCjkv6uvr7fRHIMzxM0VhEQqFRo0aRUtop4UQQgh/IwEuCXoemdmx+GcOXcwmNZ475V/HHfTVwz5zfNUXHH8axNS55OLOJefYffaa1tbWlZHXU9XW1hLKE/DhuhiLeT1VY2MjrquhgCJdBr3L14DBmgELGXTlbdy4EW/nLLDTiWDvwE58hHH+dGVb+BCqLnUYE7bTQgghhI+RAJcEHbed1XXXJQ5dzDh98MDcT+63zyWTj0ODhw0Z8sdZFzsWGKzUvbyhbdZxdp+zAAfAZhsaGurr63FdgntctyLyeirmmNdT6fdaRDb4pMvXEO34tdPp0NraivmwBjudCNw4XnQ5g/iihs4WDRxKGslgMKg7GkIIIXyOBLgk6H8F9N2X9fzmZk/S49ddEBn8/EPzARNOuIADljd//eD+OfiznRszP/vUff/MdF8EjXhgs42NjcTo+G1lZSVZQgb4HH09FSG+XVqIrPFJl6+BzKCm1PbMRNT0+6Ue+4obx7/jCkdiu5x3dloUBeY5cFrRwb2hI4QQQqRGAlwSoIXIoUMXM07nBo4eUT7sv++63qhs5b988r3ls6N/jbVis4BZ2Pz1lcX9Dw/3D5yOTDae+5/eOvAHl0+w+xwHMTc2SziO1gYCAeJvNk34TvRvXk9FHK/XU4kc4asuXwPZGDNmTOrO2xTwxQHfX8VfWSZ+uASnG6ZkJ0RxUVdXx0FXWyqEEMK3SIBLgn4BXn5dz0MLsk8fLJ+N0/YbbGTy3BOP7h8FfeOFZrLjwXnHfumwfiVeFjJzGqf9Z+wCLB/71/jls0xRASbyNq+nQm5R3OjrqVBfZprXU2monsgDvuryNZiOXxQ0Yw8PhUKYfOrBEWwloSGbn5AtvE7CbW3htlXh91rCG6f3p5f+I/ziUf9MZub/a+5fpq/Un4+ggaXC86+dFkIIIfyEBLgkaLt2Uvf9NzpcMbP0eMP5/X22v/hh7OQlwWPNZLzQxi7vkGeTUOL+LuIlM2NnZpwO3ntYWVkZWyTCPvTQQ0855ZTzzjuPYF1D8kSe8WGXL5Cr+vp6zo6MO36hrq6uoqIi9WPwbW1t7Hi8ApEB5vvkRoArsNl3G/t1d/We4bWHhZ//cvjFE/rTK3XhVy/8ZzIzn/9K/zJPjQmvHR/+74ZwT+k+4Wxuc1BV7LQQQgjhGyTAJYFXPcDGb2N7dF9ZdPWokXtEjTd1D7BZGDt14KEA/+sBw1lheXn56aefPn36dPMWKyBeZz4BmZmsra3lr7AqQmYPQAqREB92+RpwEk6EmpqajG0cfeXrlZWVqV94zmKYf8K3avF1CsdO+Bm8F4PFY7HZF44Ov/Lz8H8tTiNtuCL84rHhNWPDTx8UfnNaaZow1cwMNNDr8YUQQvgKCXBJEBHghp6H5meZXll01Ue6e5OZ0/HgXIwXt7zjF2eaOY83nBed/GB56JP77R1d3nz9+KrDzZK5SB9cPuETn/jEiBEjysrKJkyY8Pbbb9si+IjW1laMFy0xAkwsbpQYXSHb5lXPYP5qXvgM6kAWA+LPLl9DtOM3GyFnJcgM8MHOSkIgEEB07UQMLS0tnGIDfn2Q2bop/OY5/d6LweKxf12cVXrtunDrKeGnx4bXH1uCQ6M51sFgkIOum4xCCCH8gwS4JGhfcErX3Vf0/Hp+lqnxnNOwxIQc/+XDWaDjgX4f/swnDoj29Jr5Jn2wrN+HY+d4m7qX39B27aSNGzcOHTr0q1/9KgK86667Tp482ZaCCwjXjPE2NzcbByaUx4exGrM7Ro/Ng8RgniUGv8f0IpeYLl/0Euvz4eBe6qfp+M2mI47vVlZWJtRaB2bYRfwZsWnTJorI1+9G2tYWfuuy8NMHhl8Khv+6yOP0l5/1S/VrU/sFu8QIhUKjRo0qpHHvQgghihoJcEnQ/zNId13S8+t52aSOB+Yc+6XPR4YrN8TO/2DZTWitmW8+XxL8duwC0ZRsDV6l7mUN5meQbrrppj322INAfMWKFQReI0eOXLx4sSmKLCGIN8ZLSIcAO4ZYsy0zGR1iTczHwvohpaIExzNdvhz9xsZGH47zJEsoa/bP3G7cuJGVUNvtdHIoB0ojYVFwXiQcFO0X3pkVfvrj4dZA+M0FTnf1MK2b0i/YaPb20rplRg2keaTZtNNCCCHE4CEBLgl6Wq7qWHy2QxfTTa/ccmX/AOb+/lvnn8498T/QvzsuqDGKG+kr/Sf9Q6Dvm2WWNCuJndN4zmkJ15lB6rrz4o7bfmR2GS3Za6+9zDt4pk2bVlZWNn78+PgR0Z6Teog1FmEmcQn+Gh1infp9QsJvxHb5+rZLk0pIDqlpWQ5PoEqzHje/2Wu2mLAyU9Wp9nbCb2xrC7d+PfxidfiN2U5fzUVCsNHs5ypLbUQ0Z01FRUUwGNR4GSGEEIOLBLgk6Hv67o4FZ/T8em426dwTvz5syG5/vOECx3zSK7dM/8iN5zaec2rEb280f/pg2Sz7GPDOc4wbg/mWJ6lj0U96HplpdpkofOTIkTiw8RPUFyVOd0R0LjDG6xhiDaY0yCSfq6urzV+bmprM8goZ/YD/u3wNpuOXTGYv58Zp41/mHI/x5IRbxHySifHgg4U+94X+Vzr/9Za8pg2Xhdd+Ptzh4wHhOYCaSePGGaS3KgghhBhEJMAlwYdvPNU++3s9LXNznR6/tg6Lu+OCmtiZKHG/OV9/QezMXKSOBVP61i63+xwZjfnpT386NvL2fES05ziGWIPRY2SGgi0vLzeT6I35K37Cwr5+rrIooIQpcyqPn7t8DSg6dT77jl/Ae1kVdcxOJ4d6O27cuJaWFjsdA9mg9pIrO+0r2laFn/l0eMNVTjvNT3r9hvDaw8N/82lblDvq6uqS3SsRQggh8oAEuCTY3vV+2zVf622Zk+vUeM5kPO3OC86InXnuCf1dx3+6/vzYmblI7bOO3/bOervPEYwuVlZWxspAdET0unXr7KzCwQyxBiPAyYZYE2Ly14aGBrOwhlhnRltbm3moFfzc5WvAQk33mifPnLO/WIqbVXFycYole76XqhgMBu2Er/ifeeHnvhh+I+T00nymN+eHX/h6+I2f2SyVDM3NzTRZbkYWCCGEEJ4jAS4V2ud8t/vuK3ofnJ3T9Grj5f2P+B7yifebrzdznrjmXMTs+C8fFl0mV2n59ZtnfMXu7UcgfoRZRx99dCAQsLMiYDJ4AhrsmF8EGONNNsQaUeFzdIg1kmOW97na5Z8C6vI1mI5fr94yVV9fP27cOJf3TahOtUl+2peqxXr8WLuwX8zzzXnhvy4c/PTSyeHXzrQZKxk4raixdXV1dloIIYTIFxLgUqH3942djVOd0piDtPm+Gz45+p+P+MKd55/uWCYXqXPxOd3LLrF7GwOOd+SRRyJ+8e+wXbFixejRo4cPH+7bEdGeEx1iTbEYBzZ6XLHzEOtgMGj+2tLSYpa33y92CqvL17BhwwbT8csHOys7cH7OF5f7jsCwdTuxM6wBw/Fj5WlbFen7nRd+c6Ff0ovf7HfyEoPmiHpL/SmIE00IIUTRIAEuFba9s7591nd6HwwVa+qcF9yy/lG7tzuD0V100UXE4gkfRESMy8rKDj300EIcEe05SJQxXiPA0SHWlB6GzL9m0gyxBrOwV+o1iBRcl6+hoaGBg+LVr8v09fVhI+6FhO2mUOVAIBB/12nw6dvY/9zv6zeF32z0UXpjbr+TY+YlBlUuGAxWVFQUQRsihBCiUJAAlxCbZ36rZ+kMhzcWR+p5YNbmq4/asW2r3dWdMQOhly5dyr/Ymp0bAxF8sY6I9hxjvNEh1gSvRokjnf27EMiaSfPX6BDrTX596SuHvuC6fA0Ig+k986ps2XdsFv+PfWA+BS0tLSmGSTc1NbE2l6vKH9va+t/5vGG60z/9kHByzLzEfhvJEAqFaJzdvG5NCCGEyB4JcAnR03JV5y0/7X0gVHypu+nC6C8AJwS3wRbMm1eShewlOCLac1IPsQYzGQgEzF85ImZ5+/08UqBdvgbT8evhq5U5KThG7h/IbG1tpeiSvSLL3HLyY59e69fDL58bfvNmn6YNV4SfrQhvL8XfPMN+qTNejWUQQgghUiABLiEiP4Z0Uu8DNxVf6px/WuwPICUE70IbgEA/RUdffX39kCFDxo4dqxHRucAxxBrjMkpshlgTAZvJ2tpas4D5nSdPXmtsKNwuXwOuTs497PgFinfcuHHu3QO/5Xil6K+rqqqibO2Ef3hnVvjFb4XfuNnXqfUH4TfOsRkuMWgcqNvBYNB3AweEEEIUFxLgEmLHtq1t10zsXXadwx6LILX96mvbu963+5kEhIGonRiLAAt/sHMTgRRNnDixrKzsmGOOsbNEvjB63NLSYgQ42RDr+vp6/oqzmeWT9erHUtBdvoAVsNepzTMDKL20OpPNSOkUtsxxSX1+DQ5bN4WfOjD8+uzwGwv8ntYcEu7y7I5PYUHtovJUVVX59qEJIYQQRYAEuLTo/d28zlvO6r1/VjGlztvruu52NXSTKJ/QCpHg3wFHe65evXr06NHDhg3TqDz/QHxsjNcxxBolM4bMkWUyOsSaI/7www+fd955n/3sZwu0y9dgOn5Rd2/z39LSMiqdZy85d/CTFOcO+Rw3bpwf7eWNc8Kt33eqpj/T+h+H1x9rs12SUMHGjBlTiHephBBCFAQS4NJix7atm6/7Zs/SaxwOWbipZ/kNmxuOHrD7Nwrhe0NDAwE6YbqbUZozZszQiOgCInaI9dSpU8ePH8/hI5jed9990ePo7zxhksaQzRBrP4faGG9tba3nHb/Q1NSE/aY1vJycpHhRHHrMaYVU22n/0N/9Oyb8eij8xvzCSM98NtxR0vpn3tfAv3ZaCCGE8A4JcMnR9+clnQtO77v/xuJIXbf8uOc3DXbfXBAdCG3e4oP82D8kBwPRiOgCguPVmPwp34gdJxhijRtjyPibmTRDrBsaGszyboZY5wKkl+paV1fnbccvsHfsbFr7RWmkfrFzTU0NhmwnfMVrU8Otk8Ovzy+Y9HJ9eO14m/lSZc2aNaby22khhBDCIyTAJceObVvb53+/Z8klfctvKPTUu2xmWt2/BjMQmg9m/KdLB1i9evWBBx44bNiwGTNm2FnCZxAxZ/mUL55pjDc6xLq6uhofjg6x5gOTzDR/pS6Z5T0XVFbIXuDwueidZs3sSFoDlZubm1OPbeZsIrcp9HjQ6Grtf6r29XkFltYeEX7Pf33p+YX6RlvN6eb5+SWEEKKUkQCXIltffbJjzvcdMlmIqb8r+89L7F6lgxEYPjQ0NBDWu4+usF8cGBPWiGj/wOFL0eXrLdEh1tQcqlDdzm+xjg6xDgaDEUGejhaycLoSy7dYYX19vec+yQoDgQA5TKuUTF9cisHS5pmCXLi6B/zXheEXTnTqpf/T+p/2/2hTyUON5Wzi1ObUs7OEEEKI7JAAlyjtC07puePivuXXF27qbb5683Xf2LFtq92ldDADoU1AX1NTgw+4Nw3M4Zhjjtl11135N6euJQYE4+LwZdPl6zlkA+NNNsSaWmcmMWezQMSmV0WDe2pmdXU14X4udofqWlVVRZbS8uoBf/QI2CP2xU74jWcOCb9ymVMv/Z9euym8es/S/E3geEKhEKe554/BCyGEKE0kwCXKtr+91n7T8b33Xde37PoCTR3zTt3yfOZDBJuamswDjUD4nu6zi+vWrdOI6MECkctbl6+3kFVjvMmGWA8dOvSQQw4xPgksZpZPMfbYJXgsW0m3npNhU8h2OhHIiXmmwI/0bAg//cnw63MLMmkUdAzYLw6sd/ILIYTIHglw6YI94pAOqyyU1P/uq4eusXuSKdGB0ET548aNyyC00ojoPOPDLl9PMB2/aOQTTzxhjNcxxJr6aQzZTEaHWDc3N5vl7YqSsGHDBtbAOu20O8y9ofr6ejudCNY8ZsyYwXpJ2MC8fU34hWqnWBZKaj0t/OppdkdEpLJVVFSkO4RBCCGEcCABLmlwSEyyb9nMwkrdTRd03DrV7kMWxA6EJrTKbIgd8qwR0bmGgi3QLl834KXUPZd26hhibQbwgxlizXrMZG1trVmAhRcsWLDnnns2NTXZVbgG0wA7kQg8pLKyMoM154/nJ4T/cr5TLAslbfhV+M+j7Y6ICJz75lZR9mMihBBClCwS4FIHk8QnHYbp59RzZ33Hzafu6Ou0O5Ad0YHQfDZD7KJPY6bFunXrxo4dO2TIEI2I9pZi7fI1UNnMS24zq3XxoAeR/uBVVGwjwEcccQTV8pBDDjEdyBUVFcaQze88hUIhs3y8TvBX8pa6q62uri61IQ8yWzeF/7xP+PU5BZxK/geBE0LFGzNmTPE1CEIIIfKDBLjUwSTb536vZ8mlffdd5//Ue8+V7bMD29vetbn3guhAaMAH0noptAO+PmzYsNGjR69evdrOEhkR7fLFwXC5IuvyNTQ0NBDE57T7lJWPGjUq1hM2btxojDfZEGsKnMl/+7d/44sXX3wxazDLx5swM8m/rw/Ney39j9G+NqeA0/NHh/+vnnpNQHNzM1WUf+20EEII4RoJsAjjk+2zjuu79+q++xr8nHqXXtMRCmx7Z73Nt0fEDoSG2tpaBCCbZ8yOOeaYsrKyiRMnFqW25ZqVK1cGg0GOCAfCq35Rv4GRmo7fnA7jRHHR2nTLkLyFQqG999777LPPxpCTDbE+9dRTR44cecYZZ3C8MOEUv5A0mLzbGH5+Yvi12QWcnv9O+K2L7e6InaGu0lDU1dXZaSGEEMIdEmDRz4dvPdceOqH37ssczumjdO/V2O+Hr/3J5thTmpubowOh+Zf4nrjf/CkzNCI6XVBBI2ymyzebGxB+hv2qr69HI3Pa8Qu1tbVU6QzeTYUwIxU4rZ3eGfLf3x28atWXv/zlf//3f8eQ0XjOF46a6UDmCEYE2Q6x5pia5XP9lqy2trYEA2I3Tg8/X+1UysJKrafqPVgpoN0w95J0t1EIIYR7JMDC8o/3NuLA3bfV9S291m+pp+mi9lnHed73G0sw8lpd85lYijie2N1MZoxGRLvBdPnihEXc5WvA0CoqKmpqanIarOOolCdWkMFWTM0fcFgp9h69YeTAMcQaDTY+zGqNIZMxJs1zBxAdYp1lmVBzWDlVaKf1oI6tk8OvhQo4rT87/ML/sbsjEmEqPGdWcbceQgghPEQCLP7Jjr7OjsVndi8+2+Gfg5u6bz+v4+bJ3j73G8+mTZuI0aMjOYnjUbKWFg9+hDMQCGhEdDwl0uVr4NCjgmPGjMngNeNpwYbQS6pcBuXJVzgWSKmdTgKnBjuSsWysibzFmnIwAuwYYs2/ZpL5ZgHOQZZP0Lu7M4ceemjEr3chb//sXW/9eviln4Q3hAo4/eWX4WcOsbsjkhMKhWixc31+CSGEKA4kwGIndmzb2rX0os4FU/qWXuOH1HXLjzpu/aFX73xOTexAaCDsJqLy5OHGdevWEaCjwViQnVXClE6Xr4H9xcpy3fELmzZtogJnPHofbXbzXSQZ2bATXsPZ198dHPMWa3KFD7PRqN8aQ66rq+Ov0SHWH//4x80Chi984QsvvfRSeO3nwn+5ILzhpgJOr14TXr2nLR2REk40WpXcVU4hhBBFgwRYJKBv9R0doUDfkku2NF8zWKnvrss75wZ7HrrG5ikvxA6EhsbGxnHjxuEVdjo7Fi9ePHz48NGjR69YscLOKiVKqsvXgPGilBUVFRianZUzNm7cSNnG1t60MGOVBzworL+6utpODAbRIdZ4Dpkx2T7iiCOs+O7MXnvseslZX3UqZaGlldfvoncdu2TDhg2cbjTjpdC8CCGEyBgJsEjMh2881X7DtzvnndZ3z/Qtzb/KZ+q79+quBWe0XV+95XkPRiCnhRkIHTvesq6uDmHzMJwyI6JZZ+mMiC61Ll+D6fjF0PIQi7e2tlK8/xz6mybmF6cGrJCcFx7eD/IE48OY8NChQ6317sy0074Y3jCrgNOrMzfcNbS6upoWY8Bx4AKoxqa4fFVRhRBC+AoJsEjKjm1b+/68ZHPD0egoUurQ1BylrpvPbGv4j97H5+dn2HM8zc3NyECstBBO4W92wgtKZER0CXb5GtjxQCBALcqPsZiRnxk/r26+jkna6SRw+NgjT56Kzxg8nwygu5yPkyZNwm/NiOhzzjlnyJAhxngdtP15qlMpCyu9fGn46YPYdw6T6duU17mhrq6OuqFbBkIIIRIiARYDgIiio0hp18IfbWmekbvUveinm6/9es9vGrZ3vW+3PUgQZcaqaVtbG6EnLmenPWLx4sUjR44syhHRpdnla0D189bxC2ZzqzIdYo1SuvSEmgh2IvdQeuwUe4fuoricgNgs/5rXRzOfv0ZL+LXXXkvYA/zx/YeHXzwlvOHGAk7rfhr7FmjzUAYlUDq3kzKmubmZJkijx4UQQsQjARauQEp7Hryi7Vdf7ZpzSvctP91y7wyvUs/iczvnTkZ9u+48O9evenbJpk2bHFaw0buXQjuYPHnyrrvuWlVV9fbbb9tZBUvJdvka2H0z9jJvzh8KhSjtjN/TRob5uptazTIsmbsDakYyU3nq6urQXc419JUPwcgz+StXrky2j+gNZU7eTjzxRCO9sZwV/EL4+WPDG24o4NR6Wvjlk+zeRmiLvFGcXUaG7SyRBNpwWnIqlZ0WQgghIkiARRqgwX1rl3fd+bPNV36pc/bJ3Y1T++6+fMu9V6eb+u65smvhjzvn/GDz1Ud1LJzS9/TdPlHfKPEDoQnQicszlo0UoL7jx48vKyubNm2anVVolHKXrwEbIdT2fJhACgjrqaIDDl1OBnW7srLSTYaNJ3s4mjTZSGb2iPxworFFu2gS2GskkG8FAgHqHk5YU1MzcuRI471RWm79Yfj5SU6lLKz0wgnhNxM0C5QA+84RpLjsLJEI6lJVVVV1dfWAj7gLIYQoHSTAIhN2bNu6Zf2j3ct+ufnqr7TfeGzXnMldC87sWTyt7+4rt9xzdcLEX7tvnto159SOWSfgz933nLflxYcG60FfNzgGQoMZbpqxcqTGjIjGIQtoRDTBZSl3+RoQfnYf8mb+lDO+h/xkE9OjBLW1tXYiJWbUsZ1IE7KKoZmRzKwn9UhmN5hbLZyGnJvmTGSOmbz00kvNjwlHaXvjtvDaI8Mbri/g9PzR4f9OepOC0qMaYMI5apSKAyoYdYZaV5r35oQQQsQjARbZsu2d9b1/ur3nwSs7Fk7BbD+4fELCxF8R5t4nF3741nP2m/4GuyOwdnR8EWcTcebO9AplRLS6fA34P5Ukn4NRkV7sEbKphHV1dS7XEAqFqI12YiA4ZVAyysSMZKZksNDoSOaWlpZsRmubWy2sLfpUp+n4RWw4SflwxBFHHHTQQeTWvBDr8MMPD3e1htd8Kvzq9QWc1v5b+L0BxqibB4NpmtTJmQJqMu0VDZedFkIIUcJIgIVISvxAaAhEsBM5wM8jotXlG8V0/KKRlImdlXswnMrKyixfRoUJuOw9Zh9xhmS9i9gsOhE7kpmFY0cye9ItaeQWl3bcaol2/LIjnI/f+ta3vva1r7Fp6uTatWuRYT73L/f0x8N/qQ+/OrMg0yvXhFePDG8f+CyjECgKTkw9GJwC6gxVlPpvp4UQQpQqEmAhUkFwT2RpJyIQYeMPjpmes3TpUjMimg921qCiLt8oVACOPkXRlOnv7mYGPmk6+ux0RrS0tOCNbtTU1HOzj3xOOJIZ3c1sJPOAYHS4HJsweYhdOX+KdvzymfwwSeV03JbiT/3/vTkt/Px3wq9eV5DppR+GW78e2RtXcFgpBEqMw2FniZ2h7aLmUFu8ra5CCCEKCwmwEKkgjEYYHAOhCTSZmYcf2Jg6dWpZWdmECRMGa0S0unwdUBMIoNGMfHb8Qmvk94qy7N9jJXj7gOOQ2TUMCrn97Gc/y79s16uRzG5AUWpra8knWus47yDa8UtV5NxE9kyHMx8SV862VeFnxjvFslDSc/8efjftI86xozSoop70wBcf5qYJDVqeT2EhhBD+QQIsxAAQc+M8jvCa0JwYPT5A9xzUFwFGg5FhOysvqMvXARUA78K+KBk7K18Y68vyhou5axOf+YQjmTGoPfbYg5nYVH48iuJtampCS8w4Xtt/GwNzoh2/TJIrPpNDioWvpMrk6j3Dr0wPv9pQeOmpA8J9GRa+HgxOTV1dHadDHhpwIYQQPkQCLMTAEHnHDz0l8iaEyo8emBHRkOsR0eryTQiKiG5RDfKvE6aaZWndZBunDYVCCC2HFW+srq5mTuxIZpSJv3LEWZgKwGf75RzDGcTJhXVj4Ml2kzyzgOn4ZRJpJ4fMNPehBuiRfvXU8Asnh1+9tsDS+mnhtZ+zu5ARlBWHlcqjp14TwplF5cnyvpIQQohCRAIsxMCgBAm7C4jIk469zAE5HRGNe6jLNx4OPd6bvYJmBlLKpjMbcmxGMiM/55xzzj777DNixAh0t6qqKjqSOVn3FwvYN0jlGNwDD0dlGxoako1HZb556jiaW0qDMuG7mDMf2BEzPykfrAw/e5hTL/2fnp8UfmeW3YUsoAA5oBTgoFRgn0Ologrlp7YLIYTwDxJgIVxB+EikHu+6BJcE6HYi96C+OIyHI6LV5ZsCDjrx8WCNI2W7HBeXQwyiI5nR9ehIZj7U1tZ++ctfPvLII12uhzqQ63s6VDnTM8mJk7r/zdHxC+aI8C9HBKlz27e59nPh9eeEX72mYNLL9eGnD3Tz/meXYHqc4BS47m05oDaakhmUc1wIIcSgIAEWwi2oBTphJz6C0Jz4Kc99CCtWrEAMRo4cuXjxYjsrfXCPQCCgLt+EEBZzuGM7HvMMW0dEkwXl8SOZUWXHSGazZKoXRMVh+lRzVxkQ12AwaO4ppBZyyt/sWmz5U2P5rukP56/xJ2NS+n8QeJxTMv2cPOr+dWAKkMZKshcLZ4fpJFczKIQQJYIEWHjAtnfWb1n/aO+TCztuP6tj0RkJE3/d8uJDH771nP1OAULUSPgY/2wkwTr6gXjY6Xwxbdq0srKy8ePHpzUiGvFAP9gRdfkmI77jMZ+wUewOjKVQu8xIZrwFxeXAmZHMgUAg9UhmQHiomazBTg8E68/F86LsCKt1P8qAZdhN1N1OR2AmazCKgvqS1fSOzrpvh1tPC7/6qwJI68/O8unfFFBopvs9Fwe6oKFAOOvjm3chhBDFhwRYZMj2rvcR2s4l0zZfeWT77EBn45TO287uXv6r7gcaEib+2rHwzPa5J39w+QQ8uW/t8u1t79p1FQ4rkwyEbo38wEz+gyczInrXXXedPHmynZUcdAitIvYdsP+tZEnY8ZhP1q5de8ghh5CBKVOm4Hjl5eXUKz6gfHgLFcz9gWMXONbunx9m/WzITngEeTBPULscZWDKnyrtWJi8VVRUmH1HVPicdh+m7QSOs00fprUTwu8N9GBzdlDOejA4HkqD0023BoQQouiRAIv0+Md7G/uevrv95mDbNRMR2u77pvc+fkff7+9KK3Uvn9G5aOrm677RPvd7vb9v3Pa31+zaC4GEA6GhpaWF4GlQxDL1iOholy9qgQPbuSKOhB2POQWh5Yhgd8a6d9lll6FDh37iE59gjhnJnPFQVQ46VcK93mCqafUVp6Yv8ptG+BWwIy73Iln5c7pROGYlRlEyPMteOzP8QiD86gxfp5d+GH6hymY4x3DQq/Rg8M5QFFRaGvn0xhcIIYQoKCTAwi1bX32yfdZ32q6v7lz0454Hr+974q7sU8+vZ3Xefk5ktcf0PXuf3ZK/IRAnTE/Y2UvsTvCUsbRkSfyIaHX5uoSod9KkSfEdjx6CW1JnQqEQx4JtcVAcI5mXLFmCgnrS+0QNNOZppweCWJ/lB36dsgsoQHyVvUMh3PeiJ+v4JWOshz8ZG8l2nMW2tvAznwmvPz/8ytU+TS9fEn7mXzL+7d/MoJXgeHHUvLr9Uehw+pjaqAIRQohiRQIsBubDt55rvznYseDUnofn9D2xJBep95H5nYt+hAmj2XarPibZQGjI80uhHRC6EbehwZ/5zGcIasmJunwHpKGhAa3ytuMXkaOSYLb4mxnJDClGMjOH49XU1GSns4BqyYbQbDvtAnJFPu1EppB56h7nBSWZljkk6/hlR6jAnFDmRGOdrDzb+tzV2u/AL18efuUqP6ZnDwu//4jNah6hhKmW5tglbNZKkLq6Oqql+ycIhBBCFBASYJGKf7y3sXPJOe1zTu55cKZDWXOREGw0u2PRGdveWW9z4FcQBrTBTsRA+IgGDNYPS5ou37333nv48OEYVzbviC4F0FQOFiWWZVcP+krJoxCsyoxkxiWMhboZyWwGz7sfrpwajDEQCNgJF7D1ZHdz3BAdYM92090Fip0S4xDEd7ybWzlRLSd7FGxaVp+U/72//yFbh3n6Ib3wjfDGq2wmBwMOB20alcGTsQBFACc1J6buIQohRPEhARaJ2d71fk/LlW3XH9O99AqHpuY6dd9/TXvoRMTbz2/JIkAn6E84GtN0VeXzpdBRCUEnouEac8rKyg499NB169aZOSKK6fKixNLtdOW4c9CjI5k50LEjmSl89+N+DWSAINurjibyQGbc2yx1lUJIN88GNIn6xtcpigzuIFCGfDdhxzv1Gd1lX+x0OEzxIth2InvwTGzzlSt9lF78Qfgvady2yB1URSo2qPMTODWopYN1Q1MIIUSOkACLBGz722vt807uvOvCvsfvHKzU3Xx5e+gEP/9sEiKUrOtsw4YNHvbppQDjikpI/FO+0RHRaXUJFj0EtRUVFZTbgNrGceQoY2LJRjLHd12mBSuhCsUfuMzApVlb6t5mBxRCrGe6gULDWtlQ7N2WtDAd75Cw9CgNVh57/4i6zcIZ91EnBtt84aTwK9N9kdb9JPzc4eHtPhp7bMYFUM8zuLVRZFACVD+a0LTOLCGEEH5GAiycbFn32/bZ3+19ZJ7DSAchrVzUPud7vX++0+bMfxAggp3YGewXB85SkJKRsMs3GStWrBg9evTw4cM1IhqJMuWWsNAQWuYjhAS7GYxkThekmq14JRhkj/1Kq76xU0T2dsIFVOlgMEitps5nLO3IM2tI2PELra2t7EVstzyZ5Ch4r2HY5rpjwi8c63TR/KcXf9Bvv9t8J1ecLOZOB/96fPeh0GD3qfkVFRU5as+FEELkGQmw2Inex+d3Nk7pffS2vt/d4ZPUeWttz4PTd2zbarPoJwiMCBBxDzu9M6FQiL96a02pu3xTMGPGjCFDhpTyiGjT8Yt2ckSAo+YYyYyORkcyJzumnkC1YUMcR6/qBnE5VSKtPPMVRNRNFSKTWChFhy2jphm7EFtkDZDMIozDx46bMHNyaB1/rQuvPaL/3cuvXDE46YWj+/ui/dT362CTHgz+CJoLTpmctgxCCCHygwRYWDDMzjvP7mqa5vBPP6Suuy/quHXqjr5Om1c/QTxEdJjMCogd8auMnSFKWl2+ycBkJk6cWFZWdswxx9hZpcHatWspt5EjR37zm9+MHcmMDHsykjktOApIYPCjlxtnDyukBqb1MDObJg8DfmXNmjUUEUE//2b5RGhDQwO1N1nHL+BXLBD7NLJR9Jw/R/D3u8PPfDr8l/PCr1ye1/TyheG1lYP71iv36MFggxnXgwnbaSGEEIWJBFj0s73t3fYFp/S/7+p3Tf5M3ctmtM8O+PO1WFguhmAndgbTIGpMNkzaDRl3+SZj9erVo0ePHjZsWLGGcUhUdCQzmrfLLrvstttuFGBdXR27jO561e+aARzBysrKbOqDA6Oy6T7HS12icOxEHKwTN2a1FZEfE86yuEzHL3U4xTBmNofDx8qVsXq2bqdzSv9vIx0afuEH/T+PlJ/U+sPws5/tfx91QWEeDA4Gg96PSC8cqM9mIIlXN7CEEELkHwmw6O/7xX57Hrze4Zx+S70Pz2mfd/L2rvdtvn0DkRBxYbKuKhPKp2ubnnT5psCMiB47dmxBj4imbBFaNCnhSObbbruN0iNaje1XHEQInclhil7QDGBP0309MiVGvUqoteQQOR81ahTrZDE7NwtMx2/qrmaWoVhib+6Y20Z5ffXu1k3hddXhZz4bbj0z/PJlOUzrzgk/+4Xwc5XhnoJ8mpRDY44p51fJGiDnDg1LVVVVKd8IEEKIgkYCLML9I5+br+h9rMn/qXt5Q8fCKT58HjiFVEBagzk97/JNBrktrBHRFCPlTORtBpY7RjJTvCxgF40UoylDn4TpSDh1IK2BygNitD+tHeSgY5vxcktxmTsI6I0nYT3HYsCOX2AXKisrHScO+s0X7UQ+aVvVr6YIKprqENfs0/q68HP/Hn764+H3Cv5hWo5XXV0d51cu7s0VCqYESnxMuBBCFCgS4FKn97c3dt75897Hbi+U1HnPJV33nm9z7ydSDIQG8/BYrKE5yHWXbzLWrVt34IEH+nBEdPxIZgoHSaOUzEjmZGbFfMrQPx2/YI6+yzsgLjEvpkp2zyUZVNHYntXYWudh9tx0/AKZ4YA6doHvosSDedsCQUVT1345/NKPwi9f6kFaVxt+7uvhNWPD78yymygKaM2oNpyb/jnR8gwNFOd1Kd8FEEKIAkUCXNJsWffbzpunOAzT/6nf2H97o90H30DIPi75QGjAWFgg3liIn4gjEQZUJKddvimYMWMGDjxYI6IpE4Q2fiQzxYIAUz7xPZbJQLooSV+NzyRLRMneSoIx6nRrCznBmU3JsIZAIOB5rXPZ8UseWAYch4ljTZYG6yzYiXcbw89WhP+8d78Jv3By+C8X9b8sOq3Uelp47f/pd+lnPhV+61If/tCRJ1CRqFQl+2Aw5zU1Nq/D9YUQQmSNBLh02fbO+va5J/f8dnHvo7cXXMLbsXe7J74BTyMYStEpR5yEHpigP7bzzQ99CGT7mGOO2XXXXfk3xS5kDztOQUVHMiNyKUYyu4fVUpIUb2ZfzxHmAVdvs9Qa+bHcdI2a8uFbq1evNlmioDyvdS47fqld5nDb6Y9gj6gM/hpTunVTvwmvqw6vHhl+9vDw2q+Gn/tGv9mSHEpsZj5f3b/M2iPCfxoRfqEq/H9DBfqsb7qEQiEOva9uPOUNzJ+zKRAI5LTZFEII4SES4BJle9f77fNO7nlotkMsCyXh7dg7Dm/3xzekHggNSNpRRx3Fv8SLg9jlm4zoiOgZM2bYWdmB1bS0tBAZO0Yy1330TmZPOo5QL9yJf+20P6AyVFZWenuIKS70NQN3/bd/+7cJEyZQSuTK83sEHGXTYz/g0UQSWJKab6c/wvi5f39sdntf/9DojdPDb54TfuHL/emPw8J/2OWfycx8bWr/MpuairW/NwUcWfNYrB9u5+UZtD8YDFZUVPjq7psQQohkSIBLlK5lv+y866LeR28r3NR9/3Xtc0+y++MbiITwk4QDoQnxifv333//ESNGpPvm3jxjRkRjwmmNiCYCNiOZ0d34kcxNTU3uRzK7h4gTrwZfhZ4mIKYQvO0UYrWUZ1qeTwY4Ivvtt98ee+zBIfC8g44VUqvx6gE7foFTgFoRn38yiTz47f6FyABOQzMQIxcnu88JhUKcCCW440IIUXBIgEuRbX97rX3Wcb0rbyv01DF/8tZXn7R75RsIgMbEDITGEHCD2C5fIE7yb2dXBPJ/zDHHmHdEJ7Q49oI9xWyjI5nRXTO0lZkrV67Mw1hWlIlSdaNe+YTiohwCgYDntkktorTtxECgIhwLjstxxx2377775uIRzTVr1iCubjp+wYzcTniw0tov4X/Mg8GcArQSdlZpwI5zxvnthYJCCCEcSIBLkc4l53Tdc6lDJgsx9fw61HbjcT78VSSiedwDA+ED8RDxvWNYIOrIfP//hMa6devGjh07bNiwH//4x3kYyewe92Nu8wz5IWOph8FnBkXN/g4o1eaGC8doXOTXp//+97+jIp6PSk2r4xc4XlSYhDd9zA0Uz28WiEGH6mfu+iW8g1as0OxzxtECqEoLIYRvkQCXHFtffbJj/uTelbcWR+q45Ud9Ty2x++YPiHsWLVo0fPjwvffe23T52j/sjHkptN/8Dcg/QhsdyUwwh+7uuuuuaPCZZ56J8PBXu+hgkK565ROONceUcrPT3oFLcCBSiwRbNzdcgsFgdBC+uRdjPnuF6fgNBAIuay+ZQYQSVhs3+yUKF45sXV0dJwXtiZ1VArDX1ZFx4D5s3oUQQoAEuORon3tS9/Lren97a3Gknofmbp75TZ90Asd2+V599dUE/akje0JDgqTB7SgwI5kbGhpMRxyZNyOZkSjHSGYzInrixImDqCtGvcibDyNLCipHWt7S0kJdSjGatPmjX9LiOMaWDIcP9/Cwgpm7D2woKtgDQoGwfMLBDqyEEkuxX6I44BAHAoHKysrBvXeWZ8wrwfw/zEcIIUoQCXBpEfnh3/90OGShp87bzu59fL7dw8EAKyDKN4NOkcZoQI8qDNj5RlyYzxdiIZBmJDMbdYxkxp0IT1OLpRkRPWTIEK/eEe0e05WUlnrlE+NyuXiu23h1wjCag2V0FPuNH+TMX/kTR9xOZ425+0CVdn8HJBQKcVIkVFyzXyVlRCUOxxoHLqkHgzkrqeSeP4AghBAiSyTApcXmmd/qabmp97eLiyn1PLJw84yvDEoncLTLN3bQaRTEGGFILUUsQ1CYi0GzrJmI0zGSmX+RJeaYkcwsY5dOB6xm+PDho0ePXr16tZ2VYyhbXC4t9conppMzFy6HKrDm+CpEgVDlqHgpxtibA20nsoN6km7HL7B16nbC7CHniLHEoAQxj35Qnfx5LnvOmsjT73V1dXZaCCGED5AAlxDb3lnfHjrBYY/FkToXnLZl/aN2P3MPPhDt8nUMOnVgop/U3apGcrKUAVaCgLkZyewVgUAgDyOiWTneSzmnpV75xHRy5mKgI/uOQLJ+Ox3xRg4xm6PuUQNT3L9AM7waXZ9Bxy+wPBlI+BVyxX6hQHZalBjUCo4+1bhEHgzmtOVcoMFM6wwSQgiROyTAJUTv7xs7F/2kd8Wi4kudd5zfvfwSu5+5JHWXb0II9VjYTiQBx2Cd/GunBwLdcoxk5uvuRzJ7xbp16w499NAhQ4bkSGYo4TGRt8h6InK5gAJHDpP1wWYDu1xdXR3tOKJuoJQcZaofldDMTAYLsGT2uSIPFH66Hb98i2pJ5pMdtTwP+xf+hPpJTaisrPTtvS0PMScFbcWAJ68QQog8IAEuIfpff7XsWoc6Fkn6zbzNM75i9zMHEL647PKNh+8S9wzYwcsCmEa8tPB1hJato7uxI5n5zBzmZzyS2SsWL15sRkSvWLHCzsoaShiDYjfd3xTIM5R5ik7O7EF0KQFW3tjYSDkAH9xsi4yRKyqGnc4U6hUbTbfjl4XJNt9KVicxarI3uDVW+AeqGQ5MnSkFMwyFQqP03LsQQvgACXCpsL3t3c0NRzu9sYhS++yTPnzrObu33pFBl288WNyAA6EBNxg/fvxjjz2GY9fV1cWPZG5pacnFUFtPMCOiPRFC5I0d93PHr9E8yFEOqQDI51lnnUU5IJNp3QWgnnAs7ERGsHdsNN2OX+CLyAzni52Owzz/mZ/hCaKAoGJQ32j0sm89fA7nFCd17HMNQggh8o8EuFToe/rujsYf9j5yS7GmzlvP7nlkpt3brEFsMu7yTQg6Fz/sM3YkM5aL6w4dOnT06NHRkcy5GFubO8yIaDSYnbWz0sR0/FLsvvV8MJqHItppT6HiIZC77777Jz7xiQwqHnXGza2WFBCgs4Z0O36Buoq0U5ntdBwmbxoCKhJCfaPdoIYUvRxyCpixFRoHIYQQg4UEuFTouOX0rnunO6SxmFLPAzdunvktu7dZ4EmXbzyEd2PHjmXNGEKKkcxQ6O8HWrx48ciRIzMYEY3vEf7yr532JWjeuMg7bO20d7BmVrvvvvuWl5cvWLDAzk0H6hh5y3iAJV/PrOMXOGvYdIpx1yzAOeXhCTXI/O0WZxJewFlAw0vDWDxVJRGca+ZOn0ZDCCHEoCABLgl29HW2XTOx5zcLeh9ZWMSpbea3/vFehl2mmKeHXb58HQ9hPbEjmT//+c/jNhdccEFLS0uKQa1GsQr9F2ImT57sfkQ0dsSSwAc7y5e0trbih56/upZjTTTMmn/605/utddeGYf+6Gv0pVnpwkbJQAYdv2CKJUWNNWbuebkNJg77JQnvoHmkNeCk8HmDkCWcrZw4fh7tIoQQxYoEuCTY9s76tptO6Hl4YXGnjvmnZvBjSMRYWXb5EsHwxdiRzKyND6wWB8aEcVqzZL2LN0IDK2QNvn3/k0vefvvt8ePHo8HTpk2zsxJREB2/YBTRwxsTmyK/acQ6CfRZLZZYEXnTlf1zmrAGvt6X/qBKtov3IqiZVX6+lbprlyxxLmRs5j7FYb8k4TVUac4Oak4GN2UKBfaR08fDVkUIIYQbJMAlQd/a5R03n9HzcKMn6ZVbZ4wauQeaZ7hk8nGOBQYrdSz6Se9jc+w+D0RmXb58C6Hli+gu3uIYyYy9mJHMduk4+BMLuwl3WlpaCIyi5ly4mBHR7Ev8iGg83/Tz+H8coInFM1PEeFhPMBikTGo/+k2jLC2RekL2MuhKIid8sT7T942ZYkm9XfaUQ2wnigaH/ZJEDqBa0q5Sx4r4wWDzisRiu0MkhBD+RgJcEvQ8MrNj8c8cuphZenzmBbHS2/HrBcceebhPHLhzycWdS86x+5wc912+jpHMhCnsO87GFwnLUo9kToYJd9woH9vFlouj92Py5Mm77rorRff2228zSVyLdHEIUjw16h/MK2oz0EsHHEpWNW7cOMqBHY91TmpUNq9upnKm24VuOn6pYBkPNGAX2JfUg1TJVWVlZWZ27Wsc9ksSOYPWkhOEykaTa2cVF+wgbQItQBH3dQshhK+QAJcEHbed1XXXJQ5dzCAZ3R1Rvvt/332D409+SN3LG9pmHWf3OQ6i8NRdvhgOPuxmJHOWmE3YiZSwWNH0nqG+EyZMKCsr+/73v493FUTHLyDqVJgsDz2SiW1Snfg3XjipD1TLjC2RykkttRPuyLLjF8gzBzF1saArbKUIRjEkwGG/JJFjOHE4Tajq2d+K8iGcibT2nFPF/dizEEL4BAlwSdD/Cui7L+v5zc1Zpg/un/PJ/fap/JdPvrd8tuNP0WSWwR4Nd1z4QzP/8ev6u46Pr/pCdEkzJ7pA9qn7/pkJXwSdsMs3fiQznkN0xRwzkjl3N+OJdSorK90MhGZJYr6iGR3H7px44om77rrriBEj0n1H9KCAr3KkMq4J7C91jNoFVKqE6zH9qBnfC0AGXA4oMGTf8QucTQMWC+vnjMtmK77GYb8kkRfMqHtqYEHcPkuXUCjEWcPVx04LIYTIDRLgkgAtRA4duphZOjdwNK7YP+Y57k+kVxb3Px4ctdzGc/8zVnH57rAhQ/5440V8duPSGaQPLp9g9/kj/UAgP/nJT5511llXX321YyRzIBBAdzMbyZwleItL7WEZlkSf7HTBsnLlSnYE+0Kcpk6dat4RbUZE+xAqT3UEPthZ6eBymD2RLrUx4z4f8obKurmTYsi+45cvcgQpltT2a55JLtYBq/047Jck8gWVkHabCtbQ0JBxTfYtnKS0G0X/Y8hCCDG4SIBLgn4BXn5dz0MLsk8fLJ8d7eC9JHis46/nnnh0v9MuC5nJjgfnHfulw6JzXll0NXpsJlkyIsMXmiW9Sggwbrlo0aIjjjhi2LBh+++/P/kknjAjmQmbPBzJnCWm89lOpIQ9KuhuAdPrSMAaq4LREdHIsJ3lG8hwZWUlec4gvEZHEXtUP+Ew+1jwXsokm8NKlSaTdiIl5MQMsMzmXg+lQY0NBAKpi8WUHrtvp4sSh/2SRH4xVZoTrfjus9AycKpm1v4IIYRwgwS4JGi7dlL3/Tc6XDGb1Ditv2vXENVg48b93b8xSyK6I8qH/feSmWbSfLGq4pDYL3qYDtlnd5xq9913P/roo2fOnIldpO6qGkQIbvCEJndvgSLIw4EL8XFK0+uIqiU8EEuXLh0ZgQ921mBDIRN9pjvsnG/V19ezpyiim4ic0iB2d3n0E0LBsgY31ZutUHmy6fgFNoTYu/FtSsCllhcwDvslicGgtbV1UgQ+2FlFAacb5xFnnJtRQkIIIdJFAlwSeNgDHJtMjy4qa6Q3OukgVoBNn7BjpofpOxWjdt111/333x+HCYVCPjdGgjaUyWWIw+6wU26Exye473WcNm1aWVnZhAkTBn1ENEcEq0xr/CG6S6jKccQwXdY3RJTQluXtdPpQtmxxwIJlMfLm5hCkhv2qrKycPn26nU6Oecqg+HuuHPZLEoMH5yCnbfE9GMzZxGleZG4vhBB+QAJcEkQEuKHnofmep44H5yK0w4bs9scbL3xl0VWRB4APdywTmz5YHvrkfnsjwOYrjr9mnz64fMJpp502bNiwG264wTyESTje1NTkW290PxAa2CP3Cw8u6fY6or444eCOiDZP5LrslSXUbmhoIOwm2+l25AYCgaC714Anwzy+bieS4EnHL2C/Lm8KsIzLTumCx2G/JDGoUMnN+ch5UUz3X5qbmzmL3T/nL4QQwg0S4JKgfcEpXXdf0fPr+blI5574H/02e8OFHyzrl9vjv3y4Y4HYZBZuuqCmX5VTLplB6l5+Q9u1/b8Hc8QRR4wYMcJoSUtLC7JBDMG/PgwjiNXcD4RmYXweDbbTviSbXscVK1ZwpAZlRLQZZB77lHIy8GRTozgQGby/CiPNso+U2oJ1p1iDVx2/0Bp5/txN/TQv7/H5mAvPcNgvSfgAaj5n5ZgxY4rJGDmL2aOi+S0AIYTwAxLgkqD/Z5DuuqTn1/M8Tx0PzDn2S5+PjGduiP3sWMykV265Eu+9JPhtPmPCu+yyyx0X1MQukGXqXtZgfgapra3tE5/4xOjRo6OBO3P4jHgYb8leDDwkrYHQ7IjL7rhBgUJmX7J8O6sZET1+/Pi8jYgm21SM1EMNKfnGxkasEviQ2Q7yxSz7SFFusppCvM0hyL7jF0yXuJubAqYOZ/NCrwLDYb8k4RuojTT1VVVVvmrns4GrA7sTCASyaTqEEEJEkQCXBD0tV3UsPtuhixkkY7Cx1tp4zml4rHHa6AL973m+b1Z0gUhP706qzOQHy2765H57p7DlDFLXnRd33PYjs8vEQHvttdeBBx7oeBstkYR5mNYMlsugBy8XpDUQ2iiQGy3JJ+SKEA08KVIzInrXXXedPHmynZUzKHwqQ4quS8Lompoaypx/swmps+8jxWkpluhtHQem49erQ9DS0oLTutlftksBJstVceKwX5LwGebB4GAw6PLeos/h3GdfuHL55JolhBAFjQS4JOh7+u6OBWf0/Hpu9unxhjqMN0rEYK+NXeCDZbPMU76GiP32z28851QmI/JslzRzIvJs52SZOhb9pOeRmXafIwHQ2LFj//Vf/zXh05KEEeYVI5WVlY2NjYMbJBHcuB8IDUal/BMJNTQ0kB/HvYbsiY6IXrx4sZ3lNTgtJZ/w6HNQOCL4JGE0u5Zl34vpI82yS4qaHAgE7MTOmI5frw6BWVvqLnGDcfJsXuhVkDjslyT8B5WTM4KazInDZzu3kAmFQjSJJTTUQgghcoMEuCT48I2n2md/r6dlbnGnjgVT+tYut/scgbj8iCOOOPzww1M8N0swYfr3UAvi/sGKk4wgufdwn7xwCAnHf6qrq3Nn4xzEXIyI5kBzxMl5fBmyL1QYqkQwGPSkp930kWb5XCLynLCGMMfDjl/AGcity55qyhDsROngsF+S8CucIMX0YLC5++nbp2CEEKIgkACXBNu73m+75mu9LXOKO7XPOn7bO+vtPn8EbnDWWWfxb+rfJkWHCI8I5cvLy1lyUAYYpzUQGojqsnydUjawXdSUsNJ9x3XG4KgIHhrs1Yhos0L81lF61AEOgekycn8zIjVsorKyMsu+WTKMlMZXS287foFjmqxLPB4WphgHqwYOJg77JQl/09raau4TZTkKww9s2LChoqKC61QpnnpCCOEFEuBSoX3Od7vvvqL3wdlFm5Zfv3nGV+zexmDMYe7cuUQ/+O2AEQPLNzY2EifhFXV1dW5GgXoFeWO7afkkO5Wiczt3EEQSgbF1ryzRDStWrBg9enT2I6I3Rn7VNrbcmGNknj3yvJuIdaa++eIG1uA40J53/AJbmTRpEqeAnU4JFZUzK58VQIgsWblyJQ1XETwYzElqTn+dgEIIkQES4FKh9/eNnY1TndJYRKlz8Tndyy6xe7szGAJug7MR3xM0uLxrjhRNj7weiYCpoaEhm3cXucdk1X1MQxhE9vI5HI7SwxVHuftpnFzA1svKyg499NB169bZWelACXNMo12mBMSBQIDdqaury8UhZrXuq1wycHKOcuxKyD959rDjl5VTDu6zal4Qnc/bQ0J4BQ0mtZeWxOW9Ht9C80JrptNQCCHSRQJcKmx7Z337rO/0Phgq1tQ5L7hl/aN2b+Mwr7TFcHDgqqqqtOIewgvzCNmkSZMaGxtzHTNhNXiInXABO4UL5WfMNtqDiVGGgxs4snUOIhqc7tOna9asMeq+adMmypnY0XS5ZymoySDOpriyLCuyGquaCDx5Bg87fskhdZvDaqcHIp9VTohcQJ03L0GkSbezCpPm5mZORs/HrQghRHEjAS4hNs/8Vs/SGQ5vLI7U88CszVcftWPbVruriZg+fTragOrwobKyMgMtwaKDwWB5eTn/5jTgIJ9phWV4KTFQTvsBKC4EiXjRP9qzevXq0aNHDx8+3OWIaHJOKSGl7Ih50ttDh4wnes/FTmcKahrt6fW84xc4spwOyICdHgiWH+fjX6IWwj20ANXV1dT/gn6vsnk9Xn2pvYldCCGyQAJcQvS0XNV5y097HwgVX+puujD6C8ApCAQCppsLB66oqMhMTlDopqYmwiZUhLXlInIiLGPlaWUPYUZLcvQ8GOpIgMXOZnDXINfMmDFjyJAhA46IXrBgAap88MEHc9zz0I3f2trKEcz+dTu4LgLMh1x0/AJ1LHZA+IBQ+cmPe1sWwv/QvtEscHXI/nbVYEHLT+PALviwiRZCCB8iAS4hIj+GdFLvAzcVX+qcf5rjB5ASQnBAoGM6r8wrfLKJeIg5zBhX1lNfX++tmUTNxz1oCTGQt6N5KTG8l33083hXMjlx4sRkI6I5Ll/84hd33XXXY489NnsjdQOVasyYMS0tLXY6U7Bo04eci45fYP1U3bSe5aYypDU+X4hCgcbc9KMWqEPS8geDQdrqwtV4IYTIGxLgEmLHtq1t10zsXXadwx6LILX96mvbu963+5kSIyem25bQn8/ZjxxGsQibcInKykqiKK+6YbHZdJ9PQ06IgexE1lA+eBe75q1U54joiGhzg8N01FOGe+6554EHHrh27VqzWK4hejbVwE5nCvknlp01axa7MGnSJG9vr4AZNpmWpWPgmT07UIQ4fgOJJAof6nahPxhMy0OjXdAjuoUQIg9IgEuL3t/N67zlrN77ZxVT6ry9ruvuNMZkmmdBzW1yM7jXq6dnCTtqampYOSKKfWXpjThPNJ8uIYDDmrLvKsTh2QVWlZ8uUw+ZMWPGbrvthvTC8ccfP3HiROwxb87GEafcPPlhKgLxL37xi1TOtHpoXWKqfVq9+l490lwkOOyXJIoFGl7O4sJ9MNhc4LK/ByeEEEWMBLi02LFt6+brvtmz9BqHQxZu6ll+w+aGo112/0YxfVlGUDOQgQFpbm6Ovi4rm6Gw5DPdgdCmizubjRZWx28sFDuR6/777z927NiysrJ99tkn4OKXnz0E9SUDdiIL7rzzzt133/3oo4/OxUPdHF9qSFo3fdZE3p5dcHdDcojDfkmiuMB+uUYU6IPBOHxFRQXNUcG14UIIkR8kwCVH35+XdC44ve/+G4sjdd3y457fZNLhSWQTHS1sHrb01oGhra2tsbERg2XlxCKZ9TNnMBDa6EoGmzNdH2zR8wG3OQVLnD59OoVMUZu3czPns5/97PDhw4cNG5a3npDYuyrZcMkll2DvF198sZ32FOrSuHHj0jq+2d9SKUIc9ksSxQjnC5W/rq6u4Eb+k2HTmOfiJpoQQhQ6EuCSY8e2re3zv9+z5JK+5TcUeupdNjOD7l8DooKuRO3IOHAuhpsCCoEdVURel4WqpdWlgKukOxAa8EC2lVboQw7ZEP/a6UJg5cqVwWCQbNfW1kaljrIy5cznGTNm4MBjx45N/Y7o7DEFnu5hcsAuELAecMABF1xwgZ3lKeYHwNLKJGE0XymsWpEPHPZLEkUKp0B9fT1Xh0IcVIy60y5ldu9VCCGKGAlwKbL11Sc75nzfIZOFmPq7sv+8xO5V+mACuFO049eIU44c2EAggqoRS5l+XZe9CuhHugOhgaDNZYek8S5Iq2NwEKHcKBMOFjvI8YrdR0qYYxp7EFn4mGOOKSsr41+XBZ4uGXe5R2EX2CMqxtSpUzkQ2Xcjx1NTU0NxpVsC1dXVfNFOiCgO+yWJooarQyAQqPD3+/AT0tzcTOtkhsYIIYQwSIBLlPYFp/TccXHf8usLN/U2X735um/s2LbV7lJGrFq1iuAg2idmHDgP/V1EUXhFeXk5QRWhyYDCgxSlOxAaWDnYiUREvatQOjdQTfOaMf6NfySVUuVPCQfrrlu37sADDxw2bNiMGTPsLI9w3EbJAHaEwBrVXLt2Lavy/DYERzkYDLL+dL26rq5u0qRJubDxgsdhvyRRApgHgzmVCuVeoYEWhka+vr7eTgshRMkjAS5Rtv3ttfabju+977q+ZdcXaOqYd+qW5z14LhH3Qz+iUX5bZMynGUCba9hoU1MTjmqMLsVLR4m3WCYq6i5h/exLsrgn6l3+f0iMHcH/zRjyZD3nlCRBXuoXt5oR0ZiwVyOiyQm5yuDehIH94uhwZE0/dma3OVLDajnECDAf7Cx3cF5Q2jnqMy94HPZLEiUDJylNTWE9GEwjT/PCtUZntBBCgAS4dMEecUiHVRZK6n/31UPX2D3JGuQztqeUEAFvrPXix2xcQnRCUMVGTVyVsHsBIclgIDTOzDod499ivcvO8isUBQeCrKJwKXpZzYhol4OQvRoRTTFyRDhedjpNHDcgpk+fzmfzJ6/IuCabvvR0b7iUEA77JYlSgjOLJpSmtYAeDKa9ohWlzdF5LYQQEuCSBofEJPuWzSys1N10QcetU+0+eAGRQVVVVezIZ+ZgI4ixnc4X+B5xFS5HmEJo5eibRbcy6CFEtJAZ/o1OxnqXP6H8kXMOihmRnjqrKGi6Ud26devGjh2b5YhoosnUI8yTwd45bkBwUAimvT0iFAjFksFYhtbIC+FS96WXOg77JYnSg1OMFoCzLJsnIPIMlxVaHp3dQogSRwJc6mCS+KTDMP2ceu6s77j51B19nXYHPIJQhqA/9vFR48DEN3yws/IIRmR6PpFeNMn0VZJJ5mTw+FlzczN7h/WZV3D5OVxjH03XCoU/4ItbODQ1NTV4cmZ9ucSCGY+INm9UzqBuxN+AYCV4vrcHhUrCOjO4XUKu+KL/hwYMMg77JYlSJfpgcDavwcsnZnxHAfVdCyGE50iASx1Msn3u93qWXNp333X+T733XNk+O7C97V2be08hjsG7HHqJXxHZDIoDG5DAYOSXfvgXP0dp8D37t3Q488wzhw4dOmXKlCzH/eYO9pSi5hAgwGiwnZscdoTlsz86ZkT0xIkT3ZcMfoglptthSz4dHb8G6pi34+1NF24GEksOqV1k0k6LZDjslyRKG3OTkRPZ23EcOYLLXEVFBbkdxEubEEIMIhJgEcYn22cd13fv1X33Nfg59S69piMU2PbOepvvHIBeEhY4RCibPkavYOv4zKRJk9Cnj3/84z/96U/tH1zAd9kFgjMcL7MhuzmFeNE8wUshs48uAzJ2qrKykv2y09lhRkQPGTLEzYjohDdKBsR0/JJhR0Uibma+h2HoypUryV5m/clUDx/WED/isF+SKHk4i6dPn87ZR4Pmf7GkIaqurqbVLQhjF0IIb5EAi34+fOu59tAJvXdf5nBOH6V7r8Z+P3ztTzbHOaO2tjbeAcx4V4e6DAobN2686KKLdtttt4MOOohcDahhLS0tBGT19fVknpjMV/17SJrp3KbM0/JJCgFh9nxHQqHQ8OHDR48evXr1ajsrDvKZrl5S7GQ14bcIPZmPG9vprDHdUJkNxSSTVA//B+6+wGG/JCEicFLTrNFAJfw9Nr9RV1dHVgtl8LYQQniFBFhY/vHeRhy4+7a6vqXX+i31NF3UPuu4nPb9RklmidhmhW/en9nY2PiFL3yB2AXbwcyZjL+Lz5zq6mryHOtXzCTcyWBwrIeg4mSYbJA3PqR7W8GM7+WLdtprAoFAshHRzEm39JJ1/BomTZoU++q1LCFjGcey5rvxtUgkxmG/JCFi4MTnOsIJ7n+3bG5uHjVqFP/aaSGEKAEkwOKf7Ojr7Fh8Zvfisx3+Obip+/bzOm6enKPnfhOCBqBY8ffvjST4xIGj7rRy5Ur8iggGcyOIMT14ZJU5aHx8hx4BGX8alLeAEhSarPJvZt2e7CyHJtex2rp16w499FDHiOhkd0aSwfLJOn4NoYx+1yoZ06dPz7hymkHd6gVKA4f9koSIw4zI8P+DwbTG5NN94yaEEIWOBFjsxI5tW7uWXtS5YErf0mv8kLpu+VHHrT/0/J3PA0JAgKfFj8tFLH2iCqhObA7RLYItHHj33Xc/6KCDDjnkkBSGidvz3byZPHmj3CorKzG0AX/TKAUmmkxr+HE2LF68OHZENGUbDAbNnwaETLKzyTp+wQyl9uoQ1NXVZTxE31SkvJVqkeCwX5IQiaD1K4gHg2mWq6qqaOUya0aEEKKwkACLBPStvqMjFOhbcsmW5msGK/XddXnn3GDPQ9fYPOUd098bHw2YTkg/OHBj3BuhibH22msvghh0iEziRcnyyZIVca/78hw0rzbyY06oY5aKFQqFBqXYKcyysrKPf/zjRxxxhJv4lSLFe8lqiv1lPRQ+FcxOZwGrYnPV1dWZHUq+RSXXD6KkjcN+SUIkB730/4PBNCZkkqYpb/dGhRBisJAAi8R8+MZT7Td8u3PeaX33TN/S/Kt8pr57r+5acEbb9dVbnh/kWAGBRC3sRAzGgf3QaRYdCI1qIsMQ7RMmiDHDYgloWCY+pjHiZCe8prm5mcxQSvX19dkP/2Ml7MhghWWXXXbZ0KFD0eABhwiaipGi49dAvWIZO5EFBKwcQRTdjZnHw7eoP2TGTgshcsmajx4MzuwBkPwQCoVGDdIzMkIIkTckwCIpO7Zt7fvzks0NR6OjSKlDU3OUum4+s63hP3ofn5//Yc/xpDCE1sirmAbdgc341fPPP59/jQnHQ7BVW1tLbtmXpqamqJvlwn/Ij3nwFTHz6kldXHEQX8HNIaZs2a/FixePHDly9OjRK1assH+LgeyRTzdVgsgy4ciCdGENBNPZiDTfzd0dECFEQmgYaQGCwaBvHww2jZ4GhgghihgJsBgARBQdRUq7Fv5oS/OM3KXuRT/dfO3Xe37TsL3rfbttH0CMQrCS0OWMA3sykDVjkNtPfepTxtDsrOS0tLQQdZWXl/Ov2SMkir3z5I3KxEzYFDlBtr3qqjU9nJBZD2f2mEMc2xkyefLksrIyzDPWYNl3FsMnB9RaFnCsMDOolpWVldm8tCY/Y+CFEPHQoHEC0hRMnz59sBq31GzYsIH2gcbcn9kTQogskQALVyClPQ9e0farr3bNOaX7lp9uuXeGV6ln8bmdcyejvl13np3PVz27BwvC6xI+fYrpIZCD4sDEJfgPGWPrk9L5NR2ch69EZfXOO+/MRskwMTZNIeCErNbDaIl84nhY5WBFYMnufbz99tvjx483I6LJpMuOX0MgEMjGWg2m1mXTP9MS+XVor+5TCCEygBbGjM3xarCMt9C4cZmgYSefdpYQQhQLEmCRBmhw39rlXXf+bPOVX+qcfXJ349S+uy/fcu/V6aa+e67sWvjjzjk/2Hz1UR0Lp/Q9fbc/1TeKGbSWsLvM2Ih7//SENZFflyU6MaEJ/xJFRZ/+dQnfQqJYzwEHHFBeXv7EE0/YP7gDZzb9yRhgwrsD2UCpkrFBfDwV60a/UxxW845oNPgb3/hGwooRT1NTE9Fklj5vbsdkc8+FysMa/PwUohClA2f0pEmTaBn8eUrSCHOB87yFF0KIwUUCLDJhx7atW9Y/2r3sl5uv/kr7jcd2zZncteDMnsXT+u6+css9VydM/LX75qldc07tmHUC/tx9z3lbXnzIDw/6uoQ4gDAlob2Yvsrp06fb6VzCtsxDtg4FykauMOeJEycOGTLksMMOQ4lT3+8nA42Njdgp8MGl+6UFwVaWPZzZU11djdjbiTjYa/5KCXzzm980I6Lffvtt+7ckoPRoZ7o3KRysivxgr8ve5oSQDd/2OAlRsrS0tNDo+fPBYJoL2i41GkKIYkICLLJl2zvre/90e8+DV3YsnILZfnD5hISJvyLMvU8u/PCt5+w3C40Ur4wyDlxbW2unc0PqZ01xtmwknMyzC1OmTCHWYVXx45nxUjZtHiHO/inWZBjHy6aHM3tS3OwAcxTq6+vNAqjvhAkT0OBp06aZBRKCJGf5rLXZbjYlb2ppnkcrFCeO30AiCZEdtCecm5zjPnwweM2aNabRs9NCCFHgSICFcAv+MC75E7+ELKm7DbPBdDkSgqTo/TMDoTMeq0b+sT7z1pPm5ubo8OZly5aZ7mUz0junHRQtLS3odzY9nNljhoUnvMVgjgJ/jR+suHTp0pEjR5L5hO+IJqKlbtiJjOAQsPIsByKSBw6rnRDZ4LBfkhBeQANrHgwe3JuA8ZAxrgKBQCBh2yiEEIWFBFiINNiwYQMekuxhLePAGf8uazJSd/zGQsxUWVmZ8dZZf+zY47Vr137ta18bMmTI7rvvftxxx+X6MbDGxsbsHS9LUrwdytHxm5CpU6fGj4g2nSfZ3DhoiLxmLGGu3JO6W1ukh8N+SUJ4B80gZyuNee7G2mQArUcwGKyoqMiyLRJCiEFHAixEepiHtZL5DCECpooGe2IabAWdJuBwHwax6WwGQptHVdE81mN8jznAOskG8IFJu7R3sNrsHS9LCDoT3t3gKFAa7HuyGx+xOEZEUw3YL+qM+WsGcAiIg7PxZwiFQmRDXTee4bBfkhBeY641XAIGt2F0QGNCO+krMxdCiHSRAAuRNjhJVco3TuHALJClb5hRr6m7HOPBlBDXzPpRCbPY3D777DN06NBZs2bZuTGwWjM8j73z8A1YFFf2jpcl7Dv7FW+qmR0FMyIaJk6cmM2T4Z5UpJUrV7ILWb5/S+yEw35JQuQGhNPci/TPDSzTpETHCgkhRMEhARYiE6qrq1OLDfEKUpdZyJJWl2M8GQyEJqAJBoPENOwUpoTcpu4wRBRxs/Ly8kAg0NzcnNa2YuGLrIGdHdzYjq1TYo63Q2V5FOC4447bZZddvvCFLwz4juh4oiWTcdkaWltbiZ7VXeMxDvslCZEzaKDq6uo4kbN8kZ6HcJmgbeR6kWUDJYQQg4IEWIhMICLh8p86HDHDhtMdvRa9359NYIE4uRkIjeOZ50vJJ9ocu0U3j4zyV77FtjBnfDhdy6IMq6qqEO/BDaHYOrvguJ2RWcdvLJStGfzMPpaVlU2dOtX+wQWUDIVPkWZZMiYP/gmaiweH/ZKEyDE4Jy1VpW8eDKaZIj+0b7QzdpYQQhQIEmAhMoRwBFNN3T1oulJdOjArJJgAPthZmUJEQt5SDIQm2/iVEddku0Bww1/tRErYHN5OZMbOYs5u8k+ZsHw2w4O9gjywp3Yisi9MZtPxa8Bgo/cgVqxYQVGPHDly6dKlZk4KCCspGYrRTmcK8kxdwuHttPAQh/2ShMgLK1eupHXyz4PBtFQ0+5k9dCOEEIOFBFiIzGlJ/tLgKE1NTald1NDQ0IAjOUbhZkPCgdDIFU5O/ETIgrIyaf+QCP7KkmllCfXFuFg5X2T9yXoGWIxlPNzZjCEPlFK0HLLv+DWw7wiwnfiIadOmlZWVTZgwIcWIaOoSJeOm935ACJHBTghvcdgvSYg8Eh0olLoNzw/Nzc00m/xrp4UQwvdIgIXIClylKuULscB4cjIH9rDj10F1zEBoVl5bW1teXh4MBle6/qFdfIzIJv7VUAOyatUqNsd38UCsMjZKW7NmDfOZaacHDyI2bNPcv/Cq4xco6mS3RVBfDjQaPHnyZDsrBmoI+fGkZIiM429/CM9w2C9JiPxCo2oeDEaG7azBg2bTCLmdFkIIfyMBFh6w7Z31W9Y/2vvkwo7bz+pYdEbCxF+3vPjQh289Z79TRAQCgQGHCuOcxAcO88RPiBhyZ4NI3QEHHHDVVVchXWy9oaEhWZdsClBZcpjxCDckE+U24o1IUwKszb2B5w7j4Wa/KH9TPuZP2cAxxTxTH9AVK1aMHj165MiRixcvtrM+iiA96UVh64h0BsdauMVhvyQhBoMNkQeDKyoqBr1RpcHhQsPV0A+d0kIIkRoJsMiQ7W3v9q1d3rlk2geXT2ifHehsnNJ529ndy3/V/UBDwsRfOxae2T73ZJbHh/uevvsf7/niEabswXnMiF87nQRjONEwhUm+ReySI1HZGPlNoz322GOvvfZasmSJnZsR2QsVIZEZel1WVvbd736Xfbd/GCRMzzbHgp3iEHjY/V5XV4fq24mUcHQojfHjx7/99tvkJP7+SGZkecNCuMJhvyQhBg+aDnM18XwYUVpwKaT1IycJx78IIYR/kACL9Nj2t9d6H5vTPvd7m6/7Rueiqd33Te/7/V3ppu4Hru1c/OO266vbZ32n55GZRdAtzPUegRnw5ZxoCYstWrQopx2/zc3NREKsn62QMSISPti/ZQprwBKzGVI7ffp0LPqJJ55oaGggQuIzcwYlTsLGyUAoFPKw49dABWC/3HeAsCSluuuuu5aXl3uirFGxt9MiRzjslyTEYGMeDK6rqxvcPliyQSs04NVQCCEGEQmwcEvfs/e1XTsJZe1smtbz61l9T9yVfep5eE7XHXXtc07ePOMrPX9YvGPbVruxAgTr4Ko/oNFhv0OHDv3yl7/seccvK0QpCYBwKtQuKqvMZ2b2na6BQMBl32Y8tbW1lZWVsYWD75kH2Jjf2NjoeWkkg2KZNGnS6aef7m3HLxB0sjvphn3s+wEHHLD33ns7RkRnABlAv/3wQGDx47BfkhA+gEagvr6ehmhw2wFzNVRbJITwLRJgMTBbX32y7fpjOhf9qPe3C/ueWJKT9Ojirtt+tnnmt9Bsu9UCxLxSOFk3KaFJTU0Nockdd9yBqHjY8Ui0gZqWl5fjmQmNrrm5uaKiIpv+W+Dr7F262eZb5A3nTNYpQeYpFjKPYJPPLDM5IGRm/PjxBGcelr8hg5726TG/FM13zYjodevWmb+mBeVGIVMB7LTIKQ77JQnhG2hSaE5pWwZxMAhXIjJAi5TrJl0IITJAAixS8eFbz7XfHOxYcGrvI/OdypqDhGCj2e2zvoNy2xwUGlgQ2IkYCERQX0zPeOCmTZuQyegrmjODVYVCIVyaOKOxsTGZYRoy0LN4iKvYC/cvhSZLWBmh2IAxEAtgvyyJCVNKOYrbzj777BEjRhx55JGePynXlOhHp1JjesVjjxqfqyLviKYc7CzXUGjVMb9mLHKLw35JQviMVatW0cIM4oPBNGhmoE3eBvgIIYRLJMAiMf94b2PH7We1zzm558GZDk3Ndep5eA7KjXhve2e9zU3hgAIRc8QO/eLabzp+HVJHcMCSmXXZrVmzxvSa8q/Lsc1eDYRmDaPcvWPJSD45tNPu4FvIPF8kt3V1dR6GbieffDJueckll9hp79gYefLWfVapJMFgkNAwoTCvXr169OjRw4cPdz8iuiHyWHWsS4vc4rBfkhC+hObUtKWD1T6w6XHjxum1fEIIXyEBFgnY+soT7XNO6r7v6r7H7xys1PPAzI653+97/gGbp8LB6JDR3aamJj7X19cnVB1zg9y9IrISohlUx4ygTve2uicDoYH1EFGZgbvJ4K9kMpsubnySr5v+bXY29eZSw6rGjx8/dOjQDH7Q2A1VVVXun3aj/DnoCHDqAzFjxowhQ4YceuihA46INr8ynU35iLRx2C9JCL/ChcY8GExDmn37nwFcMrgO8q+dFkKIwUYCLJz0/vnOjgWn9a1c5DDS/Kfex27vvOWHPb/x+FnNPLBq1aq99tpr4sSJyFvqTlejQwMOEkbhamtriSEQp2yGB3syEBpYSWXyEb+tra1k1at3XFOAZt8nTZrEOtPtxyDm2zNCjoZVY+kcQTsxEGTefa84C1OFUo+INkWdfce+EKK42Rh5MHjcuHE5ug+YGtooDNyTq48QQmSPBFj8kx3btnbdV995a23f7+7wT+pacn7HbT/a0ddpc1kI4GnDhw/fd9993dgaGokRJRsQy6qqqqpM6JB9L59XA6EBl04oZngmSpaLGIt1stHy8nL+ddOZsGHDBoruiCOOOOiggxobG+1cT6EkCShddsVz+LDfdHvFU4yIZoUcTfWrCCFcYh4MnjRpUv7HJNNO0iBz1Uj3JqYQQniOBFhYtne937FwSvc9lzj80w+pe9mM9vnf/8d7BTDIE+kituAyjxqhtSn67hywMN+KRga4jRm0hhh7aziszZOB0KyBDDvu6KPr5DmnvwBJEbEVChnNrq2tTSbzDQ0NLDBjxoz4THoFJeC+O4WKwcIZ/y6IGRE9duzY6Ihotk4gy26aSSGEcIl5MJj2M93naLKEVisYDNJwZX8zVwghskECLPrZ9rfX2ued3HN/Q9/vmvyZeh66qX3Od8mnzbEvMdIVdRKjiO4VBU8jMrjtttuQXmN3WJP9m6d4NRCa4Ampi/o5e8pk3joWCKHwSfNENLsTLSvT8UsZkr1AFr9dPCA1EexESigTwk283U5nBOZ/zDHHlJWV8S+T7GDudk0IUdzQnkyP/G487TaXKjs3L9Buc4HL6X1SIYRIjQRY9Pf9Yr+9D89xOKfv0m8X4sD+7Ac20gUOZTWDVN10EmJrxp+HDx9+ww035DQiYVvkypOB0NFnUOvq6nDRQbmvT5mzdfaosrIS491///2NamLFHJEclSTH1GVH+srIL2B59QTyunXrDjzwwN122+3QQw/Nc9gqhCgyuBYEg0H3I1m8wjwpk6MnU4QQYkAkwKXOjm1b+0c+L2/ofazJ/6nnN3PaZwd89TwwEjJ9+nSu5cl6eletWoX/OMQ4FkIBQpDobxoRExCO5NokvRoIDcuWLUPaJ0yYMLhPdlHC48ePP+igg/baa6/q6urTTz/94IMPzlGWTNe3mzsIhJVe3WuIQg2hvg0bNix2RLQQQmQGDVRVVVWeHwymxeYaVFtbqxt5Qoj8IwEudbruPb/znkt6H7u9UFLXsqs7bp2Kt9sdGFSIG7iEm9G2dlYiMBYWc8gYk2Y+8CH2r+ZJ2lzHIp4MhCbb7P5nPvOZww8/fLDiGLbLjlBipuPXTA4dOnT33XevqanJRc8Gu+zmXVa5OI6m54TYkZKPHREt8orjN5BI/oOaT/2nEqa4+yZElObI79vl88Fgc/nAvWMvf0IIkQckwCVNz5O3dN72M4dh+j9h7Hi73YdBwlgWKmKka0CIKrjSm89oM4GpeZtxspGxpucwpw5MzMEmsnkQizVUfvSjPuxLdAfzSfw9CArN7BdzGhsbia5MVOdVYYZCIdZpJ5KDIXvek4/JOA6ZGRE9bNiwjF+vJTLBYb8k/0Hdo3Wi5nOCUG0CgQCVxNvBCKLI4LpmBjTxb95uaNbV1dFU5vqGrxBCxCIBLl22vvJEx4JTex+9vRAT3o692z3JOy47fmMhmDjyyCOPO+44jJGLfUNDw4DfxY0JW5MZsiewcjKTWaBDeM13o33IrAQtJJQxk3mALcbfg6BUyZXjvdlk1egoR42Sz0ZKjYIOuAbKgQPtbbeG2TWU3k7HgNjgwJiwRkTnCYf9kvwNVbGlpYXzhZO0vLx80qRJnBGrVq3Km+SIAoKmJhgM0tA5GtLcwYZoyfO2OSGEkACXKP94b2P7Tcf3/HZR76O3FWjC3nF4uz/5gjiypqYm3cgAa6qtrd1rr7123333qDG6AdPOtQOzO+TNTrjG9LI6ZCyFoXlOwnsQRPNoJ5G9nY6DbLOz5BwNcAw7d4NZ/4B9/hQpguGt/Zr7C6krT3REtLebFglw2C+poEB9OU04fZBhU6/QY1UbEQttLHUD8jNqwFzsUrTeQgjhIRLgEqXjtrO6m6c7lLKwUs/D8zbP/FY+HwY2XbLojftIEU/GhfgWIebGjRu5xpsHOO2fXWBU0+VA6wxgX1h/WgOhTTkkvAUQP0bXcxJ2/BoI6Dk6diIlhPvmxWP8y4647AdjuyxvJxLBesgDuFyhe9ium9+UXrdu3dixY4cNGzZjxgw7S+QCh/2SChYapVAoRO3izK2IvJSIMyubURKimKB5pGLQ/sTeaswRbALfpirqXowQItdIgEuRra8+2TF/cu/K2wo9ddxyVt9TS+xe5RKux5gVcYDLzljCR2SJ5bmcOzyNyXHjxqV1gccq+UruHDitgdAmHkpRDvwJO81RAE2wnmzweV1d3aRJk9IyT44CpcrayDDHN7W381d2PMWB408cbpcGnhbUpcrKSve7phHROcdhv6SigKaGM4I6zFlmtIe6pIczSxxanumRXwzmX89v7Tlg/dQ6mjvdghFC5BQJcMmxY9vW9gWndN9/nUMmCzI9cnPbDd/e3vW+3bfcQETItb+2ttaNtaJ/RqhYPllPr1E1O+EOogEcNdkvLWUPIa+bgdBEwxTFgAExixFApyX5A0JglKzjF7LcIjpt1kAhc3TiDxxrZsdTGDJrIGgjh3baO5qbm8lVBt0vGhGdQxz2Syo6qHItLS2cDlWRx4Zp1vCfnA7uEH6G+mCeH0k49sdbaI1p6lXZhBC5QwJccvQ9taTjlh/1rry1OFJn07k9D19n981ruOQT9uFFAz4ExZLYKaLCwo2Njalvk/NXBJjI0k67g02kfsA1GwYUPMDu2EGXN+YJlSg6O5E1KTp+gTDdqz5n1NfsJpsjCItuLhgMpjheubs9wRFh1zLugjMjoocMGaIR0R7jsF9SUUOTtXLlShofGq5ddtmFfzlNmKN7K6UGbRFHPw8PBpuRRPl5o4QQogSRAJcWO7Zt3Tzzmz0Pze397a3FkXoeuaXt+urtbe/aPfSOpqYmLsDEealtljgAOyovL6+pqXEfE2BWKFO6t9IJN3FgN121GUDAQZaS7Sx7x6bdx7uZSX48rIdDgJyTPTtrZwjIOEyeR2OYJ7vMmrHuqVOnHnbYYclKhgyQvYT90lmCV5MB9N5OZ8rixYuHDx8+evTo1atX21kiSxz2SyolON0aGhoCgQD107RINGWe3IESBQGNEhcLLnw5PegbNmyoiDyUnvoSLIQQGSABLi16Hr6u8/Zze3+7uJhS192/7Fxyjt1DL+CiPmDHLyrY2NjIMqbrL4OeEGNu6XbusSHyhpvZaU9JOBCa4IMtQrpRCFmlcLK5hU/5U8LkKlnxcqSQz+wVMQVz584tLy/ffffdifbiN4Qn5ygD7LLphbbTWYOulJWVTZw4MYO6Kpw47JdUqmApnOOcpJzswGnCZLrNmig4uBxw4aP1q6+vz12Twpq59FRVVanVEkJ4iwS4hOjv/p3xlZ5HFjoEsgjS5oajveoE5qKOl/JvMt8j4CPaMy8QTtYt6ZLMHu80RorPpGukA0KQQUATOxCaOZWVlexvZtuirCjMDEqJ7abu+AWTN46Unc4NxF5YKNsirOczWaqtrTV3Rsibo7i8gtKeNGmS513969atO/TQQzUi2gMc9ksSkRtStGnUW05MTnyaKU5Pz0dnCP/AxYvDTTOYzY3OAamrq+NCqbsqQggPkQCXEB++8VT73O871LE4UmdjTd/a5XY/MwVbw3CAD3ZWDDhJU1OTUaDp06ena63J4NKO6qSrlyyPlGbQKzsgSB2hhlkt4WxFRUWWw5hZIaFwwiJNhhHLFB2/QA7Zfc8V0YF56NFORKBMiOkpltGjR5eXl69YscL+wVPYr1wcXINGRHuAw35JYmc4eTmR6+vrOYPMY8OcTczJUa0WgwhqyvGtrKzMxd1AQ3NzM9eRdB8aEkKIZEiAS4ju5Zd03nF+74pFxZe6mqd33HKG3c+MiHb82ukYcB6ExHRo5OICTOiQmWSiiAh5CkvMDFbL/hLTYMKeDMFtbGxkVW7yyTJsHfslULazkpBTRTSsWbMmWf88xfLxj3/8tNNOI6scAnbQqxsiYATb88PqQCOis8JhvySREtSIis05S0OKKdHi0ZZ6eNaIQcc8GEzDwhXTzvIUGmRz99lOCyFEFkiAS4i2ayf1/HqOQx2LI/U83Nh2zcQdfZ12V9OByyoBGRYa30tJiGYiNsK1HF3UAQMhbsjsLUr1kV+I9dZhWNs+ETx8sZObjm43Hb8GImnP99oBWcVCEz7ca8o8Wh/INnkuLy8n8qPCZOnkbJH6lrvKFsvbb789fvx4NJg9srOESxz2SxKuaW1tDYVCwWCQ852mj9OnsbExrUEiwp/Q+tE4c1hpUnLRPm/atKmqqoqWNqeNvxCiFJAAlwofvvVc++yTeh+5pVhTx81Ttrz4kN1bd3C15jqNbzhMj6ss803nHn/KUmncQPBHNjJ7WG769OmomofKhIPtvffeBxxwgLdBRnXyEctsyGXHLyCZLJlrRSSrZMlOxMDMhO5NJaGqmNslLONmR+JBDDKuBhmzePHikSNHjh49OkfDuYsTh/2SREZwInPicLrRiFH5cRvcOM+ngPAWLqB1dXW00rl4MJiWNhgMxt6CFEKIDJAAlwq9j4Y6Fv/MIY3FlDrvvLDr3vPt3rqAGIuQC2OJHYaHt3BxNb9plOceCbSTiCGzMYFmjLEnAQGrIgzFxJIZYMYgjRR4/Jhq9x2/wFEz2bPTucGM5XPc+GCS6JwKk/qGCEeQMiQ+Y6eIAt3XIg4fX8nFGHs3TJ48uaysLBcj6osTh/2SRNZQ9zj16uvrqYc0wuax4VWrVqU+44Q/oemjtaQlzMWDwVxHuBDk7pFjIUTRIwEuFTbP/FbPAzc6pLGYUs9vbt484ys7tm21O5wcwizMhMtntOMXaWloaMB5MDTsZbAcwER+mUV77Av6lKUZEm5GRZps8DmznsxksGaKPbpOyhnvJdsut+L4eo6gMrDjjj4oskowR27dHx3iPw6oqVTUrtS3J1gtkeLgPt6mEdFp4LBfkvAUzgj0hjMCDUaGaRhptNHjzG4RisGC5trcaPb8hjJr5nKQi05mIUQpIAEuCba3vbu54ejeRxYWd2qffdKHbz1n9zkJXDVNf6MJpPAcPhNgBYNBP4y7I1BINk54QEwfcsYOTDngYLHxJQEoK/T2doBZJ8FQ9EC4XD+LJexA9hwOgUNE2TQlk/FxoV7xXWI1QvmmpqaE+8tGqYF2YlDRiGhXOOyXJHIJJxHnfiAQoNGgHaDd4FTy3KlEjjAdtnV1dd5eTagAVAZa18zuGgshShkJcEmw9dUn2+cFex5eWNypo/GHfU/fbfc5Di69hE3ET6gXnxsbG7l2jhs3rqGhwT+9CmSMXGV8V9tYJf/aaXcQPZjBvfHRiecDoeGmm25Csfbff3/3+SSH2CPxk53OGZR8VVWVnYiwceNGKoknfbPNzc1mgD3/xg51Zr8y7vnPEZMnTx4yZAi5evvtt+0sIfwB2oP90i7RVNLccTbhV7l+LEJkCRcXM/DK25uYrJYrFy1V/MVLCCFSIAEuCXr/dDty2PNwYzbp8ZkX7LIzlf8y9r3750QXeOXWGaNG7hE/PzadG/gGCwwbMuSPsy42c8xq77hwanSZjFPHbdN6Wq6y+7wz0f7GtWvXmu44lC9dUcwPhHdkNeOnm9ZEfivC/a4RNxA9EEQmFDBmejsQ2hyIL33pS0ceeaR75SN7RDl2ImdQ8lSM2LHKRNXsvrej7Chwwnd8nm1RFS+66CI24cPoDfWdMGFCWVnZtGnT7CwhfMamTZuam5sxq8rKyvLycjN8Q4+G+hbaWI5RRUWFtxdfKgCtqG6CCCHcIwEuCbruPb/jjl84dDHd5DBVo7uxrhtryAmFNmrIORLgruar2hecYvf5I4iQuOIefPDB559/PqaHfdXX16d+IHPQMYOZM84kcQBfx7LsdHLYxICDe70aCM0aTKeNGWoeCATQWvOn1BDRkslcd5CyfrYSW2imGHP3VioK/8wzz9xtt90OOugg6iShof2Dn1i6dOnIkSNxdY2IFj6HUxitMo8Nc02htee0oi314d2lEofDxIWA67KHjR4NNc1U7pprIUSRIQEuCTpuOb3r7st6fnNzNunx64yp/jA6p/Hc/4ydYxY476RvfnK/fY6v+kJ0sWg6N3D0iPJhV51+Yr8A33iRmRm/2oxT9/0zN8/8lt3nCPjMXnvtRST0sY99jKiogK6OhHFkO2PrI7AYN9BvC5tlGhoa7HRysh8ITcmbWw/RPTLCOeDW2QUymYcx6uQNJ7cTkRCNcMrbbgoHlD9lwib4UBf51RAKpLGx0T8D8qNMnTrVvCNaI6JFobBmzRqaF05qTmR0i0aMxsTntz5LCs8fDDajnzx5XEUIUfRIgEuC9jkndTXPcOhiusmlAF8y+ThEN1ZxTfrg/jlGjPlWjgS4p2X25hlfMbuMRXzhC18YMWLEyJEjCX08vNOcNwjdstFOQr0UfkusQPCR2pCjIKusKjMbND3w0Y7fWMgh8UpLS4udjsN0PudhYJujl5tiyfV2KRaK1DG4mhLmiJeXl3PoyUPGtz9ygUZEi8KFc5lzLRgMctIBH5jMQ8MiUkOT6+2DwbSrVVVVtJ/q9hdCpEYCXBJsnvmt7vtnOnUxzRRvqg7RjQpw9EN0SVLUe3MowGj25RO4BB5zzDFE6gcccMCiRYt8ZRFpQc7xxmwiA4qiMtGP62TQvZnZQGgsjg3Fdvw6MB6eMBLdEHkiNzPrTgt2ipg4+twgkTGTOQ2OKQ2iNCI/O70z/LW5uZkYDhPGh/NQAu5ZunQpBwX4YGcJUVBs3LiR86u2tpa2kZpcXV3d0NAQPf1F/uGI0NxxsUtxM9Q9tJ/BYJCDq95+IUQKJMAlQb8AL7+u56EF2aTHG87vN9Vf/NBMvrLo6lEj9+gf6rzzApcEj+14cN6xXzpsRPmw/14y0/zJzKn8l0++tyzUOM0I8IWx34quNst0+JjhrG348OFcULmaEtYggbYUChAu4YRo2QRn2B2hQOxTvkZKMxC8tAZCU+zJOn4dEIwinI7DZKTU0UGaI4iWoi46ffp08pzryIktUj/tRHIoE0qAwzdmzBgK3z8dVtOmTSsrK5swYULpjoh2/AYSSRQgtDMrV66sj/wAOxeOSZMm8Zk56d7pE9nDZY62jkPgSUNnxlfrvoYQIhkS4JKg7dpJ3fff6HDFdJMxVQex4hoVYD5jubF/jbXcnArwMZ/ei9D8i1/84sUXX4zVcDU1kQ02xWfEA8NBKrgu+kcnUkM0xoU8GyUjmMNFjbuy+xRFZgPC+1wPhB6w49eBCUCjC/OBSWaayZxCVjFes2nTKZTr2Jf9YisuS8bA0TcHjqw2NDT4oWcD9eUYca5NnTrVziopHPZLEoUP1wVONFrL8vJyc9+wubm5oG+hFhxcnc39vuyL3Vw683MXVQhRcEiAS4JID3BDz0Pzs0mPN5wXMdUzo3POPfE/mBMx3n8uYCY/WB765H57R7p8bzJLRjqEr+Nz47TThg3ZLSLAiVebTfrg8gkPPfTQiBEj9t1339i7v/gGkya+MSEOPkyUA3xg0sw3y6QlJ3kA50lXmRzwXfbxU5/61OGHH56NPlE4qQdCu+/4dRCIeSk0n910kGYPRcHubNiwgfJh6+Q81/ZrurszPgSUKqEheUY+CewGvZ9qxYoVhJgjR44suRHRDvslieKitbU1FArRLHC6cc7W1NRwxhXiuyQKDpq1+vp6ip0LX5bXYo4XFyPaTL9d04UQg44EuCRom3Vc99Jren49P5tkTfWCM6NzOh6Y+9FQ5+uiC/QLcOSvSG+/6N5w4Su3XDVq5B7R+Y3nRAT4hgvNZPxqM07dD87ZfOWX2N+VK1fuvffeOLCbTkgCHbyO4AYBJsrBhwl3yJIZjlVXV8d8vIVlBrHnjTgM7ET6UAjf//73CSmOPvroLEMBgolkA6HT7fiNha9Q4BQ1X4/tDc4pHF9iXLaF+qLcud4oVYjy8WToQUtLC/WhvLycf6mcdu4gUYojoh32SxLFCy0/jRtNHzbFKUxbgZule49PpAVlTjlzLc7ywWB0muada8qg3y4UQvgKCXBJ0P8zSHdd6tDFdFNCU41abnSBqOhGJ2OXIeVQgJc1RH8GCQfef//9TzjhhAx6Iw2bNm3CWLj6YmWxo6nRSD4jHsxHn1gmD5GQ8UOiLjudDlz4ybARPNw1y1CAlVCkDunKuOM3FiKefffdd7/99stPpEJhUixsi4JNpvQewt4ROnvylpcoZJ64nL1gzewCVdH+Ie+YEdFDhgwplRHRDvslidKAto6zmCuCuRxw9nEh4HKT69tnpQltmrkTneV9Q44XLl0ozz0JIfKABLgk6LzznM47ftHz63nZpMcb6iKmWhOd0/HAnGO/9PlID3BDdIFLgt+O/Stz4PgvH25mkj4SYJuf+NVmnLruvbJ9zkl2nyMOjKzedNNN6EFm6pgMrsrAOgl9ED9jIOwFH4CZJiRiGQ9dzhgUq7XT7iBccwieeQY1m4xhuRQsazaT2XT8xsKu7RkhDzcUzC6sXbuWouBg2bk5g9KuyO6F3qnhWLByNkGQx4EYrIGaK1asGD169MiRIxcvXmxnFSsO+yWJ0oMWj0aeBoRmvzzy2DCihR5H20bhCZ48GNzc3Mx1atDHywghfIIEuCTofWxOx8KzHLqYboo3VVSWOVHjdQhwdAFwfCtHAtxx+3ld955v9zmCceB7773XDILKtRiwfuKh2NHUOAl7x7985vrNfHSRZTLLCV/kEo4J2+mBYEmMKF7wmEOW3K8nHiwrGAwSjnhVsK2trRwpdpDwkQ/Z5G1ATCf2/PnzKZzcSWkUNmeOvp3OJRwI09fBDrJrgxKIUzfKysrGjx9fzCOiHfZLEiXPmjVrOOkCgQCtNCcglwBa+1xfdEqENi8eDDb3PeMviEKIEkQCXBJsWf9ox7xgT8vcbNLj1/abaiz9Hnv9BY4FLjnl29E5Hyyb1f8qrEM++d7SG6MzG885NfaL5lv9AvzRAhmnjptrev90u93njzBmhQkTi/AhD8ITDxdvo3ZcermKo0PAXhMn8YGAiflc11kG7HeSYDr63EQA7DjrZ6/t9M5g6WhSxp5JBg488EDW70nXOp5GZqJZZZ2V2b30KzW46AknnJCicLyFzVVXV+dudxJCRSL+Zh/ZNLvp4UgEN7C5qsg7oidPnmxnFRkO+yUJEQPeSxvLOUjLxnWHRp6mOw9jW4obLljmweCMO3K51tA0sZI8N4lCCL8hAS4Jtv3ttfYbj+1tmVPcqWPuD7a++qTd5xiiDkxQwsUPJRiUnrGEGOk1o6m5KuPDZBU3Jp98xpaZjzmzTDTPBFUsaT4ng51FfviinU6EuSOQwWNRphg///nPjx49OvuSxAzjxyEH3f1SbgZQMgdE4IOdlUs4shUVFYMVbFG2RIqUpHldVur64DnFPCLaYb8kIZJAI8lpWFdXR0NnfneA5o4mPc83xYqGNWvWcAGCzG4oUOw0hhyLnI4zEkL4HAlwqbB5xld6l9/Q++CcIk6brz5qR1+n3eGdiTown3ESPuen9y9jkEwiJDJJqFRbW0vMhEchxvz7ta99bb/99ps4cWJjkh80NmbrJjgw443TcmBKL9rxawZCm/kZU11dHb8SYhTiG9Zvpz2CSJTM77vvvvnpiqF42ZwfwiwMnNpCkXK4qU4Z3PXIGA5iEY6IdtgvSQgX0LJxGaJVp0k3NzrNY8PqkEyX5uZmWjOuHZndhA2FQjTOXEDttBCixJAAlwrdyy7pXHxO74OzizV13Vnfccvpdm8TEevA6CUmybWz4MIOMsw1+4477hg5cuQpp5xCFGUCKa7lfEAmjz76aD4vXrzYZQ8DBRItltSYjl/gg5nD+inGbF4rQvBHthPmk7Amm6FuCTnssMMot/zoH1vhQPht0CM2TvDNUaNs+ZAfOafSTpw4sahGRDvslyRE+tBKNzQ00G7TVnBW1tbWNjU1qWfSJVw4aMQoOv51c7FzwFWP7zY2NtppIUQpIQEuFba++mTHnB84pLGYUseC0/uevtvubRJiHZjrZX3kpRpu3M+HEDmR+aiLAq518skn77///j//+c/jR1OjmkQJ+CRfdARYfHHAcojt+I3FfDfje/DEfCnuQXjrkJTJ7rvv/tprr9npXEIJUyze2ru3ULZE22SS6kEImNkRTIvVq1ePHj16+PDhxTAi2mG/JCGyg1OSMzEYDJrHhvlAC8lM+2eRBNouyiqz9tbcCqclzMCfhRAFjQS4VNixbevmq4/qeWBW74OhokybG/5je9u7dm+TE+vAgFxx/aupqSnE6x/RUlQgyT97gczE+yQyhvQSHCDAZjR1ZWUlYkyYxWdCB+b/4he/2GeffS677DL7nRjiO34dZDYQ2uXwYK9GEZ9++um77bbb2rVr7XQu4VjEP9XsWyhhDl95eXkgEKCS5PpEmDFjxpAhQw499NB169bZWYWIw35JQngHLR4nI801LTznZnV1Ne0Jzbj9s4iDS7m5TqV7w5QrJsXLF1PcihVCFB8S4BKi886zu24/r/eBUPGl7rsub5/zXbufA+FwYC57qCNxhlc9jfmECImLt7mEQ1r2wsJEVJQDoRUceeSRRFpDhw41r2kBZh599NEjRow466yzUgQHrIfSS+vuO4fAfdfugB3FAzJlypSRI0cuWLDATucYDkQGdwQGFw5iU1MTOee4cDrkNNTmUJoR0Tl6z1k+cNgvSYjcwPnS0tJSX1+PpJkRPXym3c6mSSxWuAyZzvN0h7SYX49Tf7sQpYMEuITY8uJDHfNO7X3gpuJLnY0/7P39zXY/XeBwYOAzcwgsct0D5i3k9ogjjjjggAOQFjsrCzZGfje4oaGB8rnzzjsPPvjgT3ziE8ceeywyzHxir8rKSj5j3bgxvoQmmW5hVJbScxlzsBUWTkuYjefbiXSgfPjiIYcccvzxx9tZOYZAigi1sGpRLBzEUCjEgeYYsS/Juv2zp7BHRDvslyREXqDVpfmlWSsvL+c8pW2kLc1+jEzRQNtL+YxK/8FgipFvpXVhEkIULhLgEmJHX+fmq49yqGNxpPYbjt32t/Se7Yx34La2tkAgQEiRu6Dfc4h7PvnJT37sYx9r8egXbvAfSsC8SSv+iV82R/hFiEBsYd5fZTolKMmxY8diy8znWyyTrHeXQmb98WtODXEM22KLdtodbItvESm6l/MsaYz8unJx9MxwFtTX17M7FRUVKHGOIuwZM2YMGzas8EZEO+yXJETe4SrGuRmMPAHLqcoHmiB1YwINvikWCsTOcoG5k8tVzE4LIYoXCXBpERkFXdf7wKxiSt13Xep+/HMs8Q4M5jeE0jW0QcHknws8l2181RNvZyVHHHHEiBEj0hrEi6A+9thjOPD3vvc9ogecE/MsLy/HjfkAqBTzly1bduSRR5555pn2a+mAVRLhuY9mjMn/9Kc/5Vs5HdAbhYrk1VHwFZReTU0Nu8Zx5OzwXO9Z4THHHFNWVsa/dpb/cdgvSYhBhZaH09M8zsPZSiNs7kXaP5ckXCJptbgQuC8HLhxVVVWBQKAI7mP2ftj15v+uW//uUytfvYs0/48XhVb9PJrMzBffWcUyH/T83X5HiJJBAlxabG97t23mt3qW39B7/6yiSe03BT586zm7h2liHNLRfcolkOiBq6Cfx5WZMdvR8VqEPtn3PRIwsU4jOZRAusOqjYc7+lopYYIPxBUB/uxnP7vPPvscfPDBiDFRGqEJm2A+f2WZAdWRBciem1CGA0dpsGbWn26/cWaYvDluphQZVLZg5HVZ/Ov5QMF169YdeOCBw4YNC4VCdpafcdgvSQjfQCPMRc08jmHuQtIY0joV7qMZ2UBRcDnAaV1e0Cklmji02c8BQAqw2af+6xF096KHAtf+7kfXP3H23D9eTFqy9sa7nwtFk5k568lpLHPZI6c0PH7WE68t/X+d79i1CFHsSIBLjp7fNHTd8uO++28sjtR928877zzb7ltGGAfG+uz0R0Rt0E77CfQjXgXNmGQ7kSYUAqES0hvVV4IAJgka0oqZCLP4lp3YGcoz9l1WbIj8E5rwldjR1KankZUwH1gmdjdNL2vquCR6QCkltpiHmI99Sat3uqDhCLKnHCMORG1tbbKx7plhRkSPHTu2sN8RLYRvoAGkCaUt5ZylgcXraG9pGx13KosbCsFc0Ovr613eJg6FQjRxsVcfn4P3YrB4LDY7+w/nLVl7w4pX7nWflr4wf+4fL5r+29OuWHHqAy8tkAmLokcCXHJs73q/7fpj+pZe07f8hiJI7Td8O92nf+MxHYbxrrsh8gtAsVroB7gwcyFH8+z0R3CNJ8RJt8OTbxETcKWP333+VFNTw+7zwc4aCJYkwIpflTF2lzfUI867iniFoI2tG9cidONY8HnixImjR4++7bbbWCb+uJiHuPBqtpWwlDyHXSZj6RZ7EUAJm5saprN9wA58lxCeFt6IaCEKBFpITttAIECjyplLC9/Y2OjVyetzuF7URn783OXNSnO/1f93Njv7Nt/fOh/vnfuHi5qfn//Iy/dmk5a3Lrp59WWY8C1/vkxDo0URIwEuRfr+vKRzwekOkyzE1LX47O776u1eZUcyBwaCe66CPhndat5LlMwkkQf+6n54KsEQApPa8ImQEDyXd83BdMDGrtAMjc7eRYnSkF7CkSOOOOKggw5Chsk8Yswu8zkYDJ522ml77rnnzJkz2RZz8jOYlu1SgHaiJKG08X8OemVlJUfHk7tFBTYiWogChBaVE5YWniaUJhorxo29HdPhQ8zVweWDwRQRVxm02f1d4HzS+2HXilfuuPyRYOPqyx95+R5vU9OaBqS6+YWbEGy7PSGKCAlwKbJj29bN132jt/nqvuXXF27qXXbd5oajt3e9b/cqa1I4sBFFAgX3HpgLyACX7dR54Oruxja5nCfr+I2HJQfcbiym59Z8plTZiuMp6+xh/QQl5jMZI5SZNm1aeXn5mWeeSXBzyCGHIMaxP2gMK1euZDFv4xhTMv6MjfIPJUwVpdiJpKlX2RcL9qsR0ULkgU2bNjU3N9fV1dGgmZaTNtPzBtM/uH8wmOuLGYg0uFf/eFa9cT/qO/9Pv/zN+iUOd/UwLfrzlWwFzd72j612w0IUBRLgEmXrq092zDnZoZSFlToX/qj3t7Ps/nhECgc2xjjG3UuYPIetcw0GN+EIcQx7kaIjzk3HrwOCIb4yYKxgIJNEURQjEQPfykUnnmPNfGCXzUA+5D/aBc3BAjOamliHIIY/mQfh+IxCM598sozLXYslrXHdpQNHnyKltAmj8eHsh05ER0T7LQAVoijhROO05XpHI2mePUGMMUZPBnf4B1oqLg204ezpgG0LJcAlZsA7y/mh98Ou+X+8cM4fftGyvunhl+/JdXpo/RI0+/onajUiWhQTEuDSpeeha/rfhrXs+kJM3U2/6Ly9dsc2729JpnBgICww10s3IuoVXJsRNlzC/Ua5WhO7xC/PHDLvsuPXQWPkR25d+h6BwgEHHHDUUUeREzvLa8gJO8IRQWIpH5MxdhAxHnAQuBlNTSHwXTSYsuJbhHocXD4jb8xHqlkm2YBA/uSmp72UIVymznBoKFWqQTZltW7durFjxw4bNmzGjBl2lhAiL5h7iNXV1bR4tJNciWg5zd3GIoBmiksAuzbgjVouKyzm+WimdMFCZz7+kyXP3vjwX+7OZ7r3ubkNv/vR2x+UxOPiohSQAJc0HbdO7W66oG/ZzMJKPXdd1j73ezv6Ou1ueE1qB0ZHiQCIA/LzrBSZYVsZaCTxiuNbGXT8OqBMkBmXJvP5z39+9OjRdiI3EJkNHz6cnYrevyeU4eiYzxnAelinkWpAhgExBvO5PvKDxnfcccfIkSPvvvtu+zWREmJlCo1ziiNFJO3yHko8RKg48IEHHjj4I6Idv4FEEqIEoPFvbGwMBoNcCCAQCHBWFsF9QHaB5p0GKvWIFa6h7DWtmZ3OO2/+77oZj9YsfWHBb/5yd/7T/a23NvzurKff+q3NjRCFjAS4pMEhMUl80mGYvk7NM9pnfWd727t2H3JDageGlpaWUaNGEc3b6dzAVZlsDHhnOiG4XHQXsun4dcCOEwEMGPEQIhweIfstJoOdIvz613/914MPPtgIMLELuxyVYW8h9MGNORYXX3zxnnvuecghh1AOiDExE5ET1s0us7MsUzR9I55DGZrOFkqMMDqzI+WLEdEO+yUJUWJwlaTF44ymDSwvL6+O/HYdDaD9cwHCFYR9YUdStOGbNm2qqqri0hM/wCrX/OnNX898/KcPrrvd4aX5TL9ed2foybrlL86zeRKiYJEAlzqYJD7Zd+/Vffdd5//Uu/Tajtnf+/Ct52zuc8mADsyFkCsl18IcCQ+RBIqVjUCSMWRj8eLF5qKeccevA6IEMpbiTjl5pugoQDyZJb3abizID3sUDAaJQsx477fffptt5bpbns2xLWI+Ox2pJxyp5uZmgj/m89fKykrE2GieCQobGhpYBux3Sh6Ki2NH0My/A45Xj2fdunWHHnroYI6IdtgvSYgShga5paWlvr6eCyKtH//ymTmDeZcqU0KRXwDmspIs81wFaLiiz93kB+wX8/z1ujt+85e7Bj3d/KdL7n3+RpszIQoTCbAI45NYZe/Sa/rua/B56px7ypaXVth8554BHRj4K96VWSdtCkxHa+rhWAPCdfqkk04qKyubPXu2neURZiRYwuyhefwp2kWM/iGB5rNXEJcQfMRaKJv41Kc+xbbsdM4wiuvm3j/LUBQUEbkCvgUon4kO+UyAxXwONIvl4h6B/+E4cvpQFISbNTU16d4gWLx48fDhww888MDVq1fbWXnDYb8kIcRHcC6bRo8WryLyM0Kc6fnUxSyhaaJ9pl1KcWU3npxuq5UZb/7vupmP17a8dMdD6+/ySZr9hwtwcps/IQoQCbDop++5+zvmfD/SD+x0Tp8k/LxzwX/2PjbH5jhfuHHgDRs2oDQedrE2NjZyZR1wmHFqcFQiD7yCCznZc+NsaWF6dx0lY/qcY8WY7SKrqQswLTgi7BfRlZ2OcNNNN+FCN9xwg53ODUQ8bDr7Pg2KjrCJtbEXwWCQMJE6hhjzL5+Zw3zqAMtkWQcKBY6pKVtKoL6+Pq0hFYFAoKysbOLEidkflzRw2C9JCJEIrkSc3ZynXC+A9o3GrSBaNhoiLuu0S8nuRDOfPWJ37HRu+KDn7zMerXngpVsfWr/EP6nlpSacHDO3uRSi0JAAC8vWlx9vD53Qs+SXfUuv9VvqvfuKjlCgd829Nq/5xTgwl3A7nQTzgwrZmx7yw+ayuVmOCdTW1pKZ6GWb4CO2v9QriA/IanSX2S6T8dGAUWVP7g6wqvhNGOt+4oknYnfZc1oiT31nc1wGhJUjvWY0tRnXbcYTlu/8g8YsA57f0fADHEp2nONYWVnJGeeyzpgR0UOGDMnfiGiH/ZKEEAPBCc71wrxFkuYUvTSPh9g/+xKuKeSWrJJ5OysGZvJXLq85apB7P+ya+fhPmp+f7/BPPyScHDPXbyOJAkUCLP7JP97b2D73e923n+fwz8FNPU0Xtd90/LZ31ttcDgaYCRc53MNOJ8FcC7HNjDujiAwI/bNxRXNPmvXE5oHPZCwXN6rN3QGCGC7/2Br2Yv+wMxQd/mYnMsWItOMWg9mumblmzZrse84TwjpZ82AFauxjxHn7RxUCoRiFaUZTU1v4TLEzH3NmmZwqet6gGlOHTYjMwXUTXJoR0aNHj87HiGiH/ZKEEOnAZa6lpYW2i0aMpox2rL6+nhM/46tnTglFBjwjuvFXZzJs2uRc5HzeH39xxzPXP7T+Tn+m5ufnXfO7qdv+4f0PUgqRayTAYid29HV23PrDrlt+1Lf0Gj+krsVnt8/7/vau923+Bg+ubVyn0Qw7nQQida7iGXRF8kXMmetoxhdRvogzJNs0cs6fECQ77R0EBJSMMX87Kw72jmWyMXB2ivgjftc4IrHbRQIR8mzuIMRjJD+DdzXlAcycY0rBUg4cfYIwsko0ybHmsxlNTejGMrl+PVguoNpQ7Bxf87oswmX7h+RMnjw5HyOiHfZLEkJkCmc6bTuNFa2Wua+HanLu++p2Hk0Kus5lyNzwtXM/gj/R9np7+3XVG/fPXnXBr9ff6ee04E+X3t863+ZYiMJBAiwS0PPQNZ1zftB31+Vbmq8ZrNR3z5Wd86d03123Y5tfbi66dGCIPn/rMgpnsaqqKkL8+MuqS4gecJ7UWzQv1spFSMG1f8SIEWeddZadTgQGTuiQ2daJhMh5vMIxh/kO3TVvIs24JB2wHg4667TTBQJlgvRyxKmuHB3CSjOaGvgMzAeqDYu5rKWDCLuD5LMLHG4i49RR5ttvvz1+/PghQ4bk8Kg57JckhPAIGnYkMxAIcMnAKrmucfonHIGcf8hGdXU1uYq/H8d1igy7uU/nhs6+zZc9csqDL9326/V3+DxdtfL0/2n7q823EAWCBFgkZstLK9qur+5acEbfPdO3NP8qn6nv3qu7bj6z/fpj+lbfYXPjG9w7MEty2UaDB+x5wwnNDW87nSZmQ4hBfO9oPEQVHsqhgdCEaOD1118nLCAndm4i2DrqZSdcY9Yf7zzsOPMT7jWRUzAYtBPZ4eGqfALGCxwLqrEZuUfQhhhTV/lMPWR+k19/0JiThexx3IEPKe6nLF68eOTIkaNHj16xIgfvjXfYL0kIkQNohbgE0AhzytNS0SDTdg14Vc01XHe4atNgOi5M5p6smwhhQO5vnb/gT5c4VNOf6danf7Xwz5fafAtRIEiARVJ29HX2Pj4fEUVHHY6au9S18CdtM7/V85sGPwx7Toh7BwbTMVtfX5/MObm6c13nim6n08SsP3XHrwMCiNSamhZkgKDEmBL7iFCx/hSCjX4TzdgJFxjbSeg57EVdkkeOTbdtxqUahfV7fr/At3AQkV6ODmVO2RLbocSIMceXzxxW5lOkEX0e/JfWEGji6lR+U6OS1X8zIppl3J8grnDYL0kIkWO4EDQ3N3Pi07ybwSw0SlyDBquJpuWhCSI/saOQ+EyDk/o6OCAfdf/e2rK+yZN0f+ttX5pYecH1tY75XqUZj9a8/YHvbpgKkQIJsBgARBQd3Xzt11HTLc0zcpd6Fp/TfkN19z3nbW97127br6TlwCzMtRCXiO9PI4jHLhxvdXIJq8VSuPpy+bez3MFVmcwM+FJrN7RG3koVq0OsPBgMosHJrv0UArucouMuFhPoJFQXwiD2IkWEwSbIWzaj0QhucG/H+OoShPLnEJvR1PX19QSd0D+W+qMfNGYmf2IBFst/cbFdqlx5eTlnGbUivkqYEdFosJcjoh32SxJC5BHaJa59pkWiLeJKUVdXRwuQ5yaIbJAHrjUNMQ8Gm+sgWXJ5pYun+YVZjX+6vGVdU2bphCnHmCYavvwf/8ac+1+MCPDM2tjFPEx3rb3p2t/9yOZeiEJAAixcgZSipm3XfaNr7qk9t1+w5d4ZXiXW1jXvP1Hfjlunbvvba3Z7vofLnnsHBizXXCPt9Ed9p+nqq4Fvsba0On5j4arMprPsxyPOwA8T2jsZS9HnRiEQstiJJBBAmE7IhCth0+z+gK8bMfcXBlwsIaaE4+9ZiFioQsAB5UTAPzleFBohFxWDzxxB5jfm5QeNqSdUxerqao4422WL9g8f4fGIaIf9koQQg4dpiGgBysvLKyIv4KBByFsDziWVBpB2L/aWq3lxdHxbNCD/0/bXq1ae/uC62zNI9629ZfSB+yK90TnI8Cm1Jy5/8VYE+PyZP4nO9zxd93jt+nefsvsghO+RAIs0+Md7G3v/dHvHnO+2/eqrXXNO6b6ldsu9V2eWehadzRo2X/t11tb7+5sLSH2jpOvAaBuXZ8yQqzLX5szcjI1yaUczMjPnKEa/M74/jaCy7ym61OoiP26RzIEpBLzITsTBylMPpUauYm8lpKA5o5dCm27qLEu4lKEACfuo5JwdtbW1HK/Y0dQcXOYDy0Cyo5wZHGviTjbHOUIldETAU6dOHTJkSMK7Mxiy/eQGh/2ShBD+gAsrjUAwGKQRAC4lTObhsWFaM656NHHRK7u5kZriYpeQ3/xl8bw/XOTQS5cJ3T3kcwc3P7vQMT8PAnzbmmvm//FCuw9C+B4JsMiE7V3v961d3nXnzzZf+aXO2Sd3zTm1q/HHPYun9d195ZZ7rk6Y+Gv3wlqWZPnNVx/VcetU1uD/0c6pSdeBAXMzPVEZ3Jw2V1MEOJlYpgUxAZnPTD9wGMILO5EEigUPSejYxjAT/skUKftop+Nw04EcC8untZtkAGdON2QRbqBsiRGpxhH/7f/JE4gM07OjqVFW5jd78YPG1LH6+noOJZWQqh69CfL2229PmDChrKxs2rRpZg65Ov7445nDn8ycgXHYL0kI4T9oRpqammpra2kHysvLaWRoYTy/7xYL1w4u01wfTZtDQ8SmyYD7Lc5YecY9z8126KWbZLp/E1quEeBzrvohC9DeDhk6ZOY9l8f+ybTD5cN3v+MPc6LfSis90Lr4oocC+k1gUShIgEVW7Ni2dcv6R3ufXNh9z3kdC6fgwx9cPiFh4q8IM0uy/I6+Tvv9wscIG9dUOz0Q5kpMCI5Duu+ZZCs4IV/09jY2F+kBPTYeLIUwws3lHPHAQBKaTEKPZUkKM0XHcmvkqeN0e3TZx0Dy3yiOhZ3CxNhBOy3yBRWbqJQKw6kUP5qaI8h8/soy6Z4CfIVzx3Q+EwpzKjFz6dKlI0eOZOaKFSt+/vOf77rrrmxr/Pjx5isD47BfkhDC33Dut7S00LzTyHO+m6aeOaZN8BBWyFWM5oVWi2sKk1zuaX/cbOj/db4zfcWpD7x0WwapccXMUaM/dt3dlznmk5a9sPiIiV/Ae81fj5/yrUM+d/C9zzSa+edd9xOzGPOP/PoE8zmDpFHQooCQAAuRLVzV3DgwF0Li+OhVkOW5QMY+MpQMM16aC6r7W8guYYXk3OVwYoNxWjcXcgOZx2QSDvYm/ojtaMV+WXOKzJDbioqK5uZmO+0avsi2Unh1FA4QkYqdED6AWoHBctA5X8xoampsf09FpDMHmA8rB/pBY+oAK+H48kX+Nefd1KlTyyKwQgPV2yw/AA77JQkhCgcaBFoMmg7aEPPYMM0LV6uEt2szg1UFAgEuf+aahWxzgRvwuaffbbh39qoLHGLpMg0owFHR/VVT/e7Dd29aNTu6gElnX3mmEWPHfJfp5tWXL1mb7Y8vCJEfJMBCeIBxYK6gdjoOFuBC63iudc2aNVx3Uwxp3hR5bNjzjt9YuEhj1y6fd0UbWDjdEIHLf0IHjh0IzV/5TPxh/pQQAogUQ6NTQ0kSfKSWZ4IhDmLsARK+xcSvjtHUBLJILAeRz5yMzKdGsVjs4waca42NjVVVVdS3M88887vf/a5RXwMy/Prrr9tFU+CwX5IQomDhChsKhYyvQjAYZHJAWXUD7Q8tEg0Om+ACRLMTf9c79qJzwxM/veOZGxxi6TItfXbh6DH7RC03NqUQYLR55F572BZwl12yEeClzy+49OGT7Z4I4W8kwEJ4g1HchIaGfXEJTPgnrnz1kR9RiFfQ3HX8OuAKTQYG1FrjqJmpOHuXcB/NQOhkf42Fv6bV8xxP6vwbS0/X7YUP4UBTpYlfEWAz5oKaQ2DH8eUzMS7zqXgc8RNPPNHEfLEMGTIk9Y0YIUQRsyHylkqu17Qb5eXl1ZGX9tGk2D9nBCuk/aE5euSRR/jACs18GqJzzz03OvCks2/zL3/zvftfujXjZMYwO2aS7nthUUSAf2wmf9V0MQJ8+6rQzSuuG7HXHtH5P7uyBgG+55mbzWQGacajZ+gHgUVBIAEWwjMwVS6WDtHlasp1NHrBS4hR0Kjr5qHj1wEXYDaXwrQxQ3KYugc1NWYf4y33M5/5zJ577pk6vKBA+G6WIQi0tLSwnnjLpZxxY0/u9wvfwnGnClGHORnrIs+xjx492lpvHFWRt7XbbwohShIuPbQYNBeVkScvzKM0XMXc34qNLsnllZaHC80FF1xw5JFHBgKBt99+e+jQoaz2gAMOMBff9e8+dd3jtfe33ppxuvmRfqHtd+CP5vxseg2T9z3/kQBHZv7q9ogAPxkyy5v5zc82jh6zT78Ar7nZLJZBmvX7n//hzQfNLgvhZyTAQniJw4FNr6ObDiUuk3wLC73sssv4Sh46fh2wdS7JdmJnyBuX/7QeFU4IpYF/xpYGn7FfSC0bptfOTmQHe8G+xJYtXkSBu3kYWxQZV1xxRcR2E1NeXp79PRchRHHAVQP15Uo0KfLueq4jtbW16HHqcUNcWLma24mIUQeDQYz3qKOO2nvvvU1TA+YC9NR/PXLj76ctb12cTVr6/C24rl3vLrtgv9GZddf92CwzIyLAtz15E59/Ov0Ms+SQoUOmnHfyIZ8be/eaBWaxDNLsVRc8/JfbzM4K4WckwEJ4TNSBuVimZVZcGo844ojddttt6tSpdlYeIdtVVVXxnhndHTudHTjwuHHjjAPjonwmegiFQmzaLBAPC/PXWGXNkljVx+0rKiqyd3vhfzi/HD3A++23n4n8HHz605+mTqaOa4UQpcyaNWu4cHBx5CrPhQytbWxsjB9GxJ9oUrjixF7C+C7XetPaGD772c8yf+Wrd8168jyHUhZWWvCny/QeLFEQSICF8B4udYcddtjw4cPdj2FG80zH79tvv801dVBGYBLxjxkzxmHstbW15MdD/2QrxARf+cpXKisrcRIzExtJaKEsTLF4WxTsC5szfezsWopXl4lChBgU0SUYRXRramo41iYGpSLx2YwmoLKxDDDHBKCw22678VeNfBZCpAVtDg0ODkxTQzvDZcW0MFy/bOMS6TGO3lPj0jNy5Ej7h4949tlnUccFf7p0eeuiwk23Pn1NaNXPzW4K4WckwEJ4Dxe/gw8++KijjnLTcYoEcr10PPGLD+OiCZ0wp5AHtht1ADJAxtw/7+SSk08+ecSIERdffLGdTiK6RAlVO/9UklewR0QqX/va1/AfD91e5BNjsFRRhJYziENJFSKOpMbymVOP+VQelknhtFOmTDHRJ2er5/VcCFFqcC1rbm6ura095JBDTNsShWurucoff/zxdlYMNFzz/3jhoqdmLHtxUeGmO5+ddfXKM0xRCOFnJMBCeExdXR1XMq6CpoMxtQNHO37jNYw1oH+sIdpNmh9wBiO9XMW5YEdvWnuCKRP4+9//bp6hsn+IbNcxEBqBiY5V9pxf/vKXQ4YMefjhh+208CXUQwy2paWFysBpgtlSSUy8yAcmOd34Ewuw2IBnCtXPvBc6upIo1Ha7kBscv4FEEkKIGLii2cYlhvLy8iVLlhxwwAF2emd+eN2xTWtmLnvxlsJN9z4/7+KHcnXVFsJDJMDCA7a9s37L+kd7n1zYcftZHYvOSJj465YXH/rwrefsd4oRwmt0l9g62pWUwoETdvzG09DQgIWah2bzBl7KXmDm7odwu4FiMV1zxvajk+avwGS009v0RedI/vEl9u6OO+7gX28NX2TGhg0bMFjqOTZLlaAmcGoQERIv8pkzhfnAMmC/kxFswsSaDsyGgK0MPPLCYb8kIYSIobW11TYuMQwdOvQLX/hC7EVn6dKlv/jFLwKBAPM/9++fvOe5uQ6lLLhU98Axdt+E8DESYJEh27veR2g7l0zbfOWR7bMDnY1TOm87u3v5r7ofaEiY+GvHwjPb5578weUT8OS+tcu3t71r11UUoHP9PZtxj8smdOBQKITdDRxnR8ANKisruUBGvTrXvPbaa0OGDDnppJPstBegsuxFXV2dnY5gCoddM4VGWICRsr9Mjhs3Lv43kzyBuIStGI8yv/+Ut4IVa9asoeQpdjyT445wciIQF3K4+RwMBplvxi3Hv07GK+K7f2PBhAeueA77JQkhRAxcVmybEgOXm5deesk0evFMDB5+57M3OnyysNJ9L9z8i5bjbBEI4WMkwCI9/vHexr6n726/Odh2zUSEtvu+6b2P39H3+7vSSt3LZ3Qumrr5um+0z/1e7+8bt/3tNbv2goVLHXaXsKcXYh0YuyP+hhTPJcbDGurr67lq5sgJY2FfsJGrr76af92/wjo1mC1rw23sdAzsGtoTvXFgBkJTVjl6N5XJSex4VzbE1u2E8AIOJQZrfjIEIh2r9l1TnCZ8NuOWOQoslv8eeLZuMhOPK/sFh/2ShBAlT2tra1NTE9cUGjrakxEjRpiGxRC9iz1//nw7K4YhQ4Zc/9jZi5/61X0vLizctGTtTVesmGxKQwg/IwEWbtn66pPts77Tdn1156If9zx4fd8Td2Wfen49q/P2cyKrPabv2fvslgoN41QIqp1OhHHgL37xix/72MdcdvzGs2bNmoqKCuQwdz2W5BM/MfLJ5kx/rPlTxhAToO6pR3GzU3iv2a/x48fvt99+xoe9hXUSlziOlNllR9e0cAM1H4PFY7FZ6gzFaMK+2OHEgFKyWC4OaLpQpY2BH3vssSboHDp0qPlgcHuDyWG/JCFE6bFp0ybzhgJaFdo9IoFgMMglnhaPv3KtsS3LLruwjPkKJHwQ46yzzlqytmHeHy9xKGVhJQT+plXn2v0UwsdIgMXAfPjWc+03BzsWnNrz8Jy+J5bkIvU+Mr9z0Y8wYTTbbrVAMONpGwd6UzEaeeSRR7LkV7/61WxMgO/iimgwobyd5SmmM9ZORK7TXNGz8W3yif26ecMQCoqcvP7669jvnnvumb14xxMIBNhBOxGD6fQe8CCWLFRy4jkzbpkCJNSjuIjYOLJ8plSZz19ZJkfVMns4xJw4VK3TTz+d0+fggw82nTOPP/44YWsk/twl9T2anXDYL0kIUQJwCaahQ3Fp92gAuaabO30rV66Mv1DixjQsLOMYS0U7+YlPfMI0O1FoZh/+y203PXne0hcbCzct+NOlt625yu6nED5GAixS8Y/3NnYuOad9zsk9D850KGsuEoKNZncsOmPbO+ttDvwN1zw3dsfFkksg/3LtjB3umzFmu/WJ3h2dDVzFUVDHOvFSLvB2Ik3IJzvutlctkoE99tjjoosuMgOh7VyPYEdYZ7IS2xj5DWRz2740oWTYfeAoALXU9GkQmWGMfK6trWU+lsgyubg9kTtmzpw5fPjwAw88cP/992cvjKUTkpqRDgSy7GMa9gsO+yUJIYoU1JRLUk1NjRnhwnWEqwnX/QGbwU2bNtF4xi7GHGIAEzbsvffe/eIbgTXz1z+8+eANv5+29MWbCzeF/nDBAy8tMDsrhJ+RAIvEbO96v6flyrbrj+leeoVDU3Oduu+/pj10IuLt87dkcQEbUJm48nGxhNhLINfR7B24ra2N66jj4poNprM3/oFM8on8ZDBCmBVSPoQOdtoFoVDo0EMPNdlgoxmPFY+H8IXVpn6nNIeSDMeXQJFBIbCnZtieubtB/TRBGJ+hvr6eP7EAi2XT+T/oUHWvuuqqffbZZ8iQISeccIKjEwbM3nEip2e/4LBfkhCiWOAqQHNBS0h7SMPIdZarLZenDEa4RJtQmiPa1VGjRvEvnwkD/vVf/7WsrMy0vWb80YvvrJr5xE8dSllY6cYnz33itaVml4XwMxJgkYBtf3utfd7JnXdd2Pf4nYOVupsvbw+d4NufTeJaOKDdRTt+7XQMnjgwGMnMXhRRHbKabHe4hGOPA3Z0x0L58JW05JytG/80O7VixYoUWUoL02HuJjPGkwva+qKwvxxW9oh4i/pGJMeuEWlRqnym+jGfmsMyYL9TLBC8nnTSSXjvsGHDpk6dmv2J5sRhvyQhRMFCE0EzSJNIw8jFgkbStJDM9ORyYC5qWPSmTZvYFisH1jxjxozPfvaz5eXlpo36n7a/XrnyP5tfWFC4qeF3P17/7lNmr4XwMxJg4WTLut+2z/5u7yPzHEY6CGnlovY53+v98502Z76hvr4el0jRVYh7xHf8OvDKgbmgsp7U20oNX+R6n3qgMiLKMi7vfxM3VFRUpNWVSjnwlWhHnOldv/TSS+OHZKeLm72LxXSKZn9c8kZEYPufSaPYA5EfFmJ/EV2qKJ+pZsxHg1km4xpSKLCPtbW17P748eM/9rGPnXrqqbm6l+GwX5IQoqDgckbDSAvJpYcGk9bSDGz2dhAQjRJXMS7Q5urJ9ZpJNhq9xNBGxd7CvmLF5Duevb75hfnppiVrQmPG7jftmpoRe+0xZOhuv1py4ZzfXMXn/v7lCGYmS969du6/fe0wM3P34cNueeI6s4YrbzvPzIRPVXzyjqduMvPdp3ufn3PRrwPb/rHV7owQPkYCLHai9/H5nY1Teh+9re93d/gkdd5a2/Pg9B3b/NKkcuniApYisOZiRgjuplfWKwcG0yOd9kjOyPUYUzLjr1JDZMCSLG+nkzBg+SSEyIMv2okIptv28MMPx9/srPQhG+SZwrHT7uCgmKdD/QM7QiBFmVAaZmAemEiF0MqEbvzJjFse8BgVGa2trew+tYWK98tf/vKoo47iQwaDFdPAYb8kIYS/wWy5iplbnLSceC8XHa59OWor2Jx5UVZ08NSGDRu4HqW+ot3/0oLQqvMdYukmIcCjx+wdFVoz+b0fH8tnTHjUvnvF2u8Rkw433/rJFacZ141dJuO08M9XzP/jL+yeCOFvJMDCgmF23nl2V9M0h3/6IXXdfVHHrVN39HXavA4SmCpqlEJZubz1d/um0xnroQObrbM29/7DdvkKAYGdHggTOiTLLfPNK77StV+cjbAg/lvM32+//fbee+/MBkKnu3dRyAmxUbra7AnETOx1U1MTQRISTmmb3gnzw0KULfOBZcCTalO4UFYUBeUDfHjppZfqI7+V7ebeU7Y47JckhPAZ5r4hjQMt56hRo2gcTBOa68aT7dIWsUW2Fd0QG2XOgDep3/zfdTMeO/PeF+alm+5ccxPGO+3aGjM55zdXIrQzlvyCz3etnfNvX/u8+VPsfBLfGjN2PybN17/342+b+Zml63//s6f+6xG7J0L4Gwmw6Gd727vtC07pf9/V75r8mbqXzWifHRjE12JxSXOMXHLgvuPXgYcODCYb8e/7SUgggp1wB1lNqJSUD39CgNPdEXSduITgwE7vDOr7sY99bOzYsRmUj7FxO5EmyBXF6H7gdLqsWbOGXcaxiZA4BMgthYDojouMWybnzOevLOPJU9DFBBWmsbGRk5ESoyqa8jHjBcwjdmax3OKwX5IQwgfQtNJy0hSYW4c0p7goF0SadLtEjqF1im+LzEM9Li8oFz8UuOu5mxxuOWByCHCs0MZKL59jx0UbzLfMV5gcMnS3qCGnlS59+Acf9Pzd7oYQ/kYCLPr7frHfngevdzin31Lvw3Pa5528vet9m+88wrWTq2myvkSuuITjuFbGwbe3Dkx+yC3rRErtrEQQFlQl/1mgZLBOJM0xZDp6d8BOpwP6R07sRCIwnOHDh5944ol22h0IJFlKXQKpQT4JWbJ5bpayZSVm3DIQioH5YSHyxufayA8LERuxWN7iswKFQ9nU1MRpMmrUKGoaJWbmU27MpMLn7m5FAhz2SxJCDAY00bQMXJ25nJmmlXaVK1T+bx3SKJmG3TGmGiHnUuI+P0vWNsz540X3vDA3rXTHmln7jtn7nGtrYif77TZCdP7s30xHhq9ecoGZTJiuuK0OB069THxa/PSvrv3dj+w+COF7JMAi3D/yufmK3sea/J+6lzd0LJyS5+eBuW5x9Uo4IBbDMSOdMnj41oG3DmwyluKWM/EBHpuZsRNwsMvRa7y5O4DImcm0oNzcSPjatWt32223c889104PhLndnr1Skr2EY7MdsCFCHzZKIRCHEQARBpmwo195J03q19/p0zkWLObVIS4RKC4KNhgMlpeX8y+f7R8if4oOu8h3qTrslySEyAs0yOauIk0rpz9NfSAQoBEYxNaVSwB54GIRP/YKG+f6mNbFaMPfn7vmsakOvRwwOQQYiR1X8cmmp26MLmDSkrWz/+1rnz9i0uGO+bHJjSTHpxt+P+3JN+63+yCE75EAlzq9v72x886f9z52e6Gkznsu6br3fJv73MM1letrQr81Ha3ZdPw68NaBwWQeE3ask+iBuCGbvk0u86yZHWclXPUT3h0YEGIC99m44YYbhg8ffumll9rp/9/eu8DHTd15+ymE4EKggeWSFkr9snTx25bW7EthetmtWVrwQuGdtrQ1sIApUEy51NALBkrTJgSThGASCBMIEC4BAyG4XNpAYcmWFgwJYEghTqFLWHap+/6hvsY2IU30fzxHmQ7yzFgzkmY0o+/zOR9/RrJGc87RkfR7dI6k7LBd0v3cI9QeYZapwK6uLqo0kXyxEDLGfMqO5VIVfCYAYr4Zt+zXr0cZWil7BJuSimUHdFyG4L/+7n354bBfkhAiMDioorgcdTnkmgcicLDlNFSa3T8NjkvmWvP4y3BMcuwiqxNeQh3PFb8+/canZy17foH7tLTzKgT4nCtOTc0586cnmOuwhtS/blvdhgPbc5MPgr7+8dmX3fx9ezpJ+nrcpFtXz73s4QY9/1mUERLgSPPuS78avP5kh2GGP40Z+6+usssQJEbzCLXt6W1wYvOr49cBEX9h58tssCrWiSqklMx0aI8vVL5QAwcddNDee+9dcCXEYjHHUOrcHHHEEeQ89/OZjVSPvwyfFwRbQIAFKNYee+wxZcoUYgKqka1jxi1TapbxchFBZIT2SQ2zoU3zGB/gMsfEwd7bcOE47JckhPAPDq0cYzkUpA9sZo77gcRFgAOUOSWNP0xx5iXnHKkcVuyS/+n744xf/duy5xYUnLDfMbN9bLaZvOym76dP+p7m/fu56v4V5YUEOLpsfnNt/8Ljh3+1ZOSRW8ou4e3Yu12SYODchkqNP9363vHrAF/lZO+jAwOqQFnQNvwQc/DF21nnDjvscMwxx9jTeWLc0p5wBxW+1157HXLIIVSRPev9UGlsmlZ3zyFjbRgsqkxOTDevibSAD0wyk3+xwKOPPorqu1ytKAziXWqbxmm2YLYRg/yLiJNNU1hY6RsO+yUJITzAAdkcjTn2VlVVcSjAHtnfOUrbS4QJTn/mdt+MQm7Os9keGuKSxb+75NonL77juWsKS2f89ITqmn1v/t3c1GRSgC9PLeBjuuHpmVf8+nQ730KUCRLgiLJl6J3+a48ffuAah1iWS8LbsXcc3i6P35hY3BGFB9fx64Bf8d2BCS+OPPLInXfe+cwzz7RnecDcZPvYY4+hKwWMf+7s7OTrBVxBoOY//elPU5B4PO5QICYx6vFujFkRQvFFtqnpYCfPWC7bkc98hfkmzMoRadESyLDHjmUxHiqW9sMWMfFijh512gw7BdtLve5CVAYccjn2mrtnUwObccsCTg1Fg+MPRyEynO10gBJzcslrcFNGTCewQzXdp1ufvfrgf/6kuaQLwdkvafavz1z71lN2voUoEyTAEWXo3osH7/jxyCM3l2/aeN+V/Qu/bpfHV0wfrOMcHHTHrwPiAN8dmMwfdthhiBwxhz2rIJBJVmKufBMN8DmHOo4HUyV6KHj8KqW49NJLG5KvOEp34K997WvU2KxZs6g6c+cVUQgnfn6Lz2xT5hOUkNXCBtHRAFhhYd8VDmjYbAu2C42nqakpd/thYTYfS6Y/AUsIUXZw/GTHZ5fnWM3BOZZ8TzsnlLK4qsWBiNxyFuAE6rj8mgIrZgG/LpXe9fxV1/zHD29/ri3MadHvLrt6ldvnUwoRHiTAUWTzn9b3zz9mZOXN5Z4Grjth07on7FL5AWc13AmzSjdPZhan49eBvw7MmZtog7Js2LCBDwWbPLlCKdP7xjnZIyeO3vIcIDMEQPZEnlAbK1as2G233c4666yDDjpo1113/eIXv5i8wD1pxx135DPFJIeYEk7l+6UKVkvZw9w7EXJoftQhu1hVVRXNwE2YaO5EYAf0a0cQQhQNzgvs5uy/dWkDm82TAu0lygTyzIEo4+2+KczByseLpCPvDc169LSbnpl9+3NXhzMtXT3n54+conf/inJEAhxFBm8/d+jOSx0yWY5p+BdtfVcd49dbkYiwMUPHUyuK3PHrwC8H5uRN5JG+ntbkvZT5Kr25cj8+P6zN2LU9nR2CIepzwiUJm4iQzLhlfpTgyfQYmGFyrGGPPfa49NJLjz/++AMOOIDFCDvcG7gXiORcllSkw3bHeNl82C8O7KYCiSOpalCvuxDlArs2h26O2+zpnGI4MnP2ZHLlypVleg2LnHPG4byT+0DEqcFxadgX/qfvj7MeOfXWNfNue25+CNPsR09/pecZO69ClBUS4Mixad0TA9edMLLypspIAzecMfrU7XbZPMB5C8VK75nkRF6Sjl8H3h0Y98joh93d3ayZMMXNyqkNBIYgINvCrKehocGeyEJPTw8hUWfaK4IIKYiW8HOKyddZPwsguvzlM3OYb7oLHMEHQRVbhw9nnXXW9ttvX8zBseQK7AmREzYc+xTNj62ZSCRcNmMWM0MNS7vrCSHcwCGdvZsThLlMyc7O/ssxudxv1ze3+2K/uW/Y4eTIGSEWi3k5Tefgxf958opfn+kwzzCk+au+v/IVH6IvIUqCBDhy9C/8+sblV4786qbKSMMPLOyd8xWPncDIVXV1dfqdsQTuJez4deDFgSkaIkFx7On3YyQf25zwBE9VAB/sWePgX9QYsmpPp8G/yABQyV/60pcIj6CqqopQiXLxGUeijARMLOPyCjrbhXLdf//9rPOEE04I4tJ7NigOsY7H+6grGwJHImA2CtuXJpHXpkF6aZA0iYCiSSGER9ijOVxz7uDozWGcIz/2y56efnGzrEldg8t4RkuHJamE+LiHMvoLnolt3vbcVeFJC5/88U2dM+z8CVGGSICjRfLFv//mcMhyT4M3nzPy2HV2CfPHPNwo1dfE+Yxz+YROWGQKc2DCFAoyYe+oGeZNqTOun5n4Hv+1p7OzevXqqVOnXnbZZeSW6IGwgC8SHgGfDzjgAIyIf1GxiG6+ZRnPjTfeiEX/8Ic/5LOxptxD1HwE/aYsbm5hjRS0t9bWVtqS2dD59v+wPO2Edl4GYbTjHUgkISoXDtcctNmp6+vrOdICH5j05UgeNpBeQgJOYRMWjSMex6v0gWPBgW1e85sf3brmqjCkxFMz5jz23c1/9efuMyFKggQ4WvTOOXK44+qRXy3xMQ0+dMPRh33mtou+65jvSOd/7SvHfu5gx0zS4/Mu2rlqxzfbC8/V8MOLe2d9obBOYGSMU13KdfnAqT2bCpYWoo28HJglURGXHZWjyRHOLO9wD3OCJxSwp5OYccuJRIIs8S2kBeHBcqm6T3/60zvssMP3v/99fpdlUmvDbfgvazOTvhCPx/fdd18zEBrwfH6iaA5sutbLQNWCp6enh8YQi8Wof2LBAjYBzc/cbjBhf0tYcNgvSYjKgoMb+6M5L5iLmOykHGb9PYyHCgIACovbu7l4x4GOI17RDlnY5vW/vfjqVc23rplX2rTwNz/GfkfeG7JzJkR5IgGOEJvfXNvfdpzDHvNNeGyyS28MI7TZBNjMT0lvcAJMGlx00rtrH7HL6ZqlyYcnmXgdXeRMz/ksJcMhxL0DYxScxSmRPe0O4/9EOWY0l1HKo446ylz4JwCiutjuhAh8ZuXMpw4R3fRwgYCATKaPB+MzX0n1sfsCTo5xvfHGG+QwZaEm/0Xbgh15Pv66wqAdsk1pGLQKGkPB1W6qsaGhIQy3G7jFYb8kIcocDuMc883gHY7zHMbZrxOJRBQu8xEGUGrOUy6PY+ZcM+HoKt+5/6VE6+NnLV09xyGlRUvzV51/U+cM9f2KCkACHCFG/j0xeONZI7+8sbDU27Hoo3vufuznalNzcNpLTzx28MHFSQE+MzXfJDM/tXxSgP/23VR6fO6PxwT4rvmO+XmlwVsv3Lj8Eruc7kDeqqurjbmZkxkne/f9q6XCpQM3JZ+cnG6h2WBVGCwSwppR3y9+8Yt/93d/l7y+MWny5MkEBMzkXyzgfrQbMhOPx+2JpKz6+9QoYjK2nfElQhAymSopmSymA7e2tjpsPwpQ52xQvJe/fC64+Bs2bMCf2XxsNXtWueCwX5IQ5QbHcw6VHN7NZSyOnBy3mWR/jM4xjfMIp0uK774v11w6L9VR67n/enzmI6cseebypWvmFjPd9Ozs2b8+Q0+9EhWDBDhCjD3+6t4rHOroPmGwtX+/3zv3X+eYn02AHSlQAR558NreWV+wy+kCTnh4C/E3EQDeW0xl8g4BCs6Qo+PR3IfpkFVUnxM2Z26+TpHN1W4slxM5nwmAmA8sAxdddNF222138skn21/OE4InqteMvmZtyKpLc3aDuVqRPs4WDcPS7YltI9P87XDOgcP2Kxg2JS2HBkNroXq9bFNaCI2NVdFIyjLUdtgvSYhygL0Y0+OoxfHfvFWOg2dHR0cER7Jw5OH4w1HIze2+KThwpS6dl4r/6fvjzEdOveY3P1y6Zk5x0qLfXTrrkcYX/+dJOwdClD8S4Kiwpe+t3tYjnN7oOpnu34yWawR4cfOpLIBQTZk8+cm2i82/0qU3/fO6W66YNnUns/AVpx/vgwD/8sb+a77+3utr7NJmh3Me537O+pzwyqjj14E5B2cMWWbOnLn77rubJ1EhZpSUMlLVLM9nys78RCJBGJTukOmYIal33XUXnhOLxQo705M3Aov77ruPVfFb9lzPkBlW67ha0ZPp7UqUtzgOTIuiltINvMKgMgkQqeHa2lpajveBymw+gm9aVzmNeXbgsF+SEKGEYyZHQnPPCCcC9uKmpiZ25GzH/4jAaY5zBEch9yc4DvVEC1RgGA5cg6O9id9dggZf97tLb1kzJ7i0+JmfX/7r0+c+3vT/Bt+0f1uIikACHBVGn142kPjOyMM3FJbW3Tx77912ffLqix3zSYMPJI4+9NNj3pv87/nxL491FK+41nw+NlZrFkt9Nsubz733X4c2jwnwnVeZxQpOgzedM/zwHLu0WUB0kUC08M9//nPZdfymw5n4ggsu2Hvvvb///e8jtBQKCG5g++23/8d//EfCHea3J18slNfZmlAJw0zFRm1tbdRSYSbJT1dVVZ199tn2tGfYfIQsGQeqOQZCAwbOwqYXOmioYX6LPNjTFQFxobnOQsXywZcOIiqKvY91lul+9zcc9ksSIhywl7F/mfMCR2B2N3Y6joQ+Xogsazi7UTN4bF4VwtkHW4ZQXS5/7f97CTVFUBc/87Nb1lzpb7rxmZlXPn72ZQ83rH3rKfv3hKggJMBRYeCGU4bumuGQRvdpQgG+7cdnmMnH5/4oJbQZBdixqvTlvaThFVf1zjnSLm0mCAs45+G9BAdIXVl0/GIdnKQxK6IZc1svRcByzdA1zARZxYFZBtavX89kh4d38xAkES05VAcRisVinPjzEmlAm/fZZ58DDzzQl3o2Ha2IvT09DsdAaKAgVBdVZ08HCbXk6IUuU9jK5jFmtARq28duIloXVcQ2Sr9OUa447JckROng+M/+xTGQ3dacHTjucS7I96Bd2VAbnEY5CiUSCXuWO1LBgz0dMhBUNLX18e9e99SlN69p9Z6uf/qyOU+c87NfnfTEq/fZvyFExSEBjgRbRwf7Zn9p+MFFIw8vLiz13n/t2BDoMct1/mvwgeu3CfDY5ONzf5gU2nl83ia9Y/NTn9MXGD/pJfXNOfKvb2fup8JPiAwuuuiicHb8ohlEMIgHUYsZoU1uEV2yymczbpn/soxDsZBMo6ymd9RLhydmwjk+W0cfa87LrlkPy1PtVLgvt8hSCUi4PZEJYpTxCkq1UCiCHns6SMyFlWwVGHKoKNoSjY2tRnXR0ux/+AEbxYx5pj3Ys8odh/2ShCginDLYYdlVOb5xpojFYnxmTuXsYr4ymrzdl+Mzp7l8L8hS1Zxbi3Mh1QtP/efDs399+sUPfq31se+2/eYHNz07++bVrXmlhU9e1PrYWZf9smHmypMffmWpXnQkKhsJcCTY/ObavquPG35osZdkDNYxkzTwizEBvvVHZ5jJx+aMCe1/LZvH5/SvpD6/ctPle++262/mt5j56ct7TAPXnZjxZUicwAjrL7zwQs5/Jez45RyMVwCnUsAH8I2qqirCF4IYPhPBMJ8ghmXcexTLf+xjHzMBkD0rf6gW8pC7ZozGuKxA8mOuspueW8pl5hcGX58wezB+IDTwLeqWbNvTQWL6Tsuoh5OsUmkNDQ20Q/56GT6QkZ6eHmqe/a7Cxoc77ZckRJCwK7F7ciQ0Zw2UjB0WqeNkYS8hskC9UV3xeLyAq5NUL4cvTrL2dOgZHO3FhBO/u+THv/i/l//6O1c8ftaV//69BU/+mLTk2ctvWn1FKpmZc584l2WueOwMlr961Xn/8dr9utdXRAQJcCQYXb184PpThx9KeEmv3DRr2tSdjo19JjUncf7JTA78YlFSgE83Mx+b84NtQptISq+9fOrzX1Ys/Oieu19ywjF8NutMLe8xDdx41sijC+wyb2PlypW77rrrF7/4RU5jxen4JVLhrGmClebkOxUxQCwX+AwtyRcLkRkW88XGDzvssA9+8IOF9T2iQKg4uNE2liHzE9YkpWOF9kSyN5ivFCxXuBNfd1k6gsLxw6RNGQmA3JTRI01NTellDy1sDtSUSJpqIbwLomYSicS0adMK6HIpAxz2SxLCV9glOUGguOyhHADZlTh3mBNHBe5QwdBV0O2+Kcyppzhhg+9s/uumtW89tXLdHfe9eB1mS/phxzHNK45KJTOz/fmrWebZN36t/l4RNSTAkWD44TkDS77n0MUCknFd43JghDZfASYZ72UNLPkfV/143z1280WAB2+/aPD2c+0yJyGy/9CHPjR16lSicN9D/O7ki4WI8glKcAlOtNXJccsmUiFqYb65Qu8Yl+sv/Aon+EWLFvHr+Tpwqnc0r8qhRIQF2aqUwpKTnvffe8ZMvlLA8Dy+SH26r0AzEHp8uENWzSBq35uBA9ZPlea4V7m0UJMoOlVEJmm6js3kF/xKLAkBqD2rwnDYL0kIz7C/sFeyh3JI51TCHsSRhLOYBjbnC0c2Dvgc6MxApALg3M2JrGKPYEJEHglwJBi4+cyhOy5x6GLlpY3LW/vmH2OX2bIuueSSD37wg5zD3OtTRrAp4HSIaqK1mANKRnRSU1Nj7JH5xCgsU/wwhd9NeW/6Zzdgv4RZhQ2c5rsUnBpw1C36Rx4ydvYSiPCvvPouKAtVnW/XcXt7Oz+UUXTJMzFl0P0nrJ8MFBx4BQEts6WlhVyxydra2vK9UOIeyk7IzlajNdqzKhKH/ZKEyB/2RI5v7JucSsw5BW1jD/V4zooyHPk5I3MI8jL2xFyDCO44KYQoORLgSDD2COhlPxl+8PrKThvvm5N6EPSRRx65/fbbn3322S57/DhTYrArk2+PMOGIiUgAZeIzM/kXwQqLBdRvli/khNN8+iVq9w7MMixJiezpgqC6TJxhTycNE+yJceQ1PJgtQjjYWtBjvQgis4k9ekZkU3Bg5BKEM2NHdJFhKxNMU41sazZT0BdoaH6UmpoPunpLj8N+SUK4gPMRhwUOvBwJ2Vk4fvKBSWZW/l4TPGbQcryg230NbCBzmVubQ4jKRgIcCdBC5NChixWZ/nLZwW+88cY+++zzwQ9+8LHHHrPLnwbnRUINInViDiJ1znPoAZZrXh1hYhETjoD9nVCCzBA8jb89yY0D48xexoal09PTQ6XFYjHy09HRQWXmuOLAv1gyXZizwZKsNodL5ybbQGgD25d8FhwhucRcHQj6VzJC8dm4VLXR0SL0JrH12X1qa2uj0nPlsF+SEFlgp2B/5GhmzjXsKc3NzahaSQ4OlQqVzBEPvJy4kV4OYmypHGcxIURlIAGOBGMCvPzK4QcWVXxaHK/eYYcd9t9/f+yXE2Fb8sVC5oIuMkDwgRzyuSH5YiGCEpYpx5t8MBwKQuns6fdjHDhbdx+BAlVB+GVP+wG/uNdee+22224T+o/J+YSjms21CS9RCP7JD2VbA1XHf4MOQGlghLxF60mgsGwIWjviTQw3YSX7Aj/a0tLCL2ZrjZWJw35JQmyDAwsHWCyXgxgnHQ4C7I8cDaJyeai4cE4xt/t6PKmx1TgpuLk+K4SoACTAkaDvirqN913lcMWKTAf83Y4f+MAHiDlqky8WIgRBdDkvIroVc7kd5YglH45iT2cCEcJJxru96ZYc32/sHbK07777UueEI/asLBAFZsxbCmOn3r2RoDPbQGigioiZgr78wWaqD/6h0LguIaB5lRGt3cuFg7zgd6lDfnTCjV5pOOyXJCIMBytOMZxr2Nk5uLFTmMFEzCzazhhBqFsqmQrnr8d6NmelRJge3CCECBQJcCSITg/w/KM/OnXq1MmTJ5988snl2LXrhngSeyI74x04OOVDWRFgPrS2tvIT/JCZnw0WyKa4Po4cZv1khhjUnh4HrhhQhaRDKJz7akXBUDQMn+qqq6ujSovW1QxsIMpVU1OTo3orGYf9kkTEQJk47jU0NKQGNre0tHR0dFTMldaQY47evlx9Y6txFA3iurAQIrRIgCNBUoBbhx+4ruLTXy47GA0gNN9333333HNPghKPw6LCBjFWbW2ty6vdnNFTgme6VYOQve7kA59SYR+T5JBNkNvHzPhAe2IbZI9AxEenogYodY7qMlUUaOhDPRAi+9i3QC1Re2SbemazFrn3NdXr0tra6rHXRYgygiMbZxN2vVjyve7mZlH266CvoAkHndtu9/VlSDmHUI5m2ohCRA0JcCToX/TtoWU/Hf7FdZWdNi6f13eF7VTEJRhCU/JlBigQJ7li9o8FBIWiLHkJjxG8s846iy8G0TWBAlHDji5fZiLqucWSZRDg9K5RykUmJ+w9zpfcA6EB3w7agal57z0MrATzxKWBD9nu8Q4UisCv19fXR27Ms4genDJo8OxrHKnYfzlKxOPx1uSr3XXppyRwDGQTsCH8uq7NCYgDWhBnRiFEyJEAR4Kx1yDdccnwL66t7LTx3tbUa5Cgq6uLcxvy8+ijjzY0NBDB8Ll8T3WEYhShAO35yle+ssMOOzz55JP2tK8gutStPfF+Ojs7qX/8M9ulB+ZjvCaUMSIdxANI+BUCpty9yjQVlvHdvdMxml3A5kM1E4kElcPXCddK1VNBNgg92V6BXikQorSwn6K4HNNo6ubVAGZgs674lBYO42wIzoDeb/c1sBK2ciz418ILIcKJBDgSDHf8fGDJOQ5drLw0dNtFAzefYZc5CSc5BAwNQzxQX/yBMyhxfG4dCiHG0PJ1D3OOr6+vv++++/i67+5kpC5HAGHqn1Ay21g1ssQW4b9sFLDn+g31Rh5yh03khGUCdWDTge8y3mIxMsO2o36ow9K2WHNrNwFo7joUouzg1MCO1tTUhAuZgc18Zk6prjSJ8ZjxXJzL/LoMwdGVzc0ZRwc0ISKLBDgSjD69bGDRqcO/WFjZaeDGs4YfnmOXOQ2iGU6fxm048xkPwYqZUxbnP9SdDJNte9odlBR9Sp3jkUB/HZj1s0I3YmZ+Ops+tbe3f+hDH/rkJz8Z6LaYcCA0mHpG9uzpAGhO3vmco6T8iwoh1Es90tn+R4kw3fg0pJKMuBbCd5Cojo4OM7CZvYxdnh3NDGy2lxChgY1Sm3yhgy+3+xo4znNMS7/7RggRQSTAkeC9V5/qv+Ybwx0LKzsNLDp5dPVyu8zvh/Cd8yiBDtpm5hADcVpFzIiEwjy8DSMqYGwwxeRbWJ89ncRfB6Yy3eeK/LA8Ycf4X0fsd911189//vOBCrBLXSc2ot5oEvZ0AMTj8YwqztZhe5kRCkuL+0jnjLBTkB8qreQSLoRH2PFRXPYsdNcMbGYfZ4/TwObQwqHYbC/O1PYsP+AExDGtLVIvLRdCZEICHAm2DL3TN/ufRzoW+Jh6773qgA/veeuFp0ybutOUyds/OffCwfvajv7spyYl2blqypu3zWYxM3PxuSd+dM/dmG+WTF+Pj6l//rGb31xrl3kc+JV54kX6tWTEmCifkIi/4RzzVl9fjzraE+4wV7gz2qlfDoyhIYr5Kqvpik/vYiUwRfnID8UM+pK8KfuEYmmuHUzYXVww5opGKgKj7PwWGYvFYolEIiQRuXkyKk2o5B4eUhzvQCKJMMFuxd7EnsW+xnmHnYvDC8cfDWQIPxxzOPKYM4W/V0U5BXBY0xU9IQRIgKNC/4KvbVz205H7r/Er9d4z76N77DYmurdezuTg8quP/uwnjz3sIPPfxDkn1O6/7zvtc838Me+dcyHzzz+uzsw3i/mZls/tnfUFu7TZ6ejo4MzquACMdcyYMYP5dSF7bRJBG6FbXkEAEV518qnX9vQ4vDswgs0aCgslqWpcl0LxdSAcIT/MJ+gh2/kO886XxiT2RHbIDC3BzZKFQQXuscceJ510EkWuqakhzmOO/b9S07ntFSPer5JUMg77JYmSwoGFYzvixJ6bGtjMYVADm8sLTgGcXJqamny/FLg0+WJ8H4dSCyHKGglwVBj598Rg4nSnNHpIRoBvu/AUM7kucdne03Y1lmv+e8CH92TSCHBqscdnn59yZn/T4JJzN957iV3anCAbxPfxeHx875bp2DQCWfK+L/JATvLKBtLCOZ5S2NNZ8OjA1F4OwXYDUc6HPvQhJDB9PcaHAw1QqEwKbpQ7N6Ojo+l3UPsFbY8iI70f/vCHd95551/+8pf2P0IAlUPc6ab9CKf9kkRxYcdEbmfMmMFOyk5Nu2WHNQObS37oFgXA1uTkW1dXF8Slt5aWFk6mnGLsaSFE5JEAR4XNb67tn//Vkfvb/EppAjw2uS7xk2lTd0oOf/4b/Hdw+fxtAjy22OOzz0sK8Cwz6WMavLbh3bWP2KV1gRlklVG3OBMTVBFR4QOl6prr6OggA3mdsI3WurE7MAsX0D1CiEmMYk8UCsHroYceuvfeexOzpl/pN/3zvl/7T8cU3E2ITCYbks/Q9u7A/BzOT73x0zQqU+3t7e3EZIEW1j1Ir8mb5MEVDvslieBBjdiPGhsb0wc2sx9JbMoaTrJB3O5r4OhtGoyObEKIdCTAEaJ3zpHDd/tmnuMFeO9puzw554LUAiYVR4CHV8zvnfn5rZs32UV1h3Gh9FtS0+GsTHSFhXJuLkAUvWA6cvP6UaJAypLXVyg+v+JSmA2dnZ2+OJsRSz5Q+WQ7fdg5gk1c6905c4DmuR/ezJLkp7DgiVJQNNqPucl8fHjX0tISdGEnBHkgDwSIGhyYBw77JYkA4CDMHmQGNmO8Ncn3ire1tamtVgYcV81J1vfbfQ2snxONLxcxhRAVhgQ4Qgx3/HzwhrNHVrT5knrvTgrwBaeYycF75x99yCePPfSg1ALp81OLPX75eTvvOOXNpbNSC/iSNi79keMNwC7B5QitIJvUcQY1Q5GJvZYW5bVJxHwOJ5wQ031XwMixvByYslMJ3i/SE+uwnpRSEsuauDY1B2PEUc3nIKAgbFD35k+Ilm8HArVEifBeysKmzNFsWCDfh5z5BSVCLWgAHge0RxGH/ZKEH9AmVyUHNiMtHNOAD0wyM68dUIQfDjscfDjUBzQKhjMpx+1ATyVCiPJFAhwhki9D+vrIiqt9Sb13z00K8MmpOYP3XoXrJsc+j5EU3ZlmZmqxbQI8M/UtX9LgdSdlewGSG0w/ZG4jQmnwZBYjGgtu2CpBHjbIT9jTLmBhdI6TvT2dJ2jzhGU3YHRgTxQKNsjPOXKLH5oR6SYbphICtTLiaX7OfUhNJZOlCSuZ1RJvEdXRVBKJhJv1U3aitGzDEIKD9kwN4N7BNeZKxmG/JFEonZ2d7OwcW9jFOHGw73A04EBR8DFNhByO82xrNnQQt/saWDOnxeIfV4UQ5YIEOEJs3bypb/aXRu690mGPFZD6Lv/nLUPv2OUsCIIwfIDAy57OAqdVAjUMh7++n7xxofr6+rwk03ROenQYNw6MLxFP5OjJdAOVTNVlG75oNgEl4le6u7v5nNeI7nzJayA0mIEAGYNycku2+S/bgsXyDdxZnu9671p3CbmlmRGABlq9FY7DfknCNbRA/JZdBgXCeNlr2BMTiUS2I4OoGFIHHzeXXAuGlXP60MP8hBA5kABHi5FfXzt4w5kj982vpDR4S/PQMh9eIdvX1xePx2Ox2IQCg3DO2PbaJB+9BSVjhS4lk8WIGgu+PdVBbgemvBiax/CUWuUncg/tpiwUivCI3zJBTL4y6R4qkELlFYc5hpqTNzOcm/XQHojtzPwCYJ3Tku9DtqeDgSKTT36IbLtsZiIzDvslieywX7Oj0faQH5ofOxFHWiZXrVqldhgRaAPNydt9Ax3aA+Yorat7QojcSICjxdbNm3qv/Mrw3bMdDlm+aXj5vN7WIzx2/6bD6ZnTpxutJXTjXFvr02uTjEq5XAk/TSgJPoaPORyYHyJatScKgnJROpcD0oz6trS0sHygz4giSOKH8tpwCPxee+116aWXkjG+29TU5Je1mj724AYkU6usH/HQmGcfcNgvSbwfdi6Oig0NDez4VVVVZmAzjTy4S1oitNASUF8E2ONZckI4ZXCUC/pKohCiApAAR47R390+uOiU0fuuqow0dMN3hx/0+T4fTp8EbbiNS/Ui1MMrzAm+sPAOreLrLr9LDIF95TV81yUZHTiRSPBz9kShoNB5PeoJSeMr/O4RRxwR6DOi3A+EptqXLl1KrnbeeecPfvCDs2bNsv/hHwEJP5VJ+yQuzHh1QxSCw35Jkae7u5sdhGMgbdgMbGbn4ughG4kyHHM4mXLY9DJAxiUcyWl1usIihHCDBDhybN28qf+6bw7ffsno8nnlnkbuneNv928KbAfv4mzq/rTNedcM8UI28hp/1ZnzzlgHyAy54ofsab9xODDFd2/m2chraHc6xNN77733nnvuGdyoOXI1oRm2t7fTGKqqqvjLZ75iuo6D8El+AuwJP0Cq2YIzZszw3asjjcN+SdGDYxG7AE2LvZs2ZsYX0N7YO9TYBOcOvBf7DeI46YD2xm9B0D3MQoiKQQIcRTate2JgwTcdMlmOaawr+3e326UKAASMwI6/9rQLOAFja8SCaCpfnDAQxC35CZc3ErMwa/Y4GnlCUg5M5k0p7H8UhKmNguMSguyDDz548uTJK1assGf5jbHZ8TlkfmPygWfEVVSCYwFTSx4rZzzUeSwW82UTk/+i9b1EDof9kqIBjQrFbWhoYKc2A5tpqxy+2E/tJUTkoTGYa8HBXbhMx1wU5lityy5CCPdIgCNK/6JvD9960ejyueWbRtpn9l755a2bN9lFCgbkAYso4ORKUEh0iCMRIGaLDnEq4kgCSns6JxhXvjZeMMbuvvWtb3nsjcSiybN3ATvzzDO32267efPm2dN+09TUlCopZSd6o/gEVYlEIkdkz5JsPt+3CL/IanM/LSw3rIEWSxFcXlgReeOwX1KFQiOnhbODsDtMmjQpFovxmTm6qiLGw1nSDDnhEFrwRc+8oB1ytJzw9Q1CCOFAAhxRNv9pff/Vx47cc+XovXPLNA1ce+K7zxUjvuekTsyHBhML2rNcw1dMLyJ/HV9ntRgya7anc2J6KYvpM0uWLME577vvPns6fygvBSfn9rQ3Lr744p133vnII48MIq5iW+yzzz7f+MY3iKXY0DNmzHA56tv0ybu8hOEeU3WFPXbbPG+GiLA4AWhEcdgvqVLo6enhOMMuwNGpqqqK5t3Q0GAGNttLCJEJmg2tpZhDTszdQ8W5KCyEqDAkwNEFe8QhHVZZLmns2VcPzLZLUhTa29tR0EQiYU/nAzElASVfJ6ZMSSxhJbGCm47llcmnIhfhTqoUpmsaB+Z3CwsvTDdmYdWVjW9+85v/8A//4G9VkE+Msba2dvfdd0ewH3/8cfsfrsGB+Trb1572CdoJJXXp4QbCwVgS9c4FjsN+SeUMzQzFjcfjNDmMwgxsZi/TNRThhq6uLtoMh8FiXiUxZ+RinhaFEJWEBDjS4JCY5Oi9c8orbVz6g4GbTrfLUEQIE7ELwsTC4kJcF5kkSsAMjzrqqIMOOsjNevgKIamj9zhokHPznC3TFZmvA1NSiun7sDSz2rPPPtsMSvcSnfNdCkXQRumamppM3MaHwoZ8szYy5rIz3z3GzN1cIiED/HrBVytE3jjsl1TOYBHs7zQeXToRedHT02OOPP5e65wQjo38aJFPi0KISkICHHUwSXzSYZhhTsO3tQxcf+LW0UG7AMUFG8HrMNjChqcaLrrooqqqql133ZWgM3cXX2vyrYZFjkqJgzHMlHcV4MDxJPaEr1BdxD0PPPAAUVcBW4FCpT/S2TGknP+yzsJuvkVB0Wm03J72CYo5YU2yaagTlvRyRUDkh8N+SUJECY6WnJ448hT/bgvOm5yh8hodI4QQDiTAUQeT7F/4jeHbLx2958rwp5E7f9Z/TXxL31t27kvEyuSznQq783PVqlWmR5fzNydyPmM4GUeOEVgU/zRvDNOh3MzEDF06MNl22W9ZGNQVOSRLbAUTfrn5LVwXO8V7qW0Kku0rGDXr7Cnokbass76+nvX7WHZWhVdTRnv6/bCZzJhnL5djhBAiL8ztvhzrinx64njIj3JI1MU+IYRHJMDCwif75x8zetfM0Xtaw5xG7p490Bbf/OZaO98lBUfiNIzw5CVLGAvGm37bEifytkyvTcLWmFP80zyFIj/2RBouHTiRSLBYYQLpHnJYU1ND5QAVxedsY+EwQzNCD0vM/UjnFNhmYQOhwcRnLm/tdgllpEod/dLMJJ+0pYwbSwghgoAjLecIzk3FvN3XwEGPwzgHZx+PrkKIyCIBFmO89/qa/rbjRpb9xOGcIUp3zcR+31v/pJ3jcGAebeUyFMC+MJlsxtKx7bVJl156KQblr0S5xDz61Z4Yx4QOnOrctqeDBO9FNc1nskS9pXfId3d344fkFjemwvPqpqDa+VZhA6EN5I1AjXDNnvYMxaGAqW5e83wsfiXoCw1CCGHgaFOS230NHMM5LJsnUwghhHckwMLmr29vwIE33tw8evcVYUvDS3/cP/+YkPT9OjAjcrMNUk2BViFFE56/n3zySdY2ZcqUk08+2TEOOWjcjP7N4cDjO7cDxdRn6tnLZLu+vv7ggw+++OKLiZPIJFuk4Ar0MhDaQKTobwe+GXX/+OOPU0wKWPzuFyFENOFgay71clD18ZjmHvMcipKItxCiUpEAi7+xdXRwYMlpG5ec4/DP0qaNt1wwcP0JJb/vNwfEBGgJPpZDmczIWHsiC6wHazI9eybgqEt7bVKgmG5PN7+V0YHJOTOLPByXWqKKyDMfiI2o/1133XXHHXf8yU9+Yi/hAUK9ggdCG9iCVGlenc85YAMdddRR22+/fcr5hRAiaMzbhop/u28KjvDYb3HOg0KI6CABFu9j6+ZNQ3f/eHDRyaN3zw5DGrrhjIGbvlOqZz7nhXkkZsYuUGwKs8Vh7OlMGLFM1xuWxzP5IvMRvEAvvTc1NSHe9sREOByYfCLqrMFMFg1+F9etqqpCesm8iZC6k8+Fqs/z3uzxsHL01ctAaDAP8fYeONKoWA8x6CmnnDLhZRQhhPBO57b3ipdwvAknPuw3dfeHEEL4hQRYZGD0t7cOtMVHb7/k3fbZpUqjd1w2uLBh+IHZdp7KAc7TiEpzc3O663IKZ2ZuH+vq6mKZbEO8iD+QH+IA1hzEZXjjV+l5npB0B25oaCiyleG6/Kh5ldHpp5/+sY99zHF1wFyM8Kiv3gdCA1XESgq+L5pfZ9NT1ebCCtuIqtaNcKXH8Q4kkhCVAocdDq3eD6EeaUk+xyGIU54QQkiARWbee/Wp/nn/OnjtSaN3zni3/fJiptG7Zg4tOrVvbv27z5XfqCdMjNAhFouZG1DNrZu5/ceIlmNQ8XiIA5qamlgb6/fxkjyxDr9ewCV248DHH398TfKBzPbcIKHUpgbq6uqortSPMnO8gVMiMtbY2Oglb94HQkNhDozrovEUdsaMGenXJigO5cp2rUQUCYf9koQofzjUcMAZf9gpMvw0B15/H6MghBDpSIBFVrZu3jT6u9t7W49AR5FSh6YGlIauP62v9V9GHruuLIY9ZwM/wXmuvPJK/mYcFJ3CGHLuZdIhIGhLe22SPdcDqGPBt5UuXLhw++23nzdvnj0dDKhjc3MzNUmRKfv4LlmiJZQYWbWnt8F8Zk64CXLAGrBN7/VMBvLKBqrP77JpMj7Ha0PyXc0lHJconPZLEqLMMbf7Yp4eh714hHMcx/O4ry9UF0IIBxJgMQGIKDqKlA4tPuPd9lnBpY03nt17xeHDD7ZuGXrH/u1y5vHHH99hhx0+97nP5TiLm77BAnpfgWCFKIGvo68FxyuIeiwWsyfyhGyj7vfffz82XrBC5wDNY7V4oFl/7kc6UwMslvFBKaaD3TEu3T2mmN4jQpcOzA8RgLJk7oe+YL8so8GBJcNhvyQhyhaOcsm7fWOFnYx8hGNabW1t8Z8oIYSIGhJg4QqkdPj+n/Zd/k9DC7698Yaz371rll9peMn5gwtPQH2HbjsnzI96zgtci7P4D3/4w8bGRhQuo7yZe4MLvjvUwNf5iaqqKv7mVsTxsDxqV5hEmU5Ic4cYn310YAyQmqH2jLW6rx9jqhmX7+vrMxuisPCupaXFl5ucyRuFytGf3NbWRhH4OTcD/6glSqQhgqXBYb8kIcqQ1BW30t7uazBHyPQ3ugshREBIgEUeoMGjq5cP3fa93p99dvCa4zcmTh9ddtm7d83MN43e+bOhxd8dXPCt3pmfH1h88ujTyypGfQ34UjweN5/NuDJ0xUwa0EWk0a8ePIIYVsiv1Ll+bRKKHovFChvci3ShXulhCgVhjhcHZp1khnrDAJHVwsb3sgZqNZsTmj7Y8SOlJ4S6onSF1ZWDbA6MmeP8bJG8rmI0NzdTY4X1bAtPOOyXJERZwXGSIzbHW/6G4Rhijs9h8HAhRBSQAItC2Lp507trH9l478W9M7/Qf9XRQwtOGFp02vCS80aX/ezdO2dmTPx34/WnDy04cWD+cfjzxjsvePeFB8r6Rt9soCWYTHpIgdUwp6GhwbgZgoftZPO0guEXMStUDQnEt3OvHw9MKXq+IF2UxZ7YBj9HofJ1YPJMxMPaiMP46z36ofLr6ursiXH09PSQ+Xw9E0z3Ml+3pz1gOsxTlw+ot6ampoxW7AaKo+GCJcBhvyQhygdOEBxzOOT6ckzzDkc/8qPnGgghioYEWHhl85trR568Zfj+nw0sPhmz/ctlB2dM/BdhHnli8Xuvr7G/WYmYJ1SNl09MDzf72Mc+9pWvfAVD891+0yGMyP3aJHMHaWF5QLfIf8Yeg7wceOXKlY2NjWQShSP68bFCyB4FtycyYYKtfAfaUS6yak94I9VhTk6oAaq04OLzRVZFq7OnRXFw2C9JiHKAgz9HaQ6SJb/dNwVHQk6a+V6UFEIIL0iAhfCNjo4OfCbbiRxpPPjgg6uqqmbNmmXPChIsC7MiPw3vf20SykS0Udi19mx6n4J/5Xbgrq4u0+EZi8USiUQQ/Q+mgLk7k/ldMkAU6D4DbD6KVlg/7XiefPLJnXfeee+99/YehrKhqc8JH68l/MRhvyQhwg0HCvNScZe3yRQHMx4qJB3RQojoIAEWwh9QO2wzm1gaM+Rkb9Srvr4+h0b6CL9irDUlb+QhdwdpNlCsHHqfIqMD8y1zmb8mefNwxn5pHzHbYkK3JCeoo3unNXfweozVqJ+Wlhayd8UVV9AS2Bz2PzxAScmYulCKh8N+SUKEFXPM4RDBES/j4J2SQK44DxbtVCiEEOlIgIXwAdMLl02l+C/il/74JROOFHMQWnvytUkf+tCH9thjjzfeeMOe6xqjlC67GVMOTMHRbz6jvlh3MQ2N8vKjE8oqWcrregSFYmF7In/IFdvdXAdhkmCUtfnyxktTXoWSRcJhvyQhQom53bepqSlUvaxkxlwRtqeFEKK4SICF8ArWYW7ptKffD4qFmYy/49TciJvtW0GAjv7d3/3dcccdl+9rkwhWKILjQdY5oEKuvvrqqVOn8kMEXoUNt/ZOS0tLttuV02EBcz3Cjd6zcKovPS+obVyXduKoDVaIAPMv7w7ssrzCBxz2SxIiZHCo4WDFMaHL28v2fMecE4t57hNCCAcSYCE8gW9gL+OfimwwHafZfAmx5Lt53YnqBX7IPC2JnyP4QPn49QnvBzPK52bUNEu2t7ejc0awly1bxhdLG+VQQJfjvTs7O7FTsj1hJ2q+A6GpFtSUZpDjsVv8biwW895/S+U36aHQRcBhvyQhQsOGUN7uazBXfgu4hiiEED4iARbCE/hGtm63lckXG04YguBF7kcXFwy/Qj7tiSTkmSgE6zO9uxmLAARSYE9kgTKicHgvS+LAqVVhdKV1YDLgvu+abLM1WX7CoemUCLW2J3LCZmWFVMuEwsxPU1ceHZgisBI9FDpwHPZLEiIEcAAx41lCdbtvCnMPSNAnOyGEmBAJsBCFQ5CBQGaUFnOmdzn6F+NCkwhcAgpZcndakkkMDQlvHvfaJLKEUGXLFV9E21gzao1kZqwHZrKGwh675Qvd3d0UzWy0DZIAAHUlSURBVP3t1uayRe5tYTwzdycGtY0ks1ndR3t4Nc3JsQnyha8rxAwch/2ShCg1bW1t7Psck92PTykmnC7JXtjGYwshookEWIgCQXExq4y6ghrxr7zO9IgiFhqLxTz6z3iwNbSK3NrTWeB3iZzIdkNDg9FFnBZ/G58flBKh5V+slpBrwgwbB24s3fNOOjo6CLzcB4VkmNxSuhxb0FxTyFh2Ktz06iO0OSw6I3wxY53nBZsv3+Yn8sNhvyQhSsfKlSs5XtWF73bfFGaEi8cjmxBC+IUEWIhCMI6RsV8R7SnYYXBOtGpCWc0LIg/38on74bTk/4ADDthpp53SwylKZHq8+S9ldP8MLSi5A5PhWCyWl44uXbqUbUGR7elxsE7HqHJYtWoVVVRfX59X/aRjftdjIEsTYjOFsyOoEnDYL0mIUsBxhqMNx5zQDvrgqBuPxzlUchawZwkhRKmRAAuRN6gg9ptRU5ubmz1e58Z8iGaw1nw7DzNCVIQI5bsqgirs91Of+hQmdskll8yZMwd75DO5KljMiH5YSQkdmCAs3183w5jJdkabpVbZ1qkbjFm4oaGBWvL+4BlfHBh1z9f5hVsc9ksSorhwROV0w5kozPf8m0ufHBh1IBJChAoJsBD5wRkdpRzfMcgJHr9CObxf52YNrAoNLrgX0YCS4VHub381mAJeccUVaNjhhx8+ZcqU7bff/itf+YrHzABVhE+WyoEpF1VaQLCI4hJlUhv2dBo4Kv/akHzdMR9aWlq8b33DyuStyB57dYg7wZ4QQlQK5oCDAPt1wAkCDoycSjgq2tNCCBEaJMDCBza/ufbdtY+MPLF44JYzB248NWPiv+++8MB7r6+xv1OeoHB1dXVN4940Y9QOfLzOjXFl8y6XxOPxGXk+gZn8f+ITnzjggAOqqqpwp/bkI50RadaDj1FAj92bpqJK5cA4PKVw+WSydPhiLBYj5+MHFZ9++ulTp07N1kvsBe8OTG2TsRyjuIUQ5QUHBI83WRQHc5dQaoCMEEKECgmwKJAtfW+Nrl4+ePt5f7ns4P5r4oOJkwdvPmfj8ss3rmjNmPjvwOLT+hcez/L48OjTy/76dvk9DwMnHG+5fdsG9zrme4cQx9w6W8BlfiIPcuU+S2ghPzRlypQ99tjjxhtvHP+LrAobJ/aqzvnapAnhiyV0YGOVhY1RxyT5buqSBFXU1NS0995777fffgHFeV3JR215uQiCsbO9vI/KFkKUFk4HHDk5AnscGFIEOOBgvzrsCCFCiwRY5MfmP60feXRB/8Jv9F755cEbT994z4zRf78j37RxxRWDS77bN7e+f/5Xhx+eUy7dwjOSb6lxmCGCgaOO7xP2C3SRlfO7ed0RSqhE/OFG81htc3MzlkUp4vH4AQccMKFs53htkktK68B4LIUtTOA7OzvZFuR80aJF1ACbhupyX9sF4N2BzTjtvNqPECI8cJAJ/+2+Kcw9IzrgCCHCjARYuGX02Xv6rqhDWQeXnjf8i/mjj9/hPQ0/tGDo1ub+Bcf3zvrC8H8s2bp5k/1j4QMDGd9zyGR18pHI9nRgdCRf5OMy+kHtYrFYbmXC2YzPAx8oSHv2tzplhCXRPzNSOt/bjKG0DozAF3xz7LPPPvuRj3xkhx12SN8cSPX4J0L7hWlmXkYy035Yw/jx20KIkFMWt/umIJ+cU9yfR4QQoiRIgMXEbFr3RN/cowZvPGPkV4tHH789kPTIkqGbv9c750g02/7VMLFq1arxl7RNx5qXrrm8IKRAazG3CcMghJbF7In3gwIRTtXW1qLTRCqpEpn7tQrwWDLDCpEr1plvVZTQgflpojSXFxRSUNiWlhYqii9SV9RhU9rDutk6wd3wxtY3lyrs6fzx0u8thCg+5roVB8nucN/ua+DY0tDQwGGwLERdCBFxJMAiF++9vqb/+oaBRSeOPHydU1kDSAg2mt0//6sot52DEGAGuDpuZ0KJ8R9/X9jrBgSM381hqiZjjr4+IhLstK6ujoLgbCxj/yMJcuW9LHyd0If1IFruexpL6MCUmtpwVEUOKCClI6up0lGrTOKlZnMEOhAa+DkMls1nT+cP4Wm2KyMiPxzvQCIJ4R9dXV0crtnf3R+gSgtHJzLM4UWX2IQQZYEEWGTmr29vGLjlzP4Fxw/fP8ehqUGn4YcWoNyI9+Y319q5KR3YTnV1taOrcOXKlahOqZ5EYh7jlHFALFEIuU1ljFgEbUN7zEDljI8k4SseuxbTIW7DCfk5/rrstSihAxNculFWCkIOqaWMwajZHC0tLRQk0IHQwMaKeXiXMjkke3oriQ847JckhB9wxmlqauKQEtxwEt8x41Oam5vtaSGECD0SYJGBTa883r/g6xvvmTn62G2lSsMr5gws/ObocyvsPJUChAHfcJzXlybfTuQYDl1kCJIwGXD0taJGJre4Lp/JZzweJ8MUxCwwHtSu4Lths0GuTE81K3dzmcA4cEl6D9ra2gjdsv0u882Y59z331Je8k9TQZX5G2jk6rGuzCWS4o9cqDQc9ksSwhvs0RxnzNU09lN7bujhVEie872dRAghSosEWDgZ+d1tA4tOGl15o8NIi59GHr1l8IbvDD9YsreYohnIhj2RhNM8/uCybzNoTLSUMkys5mMf+9iZZ57JTKNhDj0eD7bMkoWp1ISwWtwbvaTGyEzuX+G/VDUElJkcZBsYbLp2+deE1WigsCx/4YUXuulV9gJVZFpmYXVF6yWfBdzvLf6Gw35JQnjA3O7Lfh3oocN3zEFSF9SEEGWHBFj8ja2bNw3d0zJ4U9Por28NTxq6/cKBm8/YOjpo57JYtLS0OB4axBx0LlQBinkUE9J79tlnb7/99oRQKLrLHBqZL0JXA0ESgR1aSAXmyFupHJifY0On9/GSSbJB5bjpvk4HVY7FYvvtt9//+T//x54VGI2NjfxWYZvPhK3lFWqHC4f9koQoiLK73TeFGQylS2lCiHJEAixstgy9M7D45I13XuLwzzCkjffO6r/um399u3jxeiKRwH/SDQHfIEYJ1cg0sofEfvzjH//gBz+44447nnHGGfY/XIACEbsUsyub3E742iRclP8W34HJG0JInfC7mDA1M2PGjILzwBp22GGH448/3p4ODOqz4DZJy3Fc3xF54LBfkhB50lOGt/umaGlp4RQZksFQQgiRLxJgMcbmP63vv/b44ftaR3+9NJxp+IGr+xd8jXzaOQ4SI4epu3yRBDPiNCT2S9hEwFRXV0fkRPyETGJcBxxwAJMZH3M1HnPXVr7dm75AHZqe51j2NxU3NjYW34FXrVq122677b///vy0967RX/7yl5MnT/6nf/onl8OnCwZRL3hUAo2Hhm1PiLxw2C9JCNeYC20chMvrdl8DmTeXg4M+uAkhRHBIgMVY3y/2O/LQAodzhi79ajEOHHQ/MHKI/abkkOgEI2poaCh5XxkZwBgxFvOM5ZTrGpslFsGEzaM4c2eVJfHPkvc5tKe9Nml8CFhkB6ZO2MS77LLLPvvs41c8OmvWrI985CNFuNBABTpGK7iE6q3TQ6ELw2G/JCHcwaGPHbbsbvc1mBNiMQ/OQggRBBLgqLN186axkc/LW0ceXRr+NPzggv5r4sHdD0xEki6HnOxra2uRMTNZKnBd9MwMHiZ4So88+Iz0pp5BQoZZhjxnG5nG8mhneN5Xgb1TvRlfm1Q0B0YgpyXvT+a3+FEfO0Wp6rPPPpsNxGr98uqMmOdvpcYsuIdcheFqSPnhsF+SEBPR2dnJMQHK7nZfA+fHMJwQhRDCOxLgqDN014WDd14y8ugt5ZKG7p05cNPpeLtdAP/Afzi7pzrEjAz79YLcAiBIampqws3q6uownIwGhcqOD0eMDmUcYIzd+Sh4ftGT5bVJQTsw8ShbnOpNube5QODXRme1bL4XX3yRzUTpst357AsFOzDtnC+WaUReMhz2SxIiO2aMCTta+T4wmWMLJ8TWnC+EE0KIckECHGmGn7hh8ObvOQwz/Aljx9vtMvgHrpWSQ3OybyvFuw35aXyJX8fNyACRk/2PceCKLJZRjFEv0/GYbo9IJusMzic9QsawOLJNoRLbXpsUkANTaayZeHT8ZQIqnPku76aeEOJFjJoPbCxWa/qZzb98x/xEASOusV++WI4DMkuGw35JQmSC/X3GjBnTvD1Xr+SYQ0TGi6pCCFGOSICjy6ZXHh9YdOLII7eUY8LbsXe7JH6AcyIqJkBBQYlXinyyRz/MA43QPz5kG8Ocwnhajk5FytLU1MQKTa8gxWHNZSE5KFw87bVJvjswds3K2eLZhiVTqyww4SZwSV1dnek2MdbNFgmuK7hgB6ZOyFi2ChFOHPZLEmIc7e3t7I8NDQ05rmOGH84dhR1VhBAitEiAI8pf397Qf/Wxw7+6ceSRm8s0Ye84vF0eb5jnEpsYhdM88lO0kz0/invU1tYSYaBkRlbdgCK6GalrIrALLriAQrlfeRhAfRF4c+fzMccc44sDUwNjd+DFYhMqKBslW+96vlCQdJ02WyS4kYSUkfUXcPmG5kcl2xMiNw77JQmRBkcYl4eakMORiiNheZ07hBBiQiTAEWXg5jM3ts9wKGV5peGHru2dc6T3m4E7OjpSfmIudRchZMGs+C18g59ubGzM9w5Mvkto5VIIf/vb306ePPmwww4rx/498mwuT+y5554HHXRQwQ7MehA8ahuztWdNBPrtlxDyo2wveyJ51YM1M8evTmYHBTswuaKW7AmRA4f9koRIwt5d7rf7puAYWFtbWxbjhoQQIi8kwFFk07onBq47YWTlzeWeBm44c/Sp2+1SFQSqgBQZ/8RSiFoCvdSNvxEVER7xo/wtLELCmlLGPiGIH/Y4b948xIYP5dsdQV3hwDvssMOMGTPyNXnT6drY2JjXQEQ2lo9vCUoNhE6BoOYl5HlBzMrmzrefmYqtqakJKEsVhcN+SSLycMTg6MROzd+CL9WFBPJfnyTfg60QQpQFEuDIsXXzpv5F395435UOmSzL9PD1ffP+dcvQO3bZ8gRJSHWUEbIgDMFd6l65ciUCRmxESMEvFhxVEJfEYjGXimIUrqmpyUya0d3BDb4tAscdd9zuu+++4447Uig3lwBYhhoo+LZbhJlW4UtPjmMgtIFJtiZNIi8zdwm/SMHdjJNPx+wUeij0BDjslySijbnKVu63+xo4PdUmX3dU7hovhBDZkABHjtGnbh+44YyRlTdVRhpcev7wQ1faZcsH09ll+vfMQK8gApeuri5WTmBkrNX7T+Az7t9jRASDXKUHMWTAGFf5XtenUJ/85Cebky8WoiDZ7tam1GxclvEo/Jgz4urLuAAaAJVvT6RBDslnASOWJ8QEsqkrIC7RQ6EnxmG/JBFV2F/Yy+rq6sr9dl9Dd3d3dXW1XyNfhBAinEiAo8XWzZt653xl+IGFI7+6qTLS8MM39M2t39L3ll1Cd2BHuFNDQwMf+Evs4q8QEkOYLmUcG73xyyUIsDATlxbN7/LrGctF3lhP+fbyYb9EnH/+85+RRsoIuGW652PFFDAej/tyUYNfYVP60kJoaRm7ZBFsSoHb+35hghVi3azZnnaHj0WuTBz2SxLRgwM7Bxn2FL/emlZyzPW+IC7GCSFEqJAAR4vhh64cvOX8kV8tqaQ0tOziwdvPtUvojqamJiO9aDCku5MXiIfa2tpwM0IiJM0x3tUj5JbVunw8tXmyVw7xNr18+Y6PDQ/knHo2hkadpF6btHr1ajYoMumyolzC1qTB2BMeYItk609OdVn7m3Mwl3uoorzaOZmhyH7tGkJUEhx5UgNMKmYfMWcN348/QggRQiTAEWKs+3fWF4YfXuwQyHzTultap03daVKS2y76ruO/JUm9rUe47wQmZMEk33jjDQwq356xjBAMJRIJbIHoAbUOqGeVrLocy2qu4k84Hs/4fywWC2LsdxFId2BYv379YYcd9oEPfOBTn/rUb37zGzPTR9i+aLA94QGaCtnOFjSz1WicbGh/o2rWhgDne62Hr+Q7fFqIioddGPVl1yjTI2dG2traKFSgz4AUQojwIAGOEO+9+lT/wm861DHf1PuL6z+65+6XnnQsnwcfuuFbdYe+2X51+gIlSYOJxtHVy+1y5qS9vR05/O1vf4uEePQZXIK1IQlVVVXYaaCj4PihmpoaN/ayIfkQI/fPbTI3oJbpVf+UA5N/6gfBe+mll8wFDsTefSW4gV9htb4MDsSlc/S980M0J4oz4SWMfGG1VEvqksGE0N6oXiJje1qIaJO63bfCRJFTIQecHCOGhBCiwpAAR4iNyy8ZvPXCkV/e6CWtu+WKvXfb9cm2ix3zS5uG2mcM3HCqXc7smK7Ru+++G5NBk+y5+YPr4hJ4L/aLZeXVq1YAPT09Lq/N4zbEZ/kObDa9jsRAQRckCH7wgx/stttue+21l+MCBNsF2aPe2NDulS83bAI3XesTkmMgdAqUnsy3tLT4u1Gaks97c18h5nqKRkWKiMOOwNGe42SgFzqLD4cXypXXdTEhhKgAJMARou+KuuFfLHCoY76pt2PRR/fc/djP1Y6fubj5VP5OmjRp56od//OOuUcf9hk+T5k8OWXLgw8uNjPNMm/eNT+1Bo9p+KFE3+wvbR0dtIuaCWMdV155JX8L68dbtWoV/oAP1NXVJRKJokUM/JxLXa9PPtnLnsgHysIXCYP8vW85aKgWtuYXv/jFT3/60xk3B7JqLlWw4XwpGl5NEOx96GPugdAGSmTGqPu7UWbMmJFXbw91SJsvr4YhhF+wG1be7b4GisbhxTwM0p4lhBDRQAIcFd57fU3/NV8fefgG7+nxuT8yEnvpiV81c3rvvw71HXPaO68yn/nvbT8+g3+dH/9y7d/v986KawcfSBx96KePjdWarzDfLG8mvaeB609+94UH7NKOgzM93nLaaacRx+R7CZ/Qv7m5ma+jDW1tbe7NwRf4RQTYnsgJmSSa8RLKmHvb/B05HBBYmRmLaMTMcT+wA3yVEBZVxie9d2b69XQoVuKmr37p0qUm+Lan/YC10Z7dt2Sj/dmqV4hKpSJv9zWw+3NG83gfkBBClCkS4Kgw8kjbwJLvOaTRS0p8/xQsN116jfGSkNuU6GLLZpnUBzPf8RXvafC2Hw3ddaFd2veDqyAb//Iv/0Io495/iA/wBEIEQn9EpSQ9YF1dXeTZjajgyeTTe5RGMSlyY2NjaPsE0DCyR7U4uvFzOzBQIr5C6YC41ksBEWliYnuiUNislMLNyHY2Kw045uvjyoxXu/l1g1/aXyE43oFEEpVFpd7ua6BQ06ZN0+39QojIIgGOCr1zjhxe4Vt3q0nrbp49bepOl5741TAI8PCD1/fO+sLWzZvsAqfR0NBw0EEHfehDH3IpG9gRsoEeIDkljH6QDVTNTX8sVk8045ei87sYJj9dEufPDZuGkjY3N2cUXePAE14voLowWNaD1BWmlPx6dXU1mbGnCwULJcMurbI1+bgyh/Z7IV8HjsfjNAx7IuI47JckKgWOexwfOABW6q3v5nxRYTczCyFEXkiAI8GWvrd6W48YeXixv2nwgeuPPvTTSQG+dpvNjs3fJsBjnx+f+8Ok985LfTDzHV/xJfVf8/X3Xl9jl3kbSNEee+yx33775fYilAYfIMQnMiDKD0Pog+a58Q1zLd/3DBs78u54fkExY0lyP4OKze1ycC/LNDU1VVVVNTQ0FPBcK6Jkqr2ALzog1CbP9sRE8KPUAF/xqyuYZsNWdtl4EHV+3d/B2OWKw35JovzhLMBRl/26grtGzTVE7wcuIYQoayTAkWDTuif6r20Yfmix95Q4/xTk1nx+bM4Pp0ye/Jv5LX9ZMWazt/7oDDPfCHBqGbz3v5bNM8uk5rNM7d/v9/Z9C82kL2kg8Z3Rp5fZZU6Cxe28886f+MQnchhRe3s7CmREiM8hGeS5atUqN3ddIkK+dEVmBN2qra2lWibMRqCkolKXxXTvwMDKzQ2xqF2+Nz93dHRgjx5dlK/n1Q0L5pE8fl3yyMuBTXtT35HTfkmizEF6OchkG11SGXDoYP8N4dAeIYQoMhLgSDDy5C3I4fBDCV8S7pp8BtbYE55/M/8i5vxlxcKkAJ+eWuDY2GfM58fm/MAIcGox892k/S4wy/iVBm4+b7jj53aZkw45ZcqUj3/84xkDGv7b2NhIxFNfX48nhyroMVJEDu3pLJgeOSI2ezoA+AnWXxPAO2ldYjqi2VJ5eWZeDmzAfqlMfgsfdt8Y+CG+5fGiCWV0PxDawOZgo1AtvrRb9JuCkw17OidmxEFexl6BOOyXJMqWldveIl7BZsjhhcMFx5kK1nshhHCPBDgSDN114cCtP3ToYuWlofaf9y/6tinyiy++uMMOOxx88MEOryBwx+gI9wkFEomEx+67gIjH4y0tLfZEdliMoM2eCBLT1VnkYYEEo3V1dQW7Nxs3XwcGfosw0bw2yeV3fbkzNq+B0AZzbYLt4su1ibwcmPZA3YZz3ykSDvsliTKEgwy7XgXf7mtAejmWcqTyeKlOCCEqBglwJBi44ZShZT8ZfvD6yk4b75vTO+dIyvuHP/xhxx13TLdfAh0Eg0AH+JCvFxUTJMRNpyKGnG+3oRewHXJFsFiEDgQKRemmTZvm8XZTarIABwYKazJAeSeMjKkQGpXHqwP8YmEqawYwk1vvLYGKorpc1jmLee/6LmMc9ksSZQW7bXOl3+5rYL/mTOH9qfVCCFFJSIAjQf+Crw+1z3LoYgWmjmt6Z33hjTfeMPf9UnC8gviG0z+SQLgT/nGbBCvEZBOOxEPtKFHxNR7RKszT3GN6m+PxuC8djAU7MGB3fN1cNOFDDtlje5HnCYes58b8VgFKSSjfmHxqt/ftQkWxHpd90Q1J7Imo4bBfkigfOClwmOWMUITLeaWFU577q1pCCBEdJMCRoHfOkRvvm+PUxUpMXed9cqeddtp///3Ribq6OqKcpqYmj2ZSNJCfWCw24aOeKA7lKpXM8+vIXr7jdd2AfQUxHNGLAxvIDxmjzvH/bFpuemI9XpLgV/gJeyJP2tvbyYD3SBclcNlfZJprRGNrh/2SRDnAfsoRhh1twouMFYA5KOX7bD8hhIgCEuBIMCbAy68cfmBRxacP77LDdtttN3ny5C996Us33FBmUSlWSWRmT2QBxcLESvsYXiSQfNbV1fnSSQuoFGWnXPwtoAt0Qrw7MPB189qkxsbGjH2tqKDHQenUJ5VQcEeu2S5IqcfgHgdmJW5ubOYXqdjStsbS4LBfkgg3XV1d7B3soeVyPdQjHPS8D0sRQohKRQIcCfquqNt431UOV6zI9IMvTt9///2xlJqamgMOOIAPeFpzc3MikSAUCEKu/ALtIV7JrZSYSXjGs5ENbM17b22qT8ajoObGFwcGNgEFZ1Uo4viulXg87nFUMPmkNrw0VNbAdnH5yqhskAG2iJun5pjh34GOig8jDvslibDCQbWpqYlW6nGnKCPMMSr8t/wIIUSpkABHgmQPcOvwA9dVfPrLZQdTXjzHPMsX9V2xYgVK0NLSYkZEExYQ2c+YMaOjoyM8o+DQDDKWWyZZhiKE6lkmRtoLfgITgSmKxRqK04XolwMbzGuTWCGxZupOQuqhtrbW42N1aJ8FD4Q20LDJG+vJfT0lN5SFrcNKJty4ZqRloNcvQofDfkkifNB02T3NMSq1k1Y8nPs4CnnZ94UQouKRAEeCvvnHbLx79vAvrqvstPH+Bb0/+6xd5qQGm+d8EhCkonPCglWrViHADQ0NRAmTJk0yVom0lLCLmBxOaLYsQ1ZLlcNsEFaiSehWvv5jOpALlufC8NeBoXPca5P4S7m8jDykibIG732qJvSnyPZ0QVA6Nu6E8mAeNRe2xhkgDvsliZDRkXxZF0cnH/f3kMN+Wp8kOrYvhBCFIQGOBGOvQbrjUocuek8DKxYe/dmDbv3BaY75pUob7201r0FKB51IaXDGLl9MI9VFjDAAHzDk9vb24gwhI1CbcNQrMsMyoQ1r8B/qzWVHLhVOWajkkvTAs63Jqr9bljZG+6GNEXquXLkS++Wzl7CbTHocCG2gmKyHlu+l5eD2yO2Ea2AxZMOeqHgc9ksSoYFmz+GFRuvlOlTZwVGIIrOzR+g6lBBCFIoEOBIM3nbu4K0/HP7Ftf6mgRULjv7sp279QaNjfqnS0F0/61/wdbvM74fw3TxmiRg9t/ywJGETwmn6viZNmsRfPjOH+b4rKFELPpa7uw+x9ChURcC4FhaUI/yisNQk5fXYLekRfp369NeBgYIbcYUTTjjhwAMP9BKJ0lA9DoQ2kAfWQ517uVubfYdC5W6B/BDW4UueywCH/ZJECOAIwyGI1h6d230N3d3d1dXV7Kf2tBBCiJxIgCPByKMLBhaf6dBF7ylsAjxwywVDd11olzkT6Kvpq6yvr3ffOYAptbe3E1ukdxET6GM73sepsirU2p7IBD+BrZVFVwbVi9/W1tZm7NolJKUgIXn3ZkAObEA1aWBTpkz5h3/4ByJye26euLky4h7WQ3yc+/JEbmilE44eZ8uyTCReu+KwX5IoKTRsmii7DEfmMBxhiglnB45mpb2qKIQQ5YUEOBK8u/aRgWsbhjsW+psG7rvGFuBx/ypJGri+ceTJW+wyZ4dQCQ0mUkc+C+gWI7oi4GAN6ARrmDRpEsrX0NCAITM/L+FhJazBnsgEvkFIV15GYdwyPRrDvmJJ/NI5XwjUgWH9+vV777335MmTG7O8NmlC2O41fgyENpjLE6yw4K1AjdEac9dYd0QeCu2wX5IoHRG83TcFRwn2OC/jO4QQIoJIgCPB5j+t77/q6JGOBf6mwfvaEODbfnAqn9ct/um0qTtd+u16MxMthJ2rprx522z+23vvVQd8eM9bLzyFZaZM3v7JuRemVuJjGlj4rU3rnrDL7AICesIm9NXlzavZIOhnDQhwfX09K0SrTBexefeSvdA4jCrkiNgwFvJWjmNKKZq5G+2NN94wN2CHc0QiW21Co/MCG3evvfY67bTT+BX8v4ALGQ0NDf42AAJlMsM6C/NqNw5sfqLCVWTTW84kSgFNkYMtO1dZjJHxHTOgKbgjmBBCVCoS4KjQO+sLI8vnjdy/wMc0uDwpwBeeui6xzX6Tc4497CCzQOKcE2r33/ed9nm991z10T12G/PhW2envu576p35+a2jg3aBXYOWYGs1NTXpnZZeQC1MFzHuR3BmXkocj8cxZNzAiAHLTPiL6LTHl8qWEAp4+OGHT548+bjjjit4GHARMLYWXARJS2D93d3dNDPC9Or3vzZpQvwdCG3g12laZIZc2bPywdQYf+3pTCQSCfYpv/quhRgPuwaHR5piAdeVKoOmpiZOIhHs9BZCCO9IgKPCxnsvGVxy7sj91/iYBpdfffRnP/nTE47Gfm+78BTmrEtctve0XZ+cc6FZoPeeeQd8eE8m+YAAm2UCSkO3tQzccIpd2vzp6OgwfoKU+h64E6MgDAgwGkzIghLvu+++Bx54IJKMIGX8OeSZ/JSpQmBWmD8lnTNnDhEqxbT/EUqCdmCKT1UY6UVlidrTX5s0IcT3fN33lmD6cnPff54NNw5MA0az7Qkh/IN9gWPptGnT+FumR0iPUGpOJRxj3V9KE0IIkY4EOCpsWvfEwIJvOaTRYzICPGnSpLFRzUnpRYCRYTP+OQXeWwQBHlh0yujTy+zSFgo6SlRhnC240Mr0Cl599dWpLmLEG1sgnsPDsUd+nTlh7jjNBpXWknwhUMqs0DxMnnAtzLFa0A6M7lID9kSy88rUEjNza6QBZ2YN9oR/kA2aH1ungJZGXVFjEw5hoIXbE0L4QXvyllf2iHI8PPoCB1L2WWogmvIvhBC+IAGOCls3b+qd+fnhFfNH7m/zKw0un48Ao7WJcxqSDnzBusRP9p62Cx8cS6YJ8Pvm+5h6W/9lS58/d+J1dnZiJoRZGKnv2sYKWTMObE8nIZhjDj9HWLP//vtPmjTp0EMPxXlMF3G5XOY3t9RSdeNjU3yPf4X52UiBOjChKjEr29eeTsLMRCJRkyT3uAPqc3yb8Qvz7NzcKpuRCR2YdkvRwnn7tyg7OHqwE0GYDyNBs2HDhurqan+fCyCEEBFEAhwhBm87Z+iWC0ZWtPmVBu+df/Qhn7ztglP4fP6xdTvvOOU/l/yMOcceelD6YqTeu5MCnFwyiLTxjsv6F3zNLqdPEN+jo2agnY+9DfhhjvCFH+UXkTGCPNSCJevq6piDafCBnLS3twckaV4gLKuvr8d2cvRn8q/0nuEQEqgDG4ntyPS4NX6X2uO/bO5sLY3tTuAbUJ9Pd3c3XkEe8m3nJhzPsU1ZgHIFpO4iItAsORTTkCJ7u6/BnB10RUkIIbwjAY4Q777wwMC1J46suNqvNHjvVUkBPjn1uXb/ff+87Ao+mMHPgBW/uXRm791zkwI8tmQQaTDxnZF/v94up68QwTc2NlZVVTU3N3vXYJw2x8OBWD86kTG+4V+mi5jM4CpULH/5jHuUtouYspArc5lgQj2jFGh8AaJVNAJ14M7kK52zPXqK+U1NTbQ0NmvGDOAAQQyETmF66XNcwsgIO0hNTQ1b354eB+2T1bKYPS2Ea/I6vFQ2HR0d1EPGK2hCCCHyRQIcIbaODvbO/LxDHSsj9c87evOf1tvlDADCdwSY+AM5KTiU54s5/IfwDqd1f88kjtTe3k5ciFIiGKyZDzgMjl20IYLIEvKD0OZVJ+SZDIe2VzBQB04kEtXV1TkuWPAvMyaZxuDo7+oJciC0gZbDBqWR53VJhYVra2tzyLkZ6V3CyzSiHKH90+AbIny7bwr2II7wAR2UhBAigkiAo0VyFHTzyIr5lZQ23nGp7+OfM0IcltLgbB6bA5Qmx+i1eDyOSdoT+YNdoEa4E3kzXcQ4CbEjtsl83yNIVmhuk863w9CAaPHdHEPBSwuFYisXVrQJoQm52dBE/2xHbLmtrS2ljswMbiC0gZWTQ7ZOXpdRyCG5pe3Z0+NwWWohgLZHc6qrqyvatbwww3GSvV5jKIQQwkckwNFiS99bfXOOHF4+b+S++RWT+q+Ov/f6GruEwUOsb0blYYDuL8nzlRwCQIjj+3tTUfSOjg7zu8RPposYD0HCPfYimi5K8uwlw1QjGSPMDWf3TnAOTKWZvnp7OicIQMP7X5sU9EBoAwXPdxOzJBuUnSLbV/gvzc+eECITNHJaOMcrjfUFdiVqg4Nk6hKYEEIIX5AAR47hB1uHbvju6H1XVUbaePP3B287xy5bESEiaWtrQxII6yf0STSGkC6b6S1NvpE16Av8xFLkkzyjTwjYpEmTampq0BUMGdtx+esUhG/x9QI6wDNi6jCcwW5wDkxLoD04RjjngOVxUXPN5a677qLGPF7CcAMtvLGxkc3tvhfOODBkdGBm1tbW5hgEIaIM7Y1GTttubW3N2H6iBhXCkTbHFSUhhBAFIwGOHFuG3umbe9To3bNHl8+rgNQ/718Dvfs3N4QmKBwyQ6SSzZRYJkeHBiaD2JTk5i4kljwjwMRYeE5VVRWlQI8pEblyRF04GDpEeOpe21xipLq5uTmEcV5wDkyp893u1I+5mfajH/3oHnvsUZxOITY3+cRJ7GkXmEH4GbO3IflQ6CDqU5Q1NGwaBgefcI4HKT7sKezpRRjrIYQQ0UQCHEVGf3f74KJTHCZZjmloyTkb7wnFfaRLly7Fcmtra8eLLj6QLY4hysEuwtP/ifcSieKimDA+TInq6+sx5O985zu77LIL8wOSLlbb0NBA7fnVsewjOGpAzmZu6C2gSsnMPvvss9NOO7Vkf22Sj/ATNAOc1v3Woc2zNTMWDfOnPkO4oUVJ4JhDU+GAoyc8pTDHnLa2NntaCCGE30iAo8jWzZt6r/zySPvM0eVzyzeN3Htlb+sRW4besUsVAlAagrmamhp82MxBbpnM2LeJHuA/efWtFRn8nCBs33333X333Q888MBJkyaZLmLyTNjquwyboeCpqgsPwTmwudZgT+QDlb/HHnscd9xxOV6b5C9sl2nTprkPymfMmEHLzzi0vmDzF5UEbSMej9MSwnkHRKngOMPRxveBNkIIIdKRAEeUTeueGFhwvEMpyysNLj5j5Ffz7fKECeK5WPL5vddcc83HPvaxjLdQosRGJu3p8IGfkD2cJ/2mTcqCCLW0tJB5/kWgxgdUh3DNFwfr7u7GmjC6sA2HDs6BqcDCHg1FZmhjf/7zn80zyWhyQQfNbB1+pd71a5xpGOQwowObJhTCQe+iCHBs0e2+GTGXmVaF9RVxQghRMUiAo8vwA7PHnoZ179xyTBuX/nDwlqatmzfZhQkfBDGEMlOnTm1raxsf5OF4YRYA0xlLJnN30yFCFBPPMQOYJ02ahCDxLdNFXNjoXOqENaDBRejVzIuAHJgaxhIL6/emolLXULBfc9mF9hZo56rxbZcZNg0p46aMx+NhvgAkAkK3+2bDXDDS3QFCCFEEJMCRZuCm0zcu/cHovXPKKw3f8ZP+hd/YOjpoFyOU4CEISWdnJ4E+AR/BTUpLUAgEL1BLKRjTy4fNZuy4nhC+hYlRWPSeUk9LvnuppaUFEcprhayEr6d3PoeBgByY1VJRBVQ4TciRH1bS8P7XJgUBGaYB80Nu2jCbntKNd+DR5EOh3Y+pFuXOKt3umwVz1Y/K0UUBIYQoDhLgSINDYpL4pMMwQ53aZ/XP/+qWvrfsMoQSNBIzSRkIAR+2gAZghsYHgpOTgkFmMFXyhp/bszzDOol6WSHhHV49adIkgjyqgnqYsIvYqLhLyyoabMogHLijo6M6+4uyckBOyI+jiliP2ZTxeJx6tuf6CiG7GcXqpipMJscvyV5AqX2vTBE22NDmUfPa1uNh5x17dVh9fagOdEIIUdlIgKMOJolPjt41c/SeK8OfRu6+YuCab7z3+ho796HEdG2NHyNKFHjMMcd84AMfOP7448N2pR8BQ1GwzaAzhkCaLmICPuTHvHupubk5kUiMVzVqkn+xWGHd0QERkAPjk4WNim9MYk+kwaqoVawDaI0FrHlC2C5sHX59wpVTXQj5+Eozlalhn5UKUscuzCZWV39GON5yssi4/wohhAgOCbCw8EmscuTu2aP3tIY8DS789rsv/tLOd1gh4MMk7Yk0EGACwXnz5rEAMkDQE4Z+YNwDFy1V5wzihPcSHDc1NaF/kyZNIifxeBxDJj+mfvhAvfnYL+0do22+P3SKDVHAbbE4BpnJsfn4F2tmGWrV9wsc/Dotma024UUKU2njLwwV3PstQg77NQc6Dnfq28wIewQtP1RHNiGEiAgSYDHG6Jr7BhZ8M9kP7HTOkCT8fHDRv408usDOcVhB54jyxwd8zKmtrW1psd9aTLif0uBSdX8hnxgReSACC6J7sDCoDYwo1UVs3r10yimnfOxjHzv00EP//Oc/28uVGoJXqm68znmBRkKRC7jz2VwjyK0ZVCx2HdBrk0wGaN65G1K2SqMFxmKx8DRC4RHaQ01NDbuw+vazYc4U/h5AhBBCuEQCLGw2vfxYf9txw7dfPHr3FWFLI8t+OtAWH+m8y85rWMFAiGky3nVJLBiPx+2JbbC8UVD+5buT5IYIFdciV2Hohc4N9YkTNifHQn/gAx+ghsk29YYnlza8DsKBKREFLGDIN1oL9kR2aHLYJj9RV1fnbw82a2a71NbW5t4otLeMvV4NSewJUbaw9WkGpRpRUi6Yh/ypioQQolRIgMXf+OvbG/oXfmPjLRc4/LO0aXjpj/uvPnbzm2vtXIYYIvhUH286yFuODi7Moa2tzXhdRnn2l56eHny7TMMv6mfPPfc86aSTEGDzWB3TRYz74VT8l8q0Fy0KQTiwuR873yHBFDyvbUqeaZO4KG3Px0pjtWRjvN+mYxyYLWhPJ2HvID+5v1hiNvdZfaustzusDTPG0ov/Yr3w+b8lM/P/tY8tMxr2i0pBQCsyo1p0u29uaOS0/yJf8RRCCJGOBFi8j62jgwM3fWfohjNG754dhjS05Jz+a7+5ZegdO38hhtC/trZ2vOUmEgnCnQl9hi8SOLIkOhecmhJ7EaFOOFQ1zBBn19fXI0upKjVdxOYhUpQOAeMDftXe3l6EKDMIBybzBQwJptlQ9rxs1rw2ifz7+NoktovZQDlWSCbZWRw3PPNF2j/+b0+HBGz2rcSY7v52F2v1QdZzh1kvHDeWXmm21v3ob8nMfO4LY8s8Nd1a/Qnrv1qt4agMANbtvi6hzdPywz/uRgghKhsJsMjA8AOzBxd8a/SOy95tn12qNHrnzwavO3njsuatmzfZ2QoxBDS4x/jBnzgJcWFeGoZKoQEESf6aAJZYU1ODGZZ22LBfYPLZOjzxKAqLQ6J2VOOkSZOQscbGRuYwf8IrEQVgujT9deB4PO5mSLODsWHQ+X+L/Lf4/doks4Fy1IlxYEduzdWEUHSO4b0YLB6LzT5/hPXK963/XJJH6v6p9cLRVud+1tP7WK+dV8EmzD6o233dMDo6yv7FEVjXCIQQouRIgEVm3n3xl31z64cWnTp654x32y8vZhq9a+bQ9af1zz1q9Le32rkJPSjW+IF/RIRE84V157a3t6MH4F2rUD40Axvx/anFpcW8g6e5uXnCnlKWpBpTXcTAByaZWcDdthnx3YGJkvGKfEeTUhVko7Amx3fNaAV+l4Lk2/88Hto/+wVqlO2iAz/Bf7GC9N/qKPlDoTf1WK+dO+a9GCwe+8clntL6K62ub1tP72etPbrChkazfdl8HKP8umhSwaQu93jfrYQQQnhHAiyysnV0cOSx6xBRdNThqMGlocVn9c05cvjB1rIY9myYkXxksT2xDSJ44niPt8MhAyiEF7Oq7KGJFAp9yj3adjx8i5C9tbWVeJTvTpo0idi0oaHBdBHntap0fHdgVjg9yzPVcsDyfMvL5safac+shArxLqKshBaYzcmNA0O6GNBo2S4lUIXNfdbrP7Ge/rD1YoP1xxt9Tr//3phUrz99TLDLHFoXhxRaSAFPLI8g3d3dHBlaMj0eQgghREmQAIsJQETR0d4rDkdN322fFVwaXnJu/7z6jXdesKXvLfu3ywHTD+nwBGJ3InhiRHvaGyhNXV0d4SZi4N4KyBh5gFAMKA0SonAqx0v/NlXE11E1U89VVVV8YPOx5rz803cHxhvJT75O3tTUVMBAaAdE7azEl9cm0RRrampYTzYtN1ci0v9LEYr9UOg351tPf8TqiluvLXK6q4/ppZPHBBvN3lKWPYEcf8zgdnTOy0WW6EDjnzZtmq4UCCFEqJAAC1cgpahp35VfHlp44vAtP3j3rll+JdY2dO2/ob4DN52++U/r7d8rEwgHiezH36xL7F4/rk/YIwRS8eTTmwlAc4ee/Bd/iFTUhaGxISi1L92GVCDe29bWxgox4UmTJrFyKh9DxkgxQ3u5TPjuwGzu2kwPV8sBC5OHwgZCO6AqjPBQD14uMZAllIn1ZLuggANTzFTDZnl+kQo3k8Gyuc/qOtx6od569RqnrwaREGw0e01t2Y2INqPT2RHyvSITWaixHMMfhBBClAoJsMiDv769YeTJWwYWfK3v8n8aWvDtjTc0vXvXzMLS8I3nsIbeKw5nbSP/fn3Zqa+BqB3siW0Q6KeH8v6C6ZnH9uIGGX8C9UIzyFVAGQgtKBOlxlRzC2phsE5iWeq8vr4eBzDvXkKPkWSMzmGnvjswypFvdyi5ohn4eCctxYl5fm2S6dBmB3HUmIHqZfOl5Ipf4ecCv3EdC13zmbFHOv/xhqKm7p9Yqz9lDfhzC3rQcNihwXNYy2tARMRhT+FA7XH0hBBCiCCQAItC2DL0zujq5UO3fa/3Z58dvOb4oQUnDiW+O7zkvNFlP3v3zpkZE//duLiJJVm+d+bnB246nTWU12hnBxgR8bojlCdeJ8QPuoeE9SN7VVVVzc3NKclB0lAUgtROnx7sVI4Y//dRPjPCRk/vImZDoGq4MQpHq2BD+OvA/ByblZ+zp91B3nwfRUzTMtdfWHlhjRytNdcpMrZSKpB6S62ZmmRrBtie+1ZZz3zc6v65006Lk/4wz1r9aetPS+zMhBIOL2xrtoIG8eYFR+b0qzlCCCFChQRYeGLr5k3vrn1k5InFG++8YGDxyfjwXy47OGPivwgzS7L81tFB+/tlC3EhkbojNEeKcIOi+SfRFWEWv3jaaaedffbZfGhtbbX/F2GwJnQRTytmHzjbYuXKlfhbPB4n8J00adLBBx88derUo446ilbhPSesn+2bV/8b2hxQDyqZafH22iQzNDRjczWXMFL9ZqbTOBCR+J9rrTX/x3q1zemlxUyvXWc9f7j16vfsLIUJ2o8Z/a7bffOCeuPg47inXQghRKiQAAtRCKa7z55IYhSFyN6eLhYIw8477zxlypRvf/vbgXhCGUIManpginYxYjyY4eWXX77rrrtioVVVVYiEuakVIy1sVKS5vJLXJuYr/K6PA6HToZITydcm1SZf1sWk/Q93kCt2Ijyhe9yQddZGSVO11NbWxk/ku/4JwH4xz9eutf64uPTpxeOt9afZGQsHHMfYsrrdN1+QXpo09eZzcxVCCOErEmAh8oaInCjHnkhC3INuFbkDFnNAIfjdlStXkgHkynTK6a4zA0E8+pfvyGF/wR8QCTYNH9BRPjQ0NKBzkyZNognxmTnMd+molIXNnVdsHcRAaAc0P9ohVU1Z8pVt0987fhuZjl/+mklKQcM2n32gb1Wy7/da67XFYUkvfGXMyUMAR4+6ujoaJ83SniXcwT7O7tns08P/hRBCBIcEWIj8QDsdHXEICSHj+KdhBQe/aHQX5U7XITQYl8AcCh6bWmHgY4Ty6FkJhyOmHNie3kZnZyf619LSQuNhUwIfmGRmjo5rbDYvFaR58OuBP0oquV+wC1AK/uZ1CYYvmm3kkGfsl7UZB6YULEDlmH95YnTD2H2/f7jaei0RovTqwjEnx8xLB/VvbvctQmupPGjzGS/lCCGECCESYCHygEDcDPi0p5MQNaIu6SIaKCgBSoMPpEt4OuSEOIxlyJU0GBAnYtMSDoc2XUPjHTgd9MN0ESOQCOGkSZPMnczMYYuntjUbl//mNdaA1VL8fPtmC6Mv7bVJed0OYL7l2LOMVJiZZpCFVzfb3Df2zOfuGU7/DEPCyTHzUrwbiUZFM6Oq+Vu041glYS7WFP/+FyGEEIUhARYiD1Apx4BSAndUszgdjDhMPPkqYNMtNiGYA3nDoxSZUWMmvreniw4thA2RVwbQP3yPryCTZL6qqooPzc3Nl19++e67757XNi3CQGgHtD1EnebX5vq1Sd3d3Sgu+UxfnkpALYwDb9iwgXrwdCGj63Dr5fOt164Paer+qfVsjbWlqApKG6NWqfbiXCKpPGicNNESXl8TQgiRLxJgIdxietLSo3MkhNAnW0+sj4wmn8jKb2Hg+XbREOCiXmAsIrIQ3yOQUKpAvwAHToev0wJpBo2NjZ/4xCcmTZq0//77x+NxVkg7xB7t5TJBm8FFiz+0FSvArGi3eLub3YR8mu769Es8fJHMU3A+m32wwD3uzfnWC0dar14f6tT1LevVc+0MBwxbJ5ZE8lYwNFcaZ+69TwghRNiQAAvhCvSDQIf4257e1jeVPicg+ImamhrMzUuYhSOZHrmIa7AZauuyC913PDpwOm1tbQjwsmXLWFt9fT1bFiWmkTQ1NfEv2ozjQgmSQ8FLIv/4Kp7AzuLy1nSySoPH81NFMA5s6i2RSPDf9OtQrtjUYz31YesP11ivLgp76tzfGgr2OXY0g4aGBtpD8a+JVAw0Tpoou3PeTVEIIUSpkQAL4QrixfTHexKREz4GLZO+x6noB47ECnEkhyBFB6OCKJk9XVx8dGDHs5HZoGxftqy5KR0fRhpxY9NF3NXVRZFpTvbSRYfsuX9tErWEXSC6qc5JU28Ujc/siZTLzHfLq+daXd90qmY409rvWmuPtrPtN1Q77WHatGn8jewRwDu0RlogqA6FEKIckQALMTHE6wTfqViHD0wGbVCYjBk76nsPA1Jh7iVubW31feVlAaWmBmKxWIGDab1hXM67A9MOKUKOdtjd3Y368kMUFplEiT/4wQ9+6UtfYrujyqXa9CtdvzbJ3LlNAc2uZ+oNMeYza0i/IDUBY92/060/tFmvXlce6ZkDrQH/hyXrdl9f4KCRuhYjhBCiHJEACzEBprM3ffgxwXd6z5vvIKgEWLhNV5Bv9GXlhMKmLyiaGtyWfGUUimhPFxG/HBiTyasIixYt2nXXXc8888y6urqqqiq+yweygRoF2tjGww6FytL8+Jvjp6ko9jXqyuyAmLDZ+/785z+j9IlEwiw2AetPt7pOsP5wXdmkl1us1Z+wM+8HHFI4nrCtUz3qojBoq9Xb7kgXQghRpkiAhZgAokZMyZ5IDr8klEz1BvsL4X5TUxNW4Day9wx6j4HgQpQrgv1ChLN4FHUe0AbNgV8OjNLQYNzfH97S0pK6fMPWX7lyJXlIdRGTpYbku5dWrVpVhPZAJZi7stnLcmj80qVLWcZYh3FgWL9+PSoy8U3FQ11jd9X+4doyS6sPsd724dIMG5ENSkWV5EJPhWGGJET8MQpCCFEBSICFD2x+c+27ax8ZeWLxwC1nDtx4asbEf9994YH3Xl9jf6dMwAQIze2J5AN4CCUDEgPiKtMhhhXYs4oFIoQA8+uoIJ/tudGA2qbOU32MxcQ4ML9uTxeKaZYumw0CietmC+LRaf6FJNPsaQ/AByaZGWjnIeunKihFW5bXJrHTIb2pUetUGp8fe+wxhGSCFvufP7Ke/79OvQx/Wnv22EubPMCG5vBlLhwU//pO5UETpTInvuAihBAi9EiARYFs6XtrdPXywdvP+8tlB/dfEx9MnDx48zkbl1++cUVrxsR/Bxaf1r/weJbHh0efXvbXt8MuWkT86bq7cuVKfCCIkaKsk2geASjtAEVKajQYu4iaBhPdUnD+2tPFwi8HZsPhh/bERJhOYzfXcViGiB+PamhoIJ+miziefPcSu4PvjYSMmWH5FCfjyk13sdlMVBqZufnmm/H5XPL/zP7WKz9x6mX40/qrrd/uUvA7gROJBBXV1NTkZiuLCaHhcS4I4uAvhBCi+EiARX5s/tP6kUcX9C/8Ru+VXx688fSN98wY/fc78k0bV1wxuOS7fXPr++d/dfjhOeHsFjYdZalxg93d3cTlBP1m0i8I3FuSb4gxwzvDAFlCb8gSnhOpgI9NzBZHq3LZVAD44sA017q6OrzRnp4IWp17YU4HR21vbzcjI1Csqqoq87sYl1+dY6ivuRBDCxy/TjZTLBYj86gd2WCTnX322Uxm7uQc7rae/qj1h4VlmQoaBU2N0ZzYKLI1vzCXWqJ2TVAIISoYCbBwy+iz9/RdUYeyDi49b/gX80cfv8N7Gn5owdCtzf0Lju+d9YXh/1iydfMm+8dCQFNTU8pJCLXN4Ewz6RdhfigrVmaeEZVRQioVJIrtjlMVWR58cWDTSl2+Mctc3/He403OaR6tra1kHi+dNGkSq0VHUdOOjg4vo8rJoRnaTc2Mz6e5RmNuYGaZI488kg1n/y/5XRj79MZs6/l6p1iWS+o6yVp3UrJArsDQ2FupDd3u6xe0IhozFPmimBBCiECRAIuJ2bTuib65Rw3eeMbIrxaPPn57IOmRJUM3f693zpFotv2rJYUIkjjSxND8JbJ337fmBsSAoApV8L1L2V8oOxpMVdTV1UVHg82FCezLni4KRNg0M48ObMY2u7R39wOh84JfT3UR03JQYj5gpzQkmpDtpfnAzsjOwhZhnem5Jf/sQdTYokWL9t577wMPPJCf4NfPPffcQw45xPbh5w62fn+hUyzLJXVfbv1uj2RZJ4DG09LSQhXpdl8fobGZy1KqUiGEqDAkwCIX772+pv/6hoFFJ448fJ1TWQNICDaa3T//qyi3nYNSQNxDKEl4bSYbGhqIv81n7xBLpcY8l1FctXTpUmSGcDAinUsbNmxAR+PxeDF7fmgPtDSPDox8sqVcZrvggdDuoVB4L2qKkWLC+DDZ40exWbLqvqe9O+21SamOZbM3sbdedNFFu+6662677bbvvvvyE/DJT35y7PW/v9vd+sOCMk4uXgis232DgDZGQ6V12dNCCCEqCAmwyMxf394wcMuZ/QuOH75/jkNTg07DDy1AuRHvzW+utXNTXEx0bj4TAGF9flnQypUrTfRfpreTYSzUBhT/YVHFx8gV2yt1KaQI+OLAzc3NqCarsqezwzK+DITOC9Sio6ODXYySUr3Iqun6bm1tRZVz72s4HovhexQwdS2G3Yo53/jGNyZPnmzs19D3x2Vjt9GuX1DG6bkjrP/OeucF1cXOSFUUecR+xWMGR0ThKCeEENFEAiwysOmVx/sXfH3jPTNHH7utVGl4xZyBhd8cfW6FnadikUgkCMfNZzMU1hdZJXA34X7Ixzy7AfGgiihLFAJEtpfprreng8cXB0aKXA7aD2ggtHsoLyLHfme8vaqqyvit6SLOdvWBtof70Qj5Is4Mu+yyiy2+2+i4ucl67kvW+mvKOD33Vev1i+wyp2Fu9w3/PRTliDnsq2KFEKKCkQALJyO/u21g0UmjK290GGnx08ijtwze8J3hB4vnHt3JRz0b4yUo57P33j/ie/SJVbW0tLjplCsXqB8shUixra2tkso1HuSQkiKlRbNE7w6MELq/QkHL5OfsiRDADoh+IMDG8VBZXLehoYE5tLr0rcDuaV6bdOyxxxrpTeeUb3zGeq7eqZTllbpOdDwHiy3L9jL7nT1L+Ae1St2qR10IISobCbD4G1s3bxq6p2XwpqbRX98anjR0+4UDN5+xdXTQzmVgYB2pwb2E4ETV3u93JV4ngscuUnctVhgYCJZCyIjkE5rbcysR7ItiskHt6YDx7sAE8S6v4KS3/HBCtScSCcSvrq6OQgEfmCTPFHD9+vVVVVW29aax5+47Wl0nWOvbyjitPcd6/nN2LWy73be5ubmy97VSQcVyuPZlyI8QQogwIwEWNluG3hlYfPLGOy9x+GcY0sZ7Z/Vf982/vh1sXEI8jcvxgeCSMMjjqNeenp6Ghgai1XZ3r6Upa3At0xGHJVZwaI5rsUFpJ/Z0wHh34I7kw8zddFyzBSla0bq4PUI+UWIaG60Odcd1t9tuOyO9DkafPcPqbivj9PuLrWf2p8grV66s7EtppYV9jYN/XV2driwIIUQUkACLMTb/aX3/tccP39c6+uul4UzDD1zdv+Br5NPOsd8QTyMARD9EQoRBBNb2Pwqira0NG8SUIhVObdiwAVurqqpqbm4uF5XKFzYoEhKLxYpTwJQD88GelSc0QnLr5uv4JL9lT5QbU6dOtZX3/TSf/I9W99VlnNbN7l62M9sF+9VdqQHBTs0+wjG/4L1MCCFEeSEBFmN9v9jvyEMLHM4ZuvSrxThwEP3ABEDV1dVmdKt5WUvBkVBnZ2dtbS3hVGTvIkODEWD8n5qs1MGE5kZB7yPk3WAcGApuk3zXfiluTlg/TTdR3Lcf+8Ivf/lL23ffz647f+DiM//ZqZTlllbOnaTbfYODY1RNTQ2HLHtaCCFEBJAAR52tmzeNjXxe3jry6NLwp+EHF/RfE/f9fuDGxkYTALW2tmLChXXb8i00A/EL872URaOnp8doMHVbkRrc2dlJU6GMReg18ujA5vqOG7M1tw2HZ3uRk1VJOpKvTTLUbYOsGtGldFOmTDGfU2A1nTftY/3+Iqt7fhmndXOs30yxq0P4jWnw5XjRRwghhBckwFFn6K4LB++8ZOTRW8olDd07c+Cm0/F2uwCewVeJlVELgmyCocJusWMlfBcBLkyeKxVqA2OhZuLxeOV1iVM6cw9qEW7L9OjA5HD69OluHohlDNOeCAxzEy+Ypz0bKJ0xW7JqJJYPZg7/sheaMYOvmO+m72unnHKK+QrQ3uwb+J//nPXS95xKWV7p5Uutp/dJFlH4jDngF2cchxBCiFAhAY40w0/cMHjz9xyGGf6EsePtdhm8sWHDBoJs9MB0BRBV2/9wDV+MxWJYkBu7iCaIihkzjAYXUMMhxzyYtwiPOvPowAT65HPC3l1W7mUgNNs6Kadj2MKafJuR8VgykHJUMwfshdLMtoD7q/mWWXNDQ8Pfvr7uJOuFb1vdV5Vxeuns9KdAC7+ghdMIddAWQohoIgGOLpteeXxg0Ykjj9xSjglvx97tkniA+Bs3Mxqcb9BPrN/S0kIUpTv03IBZUcPV1dXUObpiz60Iuru7a2pqvDyqyiWsH8Er2IGRTDcPxMo4EJpvJeV0jNbWVqOsKbNlsxr/zGi2uLf54oT6XTDkOcNjol7/sfXc0Vb3vDJOXSdZL3/dLo7wCY7btNjgWqMQQoiQIwGOKH99e0P/1ccO/+rGkUduLtOEvePwdnkKgjieMJ3Ivra2Nt9327S3t+PM7+tuEu5YunQp0Sd1XkmDD2lFCDAOVoTh0PxQwQ6MsvJ1e2Ibxk4hZbaf+tSnjMpSImO2VVVVSasdg53FLMZeYL5YhFLnhtrIUCH/3WY9V+dUyvJKzx9nvXaeXRzhGRqJuW0hffy8EEKIqCEBjigDN5+5sX2GQynLKw0/dG3vnCMLvhm4M/lOV/QVl8AK7LkuINbnK4gBcb89S+QP9ksYCpX0zDBzWaTg8cPucenAxk6hra3NKOuJJ5640047HXDAAdS8MVuwvbaurrm52Sx24403sswFF1xQcrP1xP9rt1YfanXPLeP03BHWf3l6IblIgfTSyDnaT7jjCCGEqGwkwFFk07onBq47YWTlzeWeBm44c/Sp2+1S5QMBEAaLrhDxYwIu4yEWM2OeW1tbFUL5AhpMSFpdXV0xGowxmneKBtrF1NnZiQAfeuihCxcuNMpqXt8F/LrttZMm8dnM5L9mMeqZZr/77rsvWbLEXlcWMg6ELjOGuqzO/2Wtm1vGafU/Wm/rKU0+QEvmUO/mfWBCCCEqHglw5Ni6eVP/om9vvO9Kh0yWZXr4+r55/7pl6B27bK4hDGpsbDS3pLocw7xy5crp06djHRrz7DurVq1C0qjetra2CriyQBGam5tpWgU8YgftNH22mKpR1oxmSyhvauyjH/3opZdeymI0ZvNFNz9KY3Yjt6yWX7EnypSnP2L9vmXsZULlmF6Zbf12qrVF19q8wm7FzmI/G1wIIUTkkQBHjtGnbh+44YyRlTdVRhpcev7wQ1faZXMH0T9y8sADD1RVVREY2XOzgyfgvXzF+Ygd4Stsi3g8buLUCrhDz1wxScXc3d3dRlBTZoskJ8V2DNtrt5ktNDY2msXa2trMF8GsKh2XY6HHQ8YmHPvAf1mmCCO6A+S186znvmqtu7Is04vfsboOtwsiCsXsie3BP6ddCCFEuSABjhZbN2/qnfOV4QcWjvzqpspIww/f0De3fkvfW3YJJ6Knp4dg6O677542bdqEQosA4Aks2dLSUoBjiAJAg5E66hz3KwsNTpktEbZRVlqLkdjPf/7z2223nTHbmpoaM7OhocEsRtMyXwQvratgB47H42TGnsgCpSvvgdB9q6xnPuEUy3JJa75ovVXOVx9CwNKlSzngs4vZ00IIIYQEOGoMP3Tl4C3nj/xqSSWloWUXD95+rl3CiUAVfvCDH1RXV0/47iL0GGlh+fJ+DlB5gnHhdVVVVc3NzaUac04ejJ12dHQYZQUjsYAWGrOlLZk5+KS90IwZ5ouAl+LDQYfg1FUsFsv3egF5q62tnXBHQNQpnT1Rjvx2F+uVGda61vJLT+1tjepVPYXDnsjuqQO4EEIIBxLgCDHW/TvrC8MPL3YIZF4p0XyqifsNl550rGMBl2nwoRuOPuwzx37uYMf8wlJv6xFuOoETicShSXI/CgXjamho0Ki5ksOGQIBRTbaXj52QrNbY6cqVK42vQn19vfHYlNnSAMwc/mUvlGa2edkmy7M2vm5PBwAOjM3m68DUKuWdcCgEdl3GA6HXnWg9f7y17ooyS2vPs1b/b7sIIn/MHlGqy2dCCCHCjAQ4Qrz36lP9C7/pUMd8EwJce8B+73Qs4vO6W1qnTd2pMAf2V4AHE42jq5fb5cyCGcx57LHH4jP2rEykxjxXwG2olQEhrHn4NhFtbg1mkxk7BeOrkDJbFDSH2SKB5osBRcys1uQkuIi8MAemyNRt7oo1+0659qT9ZaX17EFOvQx/eq7OenO+XQSRD+wC7GugY7gQQoiMSIAjxMbllwzeeuHIL2/0khLfP7X27/d75/7rzOT5X/vKsZ+rTf23VGmofcbADafa5czE6OhoLBY75phjampqskVFnZ2d+AOLuXkyligmbL6HHnro1FNPnTp16qc+9amzzjoLZY3H48Zjq6urjdkiaWYOGK2Fjo4OY7Y+9iEXjLm8MmGPa8EU5sBtbW3sF7nvIibn7Br2RNmx+n9ba8+11s0um/Ryi/X0h/X85wLo6elhF2BHsKeFEEKIcUiAI0TfFXXDv1jgUMd8Uw4BHnxw8dGHfcaoyM5VO75513wzf90tV0ybupOZD1MmT36y7WLHdz2m4YcSfbO/tHV00C7qOBChQw45ZPr06RktCGEgYMJMKuZttOUC0mXsFFAso6wNDQ1GYrEy02aqqqrMnH/+538+4ogj0GD+NXPmTPPFMJitezo7OzH24B6rVpgDU+fxeNyeyAICzDayJ8qLsRcCVzslM8xJ3b8F0d3dzc7FMcSeFkIIITIhAY4K772+pv+ar488fIPHlPj+KWMCvOJaPq+7eTZme9uPz+Dz4AOJow/99LGxWsdivfdf99E9d7/0xK+a5ffebdcnr77YLHN+/Mup5b2ngetPfveFB+zSvh8caffdd991110zviI1kUigvk1NTRov5y/GTqGtrc2YLW5mPDZltmDmQHNzs1msvb3dfDHbmFvUka1mnj7FYvbc8oGWhm3ikwGpOzWZrwNTpRP6bXkPhH7pX62uk6x1l5dBWnuO7v4tAA4F06dP10VMIYQQEyIBjgojj7QNLPmeQxoLSJitLS6mm/fOq8x8h9zivQd8ZC8m0+cbSTbCTPJXgAdv+9HQXRfapU0DDdh3332nTp06/olWXV1dBP2oQkYxFtmgupJ+ugoLNcqaMlsq024ckyZRt2ZmymyJTc0X/RpkzgrRYH6oo6PDnlU+UHvE6wE9aI3azteBsXHyk7smy3ggtN0JPM42Q5hWH2y9XX7tubSwH9F6g7u5QAghRCUhAY4KvXOOHF5hy6qXlOraNTbr6A221WcbuG7ReoCHH7y+d9YXtm7eZBd4GyeeeOLuu+/u6NpCDMzjhSd8B0ykwEuNoKbMtqmpyUgs2mNv1DSz5b9mMZY3XyzJpQScDdmDsntqNxVeU1NDNQYxHJrtkq8DswWxiNx9vGz9ch0Ivf406/m4tW5WqNOL37GeL9t7rUsEDZJ2q2c3CCGEcIkEOBJs6Xurt/WIkYcXe0/bBHghn9fdfPm2IdBjn5Ny25Ja0qTe+69FgG1zSipx6l/bBPhvC3tM/dd8/b3X19hlTnL77bfvtNNO3/zmN+3pJKavoKGhIbjn8YaNlNkuXbrUKCv+byQW7G0zaRK+ZOY0Njaaxdra2swXwV5XWEGDyXl1dXV5jYFEfaltNDiIocVswXwdOJFIkJkcXynjgdCb+6xn/sFae6H1ysyQppcvsZ75e737Ny+amppo5OX1IAAhhBClRQIcCTate6L/2obhhxZ7T4nzxwT47fsWmkkjsXwY+MX15h5gMz+VHpvzw/Tl01Pqu36lgcR3Rp9eZpc5OaQT+z3kkENS3WtE7TgS8X34dc4llMjYKVZvlLWlpSXpsGNUVVUZs6XIZg7abxZrbW01XwR7XRUBxaGYaDDqHkS3akAg7dODuX2RbZ2vA2MUuR+IVd4DoXHgly+zXvl5GNOzB1nvPGxnVUwEO7h5FHxezVsIIYSQAEeCkSdvQQ6HH0p4T4nzT04K7QIz+dicH0yZPPk38y/i88AvFuHAxrhg56od/2vZPPMVe1aSW390uvluUoA/Yz77kgZuPm+44+d2mS1r//3332233UxsRKhk3iVL7F4WXoS9Gzvt6OgwygpJhx0jZbbmQVCQ0WzLyAD9pauri8gYpUSDyyU47u7uxlTZjr5nmFaRlwPTbPBb9hd7OhNlPBD6/7tv7CZbh3mGIT3/ZWvD3w5fIje0Z7O/RPYoJ4QQomAkwJFg6K4LB279oUMXi5Ow35QJkxDm9El/01D7z/sXfdsU+eSTT548ebIZqLly5UpcqL6+PgxjnsmDsVNyZZQVjMQCiu4wW0TOXmjGDPNFKBepKy1ocGPy7VZUXVnUGKF8U1NTTU2N77dSUwN5OTCtlF0mxwOx2LPKdSA04JnY5is/C1F64VvW7yd4DZVIsWHDBo6Qua/RCCGEENmQAEeCgRtOGVr2k+EHry9+Spz/b7V//9G3l1+Tmty5asp/3TE3tYCPaeN9c3rnHEl577777u22227FihXESXgvoVIRng6KXRg7TTdbft14LDphzJYPZg7/sheaMYOvmO9G57bkokEbMBrc3NxcFtWLdpq+a3vaJ2hm7AjUhj09EUh4bsUt44HQgG0+/3XrlRmhSC+dZa35tLVFPZmuMC0zkUjY00IIIUSeSIAjQf+Crw+1z3LoYnHSQMd1Rx96kHE/CM5+x1LHNb2zvrB+/frJkyfjPAToxEktLS0ex8ilzBaMr4K59wyQClM0fsvMAXuhGTOQGfNFmW1pof7Nc7/5614CSwU5xC1pY/52XNMg83Jg85apHHmgqZfrQGhs86WjrOePdrpo8dML3xqz380a0+EKjqjsxTnGJgghhBATIgGOBL1zjtx43xynLlZi+tPFn9ljjz2I2mtqaurr63MP0USMjZ0CcbxR1oaGBiOxKbOtqqoycwCdNoulzDb8NiVSoMHmVvDGxsbwbziyOn36dH+HQ9N083Lg5uZm9iN7Yhysh8os14HQ8Mdma/UhY89efuWnpUnPHzHWF62+X3ckEgnam153JIQQwiMS4EgwJsDLrxx+YFHFpy/tv8v222+/1157XXbZZUZQ29rajLKmzBY3NmYLZg6kzLa9vd18sYzDepGTvr4+NjSRNE0i5MG0uX3d315Wyu7egUdHR9k70GB7ehw4SSwWK+MHEf15mfXMx63fX2C9cllR08s/slbX6qlX7qERcujWBUchhBDekQBHgr4r6jbed5XDFSsy7b/7jsZsDznkEGO2hE1JsZ2xdOlSY7bqQBCAs7W1taGX8Xjc94dO+UhPT49pyT6Oos/LgfldFm5vb7enx0HeWKE9UY6MvRvpAOv5b429Hqk4qes71rMHjj2PWriAXbWhoSEWi/l7R4AQQojIIgGOBMke4NbhB66r+NR13ieJ1JFeoiUzdJnQfOXKlYqcREaIrROJBIJHU1kV4lcit7a24uo+PsvNlNqlA3d1deUYemoGQpf3daVNPdZL9dYzB1pdp1kv/yTA9NK51rOfsdbUWsMaYOIKDt3sm/F4vIxHGQghhAgZEuBI0Df/mI13zx7+xXWVnTbev6D3Z5+1y5wEpcEcCJ6Qh5qamsbGRuJ+9QCL8ZgHPsVisdA+X6ezs5Nm3OLfq19MkV06cHt7Owtnu5DEblVbW1v2itK3akxNEVQ01SGu3tPaZmvNF62nP2K9rQc4uYXGyXE7xwh8IYQQogAkwJFg7DVId1zq0MXKSxvvbTWvQcoIsZQ6h0VusF9EDnKM+C0htNV4PE4DdmmtE5KXA7PvsNdks1yzQ9kTZQ2CiqauPsx68Qzr5Ut9SC81WWsOtzr3s96cb/+EcEFXV9f0AN4HJoQQQkiAI8HgbecO3vrD4V9cW9lp6K6f9S/4ul3miVDnsMgGGozOYYb4oT0rTJhbl/3qqc7LgamWbN1xrKGintD7VsJ6tsb63W5jJvz88dbvfzz2sOi8UtdJ1urPjbn0M//Lev1SvegoL8zj38J5HUoIIUS5IwGOBCOPLhhYfKZDFysvDdxywdBdF9plzgd1DovxrFq1ymgwwhm2wb2dnZ01NTVNTU2+ZMy9A7NH5LguUCEDodPZ1DNmwi/VW7+daj37aWv1P1lrvjxmtiSHEpuZz9WPLbP6EOvJna3nY9Z/t+le3wKggU2bNi3Mj6YTQghR1kiAI8G7ax8ZuLZhuGNhZaeB6xtHnrzFLrMH1DksUrDdTUtAg0N1QYTMNDQ0IJy+vK/LvQPzcznkpHIGQjvYMjo2NHrDDOu1c63nDxtLv5li/cekvyUzc/3pY8v0LFV/b8G0tLTQFPUWOiGEEMEhAY4Em/+0vv+qo0c6FgSUBu9rO/qznzLvH9q5asqbt81OzVx87okf3XM35k+ZvP2Tcy9M/5bvaWDhtzate8Ius0+oc1gAGtzY2Ij4sfVDtekRV+Q8W5dsXhgHdiMeHR0dLJnxtUyVNhBaFJHR0VH2straWh/f+CWEEEKMRwIcFXpnfWFk+byR+xf4ngaXj4nusYcdZCbPP+7wMQe+dbaZP+a9cy4082v33/ed9kDyYFLvzM9vHR20CxwM6hyOMtid0eDm5ubwxOgoq2mK3scem6GnbtpzS0tLLBbL+IsVOBBaBE9fX199ErUcIYQQQSMBjgob771kcMm5I/df43t6fPb5SeO93Ez23jPvo3vsdtuFpwwuv/roz36SDxkX8z0N3dYycMMpdmmLgjqHownqy0Y3GuxmzHARwBmamprQYO/XYtw7MK7Cj9oT76diB0KLYGA/qq2tbWxstKeFEEKIIJEAR4VN654YWPAthzT6kkIiwAOLThl9epld2lKgzuFIgQa3tLTgimzokGhwe3s7bY9WZ08XiksH7uvro51n/DkqxKVFC0E7qa6u5uBpTwshhBABIwGOCls3b+qd+fnhFfNH7m/zNz0++7yk2c4yk2kCPH+bAGdYzPfU2/ovW/resktbatQ5HBHYoGxZZK+hoSEMvkfDo8nF43GPLc2lA3d3d6PcGR+IxRo0EFpMyKpVq/y6iV0IIYRwiQQ4Qgzeds7QLReMrGjzN/XePWa8xx56kJk8/9i6sXt975ozeO/8ow/55G0XnGLmP375eTvvOOXNpbPMpL9p4x2X9S/4ml3OkIEDEOShSfX19UiFOocrDzaxeTcv5lnyd7eQGfMcXY85cenAHR0dFDxjHzgNXgOhRQ5oYzSelStX2tNCCCFEUZAAR4h3X3hg4NoTR1Zc7XvqvXsuDmyeAp203yuZOXjvVUkBPtkss02AZ5pJf9Ng4jsj/369Xc5w093dTdjX1NRUW1urzuFKAvNMJBKYJ9t01apV9twSQYtCXz0OKzVyO6ED04AzPhCrp6eHPOhtriIjNE52Fl0HFEIIUXwkwBFi6+hg78zPO9SxMlL/vKM3/2m9Xc7yQZ3DFcnS5PuEcEIE0p5VCvBPVJym5eWB1Yi0GweOx+MZn2BEVdCqx7uxiDjmCmBIbp4XQggRNSTA0SI5Crp5ZMX8Skob77g0tOOf80Kdw5UE9st2hPb2dntWKaAJYbBeeqTdODCKi+i2tbXZ02lg4C0tLfaEiDw0FZoE6LAmhBCiVEiAo8WWvrf65hw5vHzeyH3zKyb1Xx1/7/U1dgkrBXUOVwZocF1dXXV19dLSPeaHhoTBerFQNw68YcOGjKatgdAiBdJbm3zdkQYFCCGEKCES4Mgx/GDr0A3fHb3vqspIG2/+/uBt59hlq1zUOVzWoIVGg9va2koS+tNO6uvrY7FYwcOh3Tgwy+C648e1aiC0AA5i7AIaDiCEEKLkSIAjx5ahd/rmHjV69+zR5fMqIPXP+9dyvPvXC+ocLlPYQOY10WhwSa5ctLa28utoqj2dJ24cmJ+ozfT2I9qqzCfKdHZ2crAq4TgIIYQQIoUEOIqM/u72wUWnOEyyHNPQknM23hP1qFqdw+UFAtnY2IgMsJmKv43wkOrq6ubm5sL6Y40D51bohiT2xDY0EDrKdHR0sPULvvIihBBC+IsEOIps3byp98ovj7TPHF0+t3zTyL1X9rYesWXoHbtUQp3D5cOGDRuMBuOiXp7SXABYN4Iai8W6u7vtWfmAxuSWGRphbW3t+AdiaSB0NDGvyNYhSAghRHiQAEeUTeueGFhwvEMpyysNLj5j5Ffz7fKITKhzOOSgvgiw0eAivxImkUigJYU9oXpCB6YsGRfQQOioQcOuqakpctsWQgghciMBji7DD8weexrWvXPLMW1c+sPBW5q2bt5kF0ZMhDqHQwsajBayUdgixVSF7u5u0wwK6JWd0IFpbCzgKI4GQkcHGlU8Ho/FYrrcJoQQImxIgCPNwE2nb1z6g9F755RXGr7jJ/0Lv7F1dNAuhsgfdQ6HDWqeTYAfNjQ0FO2qBJaCAKPBBQyHntCB29raxo951kDoKEBjRn1pydrQQgghQogEONLgkJgkPukwzFCn9ln987+6pe8tuwzCMwSp6hwOCWwLc89kPB4vWk9pe3s7v8gWt6ddM6ED05AoiD2xDeZoIHQFs2HDBo4hzc3N9rQQQggRMiTAUQeTxCdH75o5es+V4U8jd18xcM033nt9jZ17EQDqHC45aDA6Wl1dTeWvWrXKnhskbHQ2d0NDQ75buaurK8dzoSlILBZrbW21p5P09PTwFQ2ErkhoD9OmTRv/CDQhhBAiPEiAhYVPYpUjd88evac15Glw4bffffGXdr5F8KhzuLQsXboUDcYhOzo67FmBwbZubm7m5/JV09wOvGHDBv7ryH97ezs/xC/a06IiMCMCitBWhRBCCC9IgMUYo2vuG1jwzWQ/sNM5Q5Lw88FF/zby6AI7x6IUqHO4JGAUVDgU9tDmvOC38NV8e/ByO/CqVav4r+M244aGBhqSPSHKn0Qigf2qY18IIUT4kQALm00vP9bfdtzw7ReP3n1F2NLIsp8OtMVHOu+y8ypCgDqHiwxqWldXV11dvXTpUntWMPT09MRiMTZrXtc1cjswDYMWkr5CMxC6OAO8RdC0tLTQMgt4lJoQQghRfCTA4m/89e0N/Qu/sfGWCxz+Wdo0vPTH/Vcfu/nNtXYuRShR53BxwBiNBre1tQU6hBilQVDz6tDL7cC0DccDsTQQugJg8zU2NrLXa08XQghRLkiAxfvYOjo4cNN3hm44Y/Tu2WFIQ0vO6b/2m1uG3rHzJ8oBdQ4HDTWJTGKbgWqwGbrMdrSnXZDDgclnLBZzPP9ZA6HLGqS3rq6OpqirGEIIIcoICbDIwPADswcXfGv0jsvebZ9dqjR6588Grzt547LmrZs32dkS5Yk6hwMC22xsbJw2bRr1GVBl9vT01NfXs8n4YM+aCHJFljKO0zbDntMfkqSB0OXLhg0b2KN1/UIIIUTZIQEWmXn3xV/2za0fWnTq6J0z3m2/vJhp9K6ZQ9ef1j/3qNHf3mrnRlQK6hz2HTzEaHBLS4t7Tc2L1tZW1p9tbPN4cjhwZ2cn/0q/WVQDocsRNjFbzfGCKyGEEKIskACLrGwdHRx57DpEFB11OGpwaWjxWX1zjhx+sFXDnqOA6RzG3zBhdQ57AfVtbm7GLfkbhAYjrggPju3SVHM4MDNZVfom1kDo8oI9dPr06UV4JrkQQggRBBJgMQGIKDrae8XhqOm77bOCS8NLzu2fV7/xzgu29L1l/7aIEhgRgTUCjAYjw+ocLgDUF0fFPKm6DRs22HN9gg0Uj8djsZjLNedwYCydrWxPaCB0WcEG1cYSQghR1kiAhSuQUtS078ovDy08cfiWH7x71yy/EmsbuvbfUN+Bm07f/Kf19u+JyIM+Yb/qHC4Aqoi6Mhrs++UDNor73r9sDjw6OsoGRYPtaQ2ELhNoV2wmXZMSQghR1kiARR789e0NI0/eMrDga32X/9PQgm9vvKHp3btmFpaGbzyHNfRecThrG/n366W+IgfqHC4AZLKtrQ1Zjcfj/lYUa2MTNDU1ufHVbA7c09ODSqWLtAZChxx2utra2iAG2AshhBDFRAIsCmHL0Dujq5cP3fa93p99dvCa44cWnDiU+O7wkvNGl/3s3TtnZkz8d+PiJpZk+d6Znx+46XTWoNHOogBwKnUOuwRHpa5QTWrJx2GrVLXRofTHWWVjw4YNZGC8Axs3Tsm5BkKHFjZ3fRLtYkIIISoACbDwxNbNm95d+8jIE4s33nnBwOKT8eG/XHZwxsR/EWaWZPmto4P294XwhjqHXYJ/Gg1OfwuRR1hntrt8HWRzYDPyOdWpSN6Y1EDoUMHWqa2tZbfSdhFCCFEZSICFEJWDOodzg2EiM+CXBnd3dxs7mrCGszmweSBWSq5YFZjPouSwfdlq7ET2tBBCCFH+SICFEJWJOoezgf1SJxl1tABw16amJqp3worN5sBkJvVALLba9OnT2XBmUpSQVatWuezhF0IIIcoICbAQIhKoc9gBemM0mGrxProVqUZc29ra7OksZHRgNkH6TDYKq4rsdgkJ7e3tuhIhhBCiIpEACyEihzqHU1DkeDxu3NWjBiO3sViMteV2V+PA1LY9naS7u3vatGmdnZ1mcmwYtAZClw7z/HCNlRBCCFGRSICFEFFHncP4J8VHQSm4x1K3tLTgTimVzYhxYH7Lnk5i+pDNA7HIg7ofS0VTU1NtbS3byJ4WQgghKgsJsBBC/I0odw7jPBQW80RivbzulQpkJa2trfZ0JjI6ML8bi8VMR7RZSYiuQWzus/pWWW93WBtmjKUX/8V64fN/S2bm/2sfW2a0XNWRmo/H47T86Fz6EUIIEUEkwEIIkZWMncOrVq3yftNsaEF9m5ubp02bxt+CNZgvUleQYw0ZHbi+vr6pqcl8ptrBfC4Z2OxbiTHd/e0u1uqDrOcOs144biy90myt+9Hfkpn53BfGlnlqurX6E9Z/tVrDE78kOTwgvbFYrKGhoYLbthBCCAESYCGEcIWjc7i2thZVW7p0aXd3OXmOSxBXSooGo6AFj4ZlDblHMo93YCq5pqbG3CHM55INhMZ7MVg8Fpt9/gjrle9b/7kkj9T9U+uFo63O/ayn97FeOy/8Jmw2REtLiz0thBBCVC4SYCGEKIT0zmFEsb6+HpGrsM5hFNRILMUsbBB4Z2cnX89hVuMduLu7m69Qk3wuwUDoTT3Wa+eOeS8Gi8f+cYmntP5Kq+vb1tP7WWuPDu3QaLYsDdhcdBBCCCEqHgmwEEJ4pbI7h1F681jgeDxegAZTOfX19bFYLNtwaBy4pqYm3YHNA7FMz/PYMOjiDITe3Ge9/hPr6Q9bLzZYf7zR5/T7741J9frTxwQ7TFDV2C9/7WkhhBCi0pEACyGEz1Rk5zCZR+mrq6uRfNM9mxdGobOJFpJcW1ub7sB8Ng/E4l98MfCB0G/Ot57+iNUVt15b5HRXH9NLJ48JNpq9JRQtgVZK+yysb18IIYQoUyTAQggRIJXXOUzmEXuKk2+3YWdnJ19sbm7OeCFgvAPH43HT9xvsQOjNfVbX4dYL9dar1zh9NYiEYKPZa2pLPiKaDVFdXW262YUQQojoIAEWQojiUTGdw9gvvgp5aTAS29DQwLcy+r/DgakTaqmtrY3PY8OggxgIjYWu+czYI53/eENRU/dPrNWfsgZyvS05OKhYtkIsFgvqmoIQQggRYiTAQghRGtCPcu8cJv9kvrq6mmzbs1zAwtOnT8/4FYcDb9iwYdq0aeYCAb/S3t5u5vtD3yrrmY9b3T932mlx0h/mWas/bf1piZ2ZYkENs8ni8XjZXXMRQgghfEECLIQQoaB8O4fJJLlFUMm/y9wi+RSTwo5f3uHAODa1gQnzK2hzwa8mdvI/11pr/o/1apvTS4uZXrvOev5w69Xv2VkKHvO8sdSbloUQQogIIgEWQojQUY6dwwh8PB7HUdva2txoMMtQKHxs/EOYjAOnPK21tZVJs3xDQ4OZ6QnsF/N87Vrrj4tLn1483lp/mp2xIKGezdaxp4UQQohIIgEWQoiwg7rgLbhfdXV1yDuHUfTGxkYySQ7xWHtudtrb27GyxLiX0BoHTt33S9mB8vowELpvVbLv91rrtcVhSS98ZczJg8Q8SMznMeRCCCFEGSIBFkKIcqKnp6ejo6OlpaWurm7SpEnh7BzesGED7opxkc8JBy2T81gsFo/HHcKc7sCoL59bW1u9DoQe3TB23+8frrZeS4QovbpwzMkx82CgeZhbqe1pIYQQIsJIgIUQoozp7OwMbecwmtrc3Eyu+JtbWcmteSsPxbFnJUl3YPNArJUrVxY+EHpz39gzn7tnOP0zDAknx8wDeDcS7YGKDfPgeSGEEKKYSICFEKJCCGfnMLnCwXBXPBaJtedmwgzTbW1ttaeTpDswYs961q9fX+BA6K7DrZfPt167PqSp+6fWszXWFt+uXIyOjlJv1F7hHeZCCCFExSEBFkKIyiRUncN4LL+O36Jk4596lQJVi8ViZDV9OHS6A1OimpqaRx99NO+B0G/Ot1440nr1+lCnrm9Zr55rZ9gbVBrVCGEYCyCEEEKEBwmwEEJUPiHpHEbGMFjcNR6P59Bgo8rp96yic4ixcWD+8vX8BkJv6rGe+rD1h2usVxeFPXXubw1lrRmXsLlTlwyEEEIIkY4EWAghIkdpO4f5Fdybn8bG0y03HebjwOTKnk5+i3widXxAhi+99NI8BkK/eq7V9U2naoYzrf2utfZoO9sF0dXVRc04RpILIYQQwiABFkKISFPCzmF+paamht8lA/asNMwgXlw3NdQ55cAbNmxAj2fNmuVqIPRY9+906w9t1qvXlUd65kBr4H0PA3OPuXBAxdrTQgghhHg/EmAhhBB/o/idw9gv1g0ZNbi1tRWjW7lypZlMObAxPfIJ5l9ZWX+61XWC9Yfryia93GKt/oSd+XwwL1VO1ZUQQgghxiMBFkIIkZlidg6jbfwK1j2+9xInZ35zc7OR8JQDJxKJAw88cL/99ss1EHqoa+yu2j9cW2Zp9SHW2xkuB+SgtbWVWspxZ7UQQgghQAIshBDCFUXoHGZtrJb1I7fpq+3r6+N3Y7GYce+UAyPkhx56KJnJOhD6P39kPf9/nXoZ/rT27LGXNrmGeqitrc39likhhBBCgARYCCFE3gTaOdzV1RWPx6dPn45vp2swVsxM099rHPjII49EgM2bk8wyTp7Z33rlJ069DH9af7X1213cvBPY1ANboS/txVFCCCGEyIYEWAghhFeC6BzGpRsbG1kbq0rZHW5cU1PDfNZs3O/www/fa6+99tlnnwxPfhrutp7+qPWHhWWZXIyCplpqk6878lLPQgghRKSQAAshhPATfzuHN2zYgOBNnz6dFZpxzsgec9BgVmgcOBaLTZ06dZdddjELYOPmX9Ybs63n651iWS6p6yRr3UnJOsgMZayurqZa7GkhhBBCuEACLIQQIkB86RzGbJubm/k6f43lYtRYMX+NAx900EEf+tCHjjjiiGuuuWb77bffbbfdxl6E+9zB1u8vdIpluaTuy63f7WGKPx5qldpIJBL2tBBCCCHcIQEWQghRJDx2DvN15Bnxa0y+CphvsQbU+s9//jMOvM8++6C+rNZwWmOD9bvdrT8sKOOU5YXA1CGVoNcdCSGEEAUgARZCCFEaCusc7uvrY7Hp06ejwc8++2xzc3NNTc1vfvObXXfd1XbfJIce/PGx22jXLyjj9NwR1n+32cXeBjVGXel1R0IIIURhSICFEEKUnnw7h5FkVBANjsfjV1999eTJk433pthj96nWc1+y1l9Txum5r1qvX2QXOImxfb3uSAghhCgYCbAQQojQ4bJzmEkk2dH3a9juAx+wnqt3KmV5pa4TU8/BoqTURiwW0+uOhBBCCC9IgIUQQoSaCTuHf/7znxvpddDz+Nes9W1lnNaeYz3/OQqI9KK+CHDuweFCCCGEmBAJsBBCiHLC0Tl85JFHVlVV2cr7fu6Y/S9Wd1sZp99fbD2z/4YNG2pqapqbm+3yCyGEEMIDEmAhhBDlSk9Pz9KlS7fbbjtbed/PkZ/7mNV9dRmndbO7btl5+vTpCL9dYCGEEEJ4QwIshBCijMGBjz/+eFt50/jgjh+47Ow6p1KWW1raMqmjo8MuqhBCCCE8IwEWQghR3tTW1trWm7xDuLm5GWnse6za+v1FVvf8Mk7r5li/mWIXUgghhBB+IAEWQghRxoyOjprHYrW3t/f09Nhz4fnPWS99z6mU5ZVevtR6eh+7OEIIIYTwAwmwEEKISmTdSdYL37a6ryrj9NLZ5inQQgghhPALCbAQQohK5PUfW88dbXXPK+PUdZL18tft4gghhBDCDyTAQgghKpH/brOeq3MqZXml54+zXjvPLo4QQggh/EACLIQQohL5f+3W6kOt7rllnJ47wvqvVrs4QgghhPADCbAQQohKZKjL6vxf1rq5ZZxW/6P1tt6BJIQQQviJBFgIIUSF8vRHrN+3jL1MqBzTK7Ot3061tozaZRFCCCGEH0iAhRBCVCivnWc991Vr3ZVlmV78jtV1uF0QIYQQQviEBFgIIUSF0rfKeuYTTrEsl7Tmi9ZbCbsgQgghhPAJCbAQQojK5be7WK/MsNa1ll96am9rdINdCiGEEEL4hARYCCFE5bLuROv54611V5RZWnuetfp/20UQQgghhH9IgIUQQlQuf1lpPXuQUy/Dn56rs96cbxdBCCGEEP4hARZCCFHRrP7f1tpzrXWzyya93GI9/WE9/1kIIYQIAgmwEEKIimbshcDVTskMc1L3rxBCCBEYEmAhhBCVzkv/anWdZK27vAzS2nN0968QQggRHBJgIYQQlY7dCTzONkOYVh9svd1hZ1sIIYQQfiMBFkIIEQHWn2Y9H7fWzQp1evE71vMxO8NCCCGECAAJsBBCiAiwuc965h+stRdar8wMaXr5EuuZv9e7f4UQQohAkQALIYSIBkNdYw788mXWKz8PY3r2IOudh+2sCiGEECIYJMBCCCEiw/9339hNtg7zDEN6/svWhp/bmRRCCCFEYEiAhRBCRAk8E9t85WchSi98y/p93M6eEEIIIYJEAiyEECJiYJvPf916ZUYo0ktnWWs+bW0ZtfMmhBBCiCCRAAshhIgY2OZLR1nPH+100eKnF741Zr+b++yMCSGEECJgJMBCCCEiyR+brdWHjD17+ZWfliY9f8RYX7T6foUQQogiIgEWQggRVf68zHrm49bvL7Beuayo6eUfWatr9dQrIYQQovhIgIUQQkSYsXcjHWA9/62x1yMVJ3V9x3r2wLHnUQshhBCi6EiAhRBCRJtNPdZL9dYzB1pdp1kv/yTA9NK51rOfsdbUWsPd9k8LIYQQorhIgIUQQgjL6ls1pqYIKprqEFfvaW2zteaL1tMfsd7usH9OCCGEEKVAAiyEEEJsA0FFU1cfZr14hvXypT6kl5qsNYdbnftZb863f0IIIYQQpUMCLIQQQryftxLWszXW73YbM+Hnj7d+/+Oxh0XnlbpOslZ/bsyln/lf1uuX6kVHQgghREiQAAshhBCZ2NQzZsIv1Vu/nWo9+2lr9T9Za748ZrYkhxKbmc/Vjy2z+hDryZ2t52PWf7fpXl8hhBAibEiAhRBCiJxsGR0bGr1hhvXaudbzh42l30yx/mPS35KZuf70sWV6lqq/VwghhAgtEmAhhBBCCCGEEJFAAiyEEEIIIYQQIhJIgIUQQgghhBBCRAIJsBBCCCGEEEKISCABFkIIIYQQQggRCSTAQgghhBBCCCEigQRYCCGEEEIIIUQkkAALIYQQQgghhIgEEmAhhBBCCCGEEJFAAiyEEEIIIYQQIhJIgIUQQgghhBBCRAIJsBBCCCGEEEKISCABFkIIIYQQQggRCSTAQgghhBBCCCEigQRYCCGEEEIIIUQkkAALIYQQQgghhIgEEmAhhBBCCCGEEJFAAiyEEEIIIYQQIhJIgIUQQgghhBBCRAIJsBBCCCGEEEKISCABFkIIIYQQQggRCSTAQgghhBBCCCEigQRYCCGEEEIIIUQkkAALIYQQQgghhIgEEmAhhBBCCCGEEJFAAiyEEEIIIYQQIhJIgIUQQgghhBBCRAIJsBBCCCGEEEKISCABFkIIIYQQQggRCSTAQgghhBBCCCEigQRYCCGEEEIIIUQEsKz/HzRKF8OGSZUJAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Insurance%20MLP.png](attachment:Insurance%20MLP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "1. SKlearn Multilayer Perceptron\n",
    "2. Tensorflow LinearRegressor (only for comparison)\n",
    "3. Tensorflow DNNLinearRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1333</td>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1334</td>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1335</td>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1336</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1337</td>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region\n",
       "0      19  female  27.900         0    yes  southwest\n",
       "1      18    male  33.770         1     no  southeast\n",
       "2      28    male  33.000         3     no  southeast\n",
       "3      33    male  22.705         0     no  northwest\n",
       "4      32    male  28.880         0     no  northwest\n",
       "...   ...     ...     ...       ...    ...        ...\n",
       "1333   50    male  30.970         3     no  northwest\n",
       "1334   18  female  31.920         0     no  northeast\n",
       "1335   18  female  36.850         0     no  southeast\n",
       "1336   21  female  25.800         0     no  southwest\n",
       "1337   61  female  29.070         0    yes  northwest\n",
       "\n",
       "[1338 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.drop('charges', axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       16884.92400\n",
       "1        1725.55230\n",
       "2        4449.46200\n",
       "3       21984.47061\n",
       "4        3866.85520\n",
       "           ...     \n",
       "1333    10600.54830\n",
       "1334     2205.98080\n",
       "1335     1629.83350\n",
       "1336     2007.94500\n",
       "1337    29141.36030\n",
       "Name: charges, Length: 1338, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = df['charges']\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_encode = ['sex', 'smoker', 'region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1333</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1334</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1335</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1336</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1337</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex     bmi  children  smoker  region\n",
       "0      19    0  27.900         0       1       3\n",
       "1      18    1  33.770         1       0       2\n",
       "2      28    1  33.000         3       0       2\n",
       "3      33    1  22.705         0       0       1\n",
       "4      32    1  28.880         0       0       1\n",
       "...   ...  ...     ...       ...     ...     ...\n",
       "1333   50    1  30.970         3       0       1\n",
       "1334   18    0  31.920         0       0       0\n",
       "1335   18    0  36.850         0       0       2\n",
       "1336   21    0  25.800         0       0       3\n",
       "1337   61    0  29.070         0       1       1\n",
       "\n",
       "[1338 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[col_to_encode] = data[col_to_encode].apply(le.fit_transform)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(936, 6)\n",
      "(402, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data,\n",
    "                                                   label,\n",
    "                                                   test_size=0.3,\n",
    "                                                   random_state=2020)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 160046861.09366411\n",
      "Iteration 2, loss = 159927386.17819330\n",
      "Iteration 3, loss = 159809651.99081045\n",
      "Iteration 4, loss = 159690827.31838402\n",
      "Iteration 5, loss = 159570894.64894253\n",
      "Iteration 6, loss = 159450728.77189553\n",
      "Iteration 7, loss = 159326623.09047666\n",
      "Iteration 8, loss = 159202911.93680161\n",
      "Iteration 9, loss = 159075360.93653834\n",
      "Iteration 10, loss = 158943538.05776072\n",
      "Iteration 11, loss = 158808433.19998142\n",
      "Iteration 12, loss = 158668573.17879236\n",
      "Iteration 13, loss = 158526069.59146175\n",
      "Iteration 14, loss = 158377992.49300531\n",
      "Iteration 15, loss = 158223539.35216627\n",
      "Iteration 16, loss = 158060233.82944882\n",
      "Iteration 17, loss = 157894668.36972862\n",
      "Iteration 18, loss = 157721969.72121102\n",
      "Iteration 19, loss = 157539321.11676306\n",
      "Iteration 20, loss = 157349748.86130422\n",
      "Iteration 21, loss = 157158275.48217171\n",
      "Iteration 22, loss = 156953663.04168248\n",
      "Iteration 23, loss = 156738630.34959161\n",
      "Iteration 24, loss = 156520328.48792124\n",
      "Iteration 25, loss = 156288463.67069221\n",
      "Iteration 26, loss = 156058384.00216463\n",
      "Iteration 27, loss = 155804381.41216466\n",
      "Iteration 28, loss = 155551227.12801844\n",
      "Iteration 29, loss = 155286865.19274005\n",
      "Iteration 30, loss = 155014363.37953398\n",
      "Iteration 31, loss = 154728108.84122109\n",
      "Iteration 32, loss = 154434035.54216579\n",
      "Iteration 33, loss = 154130958.60784867\n",
      "Iteration 34, loss = 153814896.61157539\n",
      "Iteration 35, loss = 153490215.88277194\n",
      "Iteration 36, loss = 153160109.51154333\n",
      "Iteration 37, loss = 152811813.28242058\n",
      "Iteration 38, loss = 152456184.53592449\n",
      "Iteration 39, loss = 152092769.47191900\n",
      "Iteration 40, loss = 151715634.63434008\n",
      "Iteration 41, loss = 151331362.99659938\n",
      "Iteration 42, loss = 150929570.54528356\n",
      "Iteration 43, loss = 150525741.45194682\n",
      "Iteration 44, loss = 150105577.41909030\n",
      "Iteration 45, loss = 149671837.22816545\n",
      "Iteration 46, loss = 149239570.06297421\n",
      "Iteration 47, loss = 148787605.10211444\n",
      "Iteration 48, loss = 148318779.64044765\n",
      "Iteration 49, loss = 147858531.05016133\n",
      "Iteration 50, loss = 147363698.48514384\n",
      "Iteration 51, loss = 146878709.74905574\n",
      "Iteration 52, loss = 146373164.08726972\n",
      "Iteration 53, loss = 145865146.63501567\n",
      "Iteration 54, loss = 145339129.86855796\n",
      "Iteration 55, loss = 144802340.04862916\n",
      "Iteration 56, loss = 144254606.85710484\n",
      "Iteration 57, loss = 143697607.81107539\n",
      "Iteration 58, loss = 143145058.40572160\n",
      "Iteration 59, loss = 142559307.37726068\n",
      "Iteration 60, loss = 141977499.33477205\n",
      "Iteration 61, loss = 141382180.64295894\n",
      "Iteration 62, loss = 140777347.00387299\n",
      "Iteration 63, loss = 140162447.49032447\n",
      "Iteration 64, loss = 139538759.64743593\n",
      "Iteration 65, loss = 138908598.27719152\n",
      "Iteration 66, loss = 138261040.00865796\n",
      "Iteration 67, loss = 137618085.03378975\n",
      "Iteration 68, loss = 136964422.98085800\n",
      "Iteration 69, loss = 136289398.89428604\n",
      "Iteration 70, loss = 135612961.81290355\n",
      "Iteration 71, loss = 134938573.18096986\n",
      "Iteration 72, loss = 134251592.39799264\n",
      "Iteration 73, loss = 133561935.34063518\n",
      "Iteration 74, loss = 132856443.01283850\n",
      "Iteration 75, loss = 132146081.33605747\n",
      "Iteration 76, loss = 131433542.83403166\n",
      "Iteration 77, loss = 130710414.04295945\n",
      "Iteration 78, loss = 129997620.69485940\n",
      "Iteration 79, loss = 129262164.20448034\n",
      "Iteration 80, loss = 128533800.54989405\n",
      "Iteration 81, loss = 127786388.62791055\n",
      "Iteration 82, loss = 127045262.86064604\n",
      "Iteration 83, loss = 126300904.96189523\n",
      "Iteration 84, loss = 125544841.08789657\n",
      "Iteration 85, loss = 124783683.66367611\n",
      "Iteration 86, loss = 124012311.26717977\n",
      "Iteration 87, loss = 123251023.98939928\n",
      "Iteration 88, loss = 122488848.95997550\n",
      "Iteration 89, loss = 121711227.05027370\n",
      "Iteration 90, loss = 120936975.37194331\n",
      "Iteration 91, loss = 120151200.95985390\n",
      "Iteration 92, loss = 119393808.18865409\n",
      "Iteration 93, loss = 118605904.41781981\n",
      "Iteration 94, loss = 117839937.31254658\n",
      "Iteration 95, loss = 117045851.44765283\n",
      "Iteration 96, loss = 116287388.25497106\n",
      "Iteration 97, loss = 115518186.75848992\n",
      "Iteration 98, loss = 114730788.66645122\n",
      "Iteration 99, loss = 113966591.33283514\n",
      "Iteration 100, loss = 113198929.63112839\n",
      "Iteration 101, loss = 112420509.00471157\n",
      "Iteration 102, loss = 111641271.78144915\n",
      "Iteration 103, loss = 110886674.43863763\n",
      "Iteration 104, loss = 110100739.70788936\n",
      "Iteration 105, loss = 109339926.32982518\n",
      "Iteration 106, loss = 108581328.65940480\n",
      "Iteration 107, loss = 107811292.46593638\n",
      "Iteration 108, loss = 107053544.08787386\n",
      "Iteration 109, loss = 106305275.03893590\n",
      "Iteration 110, loss = 105556883.14045593\n",
      "Iteration 111, loss = 104803353.95213877\n",
      "Iteration 112, loss = 104060441.59195212\n",
      "Iteration 113, loss = 103336636.60820481\n",
      "Iteration 114, loss = 102590025.02507304\n",
      "Iteration 115, loss = 101879041.72208679\n",
      "Iteration 116, loss = 101139046.30780743\n",
      "Iteration 117, loss = 100435105.18913011\n",
      "Iteration 118, loss = 99707470.49825352\n",
      "Iteration 119, loss = 99009779.56605853\n",
      "Iteration 120, loss = 98318029.13164298\n",
      "Iteration 121, loss = 97602741.39181741\n",
      "Iteration 122, loss = 96923003.61695574\n",
      "Iteration 123, loss = 96223923.07394588\n",
      "Iteration 124, loss = 95552874.08022618\n",
      "Iteration 125, loss = 94892303.74968012\n",
      "Iteration 126, loss = 94224206.70732059\n",
      "Iteration 127, loss = 93581291.50768837\n",
      "Iteration 128, loss = 92899273.99390213\n",
      "Iteration 129, loss = 92254432.39370173\n",
      "Iteration 130, loss = 91644832.70632808\n",
      "Iteration 131, loss = 90996751.68699892\n",
      "Iteration 132, loss = 90384350.52794559\n",
      "Iteration 133, loss = 89768128.96290243\n",
      "Iteration 134, loss = 89146920.03236786\n",
      "Iteration 135, loss = 88554377.63547970\n",
      "Iteration 136, loss = 87981422.30252285\n",
      "Iteration 137, loss = 87369287.59227689\n",
      "Iteration 138, loss = 86816879.51240256\n",
      "Iteration 139, loss = 86246091.35296372\n",
      "Iteration 140, loss = 85695378.86420251\n",
      "Iteration 141, loss = 85145115.93739364\n",
      "Iteration 142, loss = 84592350.89947337\n",
      "Iteration 143, loss = 84075565.10722809\n",
      "Iteration 144, loss = 83544005.52719887\n",
      "Iteration 145, loss = 83042998.67171311\n",
      "Iteration 146, loss = 82515139.22094721\n",
      "Iteration 147, loss = 82053502.60071039\n",
      "Iteration 148, loss = 81537957.88798779\n",
      "Iteration 149, loss = 81054036.29735726\n",
      "Iteration 150, loss = 80582719.80542234\n",
      "Iteration 151, loss = 80134825.08908096\n",
      "Iteration 152, loss = 79668149.46047850\n",
      "Iteration 153, loss = 79217207.75022756\n",
      "Iteration 154, loss = 78776253.85324541\n",
      "Iteration 155, loss = 78347469.42619643\n",
      "Iteration 156, loss = 77923002.77741225\n",
      "Iteration 157, loss = 77525415.21690471\n",
      "Iteration 158, loss = 77106539.59237120\n",
      "Iteration 159, loss = 76718382.21474822\n",
      "Iteration 160, loss = 76330971.52361533\n",
      "Iteration 161, loss = 75958401.96047685\n",
      "Iteration 162, loss = 75575345.36221492\n",
      "Iteration 163, loss = 75217593.30030699\n",
      "Iteration 164, loss = 74875553.33770941\n",
      "Iteration 165, loss = 74523351.80663508\n",
      "Iteration 166, loss = 74205162.46804146\n",
      "Iteration 167, loss = 73867834.01215854\n",
      "Iteration 168, loss = 73548536.70735900\n",
      "Iteration 169, loss = 73237617.11816160\n",
      "Iteration 170, loss = 72935731.73247696\n",
      "Iteration 171, loss = 72642771.60978448\n",
      "Iteration 172, loss = 72359648.97687021\n",
      "Iteration 173, loss = 72070493.08106160\n",
      "Iteration 174, loss = 71794533.91710685\n",
      "Iteration 175, loss = 71533574.28137024\n",
      "Iteration 176, loss = 71266519.18561058\n",
      "Iteration 177, loss = 71014902.23460454\n",
      "Iteration 178, loss = 70779350.05886394\n",
      "Iteration 179, loss = 70525931.32992116\n",
      "Iteration 180, loss = 70301775.70871238\n",
      "Iteration 181, loss = 70076704.39482798\n",
      "Iteration 182, loss = 69861097.30714646\n",
      "Iteration 183, loss = 69641613.92274830\n",
      "Iteration 184, loss = 69439428.37319496\n",
      "Iteration 185, loss = 69250580.36765014\n",
      "Iteration 186, loss = 69045780.99959427\n",
      "Iteration 187, loss = 68864098.97548343\n",
      "Iteration 188, loss = 68662619.92885862\n",
      "Iteration 189, loss = 68504868.86610028\n",
      "Iteration 190, loss = 68319973.73279892\n",
      "Iteration 191, loss = 68162289.63603784\n",
      "Iteration 192, loss = 68005271.07117106\n",
      "Iteration 193, loss = 67851950.56275935\n",
      "Iteration 194, loss = 67701292.54051669\n",
      "Iteration 195, loss = 67551222.64620323\n",
      "Iteration 196, loss = 67409832.85253541\n",
      "Iteration 197, loss = 67272607.27471666\n",
      "Iteration 198, loss = 67151925.82270123\n",
      "Iteration 199, loss = 67016507.89118440\n",
      "Iteration 200, loss = 66894563.27580934\n",
      "Iteration 201, loss = 66775584.78305636\n",
      "Iteration 202, loss = 66674361.36330450\n",
      "Iteration 203, loss = 66555326.91682068\n",
      "Iteration 204, loss = 66455368.91809364\n",
      "Iteration 205, loss = 66353053.97907550\n",
      "Iteration 206, loss = 66248475.82541243\n",
      "Iteration 207, loss = 66167597.19278441\n",
      "Iteration 208, loss = 66068782.02866458\n",
      "Iteration 209, loss = 65989348.03173164\n",
      "Iteration 210, loss = 65905005.95125033\n",
      "Iteration 211, loss = 65828867.94700778\n",
      "Iteration 212, loss = 65746890.01420384\n",
      "Iteration 213, loss = 65670744.02967798\n",
      "Iteration 214, loss = 65606263.33176757\n",
      "Iteration 215, loss = 65539789.94969585\n",
      "Iteration 216, loss = 65476339.58837261\n",
      "Iteration 217, loss = 65409182.16290987\n",
      "Iteration 218, loss = 65340839.62596279\n",
      "Iteration 219, loss = 65288863.46776248\n",
      "Iteration 220, loss = 65231376.78600436\n",
      "Iteration 221, loss = 65175539.96092524\n",
      "Iteration 222, loss = 65120019.43884693\n",
      "Iteration 223, loss = 65071858.43643918\n",
      "Iteration 224, loss = 65021748.48819708\n",
      "Iteration 225, loss = 64982312.27378584\n",
      "Iteration 226, loss = 64933759.56829159\n",
      "Iteration 227, loss = 64892940.86837122\n",
      "Iteration 228, loss = 64851692.74228471\n",
      "Iteration 229, loss = 64814956.43756916\n",
      "Iteration 230, loss = 64784351.29024236\n",
      "Iteration 231, loss = 64753622.57119320\n",
      "Iteration 232, loss = 64714035.43724661\n",
      "Iteration 233, loss = 64687695.66955344\n",
      "Iteration 234, loss = 64654948.78107704\n",
      "Iteration 235, loss = 64629467.04144903\n",
      "Iteration 236, loss = 64602553.70625196\n",
      "Iteration 237, loss = 64574147.94197306\n",
      "Iteration 238, loss = 64550967.33754929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 239, loss = 64525315.89017178\n",
      "Iteration 240, loss = 64501944.67726340\n",
      "Iteration 241, loss = 64480116.02707799\n",
      "Iteration 242, loss = 64461688.22482935\n",
      "Iteration 243, loss = 64437675.66896666\n",
      "Iteration 244, loss = 64422106.83637767\n",
      "Iteration 245, loss = 64399536.13638014\n",
      "Iteration 246, loss = 64384317.08618993\n",
      "Iteration 247, loss = 64366267.39102419\n",
      "Iteration 248, loss = 64351964.26072186\n",
      "Iteration 249, loss = 64336781.51618835\n",
      "Iteration 250, loss = 64322819.45350795\n",
      "Iteration 251, loss = 64312411.37818344\n",
      "Iteration 252, loss = 64296393.82839941\n",
      "Iteration 253, loss = 64285598.21878999\n",
      "Iteration 254, loss = 64273328.74460480\n",
      "Iteration 255, loss = 64260351.40725259\n",
      "Iteration 256, loss = 64252317.13991076\n",
      "Iteration 257, loss = 64239178.85644463\n",
      "Iteration 258, loss = 64230318.38430183\n",
      "Iteration 259, loss = 64218876.40004316\n",
      "Iteration 260, loss = 64210228.20717365\n",
      "Iteration 261, loss = 64202771.91940879\n",
      "Iteration 262, loss = 64191847.81036109\n",
      "Iteration 263, loss = 64183121.03848013\n",
      "Iteration 264, loss = 64176227.06651095\n",
      "Iteration 265, loss = 64168572.23334324\n",
      "Iteration 266, loss = 64163829.64788898\n",
      "Iteration 267, loss = 64154500.39758429\n",
      "Iteration 268, loss = 64147886.12682676\n",
      "Iteration 269, loss = 64143543.39344072\n",
      "Iteration 270, loss = 64135407.34295865\n",
      "Iteration 271, loss = 64129098.06989972\n",
      "Iteration 272, loss = 64124279.95392584\n",
      "Iteration 273, loss = 64118976.70873263\n",
      "Iteration 274, loss = 64112228.46370798\n",
      "Iteration 275, loss = 64106988.57912021\n",
      "Iteration 276, loss = 64101295.34983884\n",
      "Iteration 277, loss = 64097154.68302498\n",
      "Iteration 278, loss = 64091135.21077233\n",
      "Iteration 279, loss = 64087066.97069378\n",
      "Iteration 280, loss = 64081670.20305148\n",
      "Iteration 281, loss = 64077012.88253266\n",
      "Iteration 282, loss = 64072852.60947875\n",
      "Iteration 283, loss = 64068113.34136107\n",
      "Iteration 284, loss = 64065446.42405318\n",
      "Iteration 285, loss = 64059426.35844208\n",
      "Iteration 286, loss = 64055101.17202059\n",
      "Iteration 287, loss = 64051217.57255381\n",
      "Iteration 288, loss = 64046903.02943826\n",
      "Iteration 289, loss = 64044000.49205856\n",
      "Iteration 290, loss = 64040000.73794973\n",
      "Iteration 291, loss = 64035766.62198523\n",
      "Iteration 292, loss = 64032291.40646428\n",
      "Iteration 293, loss = 64028112.50026865\n",
      "Iteration 294, loss = 64024157.58719242\n",
      "Iteration 295, loss = 64020701.81207865\n",
      "Iteration 296, loss = 64017731.71660642\n",
      "Iteration 297, loss = 64012921.62181111\n",
      "Iteration 298, loss = 64009954.79081225\n",
      "Iteration 299, loss = 64006011.51663493\n",
      "Iteration 300, loss = 64002374.79556544\n",
      "Iteration 301, loss = 63999419.19400125\n",
      "Iteration 302, loss = 63995343.82699963\n",
      "Iteration 303, loss = 63991792.40859468\n",
      "Iteration 304, loss = 63988761.13106642\n",
      "Iteration 305, loss = 63985832.47067969\n",
      "Iteration 306, loss = 63981579.72004420\n",
      "Iteration 307, loss = 63978166.63402507\n",
      "Iteration 308, loss = 63975238.85939258\n",
      "Iteration 309, loss = 63971878.90887493\n",
      "Iteration 310, loss = 63968498.90749139\n",
      "Iteration 311, loss = 63965217.08765530\n",
      "Iteration 312, loss = 63962512.43933256\n",
      "Iteration 313, loss = 63958287.09508270\n",
      "Iteration 314, loss = 63955108.68924297\n",
      "Iteration 315, loss = 63952617.69525526\n",
      "Iteration 316, loss = 63947991.39502144\n",
      "Iteration 317, loss = 63945046.73155861\n",
      "Iteration 318, loss = 63941628.50416767\n",
      "Iteration 319, loss = 63938595.38012876\n",
      "Iteration 320, loss = 63935184.87577800\n",
      "Iteration 321, loss = 63932542.23112299\n",
      "Iteration 322, loss = 63929297.76200484\n",
      "Iteration 323, loss = 63925033.51247641\n",
      "Iteration 324, loss = 63922511.78422932\n",
      "Iteration 325, loss = 63919223.69193761\n",
      "Iteration 326, loss = 63916705.00847538\n",
      "Iteration 327, loss = 63912406.57004852\n",
      "Iteration 328, loss = 63909145.66250284\n",
      "Iteration 329, loss = 63905963.39224088\n",
      "Iteration 330, loss = 63902893.70999701\n",
      "Iteration 331, loss = 63899570.37951878\n",
      "Iteration 332, loss = 63896415.07868739\n",
      "Iteration 333, loss = 63893091.63599291\n",
      "Iteration 334, loss = 63890602.05274802\n",
      "Iteration 335, loss = 63887710.16735196\n",
      "Iteration 336, loss = 63884254.56843552\n",
      "Iteration 337, loss = 63881292.88991718\n",
      "Iteration 338, loss = 63877234.85839225\n",
      "Iteration 339, loss = 63874069.46467008\n",
      "Iteration 340, loss = 63870908.17112374\n",
      "Iteration 341, loss = 63868094.35328738\n",
      "Iteration 342, loss = 63866186.46411947\n",
      "Iteration 343, loss = 63863420.69412500\n",
      "Iteration 344, loss = 63858360.06212666\n",
      "Iteration 345, loss = 63855685.08363664\n",
      "Iteration 346, loss = 63852101.80255396\n",
      "Iteration 347, loss = 63849010.78162776\n",
      "Iteration 348, loss = 63846040.39546794\n",
      "Iteration 349, loss = 63843028.94508842\n",
      "Iteration 350, loss = 63839445.39850903\n",
      "Iteration 351, loss = 63836573.75818992\n",
      "Iteration 352, loss = 63833856.43829078\n",
      "Iteration 353, loss = 63831401.01757605\n",
      "Iteration 354, loss = 63827862.82768619\n",
      "Iteration 355, loss = 63824999.27379636\n",
      "Iteration 356, loss = 63821624.06451368\n",
      "Iteration 357, loss = 63817709.91961316\n",
      "Iteration 358, loss = 63815606.30275744\n",
      "Iteration 359, loss = 63811500.75134829\n",
      "Iteration 360, loss = 63808644.61100899\n",
      "Iteration 361, loss = 63806210.09417424\n",
      "Iteration 362, loss = 63802990.27628042\n",
      "Iteration 363, loss = 63798911.75130957\n",
      "Iteration 364, loss = 63795905.05346773\n",
      "Iteration 365, loss = 63792404.78551631\n",
      "Iteration 366, loss = 63789533.73103292\n",
      "Iteration 367, loss = 63786519.77717557\n",
      "Iteration 368, loss = 63783565.41434233\n",
      "Iteration 369, loss = 63779987.63107520\n",
      "Iteration 370, loss = 63776736.53342164\n",
      "Iteration 371, loss = 63773609.10779554\n",
      "Iteration 372, loss = 63770453.02231321\n",
      "Iteration 373, loss = 63768107.43579780\n",
      "Iteration 374, loss = 63764244.77874166\n",
      "Iteration 375, loss = 63760956.62322918\n",
      "Iteration 376, loss = 63757843.46616677\n",
      "Iteration 377, loss = 63755625.01186877\n",
      "Iteration 378, loss = 63751653.73340510\n",
      "Iteration 379, loss = 63748025.77310683\n",
      "Iteration 380, loss = 63745492.70143005\n",
      "Iteration 381, loss = 63741717.24322499\n",
      "Iteration 382, loss = 63741011.34429793\n",
      "Iteration 383, loss = 63735952.59702507\n",
      "Iteration 384, loss = 63732875.29432174\n",
      "Iteration 385, loss = 63729537.55771061\n",
      "Iteration 386, loss = 63726473.71216390\n",
      "Iteration 387, loss = 63723965.26814585\n",
      "Iteration 388, loss = 63719606.64111690\n",
      "Iteration 389, loss = 63716417.83861123\n",
      "Iteration 390, loss = 63713426.57602298\n",
      "Iteration 391, loss = 63710272.66723301\n",
      "Iteration 392, loss = 63707297.84962567\n",
      "Iteration 393, loss = 63703766.72881565\n",
      "Iteration 394, loss = 63701400.97085828\n",
      "Iteration 395, loss = 63697476.49146095\n",
      "Iteration 396, loss = 63694965.94696482\n",
      "Iteration 397, loss = 63691364.07937127\n",
      "Iteration 398, loss = 63688748.41956998\n",
      "Iteration 399, loss = 63685013.94040887\n",
      "Iteration 400, loss = 63681895.28116676\n",
      "Iteration 401, loss = 63678608.84598760\n",
      "Iteration 402, loss = 63675887.68713631\n",
      "Iteration 403, loss = 63672137.00841211\n",
      "Iteration 404, loss = 63668869.21827815\n",
      "Iteration 405, loss = 63665738.55910278\n",
      "Iteration 406, loss = 63663226.90504257\n",
      "Iteration 407, loss = 63659798.21151157\n",
      "Iteration 408, loss = 63656745.45147128\n",
      "Iteration 409, loss = 63652957.11324181\n",
      "Iteration 410, loss = 63650145.36476758\n",
      "Iteration 411, loss = 63648186.82393355\n",
      "Iteration 412, loss = 63643202.23966235\n",
      "Iteration 413, loss = 63640113.03122751\n",
      "Iteration 414, loss = 63637566.09868937\n",
      "Iteration 415, loss = 63634973.52072470\n",
      "Iteration 416, loss = 63631034.10162056\n",
      "Iteration 417, loss = 63627589.59940968\n",
      "Iteration 418, loss = 63625000.44022653\n",
      "Iteration 419, loss = 63621207.82872086\n",
      "Iteration 420, loss = 63617579.59780060\n",
      "Iteration 421, loss = 63614603.40681531\n",
      "Iteration 422, loss = 63611669.73259246\n",
      "Iteration 423, loss = 63608377.39497841\n",
      "Iteration 424, loss = 63606362.41095995\n",
      "Iteration 425, loss = 63601833.91120283\n",
      "Iteration 426, loss = 63599357.97679854\n",
      "Iteration 427, loss = 63597671.45433930\n",
      "Iteration 428, loss = 63593205.77860471\n",
      "Iteration 429, loss = 63589393.08789822\n",
      "Iteration 430, loss = 63586458.41590562\n",
      "Iteration 431, loss = 63583425.06666608\n",
      "Iteration 432, loss = 63580025.90231992\n",
      "Iteration 433, loss = 63577009.03892632\n",
      "Iteration 434, loss = 63574853.96692354\n",
      "Iteration 435, loss = 63569869.50951014\n",
      "Iteration 436, loss = 63566961.32198704\n",
      "Iteration 437, loss = 63563506.83541186\n",
      "Iteration 438, loss = 63560505.07629932\n",
      "Iteration 439, loss = 63557276.37213977\n",
      "Iteration 440, loss = 63554175.53812483\n",
      "Iteration 441, loss = 63551469.22740471\n",
      "Iteration 442, loss = 63547735.51077767\n",
      "Iteration 443, loss = 63545929.95094192\n",
      "Iteration 444, loss = 63540684.23713459\n",
      "Iteration 445, loss = 63538311.61692751\n",
      "Iteration 446, loss = 63536353.31363615\n",
      "Iteration 447, loss = 63531366.09945185\n",
      "Iteration 448, loss = 63528245.61503092\n",
      "Iteration 449, loss = 63525159.75994021\n",
      "Iteration 450, loss = 63521606.65541591\n",
      "Iteration 451, loss = 63518832.13704958\n",
      "Iteration 452, loss = 63515583.84192266\n",
      "Iteration 453, loss = 63512266.17342006\n",
      "Iteration 454, loss = 63509410.43592096\n",
      "Iteration 455, loss = 63505845.15358711\n",
      "Iteration 456, loss = 63503999.58585929\n",
      "Iteration 457, loss = 63499427.80220015\n",
      "Iteration 458, loss = 63498180.37354852\n",
      "Iteration 459, loss = 63493416.67241869\n",
      "Iteration 460, loss = 63489661.31347951\n",
      "Iteration 461, loss = 63487294.25173704\n",
      "Iteration 462, loss = 63483134.44986999\n",
      "Iteration 463, loss = 63479827.68404476\n",
      "Iteration 464, loss = 63476217.56495451\n",
      "Iteration 465, loss = 63473119.93634342\n",
      "Iteration 466, loss = 63471036.91959542\n",
      "Iteration 467, loss = 63467021.98215184\n",
      "Iteration 468, loss = 63463783.14727749\n",
      "Iteration 469, loss = 63460291.48387057\n",
      "Iteration 470, loss = 63457159.20458207\n",
      "Iteration 471, loss = 63453644.06059560\n",
      "Iteration 472, loss = 63450475.55066646\n",
      "Iteration 473, loss = 63447317.44405583\n",
      "Iteration 474, loss = 63443888.00096428\n",
      "Iteration 475, loss = 63440814.35550170\n",
      "Iteration 476, loss = 63437263.54081099\n",
      "Iteration 477, loss = 63433740.91013914\n",
      "Iteration 478, loss = 63431145.82192803\n",
      "Iteration 479, loss = 63428751.69758607\n",
      "Iteration 480, loss = 63423981.02319878\n",
      "Iteration 481, loss = 63420530.25927170\n",
      "Iteration 482, loss = 63417645.65415343\n",
      "Iteration 483, loss = 63414130.89447462\n",
      "Iteration 484, loss = 63412464.79464959\n",
      "Iteration 485, loss = 63408315.78993189\n",
      "Iteration 486, loss = 63404342.55660990\n",
      "Iteration 487, loss = 63401198.79422770\n",
      "Iteration 488, loss = 63397690.28420164\n",
      "Iteration 489, loss = 63394160.63959654\n",
      "Iteration 490, loss = 63391217.49152207\n",
      "Iteration 491, loss = 63388054.13204885\n",
      "Iteration 492, loss = 63386472.98103055\n",
      "Iteration 493, loss = 63381960.62876154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 494, loss = 63379631.33397299\n",
      "Iteration 495, loss = 63375023.08954209\n",
      "Iteration 496, loss = 63371883.49820508\n",
      "Iteration 497, loss = 63368171.95968196\n",
      "Iteration 498, loss = 63364608.60310043\n",
      "Iteration 499, loss = 63361567.61738835\n",
      "Iteration 500, loss = 63359446.97491241\n",
      "Iteration 501, loss = 63354825.39100265\n",
      "Iteration 502, loss = 63351518.03303484\n",
      "Iteration 503, loss = 63348120.09768677\n",
      "Iteration 504, loss = 63344479.61899907\n",
      "Iteration 505, loss = 63341400.68858816\n",
      "Iteration 506, loss = 63337995.63703870\n",
      "Iteration 507, loss = 63334830.27503263\n",
      "Iteration 508, loss = 63332253.24944390\n",
      "Iteration 509, loss = 63329063.97987372\n",
      "Iteration 510, loss = 63324691.82579181\n",
      "Iteration 511, loss = 63321829.02022662\n",
      "Iteration 512, loss = 63318994.91226275\n",
      "Iteration 513, loss = 63314799.91544677\n",
      "Iteration 514, loss = 63311367.77851015\n",
      "Iteration 515, loss = 63310337.95336155\n",
      "Iteration 516, loss = 63304475.38415522\n",
      "Iteration 517, loss = 63301914.22128873\n",
      "Iteration 518, loss = 63297863.71971381\n",
      "Iteration 519, loss = 63294431.85108425\n",
      "Iteration 520, loss = 63291446.16867162\n",
      "Iteration 521, loss = 63288160.96917544\n",
      "Iteration 522, loss = 63284741.76274143\n",
      "Iteration 523, loss = 63281863.24954542\n",
      "Iteration 524, loss = 63282046.33524789\n",
      "Iteration 525, loss = 63274714.27811721\n",
      "Iteration 526, loss = 63271089.00103780\n",
      "Iteration 527, loss = 63267372.29851879\n",
      "Iteration 528, loss = 63263972.07832991\n",
      "Iteration 529, loss = 63262576.02399112\n",
      "Iteration 530, loss = 63257355.99263500\n",
      "Iteration 531, loss = 63254306.16029889\n",
      "Iteration 532, loss = 63250549.20287330\n",
      "Iteration 533, loss = 63248229.21520124\n",
      "Iteration 534, loss = 63244260.36263926\n",
      "Iteration 535, loss = 63241017.45060399\n",
      "Iteration 536, loss = 63237672.39962032\n",
      "Iteration 537, loss = 63234348.80467723\n",
      "Iteration 538, loss = 63230872.81111022\n",
      "Iteration 539, loss = 63227615.83142830\n",
      "Iteration 540, loss = 63223849.70066525\n",
      "Iteration 541, loss = 63220493.87985229\n",
      "Iteration 542, loss = 63217572.09433793\n",
      "Iteration 543, loss = 63213299.87977987\n",
      "Iteration 544, loss = 63210004.67808276\n",
      "Iteration 545, loss = 63207290.20282051\n",
      "Iteration 546, loss = 63203329.04568022\n",
      "Iteration 547, loss = 63200501.27312960\n",
      "Iteration 548, loss = 63199931.45260791\n",
      "Iteration 549, loss = 63192750.97573555\n",
      "Iteration 550, loss = 63189559.46477813\n",
      "Iteration 551, loss = 63186304.71839415\n",
      "Iteration 552, loss = 63182890.24987585\n",
      "Iteration 553, loss = 63179328.56597615\n",
      "Iteration 554, loss = 63176544.69741940\n",
      "Iteration 555, loss = 63172534.03773290\n",
      "Iteration 556, loss = 63170423.98013034\n",
      "Iteration 557, loss = 63165190.03123139\n",
      "Iteration 558, loss = 63161652.97855366\n",
      "Iteration 559, loss = 63158687.74959398\n",
      "Iteration 560, loss = 63155104.96470081\n",
      "Iteration 561, loss = 63152235.17526115\n",
      "Iteration 562, loss = 63148092.35797751\n",
      "Iteration 563, loss = 63145382.68068507\n",
      "Iteration 564, loss = 63141432.37247953\n",
      "Iteration 565, loss = 63137937.33972944\n",
      "Iteration 566, loss = 63135151.13207643\n",
      "Iteration 567, loss = 63131586.93618532\n",
      "Iteration 568, loss = 63128478.73182265\n",
      "Iteration 569, loss = 63124764.23034064\n",
      "Iteration 570, loss = 63120834.43808228\n",
      "Iteration 571, loss = 63117206.16383552\n",
      "Iteration 572, loss = 63114105.70565973\n",
      "Iteration 573, loss = 63110605.45622953\n",
      "Iteration 574, loss = 63106652.33142263\n",
      "Iteration 575, loss = 63103295.54797613\n",
      "Iteration 576, loss = 63100204.78419237\n",
      "Iteration 577, loss = 63096267.86471929\n",
      "Iteration 578, loss = 63093332.03568977\n",
      "Iteration 579, loss = 63089776.36809385\n",
      "Iteration 580, loss = 63085931.76633876\n",
      "Iteration 581, loss = 63082136.36242054\n",
      "Iteration 582, loss = 63079096.56474252\n",
      "Iteration 583, loss = 63075390.09773858\n",
      "Iteration 584, loss = 63071602.04621021\n",
      "Iteration 585, loss = 63068039.55937500\n",
      "Iteration 586, loss = 63065325.75089296\n",
      "Iteration 587, loss = 63061368.13281138\n",
      "Iteration 588, loss = 63058077.98359675\n",
      "Iteration 589, loss = 63053977.00874075\n",
      "Iteration 590, loss = 63050701.24227070\n",
      "Iteration 591, loss = 63047451.41729925\n",
      "Iteration 592, loss = 63044420.84523942\n",
      "Iteration 593, loss = 63041939.83648580\n",
      "Iteration 594, loss = 63036845.60609677\n",
      "Iteration 595, loss = 63033930.16460833\n",
      "Iteration 596, loss = 63030261.05903060\n",
      "Iteration 597, loss = 63026429.20373642\n",
      "Iteration 598, loss = 63023550.26778625\n",
      "Iteration 599, loss = 63022074.59628243\n",
      "Iteration 600, loss = 63016425.13969378\n",
      "Iteration 601, loss = 63011563.57650948\n",
      "Iteration 602, loss = 63008282.56944436\n",
      "Iteration 603, loss = 63004597.08877540\n",
      "Iteration 604, loss = 63001234.25080940\n",
      "Iteration 605, loss = 62997741.00133158\n",
      "Iteration 606, loss = 62993932.19535322\n",
      "Iteration 607, loss = 62991290.58530080\n",
      "Iteration 608, loss = 62989112.39293637\n",
      "Iteration 609, loss = 62983935.80284104\n",
      "Iteration 610, loss = 62979368.41458511\n",
      "Iteration 611, loss = 62976570.11981584\n",
      "Iteration 612, loss = 62973021.22449953\n",
      "Iteration 613, loss = 62969509.95498049\n",
      "Iteration 614, loss = 62965662.86084744\n",
      "Iteration 615, loss = 62962934.42723283\n",
      "Iteration 616, loss = 62957766.88294911\n",
      "Iteration 617, loss = 62954425.71746491\n",
      "Iteration 618, loss = 62951036.04220913\n",
      "Iteration 619, loss = 62947753.49112361\n",
      "Iteration 620, loss = 62943507.45876554\n",
      "Iteration 621, loss = 62941105.62004198\n",
      "Iteration 622, loss = 62936969.10735519\n",
      "Iteration 623, loss = 62934335.81520572\n",
      "Iteration 624, loss = 62929996.58765180\n",
      "Iteration 625, loss = 62928740.79878984\n",
      "Iteration 626, loss = 62922097.38125721\n",
      "Iteration 627, loss = 62918702.39581734\n",
      "Iteration 628, loss = 62915065.72792963\n",
      "Iteration 629, loss = 62911541.60462900\n",
      "Iteration 630, loss = 62907895.14766560\n",
      "Iteration 631, loss = 62904058.31552920\n",
      "Iteration 632, loss = 62901854.72821156\n",
      "Iteration 633, loss = 62901751.21189364\n",
      "Iteration 634, loss = 62893230.32666235\n",
      "Iteration 635, loss = 62889932.71320891\n",
      "Iteration 636, loss = 62886526.41014779\n",
      "Iteration 637, loss = 62882546.35400806\n",
      "Iteration 638, loss = 62878469.37684944\n",
      "Iteration 639, loss = 62875725.34548350\n",
      "Iteration 640, loss = 62872212.46473173\n",
      "Iteration 641, loss = 62868358.40002409\n",
      "Iteration 642, loss = 62864221.96014377\n",
      "Iteration 643, loss = 62860837.54226849\n",
      "Iteration 644, loss = 62857038.18717782\n",
      "Iteration 645, loss = 62853555.89827133\n",
      "Iteration 646, loss = 62849810.55044795\n",
      "Iteration 647, loss = 62846126.63485257\n",
      "Iteration 648, loss = 62842367.84774696\n",
      "Iteration 649, loss = 62838521.42918303\n",
      "Iteration 650, loss = 62836620.36288490\n",
      "Iteration 651, loss = 62831995.70335400\n",
      "Iteration 652, loss = 62827665.78900290\n",
      "Iteration 653, loss = 62823732.31400542\n",
      "Iteration 654, loss = 62820679.09055060\n",
      "Iteration 655, loss = 62817847.14674644\n",
      "Iteration 656, loss = 62812728.47186785\n",
      "Iteration 657, loss = 62809251.10163341\n",
      "Iteration 658, loss = 62805374.37936782\n",
      "Iteration 659, loss = 62802076.89673179\n",
      "Iteration 660, loss = 62799756.60788407\n",
      "Iteration 661, loss = 62794255.07069303\n",
      "Iteration 662, loss = 62790023.00633515\n",
      "Iteration 663, loss = 62786554.25716570\n",
      "Iteration 664, loss = 62783288.92255515\n",
      "Iteration 665, loss = 62779582.90289253\n",
      "Iteration 666, loss = 62775143.42484166\n",
      "Iteration 667, loss = 62771418.44645076\n",
      "Iteration 668, loss = 62769253.85088368\n",
      "Iteration 669, loss = 62763850.44743147\n",
      "Iteration 670, loss = 62761133.22079696\n",
      "Iteration 671, loss = 62756515.92951283\n",
      "Iteration 672, loss = 62753097.14407357\n",
      "Iteration 673, loss = 62748904.83831484\n",
      "Iteration 674, loss = 62745129.68970892\n",
      "Iteration 675, loss = 62741385.21675329\n",
      "Iteration 676, loss = 62737758.84585664\n",
      "Iteration 677, loss = 62734399.10620773\n",
      "Iteration 678, loss = 62730326.50391302\n",
      "Iteration 679, loss = 62726366.59935771\n",
      "Iteration 680, loss = 62722190.95687468\n",
      "Iteration 681, loss = 62718818.80277306\n",
      "Iteration 682, loss = 62715384.43400742\n",
      "Iteration 683, loss = 62711390.01337717\n",
      "Iteration 684, loss = 62707256.71644530\n",
      "Iteration 685, loss = 62703500.31669906\n",
      "Iteration 686, loss = 62702705.56586222\n",
      "Iteration 687, loss = 62698154.44597097\n",
      "Iteration 688, loss = 62692664.77032479\n",
      "Iteration 689, loss = 62690207.15798880\n",
      "Iteration 690, loss = 62684758.07413836\n",
      "Iteration 691, loss = 62681682.37332709\n",
      "Iteration 692, loss = 62677085.40500268\n",
      "Iteration 693, loss = 62672473.60596806\n",
      "Iteration 694, loss = 62668820.62995963\n",
      "Iteration 695, loss = 62667692.17744429\n",
      "Iteration 696, loss = 62661647.32913427\n",
      "Iteration 697, loss = 62657149.72303332\n",
      "Iteration 698, loss = 62653666.31189203\n",
      "Iteration 699, loss = 62649547.21269962\n",
      "Iteration 700, loss = 62646525.50563326\n",
      "Iteration 701, loss = 62641851.73145854\n",
      "Iteration 702, loss = 62638416.10119700\n",
      "Iteration 703, loss = 62634675.62317005\n",
      "Iteration 704, loss = 62631280.83395413\n",
      "Iteration 705, loss = 62626613.67338575\n",
      "Iteration 706, loss = 62622185.55119288\n",
      "Iteration 707, loss = 62619144.82290076\n",
      "Iteration 708, loss = 62615592.81229006\n",
      "Iteration 709, loss = 62611154.49090524\n",
      "Iteration 710, loss = 62607503.04523198\n",
      "Iteration 711, loss = 62603396.63999590\n",
      "Iteration 712, loss = 62599674.54228046\n",
      "Iteration 713, loss = 62594970.51271840\n",
      "Iteration 714, loss = 62591917.21615935\n",
      "Iteration 715, loss = 62587557.48729810\n",
      "Iteration 716, loss = 62586962.25524478\n",
      "Iteration 717, loss = 62579184.94304048\n",
      "Iteration 718, loss = 62575368.03476637\n",
      "Iteration 719, loss = 62571878.70811003\n",
      "Iteration 720, loss = 62567988.54684585\n",
      "Iteration 721, loss = 62564087.68477549\n",
      "Iteration 722, loss = 62560129.60529570\n",
      "Iteration 723, loss = 62555589.17981244\n",
      "Iteration 724, loss = 62551861.28618933\n",
      "Iteration 725, loss = 62548160.73726983\n",
      "Iteration 726, loss = 62544483.25173143\n",
      "Iteration 727, loss = 62540592.30563544\n",
      "Iteration 728, loss = 62535460.04995600\n",
      "Iteration 729, loss = 62532590.83583133\n",
      "Iteration 730, loss = 62528164.94984028\n",
      "Iteration 731, loss = 62524785.88635328\n",
      "Iteration 732, loss = 62519915.53399184\n",
      "Iteration 733, loss = 62516235.62456293\n",
      "Iteration 734, loss = 62511965.93229788\n",
      "Iteration 735, loss = 62508201.11735206\n",
      "Iteration 736, loss = 62503710.39711416\n",
      "Iteration 737, loss = 62499783.24606681\n",
      "Iteration 738, loss = 62495819.43312707\n",
      "Iteration 739, loss = 62492068.03107990\n",
      "Iteration 740, loss = 62488940.99813412\n",
      "Iteration 741, loss = 62484828.56632568\n",
      "Iteration 742, loss = 62480015.32265586\n",
      "Iteration 743, loss = 62475813.87600970\n",
      "Iteration 744, loss = 62472362.84200502\n",
      "Iteration 745, loss = 62467378.18422493\n",
      "Iteration 746, loss = 62463734.26407093\n",
      "Iteration 747, loss = 62462519.80367157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 748, loss = 62457636.14786123\n",
      "Iteration 749, loss = 62452729.90471065\n",
      "Iteration 750, loss = 62448363.24006446\n",
      "Iteration 751, loss = 62444514.26271110\n",
      "Iteration 752, loss = 62439965.81767669\n",
      "Iteration 753, loss = 62435987.70916179\n",
      "Iteration 754, loss = 62432898.01644643\n",
      "Iteration 755, loss = 62427060.41230245\n",
      "Iteration 756, loss = 62424199.54299601\n",
      "Iteration 757, loss = 62419843.39018359\n",
      "Iteration 758, loss = 62415409.15465108\n",
      "Iteration 759, loss = 62410776.89175123\n",
      "Iteration 760, loss = 62406749.58460245\n",
      "Iteration 761, loss = 62404375.78739845\n",
      "Iteration 762, loss = 62398664.54985838\n",
      "Iteration 763, loss = 62394820.62525247\n",
      "Iteration 764, loss = 62390526.71231576\n",
      "Iteration 765, loss = 62386437.95272797\n",
      "Iteration 766, loss = 62381898.70577269\n",
      "Iteration 767, loss = 62380505.80620491\n",
      "Iteration 768, loss = 62373650.42760235\n",
      "Iteration 769, loss = 62369620.57553516\n",
      "Iteration 770, loss = 62366514.61694290\n",
      "Iteration 771, loss = 62361693.43263789\n",
      "Iteration 772, loss = 62357745.79036375\n",
      "Iteration 773, loss = 62354146.52364529\n",
      "Iteration 774, loss = 62349310.93518274\n",
      "Iteration 775, loss = 62344216.07502619\n",
      "Iteration 776, loss = 62339855.48678315\n",
      "Iteration 777, loss = 62335709.70207876\n",
      "Iteration 778, loss = 62333400.68670578\n",
      "Iteration 779, loss = 62328020.12239595\n",
      "Iteration 780, loss = 62323700.28372274\n",
      "Iteration 781, loss = 62319058.08182999\n",
      "Iteration 782, loss = 62316924.37907939\n",
      "Iteration 783, loss = 62311161.58409150\n",
      "Iteration 784, loss = 62307752.61139652\n",
      "Iteration 785, loss = 62303582.78658054\n",
      "Iteration 786, loss = 62299806.40260253\n",
      "Iteration 787, loss = 62294530.96715304\n",
      "Iteration 788, loss = 62291338.77188057\n",
      "Iteration 789, loss = 62288721.76668210\n",
      "Iteration 790, loss = 62280568.26410110\n",
      "Iteration 791, loss = 62276413.83306113\n",
      "Iteration 792, loss = 62272864.59797437\n",
      "Iteration 793, loss = 62269795.80381265\n",
      "Iteration 794, loss = 62264724.99966365\n",
      "Iteration 795, loss = 62261189.91486100\n",
      "Iteration 796, loss = 62256073.91455782\n",
      "Iteration 797, loss = 62252413.83947612\n",
      "Iteration 798, loss = 62247539.35147678\n",
      "Iteration 799, loss = 62243674.98527560\n",
      "Iteration 800, loss = 62239423.13889708\n",
      "Iteration 801, loss = 62235794.28243943\n",
      "Iteration 802, loss = 62230479.56584705\n",
      "Iteration 803, loss = 62228670.17544192\n",
      "Iteration 804, loss = 62221372.30486211\n",
      "Iteration 805, loss = 62216335.70099778\n",
      "Iteration 806, loss = 62213302.41684182\n",
      "Iteration 807, loss = 62209172.62825845\n",
      "Iteration 808, loss = 62204532.55599874\n",
      "Iteration 809, loss = 62200341.34491783\n",
      "Iteration 810, loss = 62195709.07665131\n",
      "Iteration 811, loss = 62190901.68897762\n",
      "Iteration 812, loss = 62186614.96664881\n",
      "Iteration 813, loss = 62183158.65595596\n",
      "Iteration 814, loss = 62180433.75486679\n",
      "Iteration 815, loss = 62174733.23640765\n",
      "Iteration 816, loss = 62169115.47581232\n",
      "Iteration 817, loss = 62165192.50685841\n",
      "Iteration 818, loss = 62160923.80524582\n",
      "Iteration 819, loss = 62157612.17816125\n",
      "Iteration 820, loss = 62151295.52919216\n",
      "Iteration 821, loss = 62147170.11460356\n",
      "Iteration 822, loss = 62144846.77259398\n",
      "Iteration 823, loss = 62138830.11480987\n",
      "Iteration 824, loss = 62134106.18979738\n",
      "Iteration 825, loss = 62129534.71294536\n",
      "Iteration 826, loss = 62126873.40695987\n",
      "Iteration 827, loss = 62120720.69959572\n",
      "Iteration 828, loss = 62116736.32959877\n",
      "Iteration 829, loss = 62111815.99882568\n",
      "Iteration 830, loss = 62108044.12526046\n",
      "Iteration 831, loss = 62106273.48962337\n",
      "Iteration 832, loss = 62099256.31118827\n",
      "Iteration 833, loss = 62094488.84078315\n",
      "Iteration 834, loss = 62089745.21540886\n",
      "Iteration 835, loss = 62085314.01681431\n",
      "Iteration 836, loss = 62080887.01064987\n",
      "Iteration 837, loss = 62077064.48442934\n",
      "Iteration 838, loss = 62074958.35609380\n",
      "Iteration 839, loss = 62070904.18278217\n",
      "Iteration 840, loss = 62062183.76867315\n",
      "Iteration 841, loss = 62059026.08163768\n",
      "Iteration 842, loss = 62054714.90766328\n",
      "Iteration 843, loss = 62049767.65442154\n",
      "Iteration 844, loss = 62044834.10457993\n",
      "Iteration 845, loss = 62040607.13614991\n",
      "Iteration 846, loss = 62036269.13046112\n",
      "Iteration 847, loss = 62031801.50608566\n",
      "Iteration 848, loss = 62026601.05438522\n",
      "Iteration 849, loss = 62022439.34195222\n",
      "Iteration 850, loss = 62018103.48869336\n",
      "Iteration 851, loss = 62013348.73569192\n",
      "Iteration 852, loss = 62009207.07155484\n",
      "Iteration 853, loss = 62005781.45368081\n",
      "Iteration 854, loss = 61999415.34040269\n",
      "Iteration 855, loss = 61996153.81800215\n",
      "Iteration 856, loss = 61991965.85543887\n",
      "Iteration 857, loss = 61986830.27096625\n",
      "Iteration 858, loss = 61981524.71342544\n",
      "Iteration 859, loss = 61977371.40661892\n",
      "Iteration 860, loss = 61972873.14822216\n",
      "Iteration 861, loss = 61967257.84082057\n",
      "Iteration 862, loss = 61964401.94976994\n",
      "Iteration 863, loss = 61961297.43430167\n",
      "Iteration 864, loss = 61954198.44250073\n",
      "Iteration 865, loss = 61949735.81511141\n",
      "Iteration 866, loss = 61944839.70543276\n",
      "Iteration 867, loss = 61939822.84047364\n",
      "Iteration 868, loss = 61935586.12616473\n",
      "Iteration 869, loss = 61930443.66873457\n",
      "Iteration 870, loss = 61925980.50552842\n",
      "Iteration 871, loss = 61921110.01703554\n",
      "Iteration 872, loss = 61917086.04527516\n",
      "Iteration 873, loss = 61914591.78343617\n",
      "Iteration 874, loss = 61908619.12836666\n",
      "Iteration 875, loss = 61902374.84827958\n",
      "Iteration 876, loss = 61898449.68091016\n",
      "Iteration 877, loss = 61893778.43536149\n",
      "Iteration 878, loss = 61889164.60054877\n",
      "Iteration 879, loss = 61884242.71561756\n",
      "Iteration 880, loss = 61879155.01998881\n",
      "Iteration 881, loss = 61874437.35732253\n",
      "Iteration 882, loss = 61869991.28281289\n",
      "Iteration 883, loss = 61865568.97935621\n",
      "Iteration 884, loss = 61860323.54669347\n",
      "Iteration 885, loss = 61855886.61557619\n",
      "Iteration 886, loss = 61854800.21841315\n",
      "Iteration 887, loss = 61846738.67129961\n",
      "Iteration 888, loss = 61841973.45849551\n",
      "Iteration 889, loss = 61836628.13503101\n",
      "Iteration 890, loss = 61833332.01035719\n",
      "Iteration 891, loss = 61827798.33917814\n",
      "Iteration 892, loss = 61822641.95352370\n",
      "Iteration 893, loss = 61818010.10485751\n",
      "Iteration 894, loss = 61813460.05621935\n",
      "Iteration 895, loss = 61808778.26373483\n",
      "Iteration 896, loss = 61803220.16525980\n",
      "Iteration 897, loss = 61800438.00945739\n",
      "Iteration 898, loss = 61793608.96186481\n",
      "Iteration 899, loss = 61789206.66290962\n",
      "Iteration 900, loss = 61784801.24649518\n",
      "Iteration 901, loss = 61780036.02668036\n",
      "Iteration 902, loss = 61774579.96873964\n",
      "Iteration 903, loss = 61769750.19493330\n",
      "Iteration 904, loss = 61766224.30641779\n",
      "Iteration 905, loss = 61759918.17612658\n",
      "Iteration 906, loss = 61755301.39089994\n",
      "Iteration 907, loss = 61750632.43040389\n",
      "Iteration 908, loss = 61745675.74414661\n",
      "Iteration 909, loss = 61741589.11921378\n",
      "Iteration 910, loss = 61736358.40173592\n",
      "Iteration 911, loss = 61731988.51564983\n",
      "Iteration 912, loss = 61726186.58066906\n",
      "Iteration 913, loss = 61721657.12294658\n",
      "Iteration 914, loss = 61716861.07960830\n",
      "Iteration 915, loss = 61711468.65774760\n",
      "Iteration 916, loss = 61707233.25336104\n",
      "Iteration 917, loss = 61701843.83876504\n",
      "Iteration 918, loss = 61697036.24378715\n",
      "Iteration 919, loss = 61692375.10775647\n",
      "Iteration 920, loss = 61688436.36681287\n",
      "Iteration 921, loss = 61681846.19197433\n",
      "Iteration 922, loss = 61676904.07253423\n",
      "Iteration 923, loss = 61672004.83084842\n",
      "Iteration 924, loss = 61667100.78883827\n",
      "Iteration 925, loss = 61661989.71815387\n",
      "Iteration 926, loss = 61657281.56249600\n",
      "Iteration 927, loss = 61653804.16768855\n",
      "Iteration 928, loss = 61647232.48491220\n",
      "Iteration 929, loss = 61643538.07028475\n",
      "Iteration 930, loss = 61636409.34310177\n",
      "Iteration 931, loss = 61630329.18245625\n",
      "Iteration 932, loss = 61627545.43306337\n",
      "Iteration 933, loss = 61620811.35798615\n",
      "Iteration 934, loss = 61616237.72266760\n",
      "Iteration 935, loss = 61611669.95915233\n",
      "Iteration 936, loss = 61610214.08843994\n",
      "Iteration 937, loss = 61602025.72248226\n",
      "Iteration 938, loss = 61596648.09748821\n",
      "Iteration 939, loss = 61590782.04411062\n",
      "Iteration 940, loss = 61587161.48598098\n",
      "Iteration 941, loss = 61580754.82311931\n",
      "Iteration 942, loss = 61576653.53229457\n",
      "Iteration 943, loss = 61570039.81511831\n",
      "Iteration 944, loss = 61565452.81707565\n",
      "Iteration 945, loss = 61560429.52590077\n",
      "Iteration 946, loss = 61554946.41863109\n",
      "Iteration 947, loss = 61550058.04282838\n",
      "Iteration 948, loss = 61545607.45477080\n",
      "Iteration 949, loss = 61538433.25486830\n",
      "Iteration 950, loss = 61534191.14631268\n",
      "Iteration 951, loss = 61528386.84152097\n",
      "Iteration 952, loss = 61523997.38092299\n",
      "Iteration 953, loss = 61519684.22265337\n",
      "Iteration 954, loss = 61514133.28850481\n",
      "Iteration 955, loss = 61509739.70719726\n",
      "Iteration 956, loss = 61504006.92704158\n",
      "Iteration 957, loss = 61501225.59747427\n",
      "Iteration 958, loss = 61493115.18111759\n",
      "Iteration 959, loss = 61491090.90198720\n",
      "Iteration 960, loss = 61484508.65900054\n",
      "Iteration 961, loss = 61477205.68899779\n",
      "Iteration 962, loss = 61474067.34524377\n",
      "Iteration 963, loss = 61467829.09889586\n",
      "Iteration 964, loss = 61462934.50070526\n",
      "Iteration 965, loss = 61457764.27417871\n",
      "Iteration 966, loss = 61452211.38381454\n",
      "Iteration 967, loss = 61446739.80874379\n",
      "Iteration 968, loss = 61446347.54212567\n",
      "Iteration 969, loss = 61434923.57625659\n",
      "Iteration 970, loss = 61430897.10335745\n",
      "Iteration 971, loss = 61425113.68825482\n",
      "Iteration 972, loss = 61420167.64838001\n",
      "Iteration 973, loss = 61417400.09244758\n",
      "Iteration 974, loss = 61408907.32901806\n",
      "Iteration 975, loss = 61403888.69804740\n",
      "Iteration 976, loss = 61397876.68962799\n",
      "Iteration 977, loss = 61392137.65830245\n",
      "Iteration 978, loss = 61388953.92341436\n",
      "Iteration 979, loss = 61383089.09331349\n",
      "Iteration 980, loss = 61378367.86002340\n",
      "Iteration 981, loss = 61371298.14683518\n",
      "Iteration 982, loss = 61366883.74333262\n",
      "Iteration 983, loss = 61361123.42804519\n",
      "Iteration 984, loss = 61357773.74048240\n",
      "Iteration 985, loss = 61350627.20012857\n",
      "Iteration 986, loss = 61345505.40299895\n",
      "Iteration 987, loss = 61341796.55315254\n",
      "Iteration 988, loss = 61333177.63026349\n",
      "Iteration 989, loss = 61327561.56278063\n",
      "Iteration 990, loss = 61323097.69169377\n",
      "Iteration 991, loss = 61317798.25685685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 992, loss = 61311432.31432065\n",
      "Iteration 993, loss = 61306706.43329711\n",
      "Iteration 994, loss = 61307017.23154634\n",
      "Iteration 995, loss = 61294904.48834773\n",
      "Iteration 996, loss = 61290458.02090662\n",
      "Iteration 997, loss = 61286854.02683195\n",
      "Iteration 998, loss = 61280446.39962215\n",
      "Iteration 999, loss = 61274729.77015456\n",
      "Iteration 1000, loss = 61268649.68730522\n",
      "Iteration 1001, loss = 61263181.18343090\n",
      "Iteration 1002, loss = 61261230.21181749\n",
      "Iteration 1003, loss = 61253230.30946960\n",
      "Iteration 1004, loss = 61246326.64469128\n",
      "Iteration 1005, loss = 61240429.08375125\n",
      "Iteration 1006, loss = 61236985.07000209\n",
      "Iteration 1007, loss = 61229314.70080982\n",
      "Iteration 1008, loss = 61224351.60263064\n",
      "Iteration 1009, loss = 61219436.05459742\n",
      "Iteration 1010, loss = 61212524.08782718\n",
      "Iteration 1011, loss = 61208648.24803328\n",
      "Iteration 1012, loss = 61202364.81286713\n",
      "Iteration 1013, loss = 61195726.17657660\n",
      "Iteration 1014, loss = 61191662.20165510\n",
      "Iteration 1015, loss = 61184491.09005576\n",
      "Iteration 1016, loss = 61179816.52153060\n",
      "Iteration 1017, loss = 61173224.33923300\n",
      "Iteration 1018, loss = 61168047.23931663\n",
      "Iteration 1019, loss = 61164201.72768361\n",
      "Iteration 1020, loss = 61156659.23495749\n",
      "Iteration 1021, loss = 61150744.93685448\n",
      "Iteration 1022, loss = 61145522.29131404\n",
      "Iteration 1023, loss = 61138904.56525709\n",
      "Iteration 1024, loss = 61133259.15455567\n",
      "Iteration 1025, loss = 61128419.02392317\n",
      "Iteration 1026, loss = 61122005.89470620\n",
      "Iteration 1027, loss = 61116348.57727260\n",
      "Iteration 1028, loss = 61111764.40081631\n",
      "Iteration 1029, loss = 61105764.94510219\n",
      "Iteration 1030, loss = 61098922.98866995\n",
      "Iteration 1031, loss = 61094098.30596600\n",
      "Iteration 1032, loss = 61088019.61058079\n",
      "Iteration 1033, loss = 61082112.28271129\n",
      "Iteration 1034, loss = 61076596.11401471\n",
      "Iteration 1035, loss = 61070978.22713216\n",
      "Iteration 1036, loss = 61065009.46130273\n",
      "Iteration 1037, loss = 61059089.81889907\n",
      "Iteration 1038, loss = 61053825.41669291\n",
      "Iteration 1039, loss = 61046855.96650306\n",
      "Iteration 1040, loss = 61043470.11687166\n",
      "Iteration 1041, loss = 61037568.52814015\n",
      "Iteration 1042, loss = 61029372.13544608\n",
      "Iteration 1043, loss = 61026395.00599904\n",
      "Iteration 1044, loss = 61018617.25579787\n",
      "Iteration 1045, loss = 61012310.60532083\n",
      "Iteration 1046, loss = 61009301.98638843\n",
      "Iteration 1047, loss = 61001244.87305864\n",
      "Iteration 1048, loss = 60994238.02162283\n",
      "Iteration 1049, loss = 60988393.01706441\n",
      "Iteration 1050, loss = 60982540.31036459\n",
      "Iteration 1051, loss = 60976729.87000406\n",
      "Iteration 1052, loss = 60972691.68093766\n",
      "Iteration 1053, loss = 60967868.08457726\n",
      "Iteration 1054, loss = 60958390.17245448\n",
      "Iteration 1055, loss = 60958178.28360079\n",
      "Iteration 1056, loss = 60947927.97649894\n",
      "Iteration 1057, loss = 60942282.33899467\n",
      "Iteration 1058, loss = 60935519.32997826\n",
      "Iteration 1059, loss = 60928890.49513199\n",
      "Iteration 1060, loss = 60924938.26051651\n",
      "Iteration 1061, loss = 60917592.86340064\n",
      "Iteration 1062, loss = 60911421.08443359\n",
      "Iteration 1063, loss = 60905814.97998285\n",
      "Iteration 1064, loss = 60898539.68223572\n",
      "Iteration 1065, loss = 60894708.20482410\n",
      "Iteration 1066, loss = 60886509.63464793\n",
      "Iteration 1067, loss = 60881010.03282172\n",
      "Iteration 1068, loss = 60874374.18306648\n",
      "Iteration 1069, loss = 60870650.35572718\n",
      "Iteration 1070, loss = 60862581.48765383\n",
      "Iteration 1071, loss = 60856518.54714379\n",
      "Iteration 1072, loss = 60853760.53233990\n",
      "Iteration 1073, loss = 60845017.32657543\n",
      "Iteration 1074, loss = 60838480.35895408\n",
      "Iteration 1075, loss = 60832878.67728479\n",
      "Iteration 1076, loss = 60827531.98758724\n",
      "Iteration 1077, loss = 60820313.82578240\n",
      "Iteration 1078, loss = 60813459.76093247\n",
      "Iteration 1079, loss = 60806993.97222061\n",
      "Iteration 1080, loss = 60802562.28105655\n",
      "Iteration 1081, loss = 60796179.45129316\n",
      "Iteration 1082, loss = 60790373.67066731\n",
      "Iteration 1083, loss = 60782552.52438179\n",
      "Iteration 1084, loss = 60778214.18609200\n",
      "Iteration 1085, loss = 60770764.33157689\n",
      "Iteration 1086, loss = 60763739.57274483\n",
      "Iteration 1087, loss = 60757914.97600368\n",
      "Iteration 1088, loss = 60753084.17012752\n",
      "Iteration 1089, loss = 60748431.86639713\n",
      "Iteration 1090, loss = 60740792.23161425\n",
      "Iteration 1091, loss = 60735231.87733404\n",
      "Iteration 1092, loss = 60727364.03823039\n",
      "Iteration 1093, loss = 60720388.59861097\n",
      "Iteration 1094, loss = 60714994.59485309\n",
      "Iteration 1095, loss = 60710590.46467733\n",
      "Iteration 1096, loss = 60701227.49608243\n",
      "Iteration 1097, loss = 60695748.94746276\n",
      "Iteration 1098, loss = 60689918.59810540\n",
      "Iteration 1099, loss = 60683088.68028937\n",
      "Iteration 1100, loss = 60675895.05037922\n",
      "Iteration 1101, loss = 60669975.39904187\n",
      "Iteration 1102, loss = 60662956.33090620\n",
      "Iteration 1103, loss = 60656268.53400198\n",
      "Iteration 1104, loss = 60650048.77868215\n",
      "Iteration 1105, loss = 60644446.64109964\n",
      "Iteration 1106, loss = 60638394.24544895\n",
      "Iteration 1107, loss = 60634842.24076335\n",
      "Iteration 1108, loss = 60626965.83787905\n",
      "Iteration 1109, loss = 60620240.52414651\n",
      "Iteration 1110, loss = 60612624.34348737\n",
      "Iteration 1111, loss = 60605614.55225623\n",
      "Iteration 1112, loss = 60602362.21310693\n",
      "Iteration 1113, loss = 60593811.55949969\n",
      "Iteration 1114, loss = 60587680.50519855\n",
      "Iteration 1115, loss = 60580700.77063479\n",
      "Iteration 1116, loss = 60573747.49144164\n",
      "Iteration 1117, loss = 60568035.05199832\n",
      "Iteration 1118, loss = 60560997.11212999\n",
      "Iteration 1119, loss = 60553814.39064335\n",
      "Iteration 1120, loss = 60550036.67727465\n",
      "Iteration 1121, loss = 60541028.65637080\n",
      "Iteration 1122, loss = 60535879.33331569\n",
      "Iteration 1123, loss = 60530238.66209575\n",
      "Iteration 1124, loss = 60524106.75705944\n",
      "Iteration 1125, loss = 60518657.80988612\n",
      "Iteration 1126, loss = 60508288.99016542\n",
      "Iteration 1127, loss = 60501247.27134630\n",
      "Iteration 1128, loss = 60494894.28613041\n",
      "Iteration 1129, loss = 60488981.14440980\n",
      "Iteration 1130, loss = 60484771.67841146\n",
      "Iteration 1131, loss = 60476337.62048259\n",
      "Iteration 1132, loss = 60471699.17211723\n",
      "Iteration 1133, loss = 60463850.19237722\n",
      "Iteration 1134, loss = 60456632.48433063\n",
      "Iteration 1135, loss = 60448860.72772044\n",
      "Iteration 1136, loss = 60441983.91096646\n",
      "Iteration 1137, loss = 60435227.89975441\n",
      "Iteration 1138, loss = 60430386.67105951\n",
      "Iteration 1139, loss = 60422190.60385668\n",
      "Iteration 1140, loss = 60415620.06573246\n",
      "Iteration 1141, loss = 60411311.29703487\n",
      "Iteration 1142, loss = 60405362.09956732\n",
      "Iteration 1143, loss = 60395715.03049587\n",
      "Iteration 1144, loss = 60388339.84951617\n",
      "Iteration 1145, loss = 60383761.79021949\n",
      "Iteration 1146, loss = 60376122.00861976\n",
      "Iteration 1147, loss = 60370206.73081347\n",
      "Iteration 1148, loss = 60363103.78035965\n",
      "Iteration 1149, loss = 60354506.13544875\n",
      "Iteration 1150, loss = 60348005.52943821\n",
      "Iteration 1151, loss = 60341858.35849002\n",
      "Iteration 1152, loss = 60335558.94485079\n",
      "Iteration 1153, loss = 60327456.15946504\n",
      "Iteration 1154, loss = 60322317.64795119\n",
      "Iteration 1155, loss = 60317728.82603444\n",
      "Iteration 1156, loss = 60306662.11097401\n",
      "Iteration 1157, loss = 60304533.48907132\n",
      "Iteration 1158, loss = 60295617.47926319\n",
      "Iteration 1159, loss = 60288318.76165541\n",
      "Iteration 1160, loss = 60278751.05710810\n",
      "Iteration 1161, loss = 60274776.84131340\n",
      "Iteration 1162, loss = 60266228.54174811\n",
      "Iteration 1163, loss = 60260308.74578822\n",
      "Iteration 1164, loss = 60251983.95790438\n",
      "Iteration 1165, loss = 60245888.59877479\n",
      "Iteration 1166, loss = 60238240.27105662\n",
      "Iteration 1167, loss = 60233505.53304683\n",
      "Iteration 1168, loss = 60223861.17033158\n",
      "Iteration 1169, loss = 60218070.65116791\n",
      "Iteration 1170, loss = 60210499.85036578\n",
      "Iteration 1171, loss = 60203851.35510734\n",
      "Iteration 1172, loss = 60196978.24976034\n",
      "Iteration 1173, loss = 60190771.58779134\n",
      "Iteration 1174, loss = 60184226.52300637\n",
      "Iteration 1175, loss = 60175593.99354459\n",
      "Iteration 1176, loss = 60168593.08189291\n",
      "Iteration 1177, loss = 60165147.38015700\n",
      "Iteration 1178, loss = 60155510.92575967\n",
      "Iteration 1179, loss = 60148544.63357293\n",
      "Iteration 1180, loss = 60141261.92259780\n",
      "Iteration 1181, loss = 60134678.40511712\n",
      "Iteration 1182, loss = 60126207.20002832\n",
      "Iteration 1183, loss = 60119430.96991637\n",
      "Iteration 1184, loss = 60112755.87259776\n",
      "Iteration 1185, loss = 60105232.74767505\n",
      "Iteration 1186, loss = 60099366.41150274\n",
      "Iteration 1187, loss = 60092037.29215001\n",
      "Iteration 1188, loss = 60084307.72882315\n",
      "Iteration 1189, loss = 60077143.55544732\n",
      "Iteration 1190, loss = 60069975.32333953\n",
      "Iteration 1191, loss = 60063075.45777151\n",
      "Iteration 1192, loss = 60057300.56073497\n",
      "Iteration 1193, loss = 60048469.42061108\n",
      "Iteration 1194, loss = 60041606.90797449\n",
      "Iteration 1195, loss = 60035837.63137460\n",
      "Iteration 1196, loss = 60026649.36926405\n",
      "Iteration 1197, loss = 60020397.52207148\n",
      "Iteration 1198, loss = 60012330.08678775\n",
      "Iteration 1199, loss = 60009709.80634325\n",
      "Iteration 1200, loss = 59997802.01762054\n",
      "Iteration 1201, loss = 59993517.18609327\n",
      "Iteration 1202, loss = 59983894.58532514\n",
      "Iteration 1203, loss = 59976335.19589023\n",
      "Iteration 1204, loss = 59970341.58377469\n",
      "Iteration 1205, loss = 59962465.74610121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1206, loss = 59955047.78300130\n",
      "Iteration 1207, loss = 59948227.98820651\n",
      "Iteration 1208, loss = 59941006.41347991\n",
      "Iteration 1209, loss = 59933578.12515977\n",
      "Iteration 1210, loss = 59925795.09961496\n",
      "Iteration 1211, loss = 59921326.84576463\n",
      "Iteration 1212, loss = 59911320.15138473\n",
      "Iteration 1213, loss = 59903933.36984088\n",
      "Iteration 1214, loss = 59896939.68051448\n",
      "Iteration 1215, loss = 59888929.76378832\n",
      "Iteration 1216, loss = 59884537.52254391\n",
      "Iteration 1217, loss = 59876321.76570019\n",
      "Iteration 1218, loss = 59867626.77465127\n",
      "Iteration 1219, loss = 59866043.28542701\n",
      "Iteration 1220, loss = 59852976.85086701\n",
      "Iteration 1221, loss = 59845604.15569213\n",
      "Iteration 1222, loss = 59836962.06103750\n",
      "Iteration 1223, loss = 59829379.46956323\n",
      "Iteration 1224, loss = 59823086.98226178\n",
      "Iteration 1225, loss = 59815115.54134463\n",
      "Iteration 1226, loss = 59809040.05085736\n",
      "Iteration 1227, loss = 59801714.01399022\n",
      "Iteration 1228, loss = 59791956.50896334\n",
      "Iteration 1229, loss = 59789000.08867655\n",
      "Iteration 1230, loss = 59777253.72707680\n",
      "Iteration 1231, loss = 59770361.87427158\n",
      "Iteration 1232, loss = 59762949.41628084\n",
      "Iteration 1233, loss = 59754923.41318682\n",
      "Iteration 1234, loss = 59750974.69103403\n",
      "Iteration 1235, loss = 59739432.01496375\n",
      "Iteration 1236, loss = 59732742.49319049\n",
      "Iteration 1237, loss = 59728202.22148945\n",
      "Iteration 1238, loss = 59719781.53062446\n",
      "Iteration 1239, loss = 59709224.45833912\n",
      "Iteration 1240, loss = 59702300.58686876\n",
      "Iteration 1241, loss = 59693849.92518239\n",
      "Iteration 1242, loss = 59686917.60554332\n",
      "Iteration 1243, loss = 59680526.71804497\n",
      "Iteration 1244, loss = 59671456.86844789\n",
      "Iteration 1245, loss = 59663474.50970577\n",
      "Iteration 1246, loss = 59655678.85436732\n",
      "Iteration 1247, loss = 59647273.85675640\n",
      "Iteration 1248, loss = 59641242.66624218\n",
      "Iteration 1249, loss = 59632561.15916892\n",
      "Iteration 1250, loss = 59624046.49940376\n",
      "Iteration 1251, loss = 59616539.73528297\n",
      "Iteration 1252, loss = 59608949.21285509\n",
      "Iteration 1253, loss = 59601812.97546746\n",
      "Iteration 1254, loss = 59593548.87404318\n",
      "Iteration 1255, loss = 59585585.23556048\n",
      "Iteration 1256, loss = 59576719.11119091\n",
      "Iteration 1257, loss = 59571022.57907677\n",
      "Iteration 1258, loss = 59561898.08246431\n",
      "Iteration 1259, loss = 59553519.42715030\n",
      "Iteration 1260, loss = 59547677.77394270\n",
      "Iteration 1261, loss = 59537970.18888397\n",
      "Iteration 1262, loss = 59529059.13124847\n",
      "Iteration 1263, loss = 59521770.54034408\n",
      "Iteration 1264, loss = 59514440.98037324\n",
      "Iteration 1265, loss = 59505395.45821249\n",
      "Iteration 1266, loss = 59498601.85151080\n",
      "Iteration 1267, loss = 59490460.00641350\n",
      "Iteration 1268, loss = 59483576.15454000\n",
      "Iteration 1269, loss = 59473357.54329161\n",
      "Iteration 1270, loss = 59466188.16320124\n",
      "Iteration 1271, loss = 59458616.88146450\n",
      "Iteration 1272, loss = 59450806.50023435\n",
      "Iteration 1273, loss = 59442672.94944911\n",
      "Iteration 1274, loss = 59433939.13757223\n",
      "Iteration 1275, loss = 59425085.17810079\n",
      "Iteration 1276, loss = 59417435.52465031\n",
      "Iteration 1277, loss = 59410915.59010531\n",
      "Iteration 1278, loss = 59401223.02945144\n",
      "Iteration 1279, loss = 59392868.10095005\n",
      "Iteration 1280, loss = 59387684.14309215\n",
      "Iteration 1281, loss = 59376399.87675575\n",
      "Iteration 1282, loss = 59369173.45820729\n",
      "Iteration 1283, loss = 59364339.41066402\n",
      "Iteration 1284, loss = 59353367.82709640\n",
      "Iteration 1285, loss = 59345819.96638124\n",
      "Iteration 1286, loss = 59335963.98212017\n",
      "Iteration 1287, loss = 59328320.47434971\n",
      "Iteration 1288, loss = 59319532.18493945\n",
      "Iteration 1289, loss = 59311315.97843106\n",
      "Iteration 1290, loss = 59303137.30730669\n",
      "Iteration 1291, loss = 59295375.04064249\n",
      "Iteration 1292, loss = 59286730.63651342\n",
      "Iteration 1293, loss = 59279599.37524580\n",
      "Iteration 1294, loss = 59270090.84706212\n",
      "Iteration 1295, loss = 59262180.79135799\n",
      "Iteration 1296, loss = 59254322.09364871\n",
      "Iteration 1297, loss = 59244650.79851185\n",
      "Iteration 1298, loss = 59236149.96977016\n",
      "Iteration 1299, loss = 59231482.70758738\n",
      "Iteration 1300, loss = 59219327.94245413\n",
      "Iteration 1301, loss = 59211351.33328464\n",
      "Iteration 1302, loss = 59203813.45882347\n",
      "Iteration 1303, loss = 59193901.34393174\n",
      "Iteration 1304, loss = 59185992.29058135\n",
      "Iteration 1305, loss = 59177304.73260843\n",
      "Iteration 1306, loss = 59169248.76960538\n",
      "Iteration 1307, loss = 59161362.07443465\n",
      "Iteration 1308, loss = 59151980.37592749\n",
      "Iteration 1309, loss = 59143533.24120331\n",
      "Iteration 1310, loss = 59135865.65876500\n",
      "Iteration 1311, loss = 59126025.58688816\n",
      "Iteration 1312, loss = 59117801.46541265\n",
      "Iteration 1313, loss = 59109093.95386600\n",
      "Iteration 1314, loss = 59101482.46086525\n",
      "Iteration 1315, loss = 59092479.19955420\n",
      "Iteration 1316, loss = 59084311.06160890\n",
      "Iteration 1317, loss = 59074391.42882949\n",
      "Iteration 1318, loss = 59066948.93154000\n",
      "Iteration 1319, loss = 59057674.17000864\n",
      "Iteration 1320, loss = 59049401.86837354\n",
      "Iteration 1321, loss = 59045531.22543566\n",
      "Iteration 1322, loss = 59031648.98706609\n",
      "Iteration 1323, loss = 59023339.43388089\n",
      "Iteration 1324, loss = 59014134.40274861\n",
      "Iteration 1325, loss = 59005188.73521246\n",
      "Iteration 1326, loss = 58998162.46967032\n",
      "Iteration 1327, loss = 58989132.40705793\n",
      "Iteration 1328, loss = 58982273.13078279\n",
      "Iteration 1329, loss = 58971110.15033243\n",
      "Iteration 1330, loss = 58961981.89435983\n",
      "Iteration 1331, loss = 58954172.00442758\n",
      "Iteration 1332, loss = 58945155.05741842\n",
      "Iteration 1333, loss = 58935444.94995459\n",
      "Iteration 1334, loss = 58929992.54345890\n",
      "Iteration 1335, loss = 58918199.35759030\n",
      "Iteration 1336, loss = 58911691.77607986\n",
      "Iteration 1337, loss = 58904157.77423492\n",
      "Iteration 1338, loss = 58895063.41527668\n",
      "Iteration 1339, loss = 58886907.35542220\n",
      "Iteration 1340, loss = 58875557.25626771\n",
      "Iteration 1341, loss = 58865978.71861708\n",
      "Iteration 1342, loss = 58857323.69032681\n",
      "Iteration 1343, loss = 58850667.23126277\n",
      "Iteration 1344, loss = 58839563.33885632\n",
      "Iteration 1345, loss = 58830620.79850975\n",
      "Iteration 1346, loss = 58821144.12716060\n",
      "Iteration 1347, loss = 58812046.10300571\n",
      "Iteration 1348, loss = 58803396.75299567\n",
      "Iteration 1349, loss = 58793914.05212537\n",
      "Iteration 1350, loss = 58784831.77977936\n",
      "Iteration 1351, loss = 58777980.14417049\n",
      "Iteration 1352, loss = 58770831.38910758\n",
      "Iteration 1353, loss = 58758080.33573147\n",
      "Iteration 1354, loss = 58749660.99475624\n",
      "Iteration 1355, loss = 58744402.30535167\n",
      "Iteration 1356, loss = 58732685.84936775\n",
      "Iteration 1357, loss = 58723545.47948917\n",
      "Iteration 1358, loss = 58715296.92970321\n",
      "Iteration 1359, loss = 58705250.00095192\n",
      "Iteration 1360, loss = 58696291.79553352\n",
      "Iteration 1361, loss = 58689476.78375871\n",
      "Iteration 1362, loss = 58678396.06666397\n",
      "Iteration 1363, loss = 58667954.07166091\n",
      "Iteration 1364, loss = 58658728.45687138\n",
      "Iteration 1365, loss = 58649787.47164684\n",
      "Iteration 1366, loss = 58641681.27555931\n",
      "Iteration 1367, loss = 58631913.06733713\n",
      "Iteration 1368, loss = 58623199.03755395\n",
      "Iteration 1369, loss = 58615696.28838901\n",
      "Iteration 1370, loss = 58607068.39344127\n",
      "Iteration 1371, loss = 58596056.30309295\n",
      "Iteration 1372, loss = 58586137.14309701\n",
      "Iteration 1373, loss = 58578359.58172094\n",
      "Iteration 1374, loss = 58566918.56226398\n",
      "Iteration 1375, loss = 58557971.91975599\n",
      "Iteration 1376, loss = 58550651.28061554\n",
      "Iteration 1377, loss = 58548106.93518528\n",
      "Iteration 1378, loss = 58529663.73516554\n",
      "Iteration 1379, loss = 58521131.41623289\n",
      "Iteration 1380, loss = 58513669.49118433\n",
      "Iteration 1381, loss = 58503144.95300455\n",
      "Iteration 1382, loss = 58492534.58314467\n",
      "Iteration 1383, loss = 58483808.88816975\n",
      "Iteration 1384, loss = 58474250.70451762\n",
      "Iteration 1385, loss = 58465070.27592271\n",
      "Iteration 1386, loss = 58455431.80334666\n",
      "Iteration 1387, loss = 58446512.38306199\n",
      "Iteration 1388, loss = 58437431.81180415\n",
      "Iteration 1389, loss = 58430376.06065318\n",
      "Iteration 1390, loss = 58420543.37617337\n",
      "Iteration 1391, loss = 58409037.09208760\n",
      "Iteration 1392, loss = 58407091.08573695\n",
      "Iteration 1393, loss = 58390676.88487250\n",
      "Iteration 1394, loss = 58380054.68976902\n",
      "Iteration 1395, loss = 58370935.44869178\n",
      "Iteration 1396, loss = 58361107.42508711\n",
      "Iteration 1397, loss = 58352002.77431230\n",
      "Iteration 1398, loss = 58343391.66964626\n",
      "Iteration 1399, loss = 58333866.10704517\n",
      "Iteration 1400, loss = 58322256.44842232\n",
      "Iteration 1401, loss = 58316049.12506062\n",
      "Iteration 1402, loss = 58303886.37664672\n",
      "Iteration 1403, loss = 58295545.12278315\n",
      "Iteration 1404, loss = 58285282.53895511\n",
      "Iteration 1405, loss = 58276277.03379694\n",
      "Iteration 1406, loss = 58269118.81278403\n",
      "Iteration 1407, loss = 58257432.16769079\n",
      "Iteration 1408, loss = 58245973.09868710\n",
      "Iteration 1409, loss = 58235925.87820813\n",
      "Iteration 1410, loss = 58226806.86373907\n",
      "Iteration 1411, loss = 58216886.39345913\n",
      "Iteration 1412, loss = 58209101.37971850\n",
      "Iteration 1413, loss = 58196610.42882857\n",
      "Iteration 1414, loss = 58187270.53630092\n",
      "Iteration 1415, loss = 58179683.42243724\n",
      "Iteration 1416, loss = 58169112.30020005\n",
      "Iteration 1417, loss = 58159183.26105285\n",
      "Iteration 1418, loss = 58148207.45382558\n",
      "Iteration 1419, loss = 58138374.50626069\n",
      "Iteration 1420, loss = 58131079.02206255\n",
      "Iteration 1421, loss = 58123050.16159391\n",
      "Iteration 1422, loss = 58109655.59668615\n",
      "Iteration 1423, loss = 58098920.83220581\n",
      "Iteration 1424, loss = 58089759.67440835\n",
      "Iteration 1425, loss = 58081743.84590768\n",
      "Iteration 1426, loss = 58071636.71979740\n",
      "Iteration 1427, loss = 58059419.40657166\n",
      "Iteration 1428, loss = 58050160.97275113\n",
      "Iteration 1429, loss = 58040962.10512645\n",
      "Iteration 1430, loss = 58029993.62322106\n",
      "Iteration 1431, loss = 58020545.02395484\n",
      "Iteration 1432, loss = 58009771.81494292\n",
      "Iteration 1433, loss = 58000201.21040279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1434, loss = 57989474.36615813\n",
      "Iteration 1435, loss = 57979693.61751642\n",
      "Iteration 1436, loss = 57969963.14765029\n",
      "Iteration 1437, loss = 57959905.77546830\n",
      "Iteration 1438, loss = 57952967.39617086\n",
      "Iteration 1439, loss = 57940899.03788760\n",
      "Iteration 1440, loss = 57929364.58487557\n",
      "Iteration 1441, loss = 57924782.18180963\n",
      "Iteration 1442, loss = 57909252.22906458\n",
      "Iteration 1443, loss = 57899070.64401504\n",
      "Iteration 1444, loss = 57890734.79689521\n",
      "Iteration 1445, loss = 57879586.64029400\n",
      "Iteration 1446, loss = 57869310.41050795\n",
      "Iteration 1447, loss = 57859023.52339510\n",
      "Iteration 1448, loss = 57849812.45716958\n",
      "Iteration 1449, loss = 57841325.98086838\n",
      "Iteration 1450, loss = 57829124.31787162\n",
      "Iteration 1451, loss = 57821754.83246518\n",
      "Iteration 1452, loss = 57807558.99433590\n",
      "Iteration 1453, loss = 57800937.13200487\n",
      "Iteration 1454, loss = 57787317.56492557\n",
      "Iteration 1455, loss = 57782000.83721641\n",
      "Iteration 1456, loss = 57768253.41946492\n",
      "Iteration 1457, loss = 57759394.50268605\n",
      "Iteration 1458, loss = 57746591.12618414\n",
      "Iteration 1459, loss = 57740730.11724664\n",
      "Iteration 1460, loss = 57725618.47695005\n",
      "Iteration 1461, loss = 57718848.53007380\n",
      "Iteration 1462, loss = 57705253.39605062\n",
      "Iteration 1463, loss = 57696093.54944951\n",
      "Iteration 1464, loss = 57685152.68412722\n",
      "Iteration 1465, loss = 57674422.53902238\n",
      "Iteration 1466, loss = 57664535.05017385\n",
      "Iteration 1467, loss = 57654839.82064351\n",
      "Iteration 1468, loss = 57644458.79960424\n",
      "Iteration 1469, loss = 57634027.82960173\n",
      "Iteration 1470, loss = 57624965.26516316\n",
      "Iteration 1471, loss = 57612044.05000440\n",
      "Iteration 1472, loss = 57603176.59150235\n",
      "Iteration 1473, loss = 57591580.99957415\n",
      "Iteration 1474, loss = 57581386.29747597\n",
      "Iteration 1475, loss = 57571304.32801716\n",
      "Iteration 1476, loss = 57561204.93207786\n",
      "Iteration 1477, loss = 57550471.52844539\n",
      "Iteration 1478, loss = 57538123.79690015\n",
      "Iteration 1479, loss = 57536103.30592882\n",
      "Iteration 1480, loss = 57517778.95713361\n",
      "Iteration 1481, loss = 57507774.93824387\n",
      "Iteration 1482, loss = 57496603.30272607\n",
      "Iteration 1483, loss = 57486219.62043745\n",
      "Iteration 1484, loss = 57475470.72595717\n",
      "Iteration 1485, loss = 57464644.00032073\n",
      "Iteration 1486, loss = 57453257.85884114\n",
      "Iteration 1487, loss = 57447785.99957268\n",
      "Iteration 1488, loss = 57432804.05469019\n",
      "Iteration 1489, loss = 57425119.40575013\n",
      "Iteration 1490, loss = 57412890.07094012\n",
      "Iteration 1491, loss = 57399730.40369277\n",
      "Iteration 1492, loss = 57390724.64963838\n",
      "Iteration 1493, loss = 57379816.85155462\n",
      "Iteration 1494, loss = 57367911.21751633\n",
      "Iteration 1495, loss = 57357063.38443702\n",
      "Iteration 1496, loss = 57346294.26615115\n",
      "Iteration 1497, loss = 57335881.65026453\n",
      "Iteration 1498, loss = 57325284.74344648\n",
      "Iteration 1499, loss = 57314503.99135376\n",
      "Iteration 1500, loss = 57303483.13850243\n",
      "Iteration 1501, loss = 57292307.00791669\n",
      "Iteration 1502, loss = 57283265.07812298\n",
      "Iteration 1503, loss = 57272095.46102675\n",
      "Iteration 1504, loss = 57259502.12007774\n",
      "Iteration 1505, loss = 57249110.44722189\n",
      "Iteration 1506, loss = 57238370.09942279\n",
      "Iteration 1507, loss = 57226708.93525547\n",
      "Iteration 1508, loss = 57215366.60561898\n",
      "Iteration 1509, loss = 57204826.25032544\n",
      "Iteration 1510, loss = 57195381.26655799\n",
      "Iteration 1511, loss = 57185688.35669146\n",
      "Iteration 1512, loss = 57173076.43157480\n",
      "Iteration 1513, loss = 57161557.04850141\n",
      "Iteration 1514, loss = 57150883.32092225\n",
      "Iteration 1515, loss = 57140253.23387511\n",
      "Iteration 1516, loss = 57128428.50680320\n",
      "Iteration 1517, loss = 57117136.78573522\n",
      "Iteration 1518, loss = 57109526.35485752\n",
      "Iteration 1519, loss = 57093922.26632395\n",
      "Iteration 1520, loss = 57084743.74830265\n",
      "Iteration 1521, loss = 57072128.44034734\n",
      "Iteration 1522, loss = 57060887.22410326\n",
      "Iteration 1523, loss = 57050690.28372511\n",
      "Iteration 1524, loss = 57038188.62713850\n",
      "Iteration 1525, loss = 57028129.54092207\n",
      "Iteration 1526, loss = 57017508.04768451\n",
      "Iteration 1527, loss = 57005010.53379458\n",
      "Iteration 1528, loss = 56993890.21513993\n",
      "Iteration 1529, loss = 56983986.69757447\n",
      "Iteration 1530, loss = 56972669.99675351\n",
      "Iteration 1531, loss = 56959743.02607913\n",
      "Iteration 1532, loss = 56948389.13456643\n",
      "Iteration 1533, loss = 56936794.07672214\n",
      "Iteration 1534, loss = 56927018.20074639\n",
      "Iteration 1535, loss = 56916034.60281273\n",
      "Iteration 1536, loss = 56903408.82264542\n",
      "Iteration 1537, loss = 56890968.07024705\n",
      "Iteration 1538, loss = 56881382.70535540\n",
      "Iteration 1539, loss = 56869398.52717954\n",
      "Iteration 1540, loss = 56856747.68014719\n",
      "Iteration 1541, loss = 56846770.23999622\n",
      "Iteration 1542, loss = 56833237.11680404\n",
      "Iteration 1543, loss = 56821999.96140825\n",
      "Iteration 1544, loss = 56810348.09072659\n",
      "Iteration 1545, loss = 56798897.08286233\n",
      "Iteration 1546, loss = 56789775.16059907\n",
      "Iteration 1547, loss = 56776121.12641348\n",
      "Iteration 1548, loss = 56764922.88238888\n",
      "Iteration 1549, loss = 56753009.84918182\n",
      "Iteration 1550, loss = 56741814.30682047\n",
      "Iteration 1551, loss = 56729829.72662824\n",
      "Iteration 1552, loss = 56716896.48248866\n",
      "Iteration 1553, loss = 56707702.28805096\n",
      "Iteration 1554, loss = 56694848.77427025\n",
      "Iteration 1555, loss = 56682589.29359242\n",
      "Iteration 1556, loss = 56671317.99531359\n",
      "Iteration 1557, loss = 56662895.02027830\n",
      "Iteration 1558, loss = 56648992.59991179\n",
      "Iteration 1559, loss = 56637250.31624318\n",
      "Iteration 1560, loss = 56627065.66517520\n",
      "Iteration 1561, loss = 56614523.03784356\n",
      "Iteration 1562, loss = 56601968.87258190\n",
      "Iteration 1563, loss = 56589135.72816145\n",
      "Iteration 1564, loss = 56578161.10073593\n",
      "Iteration 1565, loss = 56565576.55417087\n",
      "Iteration 1566, loss = 56553995.48913714\n",
      "Iteration 1567, loss = 56540827.08146740\n",
      "Iteration 1568, loss = 56528389.16309527\n",
      "Iteration 1569, loss = 56516761.43422165\n",
      "Iteration 1570, loss = 56505316.65339039\n",
      "Iteration 1571, loss = 56500368.29797502\n",
      "Iteration 1572, loss = 56481468.53479750\n",
      "Iteration 1573, loss = 56470974.43041126\n",
      "Iteration 1574, loss = 56458853.81324711\n",
      "Iteration 1575, loss = 56446255.78843497\n",
      "Iteration 1576, loss = 56434697.53931460\n",
      "Iteration 1577, loss = 56425178.44372766\n",
      "Iteration 1578, loss = 56411461.13271455\n",
      "Iteration 1579, loss = 56398989.88334410\n",
      "Iteration 1580, loss = 56387759.13298167\n",
      "Iteration 1581, loss = 56373655.57635169\n",
      "Iteration 1582, loss = 56361631.97544087\n",
      "Iteration 1583, loss = 56350490.18248973\n",
      "Iteration 1584, loss = 56338069.95427922\n",
      "Iteration 1585, loss = 56326925.96526099\n",
      "Iteration 1586, loss = 56313795.01549523\n",
      "Iteration 1587, loss = 56301341.44409192\n",
      "Iteration 1588, loss = 56292393.77973174\n",
      "Iteration 1589, loss = 56277123.76121362\n",
      "Iteration 1590, loss = 56265160.30387136\n",
      "Iteration 1591, loss = 56253928.06140525\n",
      "Iteration 1592, loss = 56240477.32543492\n",
      "Iteration 1593, loss = 56228462.87356038\n",
      "Iteration 1594, loss = 56220308.83770907\n",
      "Iteration 1595, loss = 56204234.96345324\n",
      "Iteration 1596, loss = 56191544.88076135\n",
      "Iteration 1597, loss = 56179261.88345274\n",
      "Iteration 1598, loss = 56167611.10978410\n",
      "Iteration 1599, loss = 56156738.50164732\n",
      "Iteration 1600, loss = 56144188.04020821\n",
      "Iteration 1601, loss = 56131582.48888979\n",
      "Iteration 1602, loss = 56117284.79133604\n",
      "Iteration 1603, loss = 56105466.38787045\n",
      "Iteration 1604, loss = 56093653.22943317\n",
      "Iteration 1605, loss = 56080037.65061466\n",
      "Iteration 1606, loss = 56067991.36740191\n",
      "Iteration 1607, loss = 56054854.05460177\n",
      "Iteration 1608, loss = 56044676.29553406\n",
      "Iteration 1609, loss = 56029811.06153969\n",
      "Iteration 1610, loss = 56017155.39603983\n",
      "Iteration 1611, loss = 56005399.16728178\n",
      "Iteration 1612, loss = 55993836.88706871\n",
      "Iteration 1613, loss = 55982212.47594368\n",
      "Iteration 1614, loss = 55969820.37498382\n",
      "Iteration 1615, loss = 55955956.05728006\n",
      "Iteration 1616, loss = 55942713.02964627\n",
      "Iteration 1617, loss = 55930395.72675019\n",
      "Iteration 1618, loss = 55917741.34508408\n",
      "Iteration 1619, loss = 55904774.75385635\n",
      "Iteration 1620, loss = 55893105.70977320\n",
      "Iteration 1621, loss = 55878527.70965338\n",
      "Iteration 1622, loss = 55867601.72129174\n",
      "Iteration 1623, loss = 55853042.93884590\n",
      "Iteration 1624, loss = 55846075.02492037\n",
      "Iteration 1625, loss = 55830573.33676835\n",
      "Iteration 1626, loss = 55814816.20227440\n",
      "Iteration 1627, loss = 55803310.95086741\n",
      "Iteration 1628, loss = 55792156.36086010\n",
      "Iteration 1629, loss = 55777946.08632796\n",
      "Iteration 1630, loss = 55763707.74776895\n",
      "Iteration 1631, loss = 55750627.01556285\n",
      "Iteration 1632, loss = 55738726.24907759\n",
      "Iteration 1633, loss = 55724636.24038408\n",
      "Iteration 1634, loss = 55711748.58432532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1635, loss = 55700436.53927740\n",
      "Iteration 1636, loss = 55688503.96718650\n",
      "Iteration 1637, loss = 55675148.89470738\n",
      "Iteration 1638, loss = 55662279.00795410\n",
      "Iteration 1639, loss = 55648064.71410249\n",
      "Iteration 1640, loss = 55635455.33135628\n",
      "Iteration 1641, loss = 55621488.50313482\n",
      "Iteration 1642, loss = 55608967.22253514\n",
      "Iteration 1643, loss = 55595721.68100055\n",
      "Iteration 1644, loss = 55583899.56989776\n",
      "Iteration 1645, loss = 55570380.47060135\n",
      "Iteration 1646, loss = 55555933.56702328\n",
      "Iteration 1647, loss = 55543155.92106751\n",
      "Iteration 1648, loss = 55533961.77157860\n",
      "Iteration 1649, loss = 55518694.68298704\n",
      "Iteration 1650, loss = 55502965.80680345\n",
      "Iteration 1651, loss = 55490751.40618804\n",
      "Iteration 1652, loss = 55478665.23809838\n",
      "Iteration 1653, loss = 55465936.65248501\n",
      "Iteration 1654, loss = 55450574.86984149\n",
      "Iteration 1655, loss = 55438911.30773905\n",
      "Iteration 1656, loss = 55425334.73254620\n",
      "Iteration 1657, loss = 55410632.11755888\n",
      "Iteration 1658, loss = 55399445.97038051\n",
      "Iteration 1659, loss = 55388977.93215558\n",
      "Iteration 1660, loss = 55375643.13633725\n",
      "Iteration 1661, loss = 55360639.60415144\n",
      "Iteration 1662, loss = 55344706.63717674\n",
      "Iteration 1663, loss = 55332685.77716134\n",
      "Iteration 1664, loss = 55320969.40397470\n",
      "Iteration 1665, loss = 55307240.49491856\n",
      "Iteration 1666, loss = 55292926.15053012\n",
      "Iteration 1667, loss = 55278546.48396706\n",
      "Iteration 1668, loss = 55267530.32582089\n",
      "Iteration 1669, loss = 55251136.48978654\n",
      "Iteration 1670, loss = 55239512.86505999\n",
      "Iteration 1671, loss = 55224945.80974795\n",
      "Iteration 1672, loss = 55212392.09923594\n",
      "Iteration 1673, loss = 55201163.31807832\n",
      "Iteration 1674, loss = 55186100.04085460\n",
      "Iteration 1675, loss = 55172406.66249371\n",
      "Iteration 1676, loss = 55158955.99902766\n",
      "Iteration 1677, loss = 55144532.30224869\n",
      "Iteration 1678, loss = 55132578.04934514\n",
      "Iteration 1679, loss = 55118401.53965674\n",
      "Iteration 1680, loss = 55103542.96345215\n",
      "Iteration 1681, loss = 55090410.43623408\n",
      "Iteration 1682, loss = 55077475.80914751\n",
      "Iteration 1683, loss = 55064269.85338208\n",
      "Iteration 1684, loss = 55052595.59787241\n",
      "Iteration 1685, loss = 55040807.65251318\n",
      "Iteration 1686, loss = 55021915.13225327\n",
      "Iteration 1687, loss = 55009203.34665838\n",
      "Iteration 1688, loss = 54995647.74596412\n",
      "Iteration 1689, loss = 54982336.62222534\n",
      "Iteration 1690, loss = 54967388.49066619\n",
      "Iteration 1691, loss = 54953895.12102363\n",
      "Iteration 1692, loss = 54940461.44474157\n",
      "Iteration 1693, loss = 54927325.59290545\n",
      "Iteration 1694, loss = 54912793.41261835\n",
      "Iteration 1695, loss = 54898681.19086331\n",
      "Iteration 1696, loss = 54884762.92409390\n",
      "Iteration 1697, loss = 54878084.65837407\n",
      "Iteration 1698, loss = 54856687.44969431\n",
      "Iteration 1699, loss = 54843753.35999919\n",
      "Iteration 1700, loss = 54829155.85923006\n",
      "Iteration 1701, loss = 54818265.92810921\n",
      "Iteration 1702, loss = 54802242.32186279\n",
      "Iteration 1703, loss = 54788551.98371115\n",
      "Iteration 1704, loss = 54776647.96298016\n",
      "Iteration 1705, loss = 54760029.78565319\n",
      "Iteration 1706, loss = 54748468.91463654\n",
      "Iteration 1707, loss = 54733126.32137964\n",
      "Iteration 1708, loss = 54717502.92320579\n",
      "Iteration 1709, loss = 54708118.94513971\n",
      "Iteration 1710, loss = 54691334.25650641\n",
      "Iteration 1711, loss = 54678342.88965512\n",
      "Iteration 1712, loss = 54661078.95791563\n",
      "Iteration 1713, loss = 54650602.66569728\n",
      "Iteration 1714, loss = 54633712.94504433\n",
      "Iteration 1715, loss = 54619833.19035181\n",
      "Iteration 1716, loss = 54604601.59417889\n",
      "Iteration 1717, loss = 54591472.24755558\n",
      "Iteration 1718, loss = 54578495.00516104\n",
      "Iteration 1719, loss = 54563028.06871969\n",
      "Iteration 1720, loss = 54550495.74493405\n",
      "Iteration 1721, loss = 54540374.97315659\n",
      "Iteration 1722, loss = 54520257.70177151\n",
      "Iteration 1723, loss = 54505587.66062317\n",
      "Iteration 1724, loss = 54491351.79891396\n",
      "Iteration 1725, loss = 54478055.74950374\n",
      "Iteration 1726, loss = 54464200.55819280\n",
      "Iteration 1727, loss = 54447987.39527112\n",
      "Iteration 1728, loss = 54439559.44578665\n",
      "Iteration 1729, loss = 54421903.50893623\n",
      "Iteration 1730, loss = 54406582.17233551\n",
      "Iteration 1731, loss = 54391807.94672758\n",
      "Iteration 1732, loss = 54376214.45575599\n",
      "Iteration 1733, loss = 54364778.79257046\n",
      "Iteration 1734, loss = 54349480.53909401\n",
      "Iteration 1735, loss = 54334546.01473021\n",
      "Iteration 1736, loss = 54320107.77070618\n",
      "Iteration 1737, loss = 54305884.36588574\n",
      "Iteration 1738, loss = 54292950.38814702\n",
      "Iteration 1739, loss = 54279005.87850376\n",
      "Iteration 1740, loss = 54264323.01160005\n",
      "Iteration 1741, loss = 54256719.36352991\n",
      "Iteration 1742, loss = 54236353.69829309\n",
      "Iteration 1743, loss = 54218991.76124981\n",
      "Iteration 1744, loss = 54205079.57576877\n",
      "Iteration 1745, loss = 54189108.38183621\n",
      "Iteration 1746, loss = 54177765.82493448\n",
      "Iteration 1747, loss = 54163591.24526100\n",
      "Iteration 1748, loss = 54156926.72898456\n",
      "Iteration 1749, loss = 54131596.79733989\n",
      "Iteration 1750, loss = 54119800.03476495\n",
      "Iteration 1751, loss = 54102927.87234509\n",
      "Iteration 1752, loss = 54087102.78199913\n",
      "Iteration 1753, loss = 54081135.15134798\n",
      "Iteration 1754, loss = 54064200.36611904\n",
      "Iteration 1755, loss = 54044883.59718913\n",
      "Iteration 1756, loss = 54031090.73320634\n",
      "Iteration 1757, loss = 54015885.91587823\n",
      "Iteration 1758, loss = 53998782.18290275\n",
      "Iteration 1759, loss = 53984841.20974734\n",
      "Iteration 1760, loss = 53971741.99131865\n",
      "Iteration 1761, loss = 53958259.38888726\n",
      "Iteration 1762, loss = 53942327.74092183\n",
      "Iteration 1763, loss = 53926887.53600269\n",
      "Iteration 1764, loss = 53914808.24115114\n",
      "Iteration 1765, loss = 53897903.96673465\n",
      "Iteration 1766, loss = 53882414.61326066\n",
      "Iteration 1767, loss = 53867881.74766860\n",
      "Iteration 1768, loss = 53857285.09578013\n",
      "Iteration 1769, loss = 53837087.79183846\n",
      "Iteration 1770, loss = 53822783.97864071\n",
      "Iteration 1771, loss = 53806970.53109150\n",
      "Iteration 1772, loss = 53792534.11884175\n",
      "Iteration 1773, loss = 53782415.67472997\n",
      "Iteration 1774, loss = 53762534.75040179\n",
      "Iteration 1775, loss = 53749005.89106835\n",
      "Iteration 1776, loss = 53741447.12763980\n",
      "Iteration 1777, loss = 53723174.05080839\n",
      "Iteration 1778, loss = 53704739.32869458\n",
      "Iteration 1779, loss = 53689723.82300575\n",
      "Iteration 1780, loss = 53674133.97302347\n",
      "Iteration 1781, loss = 53657829.77785178\n",
      "Iteration 1782, loss = 53643060.13146001\n",
      "Iteration 1783, loss = 53628190.44170319\n",
      "Iteration 1784, loss = 53613758.80109536\n",
      "Iteration 1785, loss = 53598715.78595069\n",
      "Iteration 1786, loss = 53587068.37828515\n",
      "Iteration 1787, loss = 53572214.95941161\n",
      "Iteration 1788, loss = 53554313.34082834\n",
      "Iteration 1789, loss = 53539950.88957042\n",
      "Iteration 1790, loss = 53525302.46804354\n",
      "Iteration 1791, loss = 53508394.42592867\n",
      "Iteration 1792, loss = 53493728.43305790\n",
      "Iteration 1793, loss = 53478464.76508295\n",
      "Iteration 1794, loss = 53466071.75355832\n",
      "Iteration 1795, loss = 53448449.07906641\n",
      "Iteration 1796, loss = 53431986.65713623\n",
      "Iteration 1797, loss = 53416896.34922600\n",
      "Iteration 1798, loss = 53403230.88910953\n",
      "Iteration 1799, loss = 53386496.18935169\n",
      "Iteration 1800, loss = 53374717.87324996\n",
      "Iteration 1801, loss = 53357923.04808039\n",
      "Iteration 1802, loss = 53340893.24407666\n",
      "Iteration 1803, loss = 53324250.29931349\n",
      "Iteration 1804, loss = 53314162.03638937\n",
      "Iteration 1805, loss = 53296792.51289529\n",
      "Iteration 1806, loss = 53279459.02154454\n",
      "Iteration 1807, loss = 53263273.55588801\n",
      "Iteration 1808, loss = 53249080.87804341\n",
      "Iteration 1809, loss = 53236151.94337574\n",
      "Iteration 1810, loss = 53218529.01452590\n",
      "Iteration 1811, loss = 53203659.79415426\n",
      "Iteration 1812, loss = 53188515.45442280\n",
      "Iteration 1813, loss = 53172665.36403800\n",
      "Iteration 1814, loss = 53156681.01559590\n",
      "Iteration 1815, loss = 53140965.78092226\n",
      "Iteration 1816, loss = 53127699.69980365\n",
      "Iteration 1817, loss = 53110340.61546644\n",
      "Iteration 1818, loss = 53094873.42270581\n",
      "Iteration 1819, loss = 53078804.28897218\n",
      "Iteration 1820, loss = 53063492.91791652\n",
      "Iteration 1821, loss = 53047356.95794464\n",
      "Iteration 1822, loss = 53031581.58246718\n",
      "Iteration 1823, loss = 53017711.11205398\n",
      "Iteration 1824, loss = 53000307.82065009\n",
      "Iteration 1825, loss = 52985208.01056740\n",
      "Iteration 1826, loss = 52970242.85867680\n",
      "Iteration 1827, loss = 52953847.85534488\n",
      "Iteration 1828, loss = 52938005.56750134\n",
      "Iteration 1829, loss = 52922230.51801904\n",
      "Iteration 1830, loss = 52907817.84471580\n",
      "Iteration 1831, loss = 52890133.28468771\n",
      "Iteration 1832, loss = 52875242.82166248\n",
      "Iteration 1833, loss = 52858161.29850116\n",
      "Iteration 1834, loss = 52842477.93551888\n",
      "Iteration 1835, loss = 52829109.54603725\n",
      "Iteration 1836, loss = 52814889.78010774\n",
      "Iteration 1837, loss = 52795433.36370075\n",
      "Iteration 1838, loss = 52779395.26178439\n",
      "Iteration 1839, loss = 52764061.92895086\n",
      "Iteration 1840, loss = 52748684.06924083\n",
      "Iteration 1841, loss = 52735663.98292092\n",
      "Iteration 1842, loss = 52717279.93724223\n",
      "Iteration 1843, loss = 52700331.72783160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1844, loss = 52683958.08990533\n",
      "Iteration 1845, loss = 52672093.85894524\n",
      "Iteration 1846, loss = 52652061.23614401\n",
      "Iteration 1847, loss = 52636264.27440505\n",
      "Iteration 1848, loss = 52620846.16348987\n",
      "Iteration 1849, loss = 52604434.81799836\n",
      "Iteration 1850, loss = 52590774.86418463\n",
      "Iteration 1851, loss = 52573789.40460590\n",
      "Iteration 1852, loss = 52557917.07039693\n",
      "Iteration 1853, loss = 52538884.36319022\n",
      "Iteration 1854, loss = 52524043.45918584\n",
      "Iteration 1855, loss = 52512406.08555596\n",
      "Iteration 1856, loss = 52493102.95365868\n",
      "Iteration 1857, loss = 52475497.37009506\n",
      "Iteration 1858, loss = 52459589.44317490\n",
      "Iteration 1859, loss = 52445649.61336585\n",
      "Iteration 1860, loss = 52427528.75348283\n",
      "Iteration 1861, loss = 52412196.73941237\n",
      "Iteration 1862, loss = 52394952.75546153\n",
      "Iteration 1863, loss = 52379634.65558060\n",
      "Iteration 1864, loss = 52362228.04790588\n",
      "Iteration 1865, loss = 52346205.03685662\n",
      "Iteration 1866, loss = 52331596.38372730\n",
      "Iteration 1867, loss = 52313599.60747290\n",
      "Iteration 1868, loss = 52297400.26835776\n",
      "Iteration 1869, loss = 52281819.87019588\n",
      "Iteration 1870, loss = 52266218.81300687\n",
      "Iteration 1871, loss = 52247250.42529029\n",
      "Iteration 1872, loss = 52231471.49022487\n",
      "Iteration 1873, loss = 52215963.43148781\n",
      "Iteration 1874, loss = 52200742.11898903\n",
      "Iteration 1875, loss = 52185149.68765742\n",
      "Iteration 1876, loss = 52166935.02620386\n",
      "Iteration 1877, loss = 52149022.42890386\n",
      "Iteration 1878, loss = 52142110.90582623\n",
      "Iteration 1879, loss = 52117060.08664707\n",
      "Iteration 1880, loss = 52102472.67070678\n",
      "Iteration 1881, loss = 52084001.57651704\n",
      "Iteration 1882, loss = 52073472.23505661\n",
      "Iteration 1883, loss = 52050455.55875667\n",
      "Iteration 1884, loss = 52033886.50168330\n",
      "Iteration 1885, loss = 52019534.22748958\n",
      "Iteration 1886, loss = 52000140.28716066\n",
      "Iteration 1887, loss = 51985121.06582768\n",
      "Iteration 1888, loss = 51967414.47077402\n",
      "Iteration 1889, loss = 51955054.35895784\n",
      "Iteration 1890, loss = 51934651.92277154\n",
      "Iteration 1891, loss = 51918608.21815783\n",
      "Iteration 1892, loss = 51901389.71943700\n",
      "Iteration 1893, loss = 51886318.83170814\n",
      "Iteration 1894, loss = 51871425.05888397\n",
      "Iteration 1895, loss = 51851333.58679463\n",
      "Iteration 1896, loss = 51836783.52867628\n",
      "Iteration 1897, loss = 51818042.20794070\n",
      "Iteration 1898, loss = 51810326.26176167\n",
      "Iteration 1899, loss = 51785133.60387396\n",
      "Iteration 1900, loss = 51767523.60416861\n",
      "Iteration 1901, loss = 51752499.22630292\n",
      "Iteration 1902, loss = 51739890.47331212\n",
      "Iteration 1903, loss = 51724587.67651081\n",
      "Iteration 1904, loss = 51701480.42090781\n",
      "Iteration 1905, loss = 51685709.92049426\n",
      "Iteration 1906, loss = 51669653.01586301\n",
      "Iteration 1907, loss = 51652609.86787318\n",
      "Iteration 1908, loss = 51636159.41003584\n",
      "Iteration 1909, loss = 51618373.41456670\n",
      "Iteration 1910, loss = 51602299.53614240\n",
      "Iteration 1911, loss = 51585942.45742134\n",
      "Iteration 1912, loss = 51568172.70615309\n",
      "Iteration 1913, loss = 51551006.80581462\n",
      "Iteration 1914, loss = 51534038.47205554\n",
      "Iteration 1915, loss = 51519019.29355777\n",
      "Iteration 1916, loss = 51502597.36728682\n",
      "Iteration 1917, loss = 51483802.63403124\n",
      "Iteration 1918, loss = 51467468.45448572\n",
      "Iteration 1919, loss = 51451669.88153785\n",
      "Iteration 1920, loss = 51434397.68842381\n",
      "Iteration 1921, loss = 51417168.80451817\n",
      "Iteration 1922, loss = 51398429.94328117\n",
      "Iteration 1923, loss = 51380205.01882229\n",
      "Iteration 1924, loss = 51363712.90162980\n",
      "Iteration 1925, loss = 51347185.35518687\n",
      "Iteration 1926, loss = 51333964.55659115\n",
      "Iteration 1927, loss = 51315523.82013128\n",
      "Iteration 1928, loss = 51295948.33536752\n",
      "Iteration 1929, loss = 51280927.96507011\n",
      "Iteration 1930, loss = 51261590.48854223\n",
      "Iteration 1931, loss = 51245863.86639458\n",
      "Iteration 1932, loss = 51231241.57472575\n",
      "Iteration 1933, loss = 51212979.75481272\n",
      "Iteration 1934, loss = 51195616.39218704\n",
      "Iteration 1935, loss = 51178154.48911314\n",
      "Iteration 1936, loss = 51159861.58045614\n",
      "Iteration 1937, loss = 51142420.02442785\n",
      "Iteration 1938, loss = 51126734.79864063\n",
      "Iteration 1939, loss = 51110867.15990601\n",
      "Iteration 1940, loss = 51090759.02438830\n",
      "Iteration 1941, loss = 51073663.12265116\n",
      "Iteration 1942, loss = 51058647.45596632\n",
      "Iteration 1943, loss = 51040425.44434776\n",
      "Iteration 1944, loss = 51022021.08705515\n",
      "Iteration 1945, loss = 51006211.06292622\n",
      "Iteration 1946, loss = 50988194.78451958\n",
      "Iteration 1947, loss = 50969546.38065599\n",
      "Iteration 1948, loss = 50956245.39934023\n",
      "Iteration 1949, loss = 50935683.59013224\n",
      "Iteration 1950, loss = 50917809.25073431\n",
      "Iteration 1951, loss = 50902219.61252871\n",
      "Iteration 1952, loss = 50885984.14823044\n",
      "Iteration 1953, loss = 50867414.04952852\n",
      "Iteration 1954, loss = 50852313.37540956\n",
      "Iteration 1955, loss = 50834304.63164657\n",
      "Iteration 1956, loss = 50816254.20202324\n",
      "Iteration 1957, loss = 50798800.74400578\n",
      "Iteration 1958, loss = 50780365.54856991\n",
      "Iteration 1959, loss = 50764486.57917589\n",
      "Iteration 1960, loss = 50744969.34400730\n",
      "Iteration 1961, loss = 50726634.75123806\n",
      "Iteration 1962, loss = 50709684.53757064\n",
      "Iteration 1963, loss = 50691304.61250164\n",
      "Iteration 1964, loss = 50673207.56492335\n",
      "Iteration 1965, loss = 50657054.28211196\n",
      "Iteration 1966, loss = 50639080.21878079\n",
      "Iteration 1967, loss = 50621126.63027649\n",
      "Iteration 1968, loss = 50605278.54889457\n",
      "Iteration 1969, loss = 50586142.72047573\n",
      "Iteration 1970, loss = 50570091.78172559\n",
      "Iteration 1971, loss = 50550074.79276794\n",
      "Iteration 1972, loss = 50532959.27661456\n",
      "Iteration 1973, loss = 50516278.68994780\n",
      "Iteration 1974, loss = 50498243.48559523\n",
      "Iteration 1975, loss = 50479085.87335873\n",
      "Iteration 1976, loss = 50461895.28190125\n",
      "Iteration 1977, loss = 50447177.07063234\n",
      "Iteration 1978, loss = 50426780.11463270\n",
      "Iteration 1979, loss = 50411376.95875420\n",
      "Iteration 1980, loss = 50391793.83756138\n",
      "Iteration 1981, loss = 50375293.53412957\n",
      "Iteration 1982, loss = 50355917.00859721\n",
      "Iteration 1983, loss = 50337633.97819582\n",
      "Iteration 1984, loss = 50320535.57484966\n",
      "Iteration 1985, loss = 50302163.99124729\n",
      "Iteration 1986, loss = 50287997.92276970\n",
      "Iteration 1987, loss = 50267221.60931253\n",
      "Iteration 1988, loss = 50247963.04807981\n",
      "Iteration 1989, loss = 50231969.54804756\n",
      "Iteration 1990, loss = 50218556.27159107\n",
      "Iteration 1991, loss = 50193973.51341948\n",
      "Iteration 1992, loss = 50176559.89126993\n",
      "Iteration 1993, loss = 50160634.61867644\n",
      "Iteration 1994, loss = 50140671.04497842\n",
      "Iteration 1995, loss = 50132526.80193449\n",
      "Iteration 1996, loss = 50104460.70797680\n",
      "Iteration 1997, loss = 50085306.07619642\n",
      "Iteration 1998, loss = 50067292.28929608\n",
      "Iteration 1999, loss = 50058302.31933858\n",
      "Iteration 2000, loss = 50031830.18993068\n",
      "Iteration 2001, loss = 50015140.90486222\n",
      "Iteration 2002, loss = 49998385.32505161\n",
      "Iteration 2003, loss = 49979316.08130210\n",
      "Iteration 2004, loss = 49958793.94576816\n",
      "Iteration 2005, loss = 49942340.74049793\n",
      "Iteration 2006, loss = 49925864.70938459\n",
      "Iteration 2007, loss = 49904226.30361646\n",
      "Iteration 2008, loss = 49888139.33230076\n",
      "Iteration 2009, loss = 49867755.73289647\n",
      "Iteration 2010, loss = 49851133.26634153\n",
      "Iteration 2011, loss = 49834967.56717473\n",
      "Iteration 2012, loss = 49822949.26983760\n",
      "Iteration 2013, loss = 49795221.14991713\n",
      "Iteration 2014, loss = 49776806.24981955\n",
      "Iteration 2015, loss = 49759882.21186613\n",
      "Iteration 2016, loss = 49743358.01884961\n",
      "Iteration 2017, loss = 49721355.68669230\n",
      "Iteration 2018, loss = 49703809.06607922\n",
      "Iteration 2019, loss = 49686370.63049942\n",
      "Iteration 2020, loss = 49666776.42264870\n",
      "Iteration 2021, loss = 49653864.01197071\n",
      "Iteration 2022, loss = 49630527.76402737\n",
      "Iteration 2023, loss = 49612185.01651384\n",
      "Iteration 2024, loss = 49594651.71201769\n",
      "Iteration 2025, loss = 49574874.01816141\n",
      "Iteration 2026, loss = 49558288.38456343\n",
      "Iteration 2027, loss = 49538390.39770669\n",
      "Iteration 2028, loss = 49519239.52498408\n",
      "Iteration 2029, loss = 49501564.35822069\n",
      "Iteration 2030, loss = 49484104.60046716\n",
      "Iteration 2031, loss = 49463310.08148965\n",
      "Iteration 2032, loss = 49445219.61421227\n",
      "Iteration 2033, loss = 49426891.67405669\n",
      "Iteration 2034, loss = 49410160.67824659\n",
      "Iteration 2035, loss = 49388975.02335773\n",
      "Iteration 2036, loss = 49370216.13690481\n",
      "Iteration 2037, loss = 49351645.70778142\n",
      "Iteration 2038, loss = 49333459.83639658\n",
      "Iteration 2039, loss = 49314091.33313899\n",
      "Iteration 2040, loss = 49297900.17092522\n",
      "Iteration 2041, loss = 49275876.11712226\n",
      "Iteration 2042, loss = 49261544.77044326\n",
      "Iteration 2043, loss = 49239955.63349197\n",
      "Iteration 2044, loss = 49223077.10295850\n",
      "Iteration 2045, loss = 49203076.19825418\n",
      "Iteration 2046, loss = 49184150.75446607\n",
      "Iteration 2047, loss = 49168769.96102377\n",
      "Iteration 2048, loss = 49147250.09109704\n",
      "Iteration 2049, loss = 49126692.86269736\n",
      "Iteration 2050, loss = 49108076.23025657\n",
      "Iteration 2051, loss = 49088630.61016320\n",
      "Iteration 2052, loss = 49082421.75937553\n",
      "Iteration 2053, loss = 49051716.60683338\n",
      "Iteration 2054, loss = 49034382.51327406\n",
      "Iteration 2055, loss = 49011356.50798757\n",
      "Iteration 2056, loss = 48995118.17076126\n",
      "Iteration 2057, loss = 48977948.85838626\n",
      "Iteration 2058, loss = 48958923.07227331\n",
      "Iteration 2059, loss = 48941326.92995100\n",
      "Iteration 2060, loss = 48923674.08944784\n",
      "Iteration 2061, loss = 48906140.29233492\n",
      "Iteration 2062, loss = 48882842.69876292\n",
      "Iteration 2063, loss = 48864011.14522308\n",
      "Iteration 2064, loss = 48845137.04938405\n",
      "Iteration 2065, loss = 48826606.89294385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2066, loss = 48817599.81985037\n",
      "Iteration 2067, loss = 48789886.00504467\n",
      "Iteration 2068, loss = 48770732.61361415\n",
      "Iteration 2069, loss = 48759542.74940751\n",
      "Iteration 2070, loss = 48733274.42965563\n",
      "Iteration 2071, loss = 48714559.01197324\n",
      "Iteration 2072, loss = 48695100.78345002\n",
      "Iteration 2073, loss = 48679760.78836597\n",
      "Iteration 2074, loss = 48658180.11849595\n",
      "Iteration 2075, loss = 48636950.06607721\n",
      "Iteration 2076, loss = 48619804.74033517\n",
      "Iteration 2077, loss = 48601474.21706101\n",
      "Iteration 2078, loss = 48580286.32244568\n",
      "Iteration 2079, loss = 48561423.34231597\n",
      "Iteration 2080, loss = 48542075.22498123\n",
      "Iteration 2081, loss = 48522813.35250145\n",
      "Iteration 2082, loss = 48504421.47634214\n",
      "Iteration 2083, loss = 48485701.04371380\n",
      "Iteration 2084, loss = 48466839.25757143\n",
      "Iteration 2085, loss = 48447260.71975884\n",
      "Iteration 2086, loss = 48429123.99611577\n",
      "Iteration 2087, loss = 48409288.20431559\n",
      "Iteration 2088, loss = 48390888.99000645\n",
      "Iteration 2089, loss = 48370411.71949398\n",
      "Iteration 2090, loss = 48354086.60840306\n",
      "Iteration 2091, loss = 48335568.80523472\n",
      "Iteration 2092, loss = 48313828.86560762\n",
      "Iteration 2093, loss = 48292770.03406615\n",
      "Iteration 2094, loss = 48277547.03352541\n",
      "Iteration 2095, loss = 48254939.09783130\n",
      "Iteration 2096, loss = 48235504.19377918\n",
      "Iteration 2097, loss = 48216248.15904856\n",
      "Iteration 2098, loss = 48196546.92483501\n",
      "Iteration 2099, loss = 48177953.56637330\n",
      "Iteration 2100, loss = 48160360.63560145\n",
      "Iteration 2101, loss = 48139259.02097005\n",
      "Iteration 2102, loss = 48120260.51493746\n",
      "Iteration 2103, loss = 48102990.13529335\n",
      "Iteration 2104, loss = 48082185.47466216\n",
      "Iteration 2105, loss = 48061142.37468492\n",
      "Iteration 2106, loss = 48042050.07664295\n",
      "Iteration 2107, loss = 48023789.39876848\n",
      "Iteration 2108, loss = 48002956.04009767\n",
      "Iteration 2109, loss = 47986661.66671522\n",
      "Iteration 2110, loss = 47966921.44114790\n",
      "Iteration 2111, loss = 47945307.83075964\n",
      "Iteration 2112, loss = 47928389.39613958\n",
      "Iteration 2113, loss = 47907446.11060519\n",
      "Iteration 2114, loss = 47890129.11593150\n",
      "Iteration 2115, loss = 47868692.93668472\n",
      "Iteration 2116, loss = 47848066.04862779\n",
      "Iteration 2117, loss = 47830201.25409192\n",
      "Iteration 2118, loss = 47813429.67107444\n",
      "Iteration 2119, loss = 47789632.20972393\n",
      "Iteration 2120, loss = 47769478.15154087\n",
      "Iteration 2121, loss = 47750573.13145994\n",
      "Iteration 2122, loss = 47732408.61802708\n",
      "Iteration 2123, loss = 47711491.89304518\n",
      "Iteration 2124, loss = 47691753.08824949\n",
      "Iteration 2125, loss = 47673108.77770082\n",
      "Iteration 2126, loss = 47656688.58096550\n",
      "Iteration 2127, loss = 47634063.63906914\n",
      "Iteration 2128, loss = 47616002.50451934\n",
      "Iteration 2129, loss = 47593780.67898960\n",
      "Iteration 2130, loss = 47574176.53931782\n",
      "Iteration 2131, loss = 47553656.22705909\n",
      "Iteration 2132, loss = 47534089.27125289\n",
      "Iteration 2133, loss = 47517928.36643731\n",
      "Iteration 2134, loss = 47495263.70423664\n",
      "Iteration 2135, loss = 47479302.59611370\n",
      "Iteration 2136, loss = 47456887.71504448\n",
      "Iteration 2137, loss = 47436442.21662860\n",
      "Iteration 2138, loss = 47415780.93439189\n",
      "Iteration 2139, loss = 47395240.63505761\n",
      "Iteration 2140, loss = 47376624.42618901\n",
      "Iteration 2141, loss = 47356833.97536302\n",
      "Iteration 2142, loss = 47336772.00889914\n",
      "Iteration 2143, loss = 47318363.39667904\n",
      "Iteration 2144, loss = 47296534.06569351\n",
      "Iteration 2145, loss = 47276248.25506141\n",
      "Iteration 2146, loss = 47256685.27290805\n",
      "Iteration 2147, loss = 47238406.53428046\n",
      "Iteration 2148, loss = 47219791.16706374\n",
      "Iteration 2149, loss = 47198578.42691896\n",
      "Iteration 2150, loss = 47187607.22471654\n",
      "Iteration 2151, loss = 47159139.19227800\n",
      "Iteration 2152, loss = 47139621.68911201\n",
      "Iteration 2153, loss = 47121644.85358888\n",
      "Iteration 2154, loss = 47101156.73198086\n",
      "Iteration 2155, loss = 47080188.56578098\n",
      "Iteration 2156, loss = 47058887.16388287\n",
      "Iteration 2157, loss = 47038787.62275075\n",
      "Iteration 2158, loss = 47018890.43678524\n",
      "Iteration 2159, loss = 46999843.37714741\n",
      "Iteration 2160, loss = 46980297.60403277\n",
      "Iteration 2161, loss = 46958833.37486183\n",
      "Iteration 2162, loss = 46937436.63385740\n",
      "Iteration 2163, loss = 46920244.20733304\n",
      "Iteration 2164, loss = 46899220.71312569\n",
      "Iteration 2165, loss = 46879842.19243278\n",
      "Iteration 2166, loss = 46861509.77644997\n",
      "Iteration 2167, loss = 46840842.18107069\n",
      "Iteration 2168, loss = 46819747.16747676\n",
      "Iteration 2169, loss = 46797724.25967696\n",
      "Iteration 2170, loss = 46779329.16713221\n",
      "Iteration 2171, loss = 46759439.69263987\n",
      "Iteration 2172, loss = 46746416.45733510\n",
      "Iteration 2173, loss = 46721172.89104104\n",
      "Iteration 2174, loss = 46698277.56962190\n",
      "Iteration 2175, loss = 46679562.70255291\n",
      "Iteration 2176, loss = 46656572.30996295\n",
      "Iteration 2177, loss = 46644250.62478623\n",
      "Iteration 2178, loss = 46616365.99091937\n",
      "Iteration 2179, loss = 46598560.45016173\n",
      "Iteration 2180, loss = 46580665.51971757\n",
      "Iteration 2181, loss = 46559769.95922470\n",
      "Iteration 2182, loss = 46537960.76662496\n",
      "Iteration 2183, loss = 46516320.75496656\n",
      "Iteration 2184, loss = 46500367.09866826\n",
      "Iteration 2185, loss = 46475634.40101033\n",
      "Iteration 2186, loss = 46454767.61918709\n",
      "Iteration 2187, loss = 46442368.00555922\n",
      "Iteration 2188, loss = 46416604.96799230\n",
      "Iteration 2189, loss = 46394109.09233633\n",
      "Iteration 2190, loss = 46373043.43310406\n",
      "Iteration 2191, loss = 46353619.17517594\n",
      "Iteration 2192, loss = 46333936.60744899\n",
      "Iteration 2193, loss = 46315416.32458286\n",
      "Iteration 2194, loss = 46291518.59244990\n",
      "Iteration 2195, loss = 46272706.77558063\n",
      "Iteration 2196, loss = 46253830.29314860\n",
      "Iteration 2197, loss = 46232423.38880300\n",
      "Iteration 2198, loss = 46212795.39569563\n",
      "Iteration 2199, loss = 46190194.53970779\n",
      "Iteration 2200, loss = 46175921.36892322\n",
      "Iteration 2201, loss = 46149150.30837121\n",
      "Iteration 2202, loss = 46129325.34359067\n",
      "Iteration 2203, loss = 46108889.08117945\n",
      "Iteration 2204, loss = 46088793.61996615\n",
      "Iteration 2205, loss = 46068918.97481845\n",
      "Iteration 2206, loss = 46047535.06072535\n",
      "Iteration 2207, loss = 46032446.58043855\n",
      "Iteration 2208, loss = 46008855.13887041\n",
      "Iteration 2209, loss = 45985122.81966951\n",
      "Iteration 2210, loss = 45965662.26542125\n",
      "Iteration 2211, loss = 45946265.67464617\n",
      "Iteration 2212, loss = 45924840.36309839\n",
      "Iteration 2213, loss = 45909400.30003031\n",
      "Iteration 2214, loss = 45886922.21616016\n",
      "Iteration 2215, loss = 45864440.87488785\n",
      "Iteration 2216, loss = 45846765.41852812\n",
      "Iteration 2217, loss = 45823558.30614608\n",
      "Iteration 2218, loss = 45804550.30622694\n",
      "Iteration 2219, loss = 45784321.07640415\n",
      "Iteration 2220, loss = 45765364.05812734\n",
      "Iteration 2221, loss = 45740636.93569071\n",
      "Iteration 2222, loss = 45721907.67917868\n",
      "Iteration 2223, loss = 45699164.77055708\n",
      "Iteration 2224, loss = 45678701.66956089\n",
      "Iteration 2225, loss = 45663064.99584284\n",
      "Iteration 2226, loss = 45636601.71629124\n",
      "Iteration 2227, loss = 45616944.09167280\n",
      "Iteration 2228, loss = 45596647.95170108\n",
      "Iteration 2229, loss = 45574092.89110410\n",
      "Iteration 2230, loss = 45555150.57023801\n",
      "Iteration 2231, loss = 45533358.11857527\n",
      "Iteration 2232, loss = 45512285.13916013\n",
      "Iteration 2233, loss = 45492460.92464291\n",
      "Iteration 2234, loss = 45471763.93693332\n",
      "Iteration 2235, loss = 45451740.53455085\n",
      "Iteration 2236, loss = 45429219.05022098\n",
      "Iteration 2237, loss = 45413174.30106333\n",
      "Iteration 2238, loss = 45386285.37241841\n",
      "Iteration 2239, loss = 45366082.75575919\n",
      "Iteration 2240, loss = 45350155.59072582\n",
      "Iteration 2241, loss = 45328982.64192202\n",
      "Iteration 2242, loss = 45307253.83828906\n",
      "Iteration 2243, loss = 45284066.05408886\n",
      "Iteration 2244, loss = 45265588.85721561\n",
      "Iteration 2245, loss = 45240963.41112217\n",
      "Iteration 2246, loss = 45223493.19591083\n",
      "Iteration 2247, loss = 45199464.07147740\n",
      "Iteration 2248, loss = 45178161.91298982\n",
      "Iteration 2249, loss = 45159148.64170873\n",
      "Iteration 2250, loss = 45136668.29575831\n",
      "Iteration 2251, loss = 45116155.99356230\n",
      "Iteration 2252, loss = 45094633.56588347\n",
      "Iteration 2253, loss = 45073495.08772404\n",
      "Iteration 2254, loss = 45055180.91647892\n",
      "Iteration 2255, loss = 45034118.52739013\n",
      "Iteration 2256, loss = 45011052.19989816\n",
      "Iteration 2257, loss = 44990919.16155486\n",
      "Iteration 2258, loss = 44968372.46391592\n",
      "Iteration 2259, loss = 44955492.13169916\n",
      "Iteration 2260, loss = 44927606.21439520\n",
      "Iteration 2261, loss = 44906292.79385136\n",
      "Iteration 2262, loss = 44885415.81672379\n",
      "Iteration 2263, loss = 44865727.50500353\n",
      "Iteration 2264, loss = 44844869.20024711\n",
      "Iteration 2265, loss = 44823811.55845599\n",
      "Iteration 2266, loss = 44800298.50786069\n",
      "Iteration 2267, loss = 44781305.86374704\n",
      "Iteration 2268, loss = 44762748.27281709\n",
      "Iteration 2269, loss = 44739381.57313380\n",
      "Iteration 2270, loss = 44719511.17245045\n",
      "Iteration 2271, loss = 44699696.25366710\n",
      "Iteration 2272, loss = 44675863.18904135\n",
      "Iteration 2273, loss = 44655520.53514142\n",
      "Iteration 2274, loss = 44638269.52667625\n",
      "Iteration 2275, loss = 44613659.03253747\n",
      "Iteration 2276, loss = 44592573.00654522\n",
      "Iteration 2277, loss = 44572669.71649037\n",
      "Iteration 2278, loss = 44552612.20276612\n",
      "Iteration 2279, loss = 44528967.38453422\n",
      "Iteration 2280, loss = 44508665.82799102\n",
      "Iteration 2281, loss = 44486836.19496493\n",
      "Iteration 2282, loss = 44463885.30177303\n",
      "Iteration 2283, loss = 44443780.03168337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2284, loss = 44422408.36051634\n",
      "Iteration 2285, loss = 44402167.12793453\n",
      "Iteration 2286, loss = 44380889.46163415\n",
      "Iteration 2287, loss = 44359162.15619537\n",
      "Iteration 2288, loss = 44340359.74196655\n",
      "Iteration 2289, loss = 44318204.52133281\n",
      "Iteration 2290, loss = 44294645.61203549\n",
      "Iteration 2291, loss = 44275260.14130370\n",
      "Iteration 2292, loss = 44252864.83048275\n",
      "Iteration 2293, loss = 44231965.03569306\n",
      "Iteration 2294, loss = 44214933.63047174\n",
      "Iteration 2295, loss = 44189953.56249738\n",
      "Iteration 2296, loss = 44168124.44805694\n",
      "Iteration 2297, loss = 44147085.87067208\n",
      "Iteration 2298, loss = 44127733.70320005\n",
      "Iteration 2299, loss = 44104237.71005069\n",
      "Iteration 2300, loss = 44086914.06558666\n",
      "Iteration 2301, loss = 44062682.45127480\n",
      "Iteration 2302, loss = 44040561.97077535\n",
      "Iteration 2303, loss = 44018455.49508511\n",
      "Iteration 2304, loss = 43998449.87888151\n",
      "Iteration 2305, loss = 43976110.80075800\n",
      "Iteration 2306, loss = 43954852.71060481\n",
      "Iteration 2307, loss = 43939330.29732871\n",
      "Iteration 2308, loss = 43911988.27703574\n",
      "Iteration 2309, loss = 43891715.12585860\n",
      "Iteration 2310, loss = 43870011.79903719\n",
      "Iteration 2311, loss = 43848401.07607533\n",
      "Iteration 2312, loss = 43830796.94940481\n",
      "Iteration 2313, loss = 43805299.61234172\n",
      "Iteration 2314, loss = 43784989.12923602\n",
      "Iteration 2315, loss = 43760911.46997720\n",
      "Iteration 2316, loss = 43742447.96587693\n",
      "Iteration 2317, loss = 43722266.12968099\n",
      "Iteration 2318, loss = 43697121.25435230\n",
      "Iteration 2319, loss = 43674509.99390557\n",
      "Iteration 2320, loss = 43652989.79011764\n",
      "Iteration 2321, loss = 43632138.77157941\n",
      "Iteration 2322, loss = 43609759.62748701\n",
      "Iteration 2323, loss = 43588856.56745560\n",
      "Iteration 2324, loss = 43566392.01228549\n",
      "Iteration 2325, loss = 43545948.33436756\n",
      "Iteration 2326, loss = 43525207.73837221\n",
      "Iteration 2327, loss = 43507761.92942853\n",
      "Iteration 2328, loss = 43481364.71012584\n",
      "Iteration 2329, loss = 43461572.98110788\n",
      "Iteration 2330, loss = 43438151.85015093\n",
      "Iteration 2331, loss = 43421788.49007839\n",
      "Iteration 2332, loss = 43397946.56779031\n",
      "Iteration 2333, loss = 43377826.07052626\n",
      "Iteration 2334, loss = 43354350.17643862\n",
      "Iteration 2335, loss = 43331929.99444795\n",
      "Iteration 2336, loss = 43311526.04831391\n",
      "Iteration 2337, loss = 43289965.78080796\n",
      "Iteration 2338, loss = 43267509.60807292\n",
      "Iteration 2339, loss = 43245493.69753230\n",
      "Iteration 2340, loss = 43231495.64548260\n",
      "Iteration 2341, loss = 43207415.79250348\n",
      "Iteration 2342, loss = 43178768.05598819\n",
      "Iteration 2343, loss = 43161348.40331348\n",
      "Iteration 2344, loss = 43136264.78713617\n",
      "Iteration 2345, loss = 43116118.22164893\n",
      "Iteration 2346, loss = 43093790.12625168\n",
      "Iteration 2347, loss = 43077207.03239325\n",
      "Iteration 2348, loss = 43050466.93581168\n",
      "Iteration 2349, loss = 43031018.52847049\n",
      "Iteration 2350, loss = 43009204.73369277\n",
      "Iteration 2351, loss = 42985712.94044934\n",
      "Iteration 2352, loss = 42964445.45190861\n",
      "Iteration 2353, loss = 42942957.18738554\n",
      "Iteration 2354, loss = 42920263.15405316\n",
      "Iteration 2355, loss = 42897770.03575180\n",
      "Iteration 2356, loss = 42877748.38472091\n",
      "Iteration 2357, loss = 42857270.79164975\n",
      "Iteration 2358, loss = 42833694.92785610\n",
      "Iteration 2359, loss = 42812008.83771513\n",
      "Iteration 2360, loss = 42792646.57441352\n",
      "Iteration 2361, loss = 42770678.13976300\n",
      "Iteration 2362, loss = 42748030.59189619\n",
      "Iteration 2363, loss = 42725238.43775366\n",
      "Iteration 2364, loss = 42702859.02570709\n",
      "Iteration 2365, loss = 42681422.05829448\n",
      "Iteration 2366, loss = 42661789.16621824\n",
      "Iteration 2367, loss = 42636929.52412990\n",
      "Iteration 2368, loss = 42615506.55991443\n",
      "Iteration 2369, loss = 42594493.49274096\n",
      "Iteration 2370, loss = 42573468.86281034\n",
      "Iteration 2371, loss = 42549856.57469262\n",
      "Iteration 2372, loss = 42526603.85968146\n",
      "Iteration 2373, loss = 42507532.27132226\n",
      "Iteration 2374, loss = 42484665.14810003\n",
      "Iteration 2375, loss = 42462746.54167070\n",
      "Iteration 2376, loss = 42445052.16566828\n",
      "Iteration 2377, loss = 42418849.31750668\n",
      "Iteration 2378, loss = 42398332.60648416\n",
      "Iteration 2379, loss = 42377445.84981019\n",
      "Iteration 2380, loss = 42355923.05853765\n",
      "Iteration 2381, loss = 42330518.12076427\n",
      "Iteration 2382, loss = 42309893.15761992\n",
      "Iteration 2383, loss = 42288362.33990129\n",
      "Iteration 2384, loss = 42271481.19977155\n",
      "Iteration 2385, loss = 42242984.40359384\n",
      "Iteration 2386, loss = 42221002.26313156\n",
      "Iteration 2387, loss = 42198815.58679376\n",
      "Iteration 2388, loss = 42179745.02474507\n",
      "Iteration 2389, loss = 42157213.82539644\n",
      "Iteration 2390, loss = 42133851.94220020\n",
      "Iteration 2391, loss = 42119216.43222382\n",
      "Iteration 2392, loss = 42093806.33254684\n",
      "Iteration 2393, loss = 42066632.95293011\n",
      "Iteration 2394, loss = 42048335.56843412\n",
      "Iteration 2395, loss = 42024016.86496186\n",
      "Iteration 2396, loss = 42001599.62509415\n",
      "Iteration 2397, loss = 41980948.89162547\n",
      "Iteration 2398, loss = 41960380.71838741\n",
      "Iteration 2399, loss = 41942390.35623708\n",
      "Iteration 2400, loss = 41913255.45440385\n",
      "Iteration 2401, loss = 41894245.60660604\n",
      "Iteration 2402, loss = 41871299.47520042\n",
      "Iteration 2403, loss = 41846673.30784950\n",
      "Iteration 2404, loss = 41824695.44174816\n",
      "Iteration 2405, loss = 41803804.93402214\n",
      "Iteration 2406, loss = 41780462.50474591\n",
      "Iteration 2407, loss = 41759910.72111149\n",
      "Iteration 2408, loss = 41743774.48667852\n",
      "Iteration 2409, loss = 41715149.89454450\n",
      "Iteration 2410, loss = 41699986.72545542\n",
      "Iteration 2411, loss = 41671795.42247901\n",
      "Iteration 2412, loss = 41647087.78544329\n",
      "Iteration 2413, loss = 41632902.52295695\n",
      "Iteration 2414, loss = 41604653.17550600\n",
      "Iteration 2415, loss = 41589348.32595397\n",
      "Iteration 2416, loss = 41560450.14657843\n",
      "Iteration 2417, loss = 41538236.70908300\n",
      "Iteration 2418, loss = 41524149.37021297\n",
      "Iteration 2419, loss = 41496296.47403881\n",
      "Iteration 2420, loss = 41473851.47235639\n",
      "Iteration 2421, loss = 41451803.86537874\n",
      "Iteration 2422, loss = 41436394.33871980\n",
      "Iteration 2423, loss = 41408005.70326017\n",
      "Iteration 2424, loss = 41387487.72790460\n",
      "Iteration 2425, loss = 41364603.87371439\n",
      "Iteration 2426, loss = 41343159.19737643\n",
      "Iteration 2427, loss = 41316856.65126065\n",
      "Iteration 2428, loss = 41296349.87074472\n",
      "Iteration 2429, loss = 41273164.32179200\n",
      "Iteration 2430, loss = 41250411.42657162\n",
      "Iteration 2431, loss = 41227965.32273823\n",
      "Iteration 2432, loss = 41206726.19543758\n",
      "Iteration 2433, loss = 41184970.79955726\n",
      "Iteration 2434, loss = 41162505.28342982\n",
      "Iteration 2435, loss = 41140013.48375093\n",
      "Iteration 2436, loss = 41122874.59191192\n",
      "Iteration 2437, loss = 41100540.39293774\n",
      "Iteration 2438, loss = 41074258.66719238\n",
      "Iteration 2439, loss = 41051730.10999443\n",
      "Iteration 2440, loss = 41030189.48066612\n",
      "Iteration 2441, loss = 41007280.03441909\n",
      "Iteration 2442, loss = 40986507.31904064\n",
      "Iteration 2443, loss = 40962086.88289597\n",
      "Iteration 2444, loss = 40939996.36535601\n",
      "Iteration 2445, loss = 40918820.54728588\n",
      "Iteration 2446, loss = 40897910.26894052\n",
      "Iteration 2447, loss = 40875267.28778006\n",
      "Iteration 2448, loss = 40852858.73356923\n",
      "Iteration 2449, loss = 40830241.66835078\n",
      "Iteration 2450, loss = 40807910.10254470\n",
      "Iteration 2451, loss = 40785415.77325581\n",
      "Iteration 2452, loss = 40763778.19618157\n",
      "Iteration 2453, loss = 40743467.19759545\n",
      "Iteration 2454, loss = 40719750.45772088\n",
      "Iteration 2455, loss = 40696718.33912490\n",
      "Iteration 2456, loss = 40675530.83582045\n",
      "Iteration 2457, loss = 40652768.69809796\n",
      "Iteration 2458, loss = 40632371.32979362\n",
      "Iteration 2459, loss = 40607033.18496793\n",
      "Iteration 2460, loss = 40586311.62340336\n",
      "Iteration 2461, loss = 40565055.32337590\n",
      "Iteration 2462, loss = 40544748.48019061\n",
      "Iteration 2463, loss = 40518878.18837985\n",
      "Iteration 2464, loss = 40501057.71900465\n",
      "Iteration 2465, loss = 40480613.65451494\n",
      "Iteration 2466, loss = 40457835.25060604\n",
      "Iteration 2467, loss = 40429695.08045057\n",
      "Iteration 2468, loss = 40408338.61942200\n",
      "Iteration 2469, loss = 40388962.49120480\n",
      "Iteration 2470, loss = 40362189.22312860\n",
      "Iteration 2471, loss = 40341009.59242599\n",
      "Iteration 2472, loss = 40318740.87825596\n",
      "Iteration 2473, loss = 40299405.05522036\n",
      "Iteration 2474, loss = 40274118.31773011\n",
      "Iteration 2475, loss = 40252277.20626849\n",
      "Iteration 2476, loss = 40229965.58055265\n",
      "Iteration 2477, loss = 40209141.18376524\n",
      "Iteration 2478, loss = 40188748.35654969\n",
      "Iteration 2479, loss = 40165175.10610989\n",
      "Iteration 2480, loss = 40143287.75259874\n",
      "Iteration 2481, loss = 40119327.30752926\n",
      "Iteration 2482, loss = 40097397.54776528\n",
      "Iteration 2483, loss = 40075321.88686884\n",
      "Iteration 2484, loss = 40050429.83844136\n",
      "Iteration 2485, loss = 40029794.34700330\n",
      "Iteration 2486, loss = 40008424.80341477\n",
      "Iteration 2487, loss = 39984283.59515806\n",
      "Iteration 2488, loss = 39962375.66200860\n",
      "Iteration 2489, loss = 39941258.40168129\n",
      "Iteration 2490, loss = 39918657.91441502\n",
      "Iteration 2491, loss = 39894941.61078442\n",
      "Iteration 2492, loss = 39874906.51574348\n",
      "Iteration 2493, loss = 39850146.29881199\n",
      "Iteration 2494, loss = 39833374.65083557\n",
      "Iteration 2495, loss = 39807071.68033540\n",
      "Iteration 2496, loss = 39782864.67608754\n",
      "Iteration 2497, loss = 39769899.09477552\n",
      "Iteration 2498, loss = 39746758.84799828\n",
      "Iteration 2499, loss = 39716816.85410400\n",
      "Iteration 2500, loss = 39699329.66167756\n",
      "Iteration 2501, loss = 39672069.31430683\n",
      "Iteration 2502, loss = 39649722.34815771\n",
      "Iteration 2503, loss = 39627978.55939872\n",
      "Iteration 2504, loss = 39605780.84230115\n",
      "Iteration 2505, loss = 39583757.19761693\n",
      "Iteration 2506, loss = 39560839.16954313\n",
      "Iteration 2507, loss = 39539048.51289389\n",
      "Iteration 2508, loss = 39515706.28423790\n",
      "Iteration 2509, loss = 39493434.62320209\n",
      "Iteration 2510, loss = 39472903.13374325\n",
      "Iteration 2511, loss = 39448623.25729385\n",
      "Iteration 2512, loss = 39432906.33885729\n",
      "Iteration 2513, loss = 39408222.78567766\n",
      "Iteration 2514, loss = 39383290.45343354\n",
      "Iteration 2515, loss = 39360532.23698047\n",
      "Iteration 2516, loss = 39340873.78582975\n",
      "Iteration 2517, loss = 39315603.04487870\n",
      "Iteration 2518, loss = 39294784.30677629\n",
      "Iteration 2519, loss = 39272729.83288929\n",
      "Iteration 2520, loss = 39251804.07745598\n",
      "Iteration 2521, loss = 39228465.70018472\n",
      "Iteration 2522, loss = 39211747.80307760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2523, loss = 39183409.63769186\n",
      "Iteration 2524, loss = 39163048.41840065\n",
      "Iteration 2525, loss = 39142945.39788871\n",
      "Iteration 2526, loss = 39117371.64229660\n",
      "Iteration 2527, loss = 39093450.35844442\n",
      "Iteration 2528, loss = 39070992.84032888\n",
      "Iteration 2529, loss = 39050587.79901975\n",
      "Iteration 2530, loss = 39026353.25545499\n",
      "Iteration 2531, loss = 39005359.73135371\n",
      "Iteration 2532, loss = 38980070.22532194\n",
      "Iteration 2533, loss = 38964327.72412001\n",
      "Iteration 2534, loss = 38937131.46847288\n",
      "Iteration 2535, loss = 38919641.14031298\n",
      "Iteration 2536, loss = 38897620.78157128\n",
      "Iteration 2537, loss = 38870512.87585978\n",
      "Iteration 2538, loss = 38849270.77239018\n",
      "Iteration 2539, loss = 38829181.23340787\n",
      "Iteration 2540, loss = 38802251.91338224\n",
      "Iteration 2541, loss = 38781994.50015724\n",
      "Iteration 2542, loss = 38757932.18592894\n",
      "Iteration 2543, loss = 38738336.40719662\n",
      "Iteration 2544, loss = 38718028.26798817\n",
      "Iteration 2545, loss = 38691576.04819607\n",
      "Iteration 2546, loss = 38668507.86388108\n",
      "Iteration 2547, loss = 38646676.92491410\n",
      "Iteration 2548, loss = 38624259.35667369\n",
      "Iteration 2549, loss = 38601307.27077630\n",
      "Iteration 2550, loss = 38579175.69508389\n",
      "Iteration 2551, loss = 38556787.91250530\n",
      "Iteration 2552, loss = 38534621.90671900\n",
      "Iteration 2553, loss = 38512594.20991968\n",
      "Iteration 2554, loss = 38488565.78555734\n",
      "Iteration 2555, loss = 38467409.22313786\n",
      "Iteration 2556, loss = 38446066.63797803\n",
      "Iteration 2557, loss = 38420778.76161014\n",
      "Iteration 2558, loss = 38400020.04184401\n",
      "Iteration 2559, loss = 38377863.66056157\n",
      "Iteration 2560, loss = 38356448.47909044\n",
      "Iteration 2561, loss = 38333101.12197375\n",
      "Iteration 2562, loss = 38309240.35061365\n",
      "Iteration 2563, loss = 38289553.90412540\n",
      "Iteration 2564, loss = 38264149.18345910\n",
      "Iteration 2565, loss = 38241415.45436856\n",
      "Iteration 2566, loss = 38220458.72480153\n",
      "Iteration 2567, loss = 38195749.89559159\n",
      "Iteration 2568, loss = 38177585.59203795\n",
      "Iteration 2569, loss = 38152870.30558682\n",
      "Iteration 2570, loss = 38131578.17085764\n",
      "Iteration 2571, loss = 38105822.59337622\n",
      "Iteration 2572, loss = 38083850.93605146\n",
      "Iteration 2573, loss = 38064219.93093525\n",
      "Iteration 2574, loss = 38040858.62465673\n",
      "Iteration 2575, loss = 38018670.34476269\n",
      "Iteration 2576, loss = 37994420.07848065\n",
      "Iteration 2577, loss = 37973246.29483561\n",
      "Iteration 2578, loss = 37964951.96471777\n",
      "Iteration 2579, loss = 37928707.45155649\n",
      "Iteration 2580, loss = 37906455.09117456\n",
      "Iteration 2581, loss = 37882792.58685309\n",
      "Iteration 2582, loss = 37864450.31162430\n",
      "Iteration 2583, loss = 37840550.40079879\n",
      "Iteration 2584, loss = 37817668.98617984\n",
      "Iteration 2585, loss = 37793277.79529037\n",
      "Iteration 2586, loss = 37770687.85867008\n",
      "Iteration 2587, loss = 37749294.11602693\n",
      "Iteration 2588, loss = 37729525.88966648\n",
      "Iteration 2589, loss = 37702637.11607382\n",
      "Iteration 2590, loss = 37687907.86837156\n",
      "Iteration 2591, loss = 37662754.78213359\n",
      "Iteration 2592, loss = 37641184.74657549\n",
      "Iteration 2593, loss = 37615694.42465220\n",
      "Iteration 2594, loss = 37592041.02916662\n",
      "Iteration 2595, loss = 37582460.04692435\n",
      "Iteration 2596, loss = 37549116.87261995\n",
      "Iteration 2597, loss = 37523985.50578125\n",
      "Iteration 2598, loss = 37504367.23776069\n",
      "Iteration 2599, loss = 37480387.55340537\n",
      "Iteration 2600, loss = 37459664.10404740\n",
      "Iteration 2601, loss = 37435944.24725903\n",
      "Iteration 2602, loss = 37411866.44618947\n",
      "Iteration 2603, loss = 37390463.09862533\n",
      "Iteration 2604, loss = 37370368.61470748\n",
      "Iteration 2605, loss = 37345240.91615051\n",
      "Iteration 2606, loss = 37324447.68764538\n",
      "Iteration 2607, loss = 37300970.19666908\n",
      "Iteration 2608, loss = 37280535.00481683\n",
      "Iteration 2609, loss = 37258091.87692743\n",
      "Iteration 2610, loss = 37234209.26931156\n",
      "Iteration 2611, loss = 37213283.85597427\n",
      "Iteration 2612, loss = 37196818.29003160\n",
      "Iteration 2613, loss = 37165703.32334130\n",
      "Iteration 2614, loss = 37144695.08071460\n",
      "Iteration 2615, loss = 37122749.08048272\n",
      "Iteration 2616, loss = 37106727.30866388\n",
      "Iteration 2617, loss = 37076631.60644590\n",
      "Iteration 2618, loss = 37063277.14548667\n",
      "Iteration 2619, loss = 37033348.97225653\n",
      "Iteration 2620, loss = 37011037.99526379\n",
      "Iteration 2621, loss = 36989661.15852511\n",
      "Iteration 2622, loss = 36966132.12348219\n",
      "Iteration 2623, loss = 36947123.22778594\n",
      "Iteration 2624, loss = 36928674.02516325\n",
      "Iteration 2625, loss = 36899851.61722536\n",
      "Iteration 2626, loss = 36876624.10316084\n",
      "Iteration 2627, loss = 36854845.07286243\n",
      "Iteration 2628, loss = 36831517.45103553\n",
      "Iteration 2629, loss = 36809751.22132288\n",
      "Iteration 2630, loss = 36787504.85526545\n",
      "Iteration 2631, loss = 36767120.78784229\n",
      "Iteration 2632, loss = 36743852.20556031\n",
      "Iteration 2633, loss = 36721987.75477725\n",
      "Iteration 2634, loss = 36698714.89677718\n",
      "Iteration 2635, loss = 36676927.47552352\n",
      "Iteration 2636, loss = 36656167.57846796\n",
      "Iteration 2637, loss = 36631454.17672406\n",
      "Iteration 2638, loss = 36608465.44065566\n",
      "Iteration 2639, loss = 36589546.39538425\n",
      "Iteration 2640, loss = 36565144.59160400\n",
      "Iteration 2641, loss = 36541155.20177590\n",
      "Iteration 2642, loss = 36518975.41067855\n",
      "Iteration 2643, loss = 36498880.67036680\n",
      "Iteration 2644, loss = 36476247.23059176\n",
      "Iteration 2645, loss = 36454440.98310114\n",
      "Iteration 2646, loss = 36431269.28472841\n",
      "Iteration 2647, loss = 36414114.59822841\n",
      "Iteration 2648, loss = 36386327.96943396\n",
      "Iteration 2649, loss = 36361646.23504899\n",
      "Iteration 2650, loss = 36339172.65999962\n",
      "Iteration 2651, loss = 36317462.34385165\n",
      "Iteration 2652, loss = 36295383.33255658\n",
      "Iteration 2653, loss = 36274240.59789693\n",
      "Iteration 2654, loss = 36252031.62983706\n",
      "Iteration 2655, loss = 36228812.81218328\n",
      "Iteration 2656, loss = 36214397.48622159\n",
      "Iteration 2657, loss = 36185405.90623160\n",
      "Iteration 2658, loss = 36163003.81211399\n",
      "Iteration 2659, loss = 36141115.94658151\n",
      "Iteration 2660, loss = 36118443.62824535\n",
      "Iteration 2661, loss = 36094268.56263552\n",
      "Iteration 2662, loss = 36073795.91123877\n",
      "Iteration 2663, loss = 36050522.42725558\n",
      "Iteration 2664, loss = 36027559.74275479\n",
      "Iteration 2665, loss = 36006497.78889066\n",
      "Iteration 2666, loss = 35984976.09676132\n",
      "Iteration 2667, loss = 35961118.47807843\n",
      "Iteration 2668, loss = 35941043.40488368\n",
      "Iteration 2669, loss = 35921064.31475270\n",
      "Iteration 2670, loss = 35895329.20694318\n",
      "Iteration 2671, loss = 35871758.79589491\n",
      "Iteration 2672, loss = 35850894.55755001\n",
      "Iteration 2673, loss = 35828752.01280354\n",
      "Iteration 2674, loss = 35810210.56823418\n",
      "Iteration 2675, loss = 35787625.06332304\n",
      "Iteration 2676, loss = 35763845.61215270\n",
      "Iteration 2677, loss = 35740785.87044403\n",
      "Iteration 2678, loss = 35725759.90994837\n",
      "Iteration 2679, loss = 35698450.72263911\n",
      "Iteration 2680, loss = 35674346.63680061\n",
      "Iteration 2681, loss = 35649356.29325883\n",
      "Iteration 2682, loss = 35627913.75015455\n",
      "Iteration 2683, loss = 35607854.96985758\n",
      "Iteration 2684, loss = 35583923.43326921\n",
      "Iteration 2685, loss = 35560139.10035148\n",
      "Iteration 2686, loss = 35544454.32665485\n",
      "Iteration 2687, loss = 35519025.08994815\n",
      "Iteration 2688, loss = 35495823.28272339\n",
      "Iteration 2689, loss = 35472506.87297170\n",
      "Iteration 2690, loss = 35452428.83540808\n",
      "Iteration 2691, loss = 35429475.26728375\n",
      "Iteration 2692, loss = 35406739.72496563\n",
      "Iteration 2693, loss = 35383296.75457297\n",
      "Iteration 2694, loss = 35363822.54581279\n",
      "Iteration 2695, loss = 35343192.61769982\n",
      "Iteration 2696, loss = 35321665.08740462\n",
      "Iteration 2697, loss = 35294509.16248728\n",
      "Iteration 2698, loss = 35278891.50127532\n",
      "Iteration 2699, loss = 35249869.41680079\n",
      "Iteration 2700, loss = 35227165.52471264\n",
      "Iteration 2701, loss = 35206365.21399617\n",
      "Iteration 2702, loss = 35186132.12588625\n",
      "Iteration 2703, loss = 35161476.93183928\n",
      "Iteration 2704, loss = 35138466.73868366\n",
      "Iteration 2705, loss = 35117830.96375784\n",
      "Iteration 2706, loss = 35094620.44147488\n",
      "Iteration 2707, loss = 35077700.44874042\n",
      "Iteration 2708, loss = 35050874.78375546\n",
      "Iteration 2709, loss = 35030264.57945111\n",
      "Iteration 2710, loss = 35007036.72224537\n",
      "Iteration 2711, loss = 34985181.04753365\n",
      "Iteration 2712, loss = 34962472.38480085\n",
      "Iteration 2713, loss = 34938858.69064342\n",
      "Iteration 2714, loss = 34920751.38603244\n",
      "Iteration 2715, loss = 34894792.98579555\n",
      "Iteration 2716, loss = 34873434.33235976\n",
      "Iteration 2717, loss = 34853512.79198954\n",
      "Iteration 2718, loss = 34828532.29377373\n",
      "Iteration 2719, loss = 34806968.12313741\n",
      "Iteration 2720, loss = 34783476.28638899\n",
      "Iteration 2721, loss = 34764163.10812087\n",
      "Iteration 2722, loss = 34743136.50106694\n",
      "Iteration 2723, loss = 34720093.16868676\n",
      "Iteration 2724, loss = 34696065.26496235\n",
      "Iteration 2725, loss = 34675488.19947800\n",
      "Iteration 2726, loss = 34652444.24655537\n",
      "Iteration 2727, loss = 34628501.48469676\n",
      "Iteration 2728, loss = 34607222.48320892\n",
      "Iteration 2729, loss = 34584000.53038141\n",
      "Iteration 2730, loss = 34565872.73251381\n",
      "Iteration 2731, loss = 34541319.26197997\n",
      "Iteration 2732, loss = 34529172.02129196\n",
      "Iteration 2733, loss = 34513566.09686186\n",
      "Iteration 2734, loss = 34477016.08319800\n",
      "Iteration 2735, loss = 34455720.18867175\n",
      "Iteration 2736, loss = 34430565.52268920\n",
      "Iteration 2737, loss = 34408090.22755678\n",
      "Iteration 2738, loss = 34388178.59671329\n",
      "Iteration 2739, loss = 34365623.18301968\n",
      "Iteration 2740, loss = 34341066.64437724\n",
      "Iteration 2741, loss = 34318970.40933925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2742, loss = 34297258.48780127\n",
      "Iteration 2743, loss = 34277795.97146497\n",
      "Iteration 2744, loss = 34254264.49811373\n",
      "Iteration 2745, loss = 34233200.55702736\n",
      "Iteration 2746, loss = 34210381.60274415\n",
      "Iteration 2747, loss = 34186220.86033288\n",
      "Iteration 2748, loss = 34168364.33648849\n",
      "Iteration 2749, loss = 34143189.49487726\n",
      "Iteration 2750, loss = 34122006.52543493\n",
      "Iteration 2751, loss = 34099843.01287424\n",
      "Iteration 2752, loss = 34077655.54541277\n",
      "Iteration 2753, loss = 34055047.36908466\n",
      "Iteration 2754, loss = 34037096.22610186\n",
      "Iteration 2755, loss = 34013695.21707965\n",
      "Iteration 2756, loss = 33991184.36274833\n",
      "Iteration 2757, loss = 33967892.30197167\n",
      "Iteration 2758, loss = 33946347.87400045\n",
      "Iteration 2759, loss = 33925016.90040036\n",
      "Iteration 2760, loss = 33904901.23750672\n",
      "Iteration 2761, loss = 33884305.33132409\n",
      "Iteration 2762, loss = 33861465.48352768\n",
      "Iteration 2763, loss = 33846170.78746162\n",
      "Iteration 2764, loss = 33814775.06055861\n",
      "Iteration 2765, loss = 33793167.04562189\n",
      "Iteration 2766, loss = 33773888.97067523\n",
      "Iteration 2767, loss = 33752917.63983862\n",
      "Iteration 2768, loss = 33728992.98175427\n",
      "Iteration 2769, loss = 33707265.55315620\n",
      "Iteration 2770, loss = 33684732.79059479\n",
      "Iteration 2771, loss = 33664848.61787353\n",
      "Iteration 2772, loss = 33646417.07140646\n",
      "Iteration 2773, loss = 33618912.71475784\n",
      "Iteration 2774, loss = 33597972.16251333\n",
      "Iteration 2775, loss = 33576392.17549399\n",
      "Iteration 2776, loss = 33554676.45468688\n",
      "Iteration 2777, loss = 33537719.83677354\n",
      "Iteration 2778, loss = 33514600.42977424\n",
      "Iteration 2779, loss = 33490356.87637948\n",
      "Iteration 2780, loss = 33467751.67717150\n",
      "Iteration 2781, loss = 33447875.17401830\n",
      "Iteration 2782, loss = 33423208.89483691\n",
      "Iteration 2783, loss = 33405908.93214232\n",
      "Iteration 2784, loss = 33386065.00627100\n",
      "Iteration 2785, loss = 33359028.15504320\n",
      "Iteration 2786, loss = 33339750.56400727\n",
      "Iteration 2787, loss = 33324757.87675441\n",
      "Iteration 2788, loss = 33293427.09240752\n",
      "Iteration 2789, loss = 33273414.20290632\n",
      "Iteration 2790, loss = 33253241.34924413\n",
      "Iteration 2791, loss = 33230048.13239592\n",
      "Iteration 2792, loss = 33209306.59381165\n",
      "Iteration 2793, loss = 33185442.16026434\n",
      "Iteration 2794, loss = 33168190.16744562\n",
      "Iteration 2795, loss = 33145306.17109001\n",
      "Iteration 2796, loss = 33121970.35795052\n",
      "Iteration 2797, loss = 33098578.99107067\n",
      "Iteration 2798, loss = 33084259.55039979\n",
      "Iteration 2799, loss = 33059732.68547083\n",
      "Iteration 2800, loss = 33038295.37605682\n",
      "Iteration 2801, loss = 33013233.64304643\n",
      "Iteration 2802, loss = 32992491.44203141\n",
      "Iteration 2803, loss = 32970572.07588267\n",
      "Iteration 2804, loss = 32961178.78266178\n",
      "Iteration 2805, loss = 32930598.16829545\n",
      "Iteration 2806, loss = 32909695.42492764\n",
      "Iteration 2807, loss = 32885081.95381278\n",
      "Iteration 2808, loss = 32862796.87719646\n",
      "Iteration 2809, loss = 32844987.22859450\n",
      "Iteration 2810, loss = 32821009.05273152\n",
      "Iteration 2811, loss = 32802192.52312851\n",
      "Iteration 2812, loss = 32784833.66681059\n",
      "Iteration 2813, loss = 32758826.45254207\n",
      "Iteration 2814, loss = 32734396.55543076\n",
      "Iteration 2815, loss = 32712880.46308491\n",
      "Iteration 2816, loss = 32691640.38553395\n",
      "Iteration 2817, loss = 32685115.66949350\n",
      "Iteration 2818, loss = 32653436.64182351\n",
      "Iteration 2819, loss = 32630995.38195319\n",
      "Iteration 2820, loss = 32609892.16943510\n",
      "Iteration 2821, loss = 32586042.47214898\n",
      "Iteration 2822, loss = 32565331.55313318\n",
      "Iteration 2823, loss = 32547168.84570448\n",
      "Iteration 2824, loss = 32523709.33740741\n",
      "Iteration 2825, loss = 32501985.01130490\n",
      "Iteration 2826, loss = 32479051.70517257\n",
      "Iteration 2827, loss = 32465353.61409278\n",
      "Iteration 2828, loss = 32439008.33617435\n",
      "Iteration 2829, loss = 32417438.14089259\n",
      "Iteration 2830, loss = 32394324.87379971\n",
      "Iteration 2831, loss = 32374926.87847849\n",
      "Iteration 2832, loss = 32354351.54846695\n",
      "Iteration 2833, loss = 32335307.31965907\n",
      "Iteration 2834, loss = 32324662.26199325\n",
      "Iteration 2835, loss = 32291422.61952080\n",
      "Iteration 2836, loss = 32270670.76371655\n",
      "Iteration 2837, loss = 32246773.22387563\n",
      "Iteration 2838, loss = 32226878.99065928\n",
      "Iteration 2839, loss = 32208321.56203328\n",
      "Iteration 2840, loss = 32185414.70514229\n",
      "Iteration 2841, loss = 32166317.52557644\n",
      "Iteration 2842, loss = 32148295.21522992\n",
      "Iteration 2843, loss = 32126962.14873914\n",
      "Iteration 2844, loss = 32103055.93726326\n",
      "Iteration 2845, loss = 32079526.12618024\n",
      "Iteration 2846, loss = 32058372.99480847\n",
      "Iteration 2847, loss = 32041385.72914227\n",
      "Iteration 2848, loss = 32014990.46437999\n",
      "Iteration 2849, loss = 31993081.12852640\n",
      "Iteration 2850, loss = 31972573.91224345\n",
      "Iteration 2851, loss = 31951170.57744239\n",
      "Iteration 2852, loss = 31929552.10403607\n",
      "Iteration 2853, loss = 31912697.25088916\n",
      "Iteration 2854, loss = 31886583.40504998\n",
      "Iteration 2855, loss = 31869277.30272675\n",
      "Iteration 2856, loss = 31847092.88774355\n",
      "Iteration 2857, loss = 31824982.84330743\n",
      "Iteration 2858, loss = 31803957.20049606\n",
      "Iteration 2859, loss = 31783271.61634121\n",
      "Iteration 2860, loss = 31764937.09102996\n",
      "Iteration 2861, loss = 31740664.97725091\n",
      "Iteration 2862, loss = 31741495.35151185\n",
      "Iteration 2863, loss = 31705549.60011322\n",
      "Iteration 2864, loss = 31677524.89888963\n",
      "Iteration 2865, loss = 31656354.18555753\n",
      "Iteration 2866, loss = 31636270.45851710\n",
      "Iteration 2867, loss = 31616197.02418270\n",
      "Iteration 2868, loss = 31594492.60597215\n",
      "Iteration 2869, loss = 31573873.05706618\n",
      "Iteration 2870, loss = 31553555.06671625\n",
      "Iteration 2871, loss = 31531075.26374961\n",
      "Iteration 2872, loss = 31521288.75776845\n",
      "Iteration 2873, loss = 31491813.73002239\n",
      "Iteration 2874, loss = 31471576.45241738\n",
      "Iteration 2875, loss = 31457357.65491449\n",
      "Iteration 2876, loss = 31429566.62387631\n",
      "Iteration 2877, loss = 31407083.74694663\n",
      "Iteration 2878, loss = 31387855.38300867\n",
      "Iteration 2879, loss = 31365460.57822565\n",
      "Iteration 2880, loss = 31349694.65272994\n",
      "Iteration 2881, loss = 31327350.09512877\n",
      "Iteration 2882, loss = 31303209.72210668\n",
      "Iteration 2883, loss = 31285736.14282568\n",
      "Iteration 2884, loss = 31264318.18554797\n",
      "Iteration 2885, loss = 31241098.81091398\n",
      "Iteration 2886, loss = 31220236.38516639\n",
      "Iteration 2887, loss = 31200311.84188385\n",
      "Iteration 2888, loss = 31181173.89722949\n",
      "Iteration 2889, loss = 31160098.29840079\n",
      "Iteration 2890, loss = 31140337.09347342\n",
      "Iteration 2891, loss = 31119059.82528517\n",
      "Iteration 2892, loss = 31095679.78380126\n",
      "Iteration 2893, loss = 31081014.16959442\n",
      "Iteration 2894, loss = 31059798.71111596\n",
      "Iteration 2895, loss = 31036749.38730061\n",
      "Iteration 2896, loss = 31012667.17296611\n",
      "Iteration 2897, loss = 30992781.38771407\n",
      "Iteration 2898, loss = 30973800.66894045\n",
      "Iteration 2899, loss = 30950226.84311237\n",
      "Iteration 2900, loss = 30939704.18089367\n",
      "Iteration 2901, loss = 30909695.38412927\n",
      "Iteration 2902, loss = 30888969.87443203\n",
      "Iteration 2903, loss = 30869813.35911869\n",
      "Iteration 2904, loss = 30849112.79778215\n",
      "Iteration 2905, loss = 30831419.96408123\n",
      "Iteration 2906, loss = 30806940.04646430\n",
      "Iteration 2907, loss = 30793922.78631875\n",
      "Iteration 2908, loss = 30767251.03684993\n",
      "Iteration 2909, loss = 30744855.24530837\n",
      "Iteration 2910, loss = 30722844.55588384\n",
      "Iteration 2911, loss = 30704277.90059359\n",
      "Iteration 2912, loss = 30692620.41141851\n",
      "Iteration 2913, loss = 30667816.58014306\n",
      "Iteration 2914, loss = 30643607.45130141\n",
      "Iteration 2915, loss = 30627778.88530245\n",
      "Iteration 2916, loss = 30602549.58979907\n",
      "Iteration 2917, loss = 30583038.87181944\n",
      "Iteration 2918, loss = 30561815.11022050\n",
      "Iteration 2919, loss = 30541214.41105790\n",
      "Iteration 2920, loss = 30520729.12437705\n",
      "Iteration 2921, loss = 30503438.87222809\n",
      "Iteration 2922, loss = 30480578.01470569\n",
      "Iteration 2923, loss = 30466610.98769335\n",
      "Iteration 2924, loss = 30443710.52568922\n",
      "Iteration 2925, loss = 30419158.06303986\n",
      "Iteration 2926, loss = 30402181.87431140\n",
      "Iteration 2927, loss = 30378862.50913469\n",
      "Iteration 2928, loss = 30362066.12798524\n",
      "Iteration 2929, loss = 30336576.53121575\n",
      "Iteration 2930, loss = 30317045.79981254\n",
      "Iteration 2931, loss = 30298735.53959817\n",
      "Iteration 2932, loss = 30275178.98643776\n",
      "Iteration 2933, loss = 30258951.33316478\n",
      "Iteration 2934, loss = 30237853.43820908\n",
      "Iteration 2935, loss = 30218123.33214317\n",
      "Iteration 2936, loss = 30200038.22172299\n",
      "Iteration 2937, loss = 30177825.04813010\n",
      "Iteration 2938, loss = 30158379.92334076\n",
      "Iteration 2939, loss = 30140143.43724832\n",
      "Iteration 2940, loss = 30116637.14295553\n",
      "Iteration 2941, loss = 30098587.46738955\n",
      "Iteration 2942, loss = 30080817.21213297\n",
      "Iteration 2943, loss = 30060038.36696652\n",
      "Iteration 2944, loss = 30035831.94956466\n",
      "Iteration 2945, loss = 30015443.57245893\n",
      "Iteration 2946, loss = 29995617.08154767\n",
      "Iteration 2947, loss = 29977566.60232050\n",
      "Iteration 2948, loss = 29954652.32273259\n",
      "Iteration 2949, loss = 29935103.80205652\n",
      "Iteration 2950, loss = 29913007.50239278\n",
      "Iteration 2951, loss = 29897113.79289508\n",
      "Iteration 2952, loss = 29876289.74529183\n",
      "Iteration 2953, loss = 29853732.18005084\n",
      "Iteration 2954, loss = 29833214.98279613\n",
      "Iteration 2955, loss = 29816463.43035318\n",
      "Iteration 2956, loss = 29795129.26837036\n",
      "Iteration 2957, loss = 29778898.00249297\n",
      "Iteration 2958, loss = 29754955.98244501\n",
      "Iteration 2959, loss = 29733579.16802212\n",
      "Iteration 2960, loss = 29716141.39662853\n",
      "Iteration 2961, loss = 29696075.02315260\n",
      "Iteration 2962, loss = 29681381.54188070\n",
      "Iteration 2963, loss = 29653775.83499985\n",
      "Iteration 2964, loss = 29636374.39192192\n",
      "Iteration 2965, loss = 29614179.47604188\n",
      "Iteration 2966, loss = 29592879.24859395\n",
      "Iteration 2967, loss = 29581504.92173703\n",
      "Iteration 2968, loss = 29556793.18382626\n",
      "Iteration 2969, loss = 29538229.29065865\n",
      "Iteration 2970, loss = 29522079.94699372\n",
      "Iteration 2971, loss = 29496273.00105484\n",
      "Iteration 2972, loss = 29478660.82060570\n",
      "Iteration 2973, loss = 29459826.20042019\n",
      "Iteration 2974, loss = 29438567.69321216\n",
      "Iteration 2975, loss = 29426091.05988972\n",
      "Iteration 2976, loss = 29398790.12904982\n",
      "Iteration 2977, loss = 29377253.67415940\n",
      "Iteration 2978, loss = 29358531.59224458\n",
      "Iteration 2979, loss = 29339320.63393104\n",
      "Iteration 2980, loss = 29323140.22246359\n",
      "Iteration 2981, loss = 29298600.53814156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2982, loss = 29281933.12150536\n",
      "Iteration 2983, loss = 29261205.14654741\n",
      "Iteration 2984, loss = 29241891.37722596\n",
      "Iteration 2985, loss = 29222954.27428016\n",
      "Iteration 2986, loss = 29201412.02457888\n",
      "Iteration 2987, loss = 29183119.75749667\n",
      "Iteration 2988, loss = 29164003.48383223\n",
      "Iteration 2989, loss = 29140863.25730908\n",
      "Iteration 2990, loss = 29124384.33828792\n",
      "Iteration 2991, loss = 29109283.48628069\n",
      "Iteration 2992, loss = 29082898.15212071\n",
      "Iteration 2993, loss = 29064225.41351448\n",
      "Iteration 2994, loss = 29048828.15288205\n",
      "Iteration 2995, loss = 29025736.30518428\n",
      "Iteration 2996, loss = 29010765.63791944\n",
      "Iteration 2997, loss = 28994380.02571872\n",
      "Iteration 2998, loss = 28971585.52406330\n",
      "Iteration 2999, loss = 28959015.59978033\n",
      "Iteration 3000, loss = 28927568.96302126\n",
      "Iteration 3001, loss = 28907820.18946970\n",
      "Iteration 3002, loss = 28887720.73281955\n",
      "Iteration 3003, loss = 28869656.08156108\n",
      "Iteration 3004, loss = 28850171.14947003\n",
      "Iteration 3005, loss = 28838245.03954582\n",
      "Iteration 3006, loss = 28815108.79159809\n",
      "Iteration 3007, loss = 28791530.96946518\n",
      "Iteration 3008, loss = 28775862.65653815\n",
      "Iteration 3009, loss = 28755516.60480047\n",
      "Iteration 3010, loss = 28737113.68826152\n",
      "Iteration 3011, loss = 28716618.52450081\n",
      "Iteration 3012, loss = 28701899.98163446\n",
      "Iteration 3013, loss = 28675475.45069446\n",
      "Iteration 3014, loss = 28662381.37322632\n",
      "Iteration 3015, loss = 28641465.31401465\n",
      "Iteration 3016, loss = 28623715.48699215\n",
      "Iteration 3017, loss = 28626877.16196308\n",
      "Iteration 3018, loss = 28585854.51517227\n",
      "Iteration 3019, loss = 28561216.67025227\n",
      "Iteration 3020, loss = 28543630.32075102\n",
      "Iteration 3021, loss = 28527994.37756788\n",
      "Iteration 3022, loss = 28505161.61648385\n",
      "Iteration 3023, loss = 28488123.79127956\n",
      "Iteration 3024, loss = 28466790.77874696\n",
      "Iteration 3025, loss = 28447939.46808043\n",
      "Iteration 3026, loss = 28428037.28543064\n",
      "Iteration 3027, loss = 28411520.63095818\n",
      "Iteration 3028, loss = 28389957.20497615\n",
      "Iteration 3029, loss = 28373302.20873629\n",
      "Iteration 3030, loss = 28352102.26558465\n",
      "Iteration 3031, loss = 28335917.30557330\n",
      "Iteration 3032, loss = 28318155.57491668\n",
      "Iteration 3033, loss = 28298865.29089767\n",
      "Iteration 3034, loss = 28281034.46575430\n",
      "Iteration 3035, loss = 28262766.44227097\n",
      "Iteration 3036, loss = 28239122.42619454\n",
      "Iteration 3037, loss = 28221473.07739285\n",
      "Iteration 3038, loss = 28200342.91673088\n",
      "Iteration 3039, loss = 28181527.19561720\n",
      "Iteration 3040, loss = 28166769.11884926\n",
      "Iteration 3041, loss = 28144488.12891849\n",
      "Iteration 3042, loss = 28127966.74585622\n",
      "Iteration 3043, loss = 28111042.70392137\n",
      "Iteration 3044, loss = 28088705.15720525\n",
      "Iteration 3045, loss = 28070804.65686579\n",
      "Iteration 3046, loss = 28050924.65919226\n",
      "Iteration 3047, loss = 28030556.35134280\n",
      "Iteration 3048, loss = 28012386.17119498\n",
      "Iteration 3049, loss = 27992751.70005712\n",
      "Iteration 3050, loss = 27975943.32460691\n",
      "Iteration 3051, loss = 27955262.71422083\n",
      "Iteration 3052, loss = 27936552.64581562\n",
      "Iteration 3053, loss = 27917787.65191051\n",
      "Iteration 3054, loss = 27898287.69921868\n",
      "Iteration 3055, loss = 27878978.74385256\n",
      "Iteration 3056, loss = 27862347.09887668\n",
      "Iteration 3057, loss = 27842794.63189491\n",
      "Iteration 3058, loss = 27822752.21611821\n",
      "Iteration 3059, loss = 27804239.56783718\n",
      "Iteration 3060, loss = 27786148.74241154\n",
      "Iteration 3061, loss = 27774687.20485496\n",
      "Iteration 3062, loss = 27748448.88584150\n",
      "Iteration 3063, loss = 27734615.07593520\n",
      "Iteration 3064, loss = 27712146.38972942\n",
      "Iteration 3065, loss = 27693027.21409859\n",
      "Iteration 3066, loss = 27678071.18966013\n",
      "Iteration 3067, loss = 27654859.20080927\n",
      "Iteration 3068, loss = 27637380.18665114\n",
      "Iteration 3069, loss = 27623838.67270730\n",
      "Iteration 3070, loss = 27599665.51278642\n",
      "Iteration 3071, loss = 27585085.20215065\n",
      "Iteration 3072, loss = 27566455.68010228\n",
      "Iteration 3073, loss = 27545559.91826503\n",
      "Iteration 3074, loss = 27527122.56004857\n",
      "Iteration 3075, loss = 27510439.95118943\n",
      "Iteration 3076, loss = 27488331.87297475\n",
      "Iteration 3077, loss = 27470726.24899803\n",
      "Iteration 3078, loss = 27452230.67229526\n",
      "Iteration 3079, loss = 27434360.56437711\n",
      "Iteration 3080, loss = 27418434.35154428\n",
      "Iteration 3081, loss = 27396962.04623288\n",
      "Iteration 3082, loss = 27380335.46438853\n",
      "Iteration 3083, loss = 27360958.24198774\n",
      "Iteration 3084, loss = 27343404.93394140\n",
      "Iteration 3085, loss = 27327432.93363791\n",
      "Iteration 3086, loss = 27305086.65729576\n",
      "Iteration 3087, loss = 27284595.47169299\n",
      "Iteration 3088, loss = 27270904.79020988\n",
      "Iteration 3089, loss = 27253599.11416780\n",
      "Iteration 3090, loss = 27233379.89691612\n",
      "Iteration 3091, loss = 27222395.25198453\n",
      "Iteration 3092, loss = 27197273.63477136\n",
      "Iteration 3093, loss = 27179968.74016853\n",
      "Iteration 3094, loss = 27158486.15735679\n",
      "Iteration 3095, loss = 27142791.86165857\n",
      "Iteration 3096, loss = 27131486.96528503\n",
      "Iteration 3097, loss = 27111763.47955576\n",
      "Iteration 3098, loss = 27086627.89182154\n",
      "Iteration 3099, loss = 27072249.07984430\n",
      "Iteration 3100, loss = 27054515.14803904\n",
      "Iteration 3101, loss = 27039699.10926060\n",
      "Iteration 3102, loss = 27015030.44909559\n",
      "Iteration 3103, loss = 26995981.43708137\n",
      "Iteration 3104, loss = 26980504.92928186\n",
      "Iteration 3105, loss = 26961257.01950197\n",
      "Iteration 3106, loss = 26942278.42592823\n",
      "Iteration 3107, loss = 26932983.21940390\n",
      "Iteration 3108, loss = 26906858.89538862\n",
      "Iteration 3109, loss = 26891322.12463703\n",
      "Iteration 3110, loss = 26872117.24151173\n",
      "Iteration 3111, loss = 26851003.88893754\n",
      "Iteration 3112, loss = 26835749.03667882\n",
      "Iteration 3113, loss = 26819478.28156062\n",
      "Iteration 3114, loss = 26801031.66289678\n",
      "Iteration 3115, loss = 26781694.85419535\n",
      "Iteration 3116, loss = 26763741.20105020\n",
      "Iteration 3117, loss = 26744117.63795515\n",
      "Iteration 3118, loss = 26728439.12779844\n",
      "Iteration 3119, loss = 26713613.28486920\n",
      "Iteration 3120, loss = 26692605.28607603\n",
      "Iteration 3121, loss = 26675986.35560145\n",
      "Iteration 3122, loss = 26658085.95489303\n",
      "Iteration 3123, loss = 26646796.85992513\n",
      "Iteration 3124, loss = 26627377.66051903\n",
      "Iteration 3125, loss = 26605823.79899056\n",
      "Iteration 3126, loss = 26588797.06642334\n",
      "Iteration 3127, loss = 26569827.65520390\n",
      "Iteration 3128, loss = 26555544.60958691\n",
      "Iteration 3129, loss = 26536514.24731576\n",
      "Iteration 3130, loss = 26517524.64904501\n",
      "Iteration 3131, loss = 26499784.63168850\n",
      "Iteration 3132, loss = 26480916.61224014\n",
      "Iteration 3133, loss = 26462565.01947534\n",
      "Iteration 3134, loss = 26445716.97566952\n",
      "Iteration 3135, loss = 26432607.01692598\n",
      "Iteration 3136, loss = 26409436.42396789\n",
      "Iteration 3137, loss = 26391379.47855480\n",
      "Iteration 3138, loss = 26373488.31636738\n",
      "Iteration 3139, loss = 26357107.28564847\n",
      "Iteration 3140, loss = 26339382.18183021\n",
      "Iteration 3141, loss = 26322705.93026075\n",
      "Iteration 3142, loss = 26306853.41882490\n",
      "Iteration 3143, loss = 26285886.82803319\n",
      "Iteration 3144, loss = 26268434.90849862\n",
      "Iteration 3145, loss = 26253189.23154137\n",
      "Iteration 3146, loss = 26236195.20291194\n",
      "Iteration 3147, loss = 26218621.69988741\n",
      "Iteration 3148, loss = 26204671.12868339\n",
      "Iteration 3149, loss = 26186664.12011077\n",
      "Iteration 3150, loss = 26166456.91343613\n",
      "Iteration 3151, loss = 26160669.11126775\n",
      "Iteration 3152, loss = 26137808.69603065\n",
      "Iteration 3153, loss = 26118074.06464415\n",
      "Iteration 3154, loss = 26099000.47204209\n",
      "Iteration 3155, loss = 26080681.12391924\n",
      "Iteration 3156, loss = 26066036.16116640\n",
      "Iteration 3157, loss = 26045527.27506772\n",
      "Iteration 3158, loss = 26032035.57032283\n",
      "Iteration 3159, loss = 26010097.85037585\n",
      "Iteration 3160, loss = 25994708.82579469\n",
      "Iteration 3161, loss = 25980513.16919118\n",
      "Iteration 3162, loss = 25964475.91909536\n",
      "Iteration 3163, loss = 25948326.69130219\n",
      "Iteration 3164, loss = 25928987.35193790\n",
      "Iteration 3165, loss = 25913031.17645352\n",
      "Iteration 3166, loss = 25891508.92139509\n",
      "Iteration 3167, loss = 25876147.24664340\n",
      "Iteration 3168, loss = 25858930.50306453\n",
      "Iteration 3169, loss = 25843053.72340165\n",
      "Iteration 3170, loss = 25826760.64835458\n",
      "Iteration 3171, loss = 25808715.42712574\n",
      "Iteration 3172, loss = 25793289.91447174\n",
      "Iteration 3173, loss = 25776694.09285236\n",
      "Iteration 3174, loss = 25766934.89261727\n",
      "Iteration 3175, loss = 25741119.73984137\n",
      "Iteration 3176, loss = 25726283.12069683\n",
      "Iteration 3177, loss = 25706724.57188061\n",
      "Iteration 3178, loss = 25689485.53765132\n",
      "Iteration 3179, loss = 25672314.94068336\n",
      "Iteration 3180, loss = 25655297.79876960\n",
      "Iteration 3181, loss = 25639069.07390979\n",
      "Iteration 3182, loss = 25626271.60842591\n",
      "Iteration 3183, loss = 25605419.06045652\n",
      "Iteration 3184, loss = 25590304.30303331\n",
      "Iteration 3185, loss = 25578562.73557328\n",
      "Iteration 3186, loss = 25562825.25863371\n",
      "Iteration 3187, loss = 25541222.35589657\n",
      "Iteration 3188, loss = 25522976.36292554\n",
      "Iteration 3189, loss = 25511083.42070087\n",
      "Iteration 3190, loss = 25490710.32591063\n",
      "Iteration 3191, loss = 25476050.68475451\n",
      "Iteration 3192, loss = 25455942.02723195\n",
      "Iteration 3193, loss = 25438751.08499902\n",
      "Iteration 3194, loss = 25422033.99052886\n",
      "Iteration 3195, loss = 25405291.56283524\n",
      "Iteration 3196, loss = 25390531.54368018\n",
      "Iteration 3197, loss = 25376883.99778466\n",
      "Iteration 3198, loss = 25354510.99812650\n",
      "Iteration 3199, loss = 25338169.00433046\n",
      "Iteration 3200, loss = 25323886.20787033\n",
      "Iteration 3201, loss = 25314884.21392506\n",
      "Iteration 3202, loss = 25294128.48781127\n",
      "Iteration 3203, loss = 25276632.35689442\n",
      "Iteration 3204, loss = 25257061.93180636\n",
      "Iteration 3205, loss = 25243707.74313931\n",
      "Iteration 3206, loss = 25223992.19722418\n",
      "Iteration 3207, loss = 25209482.23414480\n",
      "Iteration 3208, loss = 25191811.17466471\n",
      "Iteration 3209, loss = 25174618.50282146\n",
      "Iteration 3210, loss = 25159949.27455006\n",
      "Iteration 3211, loss = 25146536.38574355\n",
      "Iteration 3212, loss = 25126895.51772676\n",
      "Iteration 3213, loss = 25112434.41362583\n",
      "Iteration 3214, loss = 25095627.10092865\n",
      "Iteration 3215, loss = 25083977.89325125\n",
      "Iteration 3216, loss = 25063411.93405652\n",
      "Iteration 3217, loss = 25046012.61707649\n",
      "Iteration 3218, loss = 25029349.97490818\n",
      "Iteration 3219, loss = 25011649.61592411\n",
      "Iteration 3220, loss = 24997741.43934328\n",
      "Iteration 3221, loss = 24981946.16072071\n",
      "Iteration 3222, loss = 24967033.97368557\n",
      "Iteration 3223, loss = 24950759.79383004\n",
      "Iteration 3224, loss = 24933106.78916585\n",
      "Iteration 3225, loss = 24920393.96542799\n",
      "Iteration 3226, loss = 24900238.29633656\n",
      "Iteration 3227, loss = 24888260.71197260\n",
      "Iteration 3228, loss = 24870463.35129598\n",
      "Iteration 3229, loss = 24867729.63913739\n",
      "Iteration 3230, loss = 24836430.99638535\n",
      "Iteration 3231, loss = 24823434.84474456\n",
      "Iteration 3232, loss = 24808548.92992422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3233, loss = 24804523.85272588\n",
      "Iteration 3234, loss = 24777977.09555336\n",
      "Iteration 3235, loss = 24755486.73481030\n",
      "Iteration 3236, loss = 24743745.51752407\n",
      "Iteration 3237, loss = 24725414.44951100\n",
      "Iteration 3238, loss = 24715591.56377966\n",
      "Iteration 3239, loss = 24696589.79061774\n",
      "Iteration 3240, loss = 24677607.24289634\n",
      "Iteration 3241, loss = 24660838.40052816\n",
      "Iteration 3242, loss = 24644980.91744410\n",
      "Iteration 3243, loss = 24630076.26198532\n",
      "Iteration 3244, loss = 24614044.91881444\n",
      "Iteration 3245, loss = 24599480.63729140\n",
      "Iteration 3246, loss = 24582914.58087543\n",
      "Iteration 3247, loss = 24568654.48171115\n",
      "Iteration 3248, loss = 24551263.39077269\n",
      "Iteration 3249, loss = 24538848.98880495\n",
      "Iteration 3250, loss = 24518953.13147110\n",
      "Iteration 3251, loss = 24503920.38314741\n",
      "Iteration 3252, loss = 24487348.03276230\n",
      "Iteration 3253, loss = 24481462.86438092\n",
      "Iteration 3254, loss = 24465684.28942053\n",
      "Iteration 3255, loss = 24451863.39309801\n",
      "Iteration 3256, loss = 24428792.47185044\n",
      "Iteration 3257, loss = 24412813.77819565\n",
      "Iteration 3258, loss = 24395321.14669949\n",
      "Iteration 3259, loss = 24381200.63732313\n",
      "Iteration 3260, loss = 24378804.78752781\n",
      "Iteration 3261, loss = 24353832.33499413\n",
      "Iteration 3262, loss = 24338886.75550926\n",
      "Iteration 3263, loss = 24318154.18276783\n",
      "Iteration 3264, loss = 24309046.18025425\n",
      "Iteration 3265, loss = 24289097.04229047\n",
      "Iteration 3266, loss = 24271991.68055923\n",
      "Iteration 3267, loss = 24263152.37014200\n",
      "Iteration 3268, loss = 24244517.58346559\n",
      "Iteration 3269, loss = 24230044.46392267\n",
      "Iteration 3270, loss = 24214183.34052602\n",
      "Iteration 3271, loss = 24194827.05211347\n",
      "Iteration 3272, loss = 24181502.21185814\n",
      "Iteration 3273, loss = 24167919.74753578\n",
      "Iteration 3274, loss = 24154497.05606423\n",
      "Iteration 3275, loss = 24139909.85713238\n",
      "Iteration 3276, loss = 24124584.19186356\n",
      "Iteration 3277, loss = 24111265.00104171\n",
      "Iteration 3278, loss = 24089932.48888645\n",
      "Iteration 3279, loss = 24082045.12758846\n",
      "Iteration 3280, loss = 24060795.40254756\n",
      "Iteration 3281, loss = 24046772.38943413\n",
      "Iteration 3282, loss = 24030595.53185914\n",
      "Iteration 3283, loss = 24014944.00872626\n",
      "Iteration 3284, loss = 24001287.34903949\n",
      "Iteration 3285, loss = 23985046.24174407\n",
      "Iteration 3286, loss = 23971794.31648606\n",
      "Iteration 3287, loss = 23955186.06379339\n",
      "Iteration 3288, loss = 23941679.13253410\n",
      "Iteration 3289, loss = 23931158.49203649\n",
      "Iteration 3290, loss = 23910609.96891961\n",
      "Iteration 3291, loss = 23897519.82604295\n",
      "Iteration 3292, loss = 23881224.04322680\n",
      "Iteration 3293, loss = 23868799.62893572\n",
      "Iteration 3294, loss = 23852623.97658150\n",
      "Iteration 3295, loss = 23839072.52889069\n",
      "Iteration 3296, loss = 23834693.86856902\n",
      "Iteration 3297, loss = 23812016.14030657\n",
      "Iteration 3298, loss = 23799877.17397862\n",
      "Iteration 3299, loss = 23780640.80393191\n",
      "Iteration 3300, loss = 23764456.43418143\n",
      "Iteration 3301, loss = 23749188.18804430\n",
      "Iteration 3302, loss = 23733904.22106881\n",
      "Iteration 3303, loss = 23721908.40978314\n",
      "Iteration 3304, loss = 23705899.31733871\n",
      "Iteration 3305, loss = 23689361.64050008\n",
      "Iteration 3306, loss = 23676300.72628520\n",
      "Iteration 3307, loss = 23661662.11266388\n",
      "Iteration 3308, loss = 23647088.37502685\n",
      "Iteration 3309, loss = 23631085.07526622\n",
      "Iteration 3310, loss = 23618063.86857311\n",
      "Iteration 3311, loss = 23602921.58467994\n",
      "Iteration 3312, loss = 23592118.58624915\n",
      "Iteration 3313, loss = 23578436.36079620\n",
      "Iteration 3314, loss = 23561055.10505772\n",
      "Iteration 3315, loss = 23546853.14890017\n",
      "Iteration 3316, loss = 23532304.24123047\n",
      "Iteration 3317, loss = 23518274.44580161\n",
      "Iteration 3318, loss = 23501812.59946406\n",
      "Iteration 3319, loss = 23487525.13491103\n",
      "Iteration 3320, loss = 23480100.87346104\n",
      "Iteration 3321, loss = 23457782.47192189\n",
      "Iteration 3322, loss = 23443980.66702376\n",
      "Iteration 3323, loss = 23429934.71236853\n",
      "Iteration 3324, loss = 23418135.10793575\n",
      "Iteration 3325, loss = 23406238.44549390\n",
      "Iteration 3326, loss = 23389510.97133778\n",
      "Iteration 3327, loss = 23376253.74240051\n",
      "Iteration 3328, loss = 23363698.93614759\n",
      "Iteration 3329, loss = 23348764.00541131\n",
      "Iteration 3330, loss = 23340207.10760120\n",
      "Iteration 3331, loss = 23322675.05191483\n",
      "Iteration 3332, loss = 23304886.57614144\n",
      "Iteration 3333, loss = 23290329.24079400\n",
      "Iteration 3334, loss = 23274527.14739428\n",
      "Iteration 3335, loss = 23262623.34275851\n",
      "Iteration 3336, loss = 23246620.57198596\n",
      "Iteration 3337, loss = 23234563.48681989\n",
      "Iteration 3338, loss = 23222196.31721017\n",
      "Iteration 3339, loss = 23208230.91887070\n",
      "Iteration 3340, loss = 23190858.09782186\n",
      "Iteration 3341, loss = 23177429.39014484\n",
      "Iteration 3342, loss = 23162713.62426537\n",
      "Iteration 3343, loss = 23149369.33258621\n",
      "Iteration 3344, loss = 23134772.63125775\n",
      "Iteration 3345, loss = 23123399.56983650\n",
      "Iteration 3346, loss = 23107955.21045516\n",
      "Iteration 3347, loss = 23093293.27282203\n",
      "Iteration 3348, loss = 23081154.37622513\n",
      "Iteration 3349, loss = 23065756.38832043\n",
      "Iteration 3350, loss = 23052207.41904583\n",
      "Iteration 3351, loss = 23042950.76122818\n",
      "Iteration 3352, loss = 23034954.46796759\n",
      "Iteration 3353, loss = 23011738.74173848\n",
      "Iteration 3354, loss = 22998765.36787746\n",
      "Iteration 3355, loss = 22984264.01826865\n",
      "Iteration 3356, loss = 22972805.43194795\n",
      "Iteration 3357, loss = 22964650.56591172\n",
      "Iteration 3358, loss = 22943603.68780252\n",
      "Iteration 3359, loss = 22929055.33633777\n",
      "Iteration 3360, loss = 22921865.92996237\n",
      "Iteration 3361, loss = 22905804.09718616\n",
      "Iteration 3362, loss = 22891035.30715718\n",
      "Iteration 3363, loss = 22875447.47968816\n",
      "Iteration 3364, loss = 22863886.88479183\n",
      "Iteration 3365, loss = 22850612.38611909\n",
      "Iteration 3366, loss = 22835651.59439662\n",
      "Iteration 3367, loss = 22823133.00855512\n",
      "Iteration 3368, loss = 22811260.54504227\n",
      "Iteration 3369, loss = 22797138.91695004\n",
      "Iteration 3370, loss = 22790230.13276811\n",
      "Iteration 3371, loss = 22769094.48558303\n",
      "Iteration 3372, loss = 22762001.04253117\n",
      "Iteration 3373, loss = 22745877.18367806\n",
      "Iteration 3374, loss = 22732542.48578524\n",
      "Iteration 3375, loss = 22719845.75189328\n",
      "Iteration 3376, loss = 22712035.96096554\n",
      "Iteration 3377, loss = 22692398.89680332\n",
      "Iteration 3378, loss = 22677511.99621928\n",
      "Iteration 3379, loss = 22667288.33498604\n",
      "Iteration 3380, loss = 22650571.20915490\n",
      "Iteration 3381, loss = 22639064.30590325\n",
      "Iteration 3382, loss = 22624657.03478316\n",
      "Iteration 3383, loss = 22614624.66683626\n",
      "Iteration 3384, loss = 22628340.99406747\n",
      "Iteration 3385, loss = 22587639.12362070\n",
      "Iteration 3386, loss = 22580250.48797762\n",
      "Iteration 3387, loss = 22559566.29751926\n",
      "Iteration 3388, loss = 22552764.36883643\n",
      "Iteration 3389, loss = 22538242.39105788\n",
      "Iteration 3390, loss = 22519704.47296727\n",
      "Iteration 3391, loss = 22507172.55048337\n",
      "Iteration 3392, loss = 22497105.57738339\n",
      "Iteration 3393, loss = 22485770.38173322\n",
      "Iteration 3394, loss = 22470115.37127658\n",
      "Iteration 3395, loss = 22457886.04527469\n",
      "Iteration 3396, loss = 22445985.39124241\n",
      "Iteration 3397, loss = 22432416.42569765\n",
      "Iteration 3398, loss = 22422368.03342044\n",
      "Iteration 3399, loss = 22404951.13960123\n",
      "Iteration 3400, loss = 22392456.17348061\n",
      "Iteration 3401, loss = 22379886.67802325\n",
      "Iteration 3402, loss = 22369375.41945830\n",
      "Iteration 3403, loss = 22353691.00926762\n",
      "Iteration 3404, loss = 22343281.87863848\n",
      "Iteration 3405, loss = 22331796.16623234\n",
      "Iteration 3406, loss = 22315386.09505530\n",
      "Iteration 3407, loss = 22305170.65681361\n",
      "Iteration 3408, loss = 22290987.12493493\n",
      "Iteration 3409, loss = 22278157.29324538\n",
      "Iteration 3410, loss = 22269036.51530257\n",
      "Iteration 3411, loss = 22251933.61471364\n",
      "Iteration 3412, loss = 22246440.75983723\n",
      "Iteration 3413, loss = 22227890.61783891\n",
      "Iteration 3414, loss = 22218406.09388637\n",
      "Iteration 3415, loss = 22203341.51609708\n",
      "Iteration 3416, loss = 22189686.47060984\n",
      "Iteration 3417, loss = 22179109.57169464\n",
      "Iteration 3418, loss = 22166431.51631486\n",
      "Iteration 3419, loss = 22157007.89883266\n",
      "Iteration 3420, loss = 22139438.94349853\n",
      "Iteration 3421, loss = 22131567.28980668\n",
      "Iteration 3422, loss = 22119887.97234895\n",
      "Iteration 3423, loss = 22103873.39903711\n",
      "Iteration 3424, loss = 22089481.43780800\n",
      "Iteration 3425, loss = 22078207.59888031\n",
      "Iteration 3426, loss = 22066607.28095113\n",
      "Iteration 3427, loss = 22058186.11438019\n",
      "Iteration 3428, loss = 22041616.87499388\n",
      "Iteration 3429, loss = 22034058.93577355\n",
      "Iteration 3430, loss = 22017637.01270136\n",
      "Iteration 3431, loss = 22007587.68392610\n",
      "Iteration 3432, loss = 21992676.65721985\n",
      "Iteration 3433, loss = 21981597.38502952\n",
      "Iteration 3434, loss = 21969590.66181187\n",
      "Iteration 3435, loss = 21960928.14673616\n",
      "Iteration 3436, loss = 21949058.49103498\n",
      "Iteration 3437, loss = 21932746.79945349\n",
      "Iteration 3438, loss = 21918869.85339588\n",
      "Iteration 3439, loss = 21920712.55468246\n",
      "Iteration 3440, loss = 21899140.92939850\n",
      "Iteration 3441, loss = 21886150.21055616\n",
      "Iteration 3442, loss = 21873580.80813324\n",
      "Iteration 3443, loss = 21865083.93678384\n",
      "Iteration 3444, loss = 21851302.40451810\n",
      "Iteration 3445, loss = 21836623.42344240\n",
      "Iteration 3446, loss = 21831687.55298459\n",
      "Iteration 3447, loss = 21813623.64130485\n",
      "Iteration 3448, loss = 21799504.44096850\n",
      "Iteration 3449, loss = 21789396.05072779\n",
      "Iteration 3450, loss = 21780614.94634980\n",
      "Iteration 3451, loss = 21772076.89917979\n",
      "Iteration 3452, loss = 21756426.29849701\n",
      "Iteration 3453, loss = 21742711.98173710\n",
      "Iteration 3454, loss = 21731281.70502047\n",
      "Iteration 3455, loss = 21722332.84790921\n",
      "Iteration 3456, loss = 21706927.53740342\n",
      "Iteration 3457, loss = 21694566.31794778\n",
      "Iteration 3458, loss = 21685525.77936271\n",
      "Iteration 3459, loss = 21671466.31716457\n",
      "Iteration 3460, loss = 21662561.61275873\n",
      "Iteration 3461, loss = 21650659.08537091\n",
      "Iteration 3462, loss = 21637156.94668791\n",
      "Iteration 3463, loss = 21624759.48835350\n",
      "Iteration 3464, loss = 21614581.83598472\n",
      "Iteration 3465, loss = 21604169.81815983\n",
      "Iteration 3466, loss = 21594371.28823379\n",
      "Iteration 3467, loss = 21581665.32428289\n",
      "Iteration 3468, loss = 21572460.48264652\n",
      "Iteration 3469, loss = 21557875.57188335\n",
      "Iteration 3470, loss = 21544895.99583072\n",
      "Iteration 3471, loss = 21532990.44375142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3472, loss = 21521949.17976183\n",
      "Iteration 3473, loss = 21516151.52019796\n",
      "Iteration 3474, loss = 21499607.03662865\n",
      "Iteration 3475, loss = 21488326.55022902\n",
      "Iteration 3476, loss = 21475650.90420512\n",
      "Iteration 3477, loss = 21467370.41853117\n",
      "Iteration 3478, loss = 21456937.29144267\n",
      "Iteration 3479, loss = 21445789.95199775\n",
      "Iteration 3480, loss = 21435244.22760653\n",
      "Iteration 3481, loss = 21423287.19394672\n",
      "Iteration 3482, loss = 21411793.15889892\n",
      "Iteration 3483, loss = 21405106.18961868\n",
      "Iteration 3484, loss = 21387453.20144713\n",
      "Iteration 3485, loss = 21377262.97097636\n",
      "Iteration 3486, loss = 21364337.44583005\n",
      "Iteration 3487, loss = 21355897.18989362\n",
      "Iteration 3488, loss = 21343752.66331449\n",
      "Iteration 3489, loss = 21332899.45006630\n",
      "Iteration 3490, loss = 21321502.63944672\n",
      "Iteration 3491, loss = 21309408.36386569\n",
      "Iteration 3492, loss = 21300331.83026895\n",
      "Iteration 3493, loss = 21291195.38261301\n",
      "Iteration 3494, loss = 21283824.00475084\n",
      "Iteration 3495, loss = 21271394.39009284\n",
      "Iteration 3496, loss = 21263807.13390258\n",
      "Iteration 3497, loss = 21244465.64779134\n",
      "Iteration 3498, loss = 21233502.23963180\n",
      "Iteration 3499, loss = 21225441.51264941\n",
      "Iteration 3500, loss = 21213157.23064349\n",
      "Iteration 3501, loss = 21202427.52835603\n",
      "Iteration 3502, loss = 21195259.14576778\n",
      "Iteration 3503, loss = 21181055.76668547\n",
      "Iteration 3504, loss = 21170432.60646620\n",
      "Iteration 3505, loss = 21159465.19693706\n",
      "Iteration 3506, loss = 21160965.29858651\n",
      "Iteration 3507, loss = 21138366.62235025\n",
      "Iteration 3508, loss = 21138889.85014003\n",
      "Iteration 3509, loss = 21117603.27330167\n",
      "Iteration 3510, loss = 21104970.05243137\n",
      "Iteration 3511, loss = 21096189.33078045\n",
      "Iteration 3512, loss = 21102423.84183405\n",
      "Iteration 3513, loss = 21077669.73792665\n",
      "Iteration 3514, loss = 21066807.94386282\n",
      "Iteration 3515, loss = 21054120.38540545\n",
      "Iteration 3516, loss = 21044198.29039379\n",
      "Iteration 3517, loss = 21031126.78580540\n",
      "Iteration 3518, loss = 21021231.41013967\n",
      "Iteration 3519, loss = 21009834.69955227\n",
      "Iteration 3520, loss = 21000009.76239832\n",
      "Iteration 3521, loss = 20993600.34497766\n",
      "Iteration 3522, loss = 20979461.28776968\n",
      "Iteration 3523, loss = 20970739.33971069\n",
      "Iteration 3524, loss = 20968435.30102322\n",
      "Iteration 3525, loss = 20949213.49075254\n",
      "Iteration 3526, loss = 20945262.33732220\n",
      "Iteration 3527, loss = 20928130.83530551\n",
      "Iteration 3528, loss = 20919579.16982705\n",
      "Iteration 3529, loss = 20913971.41703638\n",
      "Iteration 3530, loss = 20903087.43682186\n",
      "Iteration 3531, loss = 20891645.86508047\n",
      "Iteration 3532, loss = 20877805.06100572\n",
      "Iteration 3533, loss = 20867662.84451542\n",
      "Iteration 3534, loss = 20857638.38263850\n",
      "Iteration 3535, loss = 20853543.01493380\n",
      "Iteration 3536, loss = 20837438.33631202\n",
      "Iteration 3537, loss = 20825521.93898522\n",
      "Iteration 3538, loss = 20821412.12696881\n",
      "Iteration 3539, loss = 20810668.74491486\n",
      "Iteration 3540, loss = 20803431.60609320\n",
      "Iteration 3541, loss = 20790944.36203117\n",
      "Iteration 3542, loss = 20781656.19340475\n",
      "Iteration 3543, loss = 20768205.38904180\n",
      "Iteration 3544, loss = 20757064.71259704\n",
      "Iteration 3545, loss = 20747166.76780801\n",
      "Iteration 3546, loss = 20741812.46259929\n",
      "Iteration 3547, loss = 20728215.48059339\n",
      "Iteration 3548, loss = 20718012.14703937\n",
      "Iteration 3549, loss = 20709824.16979716\n",
      "Iteration 3550, loss = 20697444.42928616\n",
      "Iteration 3551, loss = 20689036.53526527\n",
      "Iteration 3552, loss = 20681865.55019591\n",
      "Iteration 3553, loss = 20669481.46270523\n",
      "Iteration 3554, loss = 20658535.25651088\n",
      "Iteration 3555, loss = 20649225.51770393\n",
      "Iteration 3556, loss = 20639456.37832825\n",
      "Iteration 3557, loss = 20628859.70414727\n",
      "Iteration 3558, loss = 20621286.19182611\n",
      "Iteration 3559, loss = 20610900.50144695\n",
      "Iteration 3560, loss = 20602609.85599163\n",
      "Iteration 3561, loss = 20590708.25105796\n",
      "Iteration 3562, loss = 20582379.38070392\n",
      "Iteration 3563, loss = 20571761.75282013\n",
      "Iteration 3564, loss = 20563769.95655460\n",
      "Iteration 3565, loss = 20552511.58625876\n",
      "Iteration 3566, loss = 20542700.04489439\n",
      "Iteration 3567, loss = 20533896.01481935\n",
      "Iteration 3568, loss = 20532428.77530877\n",
      "Iteration 3569, loss = 20525194.04972668\n",
      "Iteration 3570, loss = 20508379.33521192\n",
      "Iteration 3571, loss = 20495894.95538808\n",
      "Iteration 3572, loss = 20489282.29722965\n",
      "Iteration 3573, loss = 20476831.81502260\n",
      "Iteration 3574, loss = 20471031.48692011\n",
      "Iteration 3575, loss = 20458751.93139445\n",
      "Iteration 3576, loss = 20449446.08073131\n",
      "Iteration 3577, loss = 20440518.19563494\n",
      "Iteration 3578, loss = 20431347.05222006\n",
      "Iteration 3579, loss = 20421500.89705936\n",
      "Iteration 3580, loss = 20412193.18706549\n",
      "Iteration 3581, loss = 20404104.15777450\n",
      "Iteration 3582, loss = 20396639.15576236\n",
      "Iteration 3583, loss = 20400269.21791955\n",
      "Iteration 3584, loss = 20376953.31755608\n",
      "Iteration 3585, loss = 20368287.91708142\n",
      "Iteration 3586, loss = 20358634.80774704\n",
      "Iteration 3587, loss = 20348083.28154073\n",
      "Iteration 3588, loss = 20339200.04658314\n",
      "Iteration 3589, loss = 20330043.34403849\n",
      "Iteration 3590, loss = 20320366.58412937\n",
      "Iteration 3591, loss = 20312624.08613677\n",
      "Iteration 3592, loss = 20306366.75122369\n",
      "Iteration 3593, loss = 20294639.42122928\n",
      "Iteration 3594, loss = 20285474.48004672\n",
      "Iteration 3595, loss = 20275798.06962688\n",
      "Iteration 3596, loss = 20267491.33969059\n",
      "Iteration 3597, loss = 20261774.60100426\n",
      "Iteration 3598, loss = 20253167.57758919\n",
      "Iteration 3599, loss = 20245390.85366001\n",
      "Iteration 3600, loss = 20231037.34580009\n",
      "Iteration 3601, loss = 20222841.46653428\n",
      "Iteration 3602, loss = 20215444.38508654\n",
      "Iteration 3603, loss = 20207100.29898540\n",
      "Iteration 3604, loss = 20196397.45555718\n",
      "Iteration 3605, loss = 20201501.72937047\n",
      "Iteration 3606, loss = 20182372.48010217\n",
      "Iteration 3607, loss = 20175787.98226989\n",
      "Iteration 3608, loss = 20167905.23425895\n",
      "Iteration 3609, loss = 20174461.61756120\n",
      "Iteration 3610, loss = 20146939.71855306\n",
      "Iteration 3611, loss = 20138918.86673875\n",
      "Iteration 3612, loss = 20128774.72170849\n",
      "Iteration 3613, loss = 20117460.48488443\n",
      "Iteration 3614, loss = 20110974.16007763\n",
      "Iteration 3615, loss = 20101903.17366940\n",
      "Iteration 3616, loss = 20094041.54886446\n",
      "Iteration 3617, loss = 20081970.13368744\n",
      "Iteration 3618, loss = 20080913.10769069\n",
      "Iteration 3619, loss = 20067340.12126027\n",
      "Iteration 3620, loss = 20058563.78955895\n",
      "Iteration 3621, loss = 20048208.37000620\n",
      "Iteration 3622, loss = 20042101.08391181\n",
      "Iteration 3623, loss = 20032771.20211051\n",
      "Iteration 3624, loss = 20026846.14518121\n",
      "Iteration 3625, loss = 20016962.39120417\n",
      "Iteration 3626, loss = 20006879.88350193\n",
      "Iteration 3627, loss = 20000380.61392890\n",
      "Iteration 3628, loss = 19990382.85595182\n",
      "Iteration 3629, loss = 19984353.21847387\n",
      "Iteration 3630, loss = 19974212.13945343\n",
      "Iteration 3631, loss = 19968895.88164642\n",
      "Iteration 3632, loss = 19957675.33876849\n",
      "Iteration 3633, loss = 19950266.32944836\n",
      "Iteration 3634, loss = 19947286.86242153\n",
      "Iteration 3635, loss = 19934461.69743671\n",
      "Iteration 3636, loss = 19927082.90357754\n",
      "Iteration 3637, loss = 19918742.68028441\n",
      "Iteration 3638, loss = 19916204.80075685\n",
      "Iteration 3639, loss = 19899869.39104778\n",
      "Iteration 3640, loss = 19891316.28140375\n",
      "Iteration 3641, loss = 19883708.25390148\n",
      "Iteration 3642, loss = 19896609.99455995\n",
      "Iteration 3643, loss = 19872340.09116956\n",
      "Iteration 3644, loss = 19860663.99343899\n",
      "Iteration 3645, loss = 19852594.18538551\n",
      "Iteration 3646, loss = 19845664.72122049\n",
      "Iteration 3647, loss = 19838045.64484523\n",
      "Iteration 3648, loss = 19832489.43951945\n",
      "Iteration 3649, loss = 19840670.28267077\n",
      "Iteration 3650, loss = 19812511.11792267\n",
      "Iteration 3651, loss = 19808432.99385761\n",
      "Iteration 3652, loss = 19796821.84678056\n",
      "Iteration 3653, loss = 19790183.85098584\n",
      "Iteration 3654, loss = 19784039.11647148\n",
      "Iteration 3655, loss = 19775850.28818143\n",
      "Iteration 3656, loss = 19769234.29390679\n",
      "Iteration 3657, loss = 19761625.67139162\n",
      "Iteration 3658, loss = 19750504.12076672\n",
      "Iteration 3659, loss = 19743004.83673981\n",
      "Iteration 3660, loss = 19743246.60899699\n",
      "Iteration 3661, loss = 19730225.43016389\n",
      "Iteration 3662, loss = 19719825.37287609\n",
      "Iteration 3663, loss = 19713847.51293264\n",
      "Iteration 3664, loss = 19713952.07876566\n",
      "Iteration 3665, loss = 19705276.10098662\n",
      "Iteration 3666, loss = 19695831.12377013\n",
      "Iteration 3667, loss = 19683517.65794346\n",
      "Iteration 3668, loss = 19674500.71209643\n",
      "Iteration 3669, loss = 19666521.96212685\n",
      "Iteration 3670, loss = 19669981.72125006\n",
      "Iteration 3671, loss = 19654344.20188235\n",
      "Iteration 3672, loss = 19643419.47131871\n",
      "Iteration 3673, loss = 19635292.32409110\n",
      "Iteration 3674, loss = 19630254.45831533\n",
      "Iteration 3675, loss = 19624966.71455974\n",
      "Iteration 3676, loss = 19617415.58326017\n",
      "Iteration 3677, loss = 19612041.17908794\n",
      "Iteration 3678, loss = 19597895.14507912\n",
      "Iteration 3679, loss = 19598120.32613618\n",
      "Iteration 3680, loss = 19588435.92511980\n",
      "Iteration 3681, loss = 19577877.54946452\n",
      "Iteration 3682, loss = 19576072.14554583\n",
      "Iteration 3683, loss = 19565343.89441307\n",
      "Iteration 3684, loss = 19558529.66743728\n",
      "Iteration 3685, loss = 19553623.01461431\n",
      "Iteration 3686, loss = 19541261.07128949\n",
      "Iteration 3687, loss = 19533524.72916002\n",
      "Iteration 3688, loss = 19528796.42581639\n",
      "Iteration 3689, loss = 19523005.15084582\n",
      "Iteration 3690, loss = 19520583.98987059\n",
      "Iteration 3691, loss = 19513797.07210160\n",
      "Iteration 3692, loss = 19505222.83151682\n",
      "Iteration 3693, loss = 19497135.76931639\n",
      "Iteration 3694, loss = 19490985.96293420\n",
      "Iteration 3695, loss = 19480198.92404796\n",
      "Iteration 3696, loss = 19480307.55767525\n",
      "Iteration 3697, loss = 19465252.42471413\n",
      "Iteration 3698, loss = 19462635.97986208\n",
      "Iteration 3699, loss = 19453202.83856048\n",
      "Iteration 3700, loss = 19447654.91065586\n",
      "Iteration 3701, loss = 19438409.25377207\n",
      "Iteration 3702, loss = 19430069.42046285\n",
      "Iteration 3703, loss = 19421916.51804955\n",
      "Iteration 3704, loss = 19419011.73286455\n",
      "Iteration 3705, loss = 19415515.16354986\n",
      "Iteration 3706, loss = 19410075.29241968\n",
      "Iteration 3707, loss = 19397634.48611744\n",
      "Iteration 3708, loss = 19392410.55055968\n",
      "Iteration 3709, loss = 19400090.78340438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3710, loss = 19376608.64397271\n",
      "Iteration 3711, loss = 19367919.55435755\n",
      "Iteration 3712, loss = 19362815.17052542\n",
      "Iteration 3713, loss = 19356069.19075238\n",
      "Iteration 3714, loss = 19348581.00800072\n",
      "Iteration 3715, loss = 19348313.95721088\n",
      "Iteration 3716, loss = 19334682.63783500\n",
      "Iteration 3717, loss = 19329226.80297852\n",
      "Iteration 3718, loss = 19326852.13775998\n",
      "Iteration 3719, loss = 19319237.32626302\n",
      "Iteration 3720, loss = 19312824.45529256\n",
      "Iteration 3721, loss = 19304087.49809742\n",
      "Iteration 3722, loss = 19300567.43817194\n",
      "Iteration 3723, loss = 19292041.54021750\n",
      "Iteration 3724, loss = 19284632.35997905\n",
      "Iteration 3725, loss = 19280447.60930355\n",
      "Iteration 3726, loss = 19273057.92181983\n",
      "Iteration 3727, loss = 19267161.47001591\n",
      "Iteration 3728, loss = 19260109.56255730\n",
      "Iteration 3729, loss = 19252973.01429270\n",
      "Iteration 3730, loss = 19247947.49333402\n",
      "Iteration 3731, loss = 19239754.83075942\n",
      "Iteration 3732, loss = 19236337.05027663\n",
      "Iteration 3733, loss = 19233398.05365289\n",
      "Iteration 3734, loss = 19221744.52382425\n",
      "Iteration 3735, loss = 19215312.71298100\n",
      "Iteration 3736, loss = 19206406.63740128\n",
      "Iteration 3737, loss = 19202630.72965101\n",
      "Iteration 3738, loss = 19195430.57382292\n",
      "Iteration 3739, loss = 19193853.55659775\n",
      "Iteration 3740, loss = 19186835.63026410\n",
      "Iteration 3741, loss = 19176759.77539623\n",
      "Iteration 3742, loss = 19172867.59371389\n",
      "Iteration 3743, loss = 19167333.27409455\n",
      "Iteration 3744, loss = 19159977.76333984\n",
      "Iteration 3745, loss = 19158094.91157154\n",
      "Iteration 3746, loss = 19152843.89131447\n",
      "Iteration 3747, loss = 19139489.65406301\n",
      "Iteration 3748, loss = 19133835.18047205\n",
      "Iteration 3749, loss = 19128321.79656078\n",
      "Iteration 3750, loss = 19123165.65328429\n",
      "Iteration 3751, loss = 19116078.80520420\n",
      "Iteration 3752, loss = 19110367.57735708\n",
      "Iteration 3753, loss = 19106591.27825584\n",
      "Iteration 3754, loss = 19103480.33577026\n",
      "Iteration 3755, loss = 19096978.76314078\n",
      "Iteration 3756, loss = 19088886.83699703\n",
      "Iteration 3757, loss = 19082215.10774525\n",
      "Iteration 3758, loss = 19074898.43815761\n",
      "Iteration 3759, loss = 19069364.43302783\n",
      "Iteration 3760, loss = 19068590.42855737\n",
      "Iteration 3761, loss = 19070502.47110112\n",
      "Iteration 3762, loss = 19059967.97513545\n",
      "Iteration 3763, loss = 19045203.30936962\n",
      "Iteration 3764, loss = 19041580.03827700\n",
      "Iteration 3765, loss = 19035920.04582334\n",
      "Iteration 3766, loss = 19031323.61621711\n",
      "Iteration 3767, loss = 19024131.29275494\n",
      "Iteration 3768, loss = 19020710.22970992\n",
      "Iteration 3769, loss = 19015117.15080141\n",
      "Iteration 3770, loss = 19008787.43927195\n",
      "Iteration 3771, loss = 19005308.60946722\n",
      "Iteration 3772, loss = 18997164.43007178\n",
      "Iteration 3773, loss = 18989773.91818963\n",
      "Iteration 3774, loss = 18983495.01356685\n",
      "Iteration 3775, loss = 18977530.66531878\n",
      "Iteration 3776, loss = 18974162.57140021\n",
      "Iteration 3777, loss = 18971351.96225462\n",
      "Iteration 3778, loss = 18964988.77992517\n",
      "Iteration 3779, loss = 18966311.27365064\n",
      "Iteration 3780, loss = 18950077.88091766\n",
      "Iteration 3781, loss = 18944408.01727493\n",
      "Iteration 3782, loss = 18941962.87481247\n",
      "Iteration 3783, loss = 18942952.41505854\n",
      "Iteration 3784, loss = 18929844.85287260\n",
      "Iteration 3785, loss = 18925325.03678826\n",
      "Iteration 3786, loss = 18918358.90063741\n",
      "Iteration 3787, loss = 18913292.05599714\n",
      "Iteration 3788, loss = 18909236.09115702\n",
      "Iteration 3789, loss = 18906847.10828656\n",
      "Iteration 3790, loss = 18899452.58835934\n",
      "Iteration 3791, loss = 18896257.95958498\n",
      "Iteration 3792, loss = 18886944.52723252\n",
      "Iteration 3793, loss = 18892038.01864641\n",
      "Iteration 3794, loss = 18876084.93129335\n",
      "Iteration 3795, loss = 18870567.31918192\n",
      "Iteration 3796, loss = 18871972.77124546\n",
      "Iteration 3797, loss = 18861140.35768293\n",
      "Iteration 3798, loss = 18857680.78403115\n",
      "Iteration 3799, loss = 18851034.55540358\n",
      "Iteration 3800, loss = 18843826.14819673\n",
      "Iteration 3801, loss = 18841129.90030194\n",
      "Iteration 3802, loss = 18836238.58916550\n",
      "Iteration 3803, loss = 18832595.82317409\n",
      "Iteration 3804, loss = 18824511.12173450\n",
      "Iteration 3805, loss = 18820706.03055437\n",
      "Iteration 3806, loss = 18817050.89552334\n",
      "Iteration 3807, loss = 18810171.08795289\n",
      "Iteration 3808, loss = 18809354.45910314\n",
      "Iteration 3809, loss = 18806893.64232615\n",
      "Iteration 3810, loss = 18804299.22697327\n",
      "Iteration 3811, loss = 18791507.95521795\n",
      "Iteration 3812, loss = 18790470.95167434\n",
      "Iteration 3813, loss = 18782682.33522921\n",
      "Iteration 3814, loss = 18788021.02454580\n",
      "Iteration 3815, loss = 18772172.05180715\n",
      "Iteration 3816, loss = 18766989.89378026\n",
      "Iteration 3817, loss = 18762123.24913448\n",
      "Iteration 3818, loss = 18756791.96041270\n",
      "Iteration 3819, loss = 18753051.55416058\n",
      "Iteration 3820, loss = 18747241.71338001\n",
      "Iteration 3821, loss = 18741878.24112451\n",
      "Iteration 3822, loss = 18740106.87214087\n",
      "Iteration 3823, loss = 18731941.58187753\n",
      "Iteration 3824, loss = 18729037.06984042\n",
      "Iteration 3825, loss = 18722414.78329860\n",
      "Iteration 3826, loss = 18716480.99717738\n",
      "Iteration 3827, loss = 18713601.90249908\n",
      "Iteration 3828, loss = 18711809.67910431\n",
      "Iteration 3829, loss = 18706359.77015457\n",
      "Iteration 3830, loss = 18700701.17069227\n",
      "Iteration 3831, loss = 18698570.74840976\n",
      "Iteration 3832, loss = 18690777.38116307\n",
      "Iteration 3833, loss = 18691482.00420840\n",
      "Iteration 3834, loss = 18679542.19076694\n",
      "Iteration 3835, loss = 18677373.61563176\n",
      "Iteration 3836, loss = 18676372.85526931\n",
      "Iteration 3837, loss = 18669310.30003396\n",
      "Iteration 3838, loss = 18667548.78185137\n",
      "Iteration 3839, loss = 18663335.57167105\n",
      "Iteration 3840, loss = 18654208.70593779\n",
      "Iteration 3841, loss = 18648134.08416777\n",
      "Iteration 3842, loss = 18656445.30745080\n",
      "Iteration 3843, loss = 18645644.75023138\n",
      "Iteration 3844, loss = 18639658.41349293\n",
      "Iteration 3845, loss = 18643650.82809279\n",
      "Iteration 3846, loss = 18628032.01904836\n",
      "Iteration 3847, loss = 18623604.35272252\n",
      "Iteration 3848, loss = 18622483.00326801\n",
      "Iteration 3849, loss = 18617033.51963881\n",
      "Iteration 3850, loss = 18613088.79026686\n",
      "Iteration 3851, loss = 18608222.85505550\n",
      "Iteration 3852, loss = 18603139.40382905\n",
      "Iteration 3853, loss = 18600921.40342702\n",
      "Iteration 3854, loss = 18593823.16378416\n",
      "Iteration 3855, loss = 18592135.25893117\n",
      "Iteration 3856, loss = 18587071.32733360\n",
      "Iteration 3857, loss = 18583079.06622716\n",
      "Iteration 3858, loss = 18585694.17483376\n",
      "Iteration 3859, loss = 18576540.65142843\n",
      "Iteration 3860, loss = 18570764.52067506\n",
      "Iteration 3861, loss = 18567423.29677865\n",
      "Iteration 3862, loss = 18560010.57415653\n",
      "Iteration 3863, loss = 18560456.47214117\n",
      "Iteration 3864, loss = 18553631.93708323\n",
      "Iteration 3865, loss = 18548913.64078830\n",
      "Iteration 3866, loss = 18549825.15895766\n",
      "Iteration 3867, loss = 18542106.62917385\n",
      "Iteration 3868, loss = 18540146.35274329\n",
      "Iteration 3869, loss = 18538383.12957060\n",
      "Iteration 3870, loss = 18529631.24353088\n",
      "Iteration 3871, loss = 18524509.25077708\n",
      "Iteration 3872, loss = 18521165.60643030\n",
      "Iteration 3873, loss = 18516199.23923388\n",
      "Iteration 3874, loss = 18514052.22360091\n",
      "Iteration 3875, loss = 18509350.73177404\n",
      "Iteration 3876, loss = 18504788.04676664\n",
      "Iteration 3877, loss = 18502410.37205689\n",
      "Iteration 3878, loss = 18497630.62094845\n",
      "Iteration 3879, loss = 18493034.77774506\n",
      "Iteration 3880, loss = 18488844.03518573\n",
      "Iteration 3881, loss = 18489443.73923995\n",
      "Iteration 3882, loss = 18480835.87044799\n",
      "Iteration 3883, loss = 18477633.68338633\n",
      "Iteration 3884, loss = 18477373.28145413\n",
      "Iteration 3885, loss = 18475384.63195898\n",
      "Iteration 3886, loss = 18466674.69430433\n",
      "Iteration 3887, loss = 18463992.06349640\n",
      "Iteration 3888, loss = 18458485.67070821\n",
      "Iteration 3889, loss = 18455200.05976679\n",
      "Iteration 3890, loss = 18452818.48971583\n",
      "Iteration 3891, loss = 18451969.94715395\n",
      "Iteration 3892, loss = 18446443.69885815\n",
      "Iteration 3893, loss = 18441453.92408701\n",
      "Iteration 3894, loss = 18436696.06959505\n",
      "Iteration 3895, loss = 18435284.02188904\n",
      "Iteration 3896, loss = 18430732.49537596\n",
      "Iteration 3897, loss = 18425728.41386207\n",
      "Iteration 3898, loss = 18421220.87352585\n",
      "Iteration 3899, loss = 18424287.89101039\n",
      "Iteration 3900, loss = 18414635.75940297\n",
      "Iteration 3901, loss = 18410535.07566266\n",
      "Iteration 3902, loss = 18407918.19931905\n",
      "Iteration 3903, loss = 18404298.51178217\n",
      "Iteration 3904, loss = 18404662.14760979\n",
      "Iteration 3905, loss = 18401400.88818761\n",
      "Iteration 3906, loss = 18396834.57870720\n",
      "Iteration 3907, loss = 18390197.76430903\n",
      "Iteration 3908, loss = 18388359.85064476\n",
      "Iteration 3909, loss = 18384415.49796042\n",
      "Iteration 3910, loss = 18381079.67810173\n",
      "Iteration 3911, loss = 18381281.00156403\n",
      "Iteration 3912, loss = 18373150.70839862\n",
      "Iteration 3913, loss = 18370751.08915039\n",
      "Iteration 3914, loss = 18365262.41329408\n",
      "Iteration 3915, loss = 18365217.56869815\n",
      "Iteration 3916, loss = 18358423.18803946\n",
      "Iteration 3917, loss = 18355755.65506969\n",
      "Iteration 3918, loss = 18352807.54007488\n",
      "Iteration 3919, loss = 18350082.35528702\n",
      "Iteration 3920, loss = 18346109.89593466\n",
      "Iteration 3921, loss = 18348746.00910943\n",
      "Iteration 3922, loss = 18338424.66996049\n",
      "Iteration 3923, loss = 18336051.36704127\n",
      "Iteration 3924, loss = 18331930.51112091\n",
      "Iteration 3925, loss = 18332575.71482875\n",
      "Iteration 3926, loss = 18324578.50116750\n",
      "Iteration 3927, loss = 18327640.55774573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3928, loss = 18327175.33338238\n",
      "Iteration 3929, loss = 18319631.35442090\n",
      "Iteration 3930, loss = 18326589.09823448\n",
      "Iteration 3931, loss = 18314653.01494155\n",
      "Iteration 3932, loss = 18308617.78843308\n",
      "Iteration 3933, loss = 18303581.91509682\n",
      "Iteration 3934, loss = 18308486.41732577\n",
      "Iteration 3935, loss = 18297194.79046253\n",
      "Iteration 3936, loss = 18296405.71642043\n",
      "Iteration 3937, loss = 18298304.94288336\n",
      "Iteration 3938, loss = 18302287.11350682\n",
      "Iteration 3939, loss = 18287655.74488128\n",
      "Iteration 3940, loss = 18282892.06013138\n",
      "Iteration 3941, loss = 18282364.75565782\n",
      "Iteration 3942, loss = 18278535.63473173\n",
      "Iteration 3943, loss = 18273508.41627752\n",
      "Iteration 3944, loss = 18275608.28383109\n",
      "Iteration 3945, loss = 18268564.61329801\n",
      "Iteration 3946, loss = 18265343.90607588\n",
      "Iteration 3947, loss = 18264391.21315874\n",
      "Iteration 3948, loss = 18264335.14247568\n",
      "Iteration 3949, loss = 18256627.76145319\n",
      "Iteration 3950, loss = 18254741.92099074\n",
      "Iteration 3951, loss = 18251628.41029947\n",
      "Iteration 3952, loss = 18248760.65521633\n",
      "Iteration 3953, loss = 18246235.16640629\n",
      "Iteration 3954, loss = 18242132.86483616\n",
      "Iteration 3955, loss = 18237190.18545195\n",
      "Iteration 3956, loss = 18235092.14048515\n",
      "Iteration 3957, loss = 18236976.00430581\n",
      "Iteration 3958, loss = 18231939.86288303\n",
      "Iteration 3959, loss = 18226209.14055801\n",
      "Iteration 3960, loss = 18224130.11016696\n",
      "Iteration 3961, loss = 18220848.28966577\n",
      "Iteration 3962, loss = 18221437.31758876\n",
      "Iteration 3963, loss = 18218009.84504804\n",
      "Iteration 3964, loss = 18218197.76433070\n",
      "Iteration 3965, loss = 18211649.50980489\n",
      "Iteration 3966, loss = 18211325.64901981\n",
      "Iteration 3967, loss = 18206705.42695861\n",
      "Iteration 3968, loss = 18201848.83080644\n",
      "Iteration 3969, loss = 18201171.81073748\n",
      "Iteration 3970, loss = 18197398.95299672\n",
      "Iteration 3971, loss = 18198475.51068893\n",
      "Iteration 3972, loss = 18194869.83151213\n",
      "Iteration 3973, loss = 18192041.37025698\n",
      "Iteration 3974, loss = 18188353.36360281\n",
      "Iteration 3975, loss = 18188012.85360944\n",
      "Iteration 3976, loss = 18191787.84906765\n",
      "Iteration 3977, loss = 18182244.71681411\n",
      "Iteration 3978, loss = 18188960.92867998\n",
      "Iteration 3979, loss = 18178522.35311581\n",
      "Iteration 3980, loss = 18173373.71616847\n",
      "Iteration 3981, loss = 18174888.81147541\n",
      "Iteration 3982, loss = 18171573.29367119\n",
      "Iteration 3983, loss = 18165434.63824984\n",
      "Iteration 3984, loss = 18162757.69658339\n",
      "Iteration 3985, loss = 18159104.19113507\n",
      "Iteration 3986, loss = 18158180.33895593\n",
      "Iteration 3987, loss = 18154017.01961866\n",
      "Iteration 3988, loss = 18151033.54091462\n",
      "Iteration 3989, loss = 18151746.74711894\n",
      "Iteration 3990, loss = 18147882.06887755\n",
      "Iteration 3991, loss = 18153068.13065445\n",
      "Iteration 3992, loss = 18142913.86393239\n",
      "Iteration 3993, loss = 18140222.07566417\n",
      "Iteration 3994, loss = 18139171.01300601\n",
      "Iteration 3995, loss = 18135311.88498173\n",
      "Iteration 3996, loss = 18136792.34010703\n",
      "Iteration 3997, loss = 18131376.30793839\n",
      "Iteration 3998, loss = 18130148.18509948\n",
      "Iteration 3999, loss = 18126615.33191969\n",
      "Iteration 4000, loss = 18125427.85833779\n",
      "Iteration 4001, loss = 18123778.26858206\n",
      "Iteration 4002, loss = 18121479.12634437\n",
      "Iteration 4003, loss = 18124956.66058260\n",
      "Iteration 4004, loss = 18117208.29580646\n",
      "Iteration 4005, loss = 18116218.75594658\n",
      "Iteration 4006, loss = 18111864.61856665\n",
      "Iteration 4007, loss = 18107729.34082161\n",
      "Iteration 4008, loss = 18107444.10099351\n",
      "Iteration 4009, loss = 18102709.86141454\n",
      "Iteration 4010, loss = 18103279.43278896\n",
      "Iteration 4011, loss = 18099553.06715684\n",
      "Iteration 4012, loss = 18098577.62522734\n",
      "Iteration 4013, loss = 18096838.56003251\n",
      "Iteration 4014, loss = 18093427.76337627\n",
      "Iteration 4015, loss = 18092913.79813475\n",
      "Iteration 4016, loss = 18092437.04742670\n",
      "Iteration 4017, loss = 18089372.16953063\n",
      "Iteration 4018, loss = 18087217.13202654\n",
      "Iteration 4019, loss = 18084649.33320903\n",
      "Iteration 4020, loss = 18084374.12100994\n",
      "Iteration 4021, loss = 18078862.83327543\n",
      "Iteration 4022, loss = 18080599.80984423\n",
      "Iteration 4023, loss = 18074912.08249908\n",
      "Iteration 4024, loss = 18073565.75022218\n",
      "Iteration 4025, loss = 18070584.31570720\n",
      "Iteration 4026, loss = 18069119.44777211\n",
      "Iteration 4027, loss = 18069489.08488541\n",
      "Iteration 4028, loss = 18065240.26643601\n",
      "Iteration 4029, loss = 18063688.02041221\n",
      "Iteration 4030, loss = 18064576.31216059\n",
      "Iteration 4031, loss = 18066640.95109761\n",
      "Iteration 4032, loss = 18059744.88854619\n",
      "Iteration 4033, loss = 18060628.28106049\n",
      "Iteration 4034, loss = 18061506.33597298\n",
      "Iteration 4035, loss = 18053418.16731711\n",
      "Iteration 4036, loss = 18049768.08533071\n",
      "Iteration 4037, loss = 18049081.24215840\n",
      "Iteration 4038, loss = 18048176.84291669\n",
      "Iteration 4039, loss = 18043186.58695230\n",
      "Iteration 4040, loss = 18042427.49240940\n",
      "Iteration 4041, loss = 18041850.08551989\n",
      "Iteration 4042, loss = 18039755.63149139\n",
      "Iteration 4043, loss = 18041059.34341276\n",
      "Iteration 4044, loss = 18034960.58733018\n",
      "Iteration 4045, loss = 18033623.90785509\n",
      "Iteration 4046, loss = 18033302.62139179\n",
      "Iteration 4047, loss = 18034135.53915212\n",
      "Iteration 4048, loss = 18029536.77670078\n",
      "Iteration 4049, loss = 18025054.93078220\n",
      "Iteration 4050, loss = 18026170.11798615\n",
      "Iteration 4051, loss = 18029115.10472756\n",
      "Iteration 4052, loss = 18025702.60646816\n",
      "Iteration 4053, loss = 18018186.94951555\n",
      "Iteration 4054, loss = 18022624.51444344\n",
      "Iteration 4055, loss = 18015061.12808985\n",
      "Iteration 4056, loss = 18019263.57536077\n",
      "Iteration 4057, loss = 18012070.98802691\n",
      "Iteration 4058, loss = 18013489.28992231\n",
      "Iteration 4059, loss = 18008412.24239900\n",
      "Iteration 4060, loss = 18011834.99005124\n",
      "Iteration 4061, loss = 18003973.10507537\n",
      "Iteration 4062, loss = 18014743.30610361\n",
      "Iteration 4063, loss = 18002521.82970998\n",
      "Iteration 4064, loss = 18003845.77423190\n",
      "Iteration 4065, loss = 17998774.95374251\n",
      "Iteration 4066, loss = 17996837.68589736\n",
      "Iteration 4067, loss = 17994770.16418416\n",
      "Iteration 4068, loss = 17992717.03113064\n",
      "Iteration 4069, loss = 17996168.75963469\n",
      "Iteration 4070, loss = 17992792.51057656\n",
      "Iteration 4071, loss = 17987486.95365065\n",
      "Iteration 4072, loss = 17987965.36420615\n",
      "Iteration 4073, loss = 17987626.09334381\n",
      "Iteration 4074, loss = 17983731.74140488\n",
      "Iteration 4075, loss = 17980760.99079984\n",
      "Iteration 4076, loss = 17983381.61885429\n",
      "Iteration 4077, loss = 17981813.17642588\n",
      "Iteration 4078, loss = 17984664.99132558\n",
      "Iteration 4079, loss = 17987369.99670877\n",
      "Iteration 4080, loss = 17976760.79166682\n",
      "Iteration 4081, loss = 17973844.19447844\n",
      "Iteration 4082, loss = 17973282.91138351\n",
      "Iteration 4083, loss = 17973050.13861357\n",
      "Iteration 4084, loss = 17967824.47218773\n",
      "Iteration 4085, loss = 17965173.91809298\n",
      "Iteration 4086, loss = 17964363.79471146\n",
      "Iteration 4087, loss = 17962959.75656325\n",
      "Iteration 4088, loss = 17965810.94821892\n",
      "Iteration 4089, loss = 17960698.20479646\n",
      "Iteration 4090, loss = 17959699.06455209\n",
      "Iteration 4091, loss = 17957230.54697961\n",
      "Iteration 4092, loss = 17956675.20119906\n",
      "Iteration 4093, loss = 17953646.24108081\n",
      "Iteration 4094, loss = 17953127.49597237\n",
      "Iteration 4095, loss = 17955590.04675396\n",
      "Iteration 4096, loss = 17951236.50515393\n",
      "Iteration 4097, loss = 17947730.80181797\n",
      "Iteration 4098, loss = 17946967.57342824\n",
      "Iteration 4099, loss = 17948970.77983125\n",
      "Iteration 4100, loss = 17950875.71502943\n",
      "Iteration 4101, loss = 17943454.30437100\n",
      "Iteration 4102, loss = 17944403.73536826\n",
      "Iteration 4103, loss = 17939815.59847837\n",
      "Iteration 4104, loss = 17941801.15052620\n",
      "Iteration 4105, loss = 17939737.70312347\n",
      "Iteration 4106, loss = 17935596.02163928\n",
      "Iteration 4107, loss = 17934158.20563522\n",
      "Iteration 4108, loss = 17934218.03599455\n",
      "Iteration 4109, loss = 17931381.60333952\n",
      "Iteration 4110, loss = 17931063.58633524\n",
      "Iteration 4111, loss = 17932955.65617185\n",
      "Iteration 4112, loss = 17933520.74364947\n",
      "Iteration 4113, loss = 17926654.35950545\n",
      "Iteration 4114, loss = 17926175.75405367\n",
      "Iteration 4115, loss = 17923927.57909289\n",
      "Iteration 4116, loss = 17929976.28916409\n",
      "Iteration 4117, loss = 17922190.48058979\n",
      "Iteration 4118, loss = 17927349.22030741\n",
      "Iteration 4119, loss = 17921092.69872073\n",
      "Iteration 4120, loss = 17919552.13768438\n",
      "Iteration 4121, loss = 17913415.62603614\n",
      "Iteration 4122, loss = 17917495.80544541\n",
      "Iteration 4123, loss = 17918948.96758454\n",
      "Iteration 4124, loss = 17914553.79732756\n",
      "Iteration 4125, loss = 17912692.56126650\n",
      "Iteration 4126, loss = 17909087.61079599\n",
      "Iteration 4127, loss = 17908521.92162038\n",
      "Iteration 4128, loss = 17908954.13970345\n",
      "Iteration 4129, loss = 17909099.17898443\n",
      "Iteration 4130, loss = 17909173.46296056\n",
      "Iteration 4131, loss = 17903603.25144400\n",
      "Iteration 4132, loss = 17903017.47569202\n",
      "Iteration 4133, loss = 17907706.57565925\n",
      "Iteration 4134, loss = 17905413.82954803\n",
      "Iteration 4135, loss = 17900717.90595333\n",
      "Iteration 4136, loss = 17896894.04414066\n",
      "Iteration 4137, loss = 17901106.20673922\n",
      "Iteration 4138, loss = 17895862.08845178\n",
      "Iteration 4139, loss = 17894889.33972130\n",
      "Iteration 4140, loss = 17892811.30085474\n",
      "Iteration 4141, loss = 17894610.90849509\n",
      "Iteration 4142, loss = 17893926.47156025\n",
      "Iteration 4143, loss = 17892653.22749172\n",
      "Iteration 4144, loss = 17890112.61550555\n",
      "Iteration 4145, loss = 17890610.66829954\n",
      "Iteration 4146, loss = 17888857.43850573\n",
      "Iteration 4147, loss = 17886931.09544786\n",
      "Iteration 4148, loss = 17889458.51818311\n",
      "Iteration 4149, loss = 17883729.54846962\n",
      "Iteration 4150, loss = 17883572.76268044\n",
      "Iteration 4151, loss = 17882599.71380380\n",
      "Iteration 4152, loss = 17880010.47979368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4153, loss = 17880287.19145949\n",
      "Iteration 4154, loss = 17883139.72184841\n",
      "Iteration 4155, loss = 17880055.21788125\n",
      "Iteration 4156, loss = 17877037.11700510\n",
      "Iteration 4157, loss = 17876029.35285697\n",
      "Iteration 4158, loss = 17886682.23900603\n",
      "Iteration 4159, loss = 17872642.60723346\n",
      "Iteration 4160, loss = 17877987.06979774\n",
      "Iteration 4161, loss = 17879746.68693242\n",
      "Iteration 4162, loss = 17875971.79381073\n",
      "Iteration 4163, loss = 17867763.66825169\n",
      "Iteration 4164, loss = 17872364.35889886\n",
      "Iteration 4165, loss = 17871088.30825864\n",
      "Iteration 4166, loss = 17868936.90082280\n",
      "Iteration 4167, loss = 17872432.95860547\n",
      "Iteration 4168, loss = 17871144.77754947\n",
      "Iteration 4169, loss = 17863109.91342844\n",
      "Iteration 4170, loss = 17867443.71533534\n",
      "Iteration 4171, loss = 17865525.39403507\n",
      "Iteration 4172, loss = 17863466.06547505\n",
      "Iteration 4173, loss = 17860468.67181776\n",
      "Iteration 4174, loss = 17859139.01665540\n",
      "Iteration 4175, loss = 17857007.63626912\n",
      "Iteration 4176, loss = 17857116.83725495\n",
      "Iteration 4177, loss = 17859096.60680461\n",
      "Iteration 4178, loss = 17856572.62518801\n",
      "Iteration 4179, loss = 17856037.22036354\n",
      "Iteration 4180, loss = 17857813.33039121\n",
      "Iteration 4181, loss = 17859976.16532108\n",
      "Iteration 4182, loss = 17852466.26373005\n",
      "Iteration 4183, loss = 17853632.97235496\n",
      "Iteration 4184, loss = 17850190.03509249\n",
      "Iteration 4185, loss = 17854757.76698083\n",
      "Iteration 4186, loss = 17852664.12043388\n",
      "Iteration 4187, loss = 17849015.56666335\n",
      "Iteration 4188, loss = 17844474.25426291\n",
      "Iteration 4189, loss = 17843859.60840582\n",
      "Iteration 4190, loss = 17846765.60512939\n",
      "Iteration 4191, loss = 17849091.06980316\n",
      "Iteration 4192, loss = 17855657.04632123\n",
      "Iteration 4193, loss = 17841568.38959912\n",
      "Iteration 4194, loss = 17842047.71680609\n",
      "Iteration 4195, loss = 17845240.96826827\n",
      "Iteration 4196, loss = 17840333.13399884\n",
      "Iteration 4197, loss = 17841701.99086003\n",
      "Iteration 4198, loss = 17841150.08273038\n",
      "Iteration 4199, loss = 17837489.35431935\n",
      "Iteration 4200, loss = 17840344.84053910\n",
      "Iteration 4201, loss = 17849472.02815687\n",
      "Iteration 4202, loss = 17838492.81950768\n",
      "Iteration 4203, loss = 17835847.79290529\n",
      "Iteration 4204, loss = 17834568.80810831\n",
      "Iteration 4205, loss = 17833651.30151658\n",
      "Iteration 4206, loss = 17831254.90617437\n",
      "Iteration 4207, loss = 17834409.80781772\n",
      "Iteration 4208, loss = 17833118.45794400\n",
      "Iteration 4209, loss = 17838974.00523105\n",
      "Iteration 4210, loss = 17830071.85210916\n",
      "Iteration 4211, loss = 17829637.33741338\n",
      "Iteration 4212, loss = 17831082.68049356\n",
      "Iteration 4213, loss = 17837043.80714722\n",
      "Iteration 4214, loss = 17834256.58157208\n",
      "Iteration 4215, loss = 17825263.13003376\n",
      "Iteration 4216, loss = 17824839.77009974\n",
      "Iteration 4217, loss = 17826129.94127489\n",
      "Iteration 4218, loss = 17824338.39214145\n",
      "Iteration 4219, loss = 17833067.78597081\n",
      "Iteration 4220, loss = 17827485.12631840\n",
      "Iteration 4221, loss = 17821504.94366476\n",
      "Iteration 4222, loss = 17820933.93777809\n",
      "Iteration 4223, loss = 17820395.83281035\n",
      "Iteration 4224, loss = 17820184.00006561\n",
      "Iteration 4225, loss = 17818926.69444327\n",
      "Iteration 4226, loss = 17817354.40580774\n",
      "Iteration 4227, loss = 17817718.69969825\n",
      "Iteration 4228, loss = 17817769.16932696\n",
      "Iteration 4229, loss = 17816340.46597274\n",
      "Iteration 4230, loss = 17815356.38518293\n",
      "Iteration 4231, loss = 17815243.79004123\n",
      "Iteration 4232, loss = 17814169.31188235\n",
      "Iteration 4233, loss = 17815801.48798872\n",
      "Iteration 4234, loss = 17813158.37482345\n",
      "Iteration 4235, loss = 17814517.49302114\n",
      "Iteration 4236, loss = 17811879.73159760\n",
      "Iteration 4237, loss = 17812062.17909988\n",
      "Iteration 4238, loss = 17812054.43857804\n",
      "Iteration 4239, loss = 17808377.99692062\n",
      "Iteration 4240, loss = 17813309.20150151\n",
      "Iteration 4241, loss = 17808274.51305639\n",
      "Iteration 4242, loss = 17810472.24115575\n",
      "Iteration 4243, loss = 17804818.68886464\n",
      "Iteration 4244, loss = 17810067.56890304\n",
      "Iteration 4245, loss = 17806427.92365257\n",
      "Iteration 4246, loss = 17805130.75595614\n",
      "Iteration 4247, loss = 17804035.88879734\n",
      "Iteration 4248, loss = 17803934.37851246\n",
      "Iteration 4249, loss = 17803674.30412539\n",
      "Iteration 4250, loss = 17803722.82583553\n",
      "Iteration 4251, loss = 17801073.80531921\n",
      "Iteration 4252, loss = 17801253.46714595\n",
      "Iteration 4253, loss = 17800250.66405756\n",
      "Iteration 4254, loss = 17801116.66873094\n",
      "Iteration 4255, loss = 17804973.78760835\n",
      "Iteration 4256, loss = 17805454.22931467\n",
      "Iteration 4257, loss = 17804092.76185576\n",
      "Iteration 4258, loss = 17800113.06101695\n",
      "Iteration 4259, loss = 17805069.86916791\n",
      "Iteration 4260, loss = 17798538.52152432\n",
      "Iteration 4261, loss = 17802327.19642169\n",
      "Iteration 4262, loss = 17796156.37514057\n",
      "Iteration 4263, loss = 17805389.48922040\n",
      "Iteration 4264, loss = 17793619.43964822\n",
      "Iteration 4265, loss = 17798754.76633570\n",
      "Iteration 4266, loss = 17794516.93622118\n",
      "Iteration 4267, loss = 17795610.64819739\n",
      "Iteration 4268, loss = 17795989.69096834\n",
      "Iteration 4269, loss = 17792725.67940519\n",
      "Iteration 4270, loss = 17792659.32675124\n",
      "Iteration 4271, loss = 17804975.46427939\n",
      "Iteration 4272, loss = 17794415.26353953\n",
      "Iteration 4273, loss = 17790725.82014553\n",
      "Iteration 4274, loss = 17796029.96840975\n",
      "Iteration 4275, loss = 17788549.51860541\n",
      "Iteration 4276, loss = 17789588.32052462\n",
      "Iteration 4277, loss = 17791073.48414664\n",
      "Iteration 4278, loss = 17790688.36171190\n",
      "Iteration 4279, loss = 17787892.79779910\n",
      "Iteration 4280, loss = 17784598.42824074\n",
      "Iteration 4281, loss = 17787566.96616403\n",
      "Iteration 4282, loss = 17784768.36685172\n",
      "Iteration 4283, loss = 17790464.71848289\n",
      "Iteration 4284, loss = 17787251.63846292\n",
      "Iteration 4285, loss = 17782730.11292027\n",
      "Iteration 4286, loss = 17784545.15664656\n",
      "Iteration 4287, loss = 17782264.99313072\n",
      "Iteration 4288, loss = 17782665.80036679\n",
      "Iteration 4289, loss = 17782759.66029635\n",
      "Iteration 4290, loss = 17781167.16405398\n",
      "Iteration 4291, loss = 17792719.77186148\n",
      "Iteration 4292, loss = 17779682.03461332\n",
      "Iteration 4293, loss = 17780279.28468365\n",
      "Iteration 4294, loss = 17783830.86430588\n",
      "Iteration 4295, loss = 17778486.09925643\n",
      "Iteration 4296, loss = 17784433.83625960\n",
      "Iteration 4297, loss = 17776633.44529610\n",
      "Iteration 4298, loss = 17776503.78091559\n",
      "Iteration 4299, loss = 17777861.43313200\n",
      "Iteration 4300, loss = 17773902.69438390\n",
      "Iteration 4301, loss = 17773063.23656999\n",
      "Iteration 4302, loss = 17776129.57653877\n",
      "Iteration 4303, loss = 17783364.77408591\n",
      "Iteration 4304, loss = 17773905.76322408\n",
      "Iteration 4305, loss = 17774699.59759255\n",
      "Iteration 4306, loss = 17771886.72663758\n",
      "Iteration 4307, loss = 17771384.33927406\n",
      "Iteration 4308, loss = 17770546.58719611\n",
      "Iteration 4309, loss = 17788951.96980754\n",
      "Iteration 4310, loss = 17774393.12048621\n",
      "Iteration 4311, loss = 17774406.39006601\n",
      "Iteration 4312, loss = 17769045.56251671\n",
      "Iteration 4313, loss = 17768940.97859021\n",
      "Iteration 4314, loss = 17771828.47407796\n",
      "Iteration 4315, loss = 17769763.30297174\n",
      "Iteration 4316, loss = 17772115.38141982\n",
      "Iteration 4317, loss = 17777783.52989887\n",
      "Iteration 4318, loss = 17766224.08970885\n",
      "Iteration 4319, loss = 17778565.52251223\n",
      "Iteration 4320, loss = 17772182.09165931\n",
      "Iteration 4321, loss = 17765417.86993472\n",
      "Iteration 4322, loss = 17764301.95434023\n",
      "Iteration 4323, loss = 17764757.68673151\n",
      "Iteration 4324, loss = 17766107.96349518\n",
      "Iteration 4325, loss = 17761996.69245155\n",
      "Iteration 4326, loss = 17763121.41740797\n",
      "Iteration 4327, loss = 17767090.36962130\n",
      "Iteration 4328, loss = 17765699.53452401\n",
      "Iteration 4329, loss = 17763220.96738080\n",
      "Iteration 4330, loss = 17762696.71210647\n",
      "Iteration 4331, loss = 17761103.03103400\n",
      "Iteration 4332, loss = 17762591.79207539\n",
      "Iteration 4333, loss = 17765338.56528073\n",
      "Iteration 4334, loss = 17759499.38247060\n",
      "Iteration 4335, loss = 17761963.81981751\n",
      "Iteration 4336, loss = 17760237.59152736\n",
      "Iteration 4337, loss = 17758742.01963064\n",
      "Iteration 4338, loss = 17760244.54133048\n",
      "Iteration 4339, loss = 17761205.22049953\n",
      "Iteration 4340, loss = 17759159.29102561\n",
      "Iteration 4341, loss = 17757543.33258512\n",
      "Iteration 4342, loss = 17757347.20538048\n",
      "Iteration 4343, loss = 17757000.69831776\n",
      "Iteration 4344, loss = 17757916.92362867\n",
      "Iteration 4345, loss = 17757015.23134317\n",
      "Iteration 4346, loss = 17762358.82112241\n",
      "Iteration 4347, loss = 17758702.63257635\n",
      "Iteration 4348, loss = 17754256.41126317\n",
      "Iteration 4349, loss = 17754718.89231393\n",
      "Iteration 4350, loss = 17754235.70344146\n",
      "Iteration 4351, loss = 17753979.41903451\n",
      "Iteration 4352, loss = 17758695.14836990\n",
      "Iteration 4353, loss = 17754444.61024270\n",
      "Iteration 4354, loss = 17755454.40253587\n",
      "Iteration 4355, loss = 17754214.64427263\n",
      "Iteration 4356, loss = 17757817.26058863\n",
      "Iteration 4357, loss = 17751447.26332287\n",
      "Iteration 4358, loss = 17752650.70328976\n",
      "Iteration 4359, loss = 17753194.61490918\n",
      "Iteration 4360, loss = 17750619.82034554\n",
      "Iteration 4361, loss = 17750238.20057328\n",
      "Iteration 4362, loss = 17750971.97050126\n",
      "Iteration 4363, loss = 17750129.57024124\n",
      "Iteration 4364, loss = 17758041.09747437\n",
      "Iteration 4365, loss = 17748791.03256946\n",
      "Iteration 4366, loss = 17756866.87534199\n",
      "Iteration 4367, loss = 17749644.87537826\n",
      "Iteration 4368, loss = 17747927.17733373\n",
      "Iteration 4369, loss = 17747397.20207490\n",
      "Iteration 4370, loss = 17748055.43486540\n",
      "Iteration 4371, loss = 17759371.98592122\n",
      "Iteration 4372, loss = 17747083.16971142\n",
      "Iteration 4373, loss = 17746991.97671095\n",
      "Iteration 4374, loss = 17747029.95871374\n",
      "Iteration 4375, loss = 17744758.64983742\n",
      "Iteration 4376, loss = 17750167.25656373\n",
      "Iteration 4377, loss = 17746330.48765851\n",
      "Iteration 4378, loss = 17751096.73811500\n",
      "Iteration 4379, loss = 17748063.79132147\n",
      "Iteration 4380, loss = 17750098.11605677\n",
      "Iteration 4381, loss = 17745678.24279470\n",
      "Iteration 4382, loss = 17742284.34342284\n",
      "Iteration 4383, loss = 17742616.03345466\n",
      "Iteration 4384, loss = 17743947.09058050\n",
      "Iteration 4385, loss = 17742124.40201714\n",
      "Iteration 4386, loss = 17741922.66705379\n",
      "Iteration 4387, loss = 17745925.30287830\n",
      "Iteration 4388, loss = 17743315.11273215\n",
      "Iteration 4389, loss = 17744368.17660278\n",
      "Iteration 4390, loss = 17740160.65811113\n",
      "Iteration 4391, loss = 17739514.33402822\n",
      "Iteration 4392, loss = 17742744.68839196\n",
      "Iteration 4393, loss = 17740112.39118579\n",
      "Iteration 4394, loss = 17747050.99553185\n",
      "Iteration 4395, loss = 17739354.49023230\n",
      "Iteration 4396, loss = 17737479.97041861\n",
      "Iteration 4397, loss = 17738142.72270210\n",
      "Iteration 4398, loss = 17737920.05628635\n",
      "Iteration 4399, loss = 17737870.20197349\n",
      "Iteration 4400, loss = 17742845.92087202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4401, loss = 17736053.11415073\n",
      "Iteration 4402, loss = 17734786.23525400\n",
      "Iteration 4403, loss = 17737406.06995778\n",
      "Iteration 4404, loss = 17739713.42323323\n",
      "Iteration 4405, loss = 17735857.21805069\n",
      "Iteration 4406, loss = 17735718.71118025\n",
      "Iteration 4407, loss = 17734688.26068861\n",
      "Iteration 4408, loss = 17736022.98960368\n",
      "Iteration 4409, loss = 17737005.89245870\n",
      "Iteration 4410, loss = 17736049.50766606\n",
      "Iteration 4411, loss = 17733971.24071925\n",
      "Iteration 4412, loss = 17734168.53734104\n",
      "Iteration 4413, loss = 17734418.37560668\n",
      "Iteration 4414, loss = 17732981.96312294\n",
      "Iteration 4415, loss = 17732823.25601785\n",
      "Iteration 4416, loss = 17733137.62468722\n",
      "Iteration 4417, loss = 17733277.88009524\n",
      "Iteration 4418, loss = 17733014.05261558\n",
      "Iteration 4419, loss = 17731695.91236755\n",
      "Iteration 4420, loss = 17730300.18746258\n",
      "Iteration 4421, loss = 17731536.17318903\n",
      "Iteration 4422, loss = 17735267.83457654\n",
      "Iteration 4423, loss = 17728620.92367038\n",
      "Iteration 4424, loss = 17728254.09078145\n",
      "Iteration 4425, loss = 17728503.31912675\n",
      "Iteration 4426, loss = 17731176.88835185\n",
      "Iteration 4427, loss = 17734743.25347517\n",
      "Iteration 4428, loss = 17730775.46536982\n",
      "Iteration 4429, loss = 17727379.28492609\n",
      "Iteration 4430, loss = 17728317.76407883\n",
      "Iteration 4431, loss = 17729816.67574776\n",
      "Iteration 4432, loss = 17729310.98113659\n",
      "Iteration 4433, loss = 17736604.27227374\n",
      "Iteration 4434, loss = 17733042.66865003\n",
      "Iteration 4435, loss = 17728056.19035287\n",
      "Iteration 4436, loss = 17725940.85962126\n",
      "Iteration 4437, loss = 17726992.01169619\n",
      "Iteration 4438, loss = 17724916.83241405\n",
      "Iteration 4439, loss = 17731839.21060470\n",
      "Iteration 4440, loss = 17728317.91785507\n",
      "Iteration 4441, loss = 17727370.00712330\n",
      "Iteration 4442, loss = 17728159.14088016\n",
      "Iteration 4443, loss = 17723591.99370142\n",
      "Iteration 4444, loss = 17724693.77981367\n",
      "Iteration 4445, loss = 17727450.79329870\n",
      "Iteration 4446, loss = 17724934.00109776\n",
      "Iteration 4447, loss = 17727801.29802629\n",
      "Iteration 4448, loss = 17722571.42634058\n",
      "Iteration 4449, loss = 17723150.16874566\n",
      "Iteration 4450, loss = 17725072.25282416\n",
      "Iteration 4451, loss = 17724451.13313492\n",
      "Iteration 4452, loss = 17724005.11451453\n",
      "Iteration 4453, loss = 17722834.32549653\n",
      "Iteration 4454, loss = 17728901.38087136\n",
      "Iteration 4455, loss = 17721238.44357636\n",
      "Iteration 4456, loss = 17719711.89022973\n",
      "Iteration 4457, loss = 17721526.89709225\n",
      "Iteration 4458, loss = 17726866.21354760\n",
      "Iteration 4459, loss = 17720346.94052807\n",
      "Iteration 4460, loss = 17724490.58262365\n",
      "Iteration 4461, loss = 17717840.88311287\n",
      "Iteration 4462, loss = 17720242.96288251\n",
      "Iteration 4463, loss = 17720669.85215514\n",
      "Iteration 4464, loss = 17719762.14381452\n",
      "Iteration 4465, loss = 17718742.84895239\n",
      "Iteration 4466, loss = 17718481.26060638\n",
      "Iteration 4467, loss = 17722019.26091078\n",
      "Iteration 4468, loss = 17719364.85364758\n",
      "Iteration 4469, loss = 17718331.79562583\n",
      "Iteration 4470, loss = 17717146.79177180\n",
      "Iteration 4471, loss = 17717880.03444440\n",
      "Iteration 4472, loss = 17719746.21867160\n",
      "Iteration 4473, loss = 17717276.52723777\n",
      "Iteration 4474, loss = 17716234.69755169\n",
      "Iteration 4475, loss = 17721068.57302250\n",
      "Iteration 4476, loss = 17714733.19411841\n",
      "Iteration 4477, loss = 17718977.02009144\n",
      "Iteration 4478, loss = 17717048.41106561\n",
      "Iteration 4479, loss = 17715328.93285729\n",
      "Iteration 4480, loss = 17718036.96650783\n",
      "Iteration 4481, loss = 17720806.38443746\n",
      "Iteration 4482, loss = 17713604.85168897\n",
      "Iteration 4483, loss = 17716297.01328424\n",
      "Iteration 4484, loss = 17714867.61383478\n",
      "Iteration 4485, loss = 17713796.88803008\n",
      "Iteration 4486, loss = 17713416.35720242\n",
      "Iteration 4487, loss = 17722608.14591618\n",
      "Iteration 4488, loss = 17714612.89073690\n",
      "Iteration 4489, loss = 17713953.23937759\n",
      "Iteration 4490, loss = 17711612.02526483\n",
      "Iteration 4491, loss = 17713811.45340984\n",
      "Iteration 4492, loss = 17712290.07321015\n",
      "Iteration 4493, loss = 17711725.44214740\n",
      "Iteration 4494, loss = 17713442.46327051\n",
      "Iteration 4495, loss = 17710573.39061106\n",
      "Iteration 4496, loss = 17711157.62759009\n",
      "Iteration 4497, loss = 17717632.17467539\n",
      "Iteration 4498, loss = 17710436.68830159\n",
      "Iteration 4499, loss = 17713543.17424185\n",
      "Iteration 4500, loss = 17710530.98584687\n",
      "Iteration 4501, loss = 17710986.32574782\n",
      "Iteration 4502, loss = 17711625.68426464\n",
      "Iteration 4503, loss = 17711274.98856160\n",
      "Iteration 4504, loss = 17708538.52669695\n",
      "Iteration 4505, loss = 17708402.15752659\n",
      "Iteration 4506, loss = 17709494.83059426\n",
      "Iteration 4507, loss = 17707698.42370744\n",
      "Iteration 4508, loss = 17707251.33165847\n",
      "Iteration 4509, loss = 17707518.73756845\n",
      "Iteration 4510, loss = 17715357.52087313\n",
      "Iteration 4511, loss = 17712832.87398162\n",
      "Iteration 4512, loss = 17708730.05712770\n",
      "Iteration 4513, loss = 17709961.21647704\n",
      "Iteration 4514, loss = 17705792.56838635\n",
      "Iteration 4515, loss = 17717609.43828522\n",
      "Iteration 4516, loss = 17706076.31720325\n",
      "Iteration 4517, loss = 17705748.96140102\n",
      "Iteration 4518, loss = 17710245.84705303\n",
      "Iteration 4519, loss = 17704859.72500653\n",
      "Iteration 4520, loss = 17704906.04725394\n",
      "Iteration 4521, loss = 17704347.56700601\n",
      "Iteration 4522, loss = 17703250.91429611\n",
      "Iteration 4523, loss = 17704527.75160515\n",
      "Iteration 4524, loss = 17705248.75054800\n",
      "Iteration 4525, loss = 17706574.00094127\n",
      "Iteration 4526, loss = 17703907.90294037\n",
      "Iteration 4527, loss = 17708412.28616742\n",
      "Iteration 4528, loss = 17704445.12361028\n",
      "Iteration 4529, loss = 17702947.12786630\n",
      "Iteration 4530, loss = 17704595.52139866\n",
      "Iteration 4531, loss = 17702370.99780984\n",
      "Iteration 4532, loss = 17710138.03594840\n",
      "Iteration 4533, loss = 17702170.96314323\n",
      "Iteration 4534, loss = 17707929.07044663\n",
      "Iteration 4535, loss = 17703054.36655417\n",
      "Iteration 4536, loss = 17712649.64749847\n",
      "Iteration 4537, loss = 17701859.96532233\n",
      "Iteration 4538, loss = 17699877.30528618\n",
      "Iteration 4539, loss = 17704871.19303460\n",
      "Iteration 4540, loss = 17699773.58288468\n",
      "Iteration 4541, loss = 17700016.32568861\n",
      "Iteration 4542, loss = 17701343.59865283\n",
      "Iteration 4543, loss = 17710271.21006069\n",
      "Iteration 4544, loss = 17702080.67869356\n",
      "Iteration 4545, loss = 17699180.25858935\n",
      "Iteration 4546, loss = 17699014.20414750\n",
      "Iteration 4547, loss = 17704859.39079893\n",
      "Iteration 4548, loss = 17700367.22467880\n",
      "Iteration 4549, loss = 17703401.64294638\n",
      "Iteration 4550, loss = 17697199.63513913\n",
      "Iteration 4551, loss = 17714006.76004541\n",
      "Iteration 4552, loss = 17703867.96244773\n",
      "Iteration 4553, loss = 17698194.29116201\n",
      "Iteration 4554, loss = 17699581.84571057\n",
      "Iteration 4555, loss = 17700313.47976313\n",
      "Iteration 4556, loss = 17698935.32408258\n",
      "Iteration 4557, loss = 17695276.68727940\n",
      "Iteration 4558, loss = 17702892.44283345\n",
      "Iteration 4559, loss = 17696075.40236488\n",
      "Iteration 4560, loss = 17694623.75848365\n",
      "Iteration 4561, loss = 17694562.57999095\n",
      "Iteration 4562, loss = 17695428.39630367\n",
      "Iteration 4563, loss = 17697045.33485741\n",
      "Iteration 4564, loss = 17696701.43962744\n",
      "Iteration 4565, loss = 17700963.26985283\n",
      "Iteration 4566, loss = 17700242.92995039\n",
      "Iteration 4567, loss = 17697129.13204540\n",
      "Iteration 4568, loss = 17697511.53068090\n",
      "Iteration 4569, loss = 17694851.41570988\n",
      "Iteration 4570, loss = 17692987.01087108\n",
      "Iteration 4571, loss = 17697859.77901422\n",
      "Iteration 4572, loss = 17697429.65982397\n",
      "Iteration 4573, loss = 17694073.81452479\n",
      "Iteration 4574, loss = 17694233.49943645\n",
      "Iteration 4575, loss = 17692632.66087221\n",
      "Iteration 4576, loss = 17691828.11991049\n",
      "Iteration 4577, loss = 17691748.04924981\n",
      "Iteration 4578, loss = 17691494.51109347\n",
      "Iteration 4579, loss = 17696427.71818005\n",
      "Iteration 4580, loss = 17691684.47729650\n",
      "Iteration 4581, loss = 17692222.56926879\n",
      "Iteration 4582, loss = 17690062.18645430\n",
      "Iteration 4583, loss = 17690862.95355340\n",
      "Iteration 4584, loss = 17690662.51296656\n",
      "Iteration 4585, loss = 17694130.24335756\n",
      "Iteration 4586, loss = 17698034.43388812\n",
      "Iteration 4587, loss = 17690531.02938974\n",
      "Iteration 4588, loss = 17701602.06845744\n",
      "Iteration 4589, loss = 17688383.05572245\n",
      "Iteration 4590, loss = 17689724.52401366\n",
      "Iteration 4591, loss = 17692141.92885026\n",
      "Iteration 4592, loss = 17693352.55792236\n",
      "Iteration 4593, loss = 17686013.62224951\n",
      "Iteration 4594, loss = 17695804.62483301\n",
      "Iteration 4595, loss = 17696414.63766514\n",
      "Iteration 4596, loss = 17691774.95462565\n",
      "Iteration 4597, loss = 17686929.88400133\n",
      "Iteration 4598, loss = 17689104.79125250\n",
      "Iteration 4599, loss = 17687414.06747967\n",
      "Iteration 4600, loss = 17687372.78945192\n",
      "Iteration 4601, loss = 17691637.08077968\n",
      "Iteration 4602, loss = 17686475.63039611\n",
      "Iteration 4603, loss = 17688269.38173027\n",
      "Iteration 4604, loss = 17692526.95856299\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "             learning_rate_init=0.001, max_fun=15000, max_iter=10000,\n",
       "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "             power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "             tol=0.0001, validation_fraction=0.1, verbose=True,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = MLPRegressor(activation='identity', max_iter=10000, verbose=True)\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7309876527860193"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicton = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f8de0ec388>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAYsElEQVR4nO3df2zc9Z3n8efLDont9nwJxW6cH1y4bsoWkDalszh3nEiP9iAEROiq1QXYEiEkkxbu6Kl3V+CfbJPeaivttrdIwVpvYQkt24BoeokQ3WwEZC2kBuI0WUhIaVzHS9xMgtlACoXYgN/3x3zcDI4djx3H37Hn9ZBG8533fL7j90wcv+b7WxGBmZlVtqqsGzAzs+w5DMzMzGFgZmYOAzMzw2FgZmbAjKwbGK8LLrggFi1alHUbZmZTyu7du9+IiIah9SkbBosWLaKjoyPrNszMphRJ/zJc3auJzMzMYWBmZg4DMzOjhDCQVCPpRUn/LGm/pG+n+iOSDknam25LUl2SHpDUKeklSZcXvdZqSQfTbXVR/XOSXk7zPCBJ5+LNmpnZ8ErZgNwHXB0R70g6D3he0s/Sc/8rIp4cMv46YHG6NQOtQLOk84G1QA4IYLekrRHxZhrTAuwEngaWAz/DzMwmxahLBlHwTnp4Xrqd6ex2K4FH03w7gdmSmoBrge0RcTwFwHZgeXquPiJ+HoWz5j0K3HQW78mmmHxfH8v27OFoX1/WrZhVrJK2GUiqlrQXeJ3CH/QX0lP/J60K+r6kWak2HzhcNHtPqp2p3jNMfbg+WiR1SOro7e0tpXWbAtZ3d/P8iROs6+7OuhWzilVSGETEhxGxBFgAXCHpMuA+4A+BPwbOB76Vhg+3vj/GUR+uj7aIyEVErqHhtGMmbIqpbW9HO3bQms8zALTm82jHDmrb27NuzazijGlvooh4C9gBLI+IfFoV1Af8HXBFGtYDLCyabQFwZJT6gmHqNs11NTdzS2MjdVWFX8O6qipubWzkUHNzxp2ZVZ5S9iZqkDQ7TdcCXwR+mdb1k/b8uQnYl2bZCtyW9ipaCpyIiDywDbhG0hxJc4BrgG3pubclLU2vdRuwZWLfppWjplmzqK+u5uTAADVVVZwcGKC+upq5s2aNPrOZTahS9iZqAjZKqqYQHk9ExFOSnpXUQGE1z15gTRr/NLAC6ATeBW4HiIjjktYDu9K4dRFxPE1/DXgEqKWwF5H3JKoQx95/nzXz5tEybx5tR46Q7+/PuiWziqSpetnLXC4XPjeRmdnYSNodEbmhdR+BbGZmDgMzM3MYmJkZDgMzM8NhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZjgMzMwMh4GZmeEwMDMzHAZmZobDwMzMcBiYmRkOAzMzo4QwkFQj6UVJ/yxpv6Rvp/pFkl6QdFDS45Jmpvqs9LgzPb+o6LXuS/VXJV1bVF+eap2S7p34t2lmZmdSypJBH3B1RPwRsARYLmkp8F3g+xGxGHgTuCONvwN4MyL+APh+GoekS4BVwKXAcuBBSdWSqoENwHXAJcDNaayZmU2SUcMgCt5JD89LtwCuBp5M9Y3ATWl6ZXpMev4LkpTqmyKiLyIOAZ3AFenWGRFdEdEPbEpjzcxskpS0zSB9g98LvA5sB34NvBURH6QhPcD8ND0fOAyQnj8BfKK4PmSekerD9dEiqUNSR29vbymtm5lZCUoKg4j4MCKWAAsofJP/zHDD0r1GeG6s9eH6aIuIXETkGhoaRm/czMxKMqa9iSLiLWAHsBSYLWlGemoBcCRN9wALAdLz/xY4XlwfMs9IdTMzmySl7E3UIGl2mq4FvggcAJ4DvpyGrQa2pOmt6THp+WcjIlJ9Vdrb6CJgMfAisAtYnPZOmklhI/PWiXhzZmZWmhmjD6EJ2Jj2+qkCnoiIpyS9AmyS9B1gD/BQGv8Q8ENJnRSWCFYBRMR+SU8ArwAfAHdFxIcAku4GtgHVwMMRsX/C3qGZmY1KhS/tU08ul4uOjo6s2zAzm1Ik7Y6I3NC6j0A2MzOHgZmZOQysHOTzsGwZHD2adSdmFcthYNlbvx6efx7Wrcu6E7OK5TCw7NTWggStrTAwULiXCnUzm1QOA8tOVxfccgvU1RUe19XBrbfCoUPZ9mVWgRwGlp2mJqivh5MnoaamcF9fD3PnZt2ZWcVxGFi2jh2DNWtg587CvTcim2WilCOQzc6dzZtPTW/YkF0fZhXOSwZmZuYwMDMzh4GZmeEwMDMzHAZmZobDwMzMcBiYmRkOAzMzw2FgZmY4DMzMDIeBmZnhMDAzM0oIA0kLJT0n6YCk/ZLuSfU/k/QbSXvTbUXRPPdJ6pT0qqRri+rLU61T0r1F9YskvSDpoKTHJc2c6DdqZmYjK2XJ4APgmxHxGWApcJekS9Jz34+IJen2NEB6bhVwKbAceFBStaRqYANwHXAJcHPR63w3vdZi4E3gjgl6f2ZmVoJRwyAi8hHxizT9NnAAmH+GWVYCmyKiLyIOAZ3AFenWGRFdEdEPbAJWShJwNfBkmn8jcNN435CZmY3dmLYZSFoEfBZ4IZXulvSSpIclzUm1+cDhotl6Um2k+ieAtyLigyH14X5+i6QOSR29vb1jad3MzM6g5DCQ9HHgJ8A3IuK3QCvwKWAJkAf+anDoMLPHOOqnFyPaIiIXEbmGhoZSWzczs1GUdKUzSedRCILHImIzQEQcK3r+b4Gn0sMeYGHR7AuAI2l6uPobwGxJM9LSQfF4MzObBKXsTSTgIeBARHyvqN5UNOxLwL40vRVYJWmWpIuAxcCLwC5gcdpzaCaFjcxbIyKA54Avp/lXA1vO7m2ZmdlYlLJkcCXwVeBlSXtT7X4KewMtobBKpxu4EyAi9kt6AniFwp5Id0XEhwCS7ga2AdXAwxGxP73et4BNkr4D7KEQPmZmNklU+GI+9eRyuejo6Mi6DTOzKUXS7ojIDa37CGQzM3MYmJmZw8DMzHAYmJkZDgMzM8NhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZjgMzMwMh4GZmeEwMDMzHAZmZobDwMzMcBiYmRklhIGkhZKek3RA0n5J96T6+ZK2SzqY7uekuiQ9IKlT0kuSLi96rdVp/EFJq4vqn5P0cprnAUk6F2/WzMyGV8qSwQfANyPiM8BS4C5JlwD3As9ExGLgmfQY4Dpgcbq1AK1QCA9gLdAMXAGsHQyQNKalaL7lZ//WzMysVKOGQUTkI+IXafpt4AAwH1gJbEzDNgI3pemVwKNRsBOYLakJuBbYHhHHI+JNYDuwPD1XHxE/j4gAHi16LTMzmwRj2mYgaRHwWeAF4JMRkYdCYACNadh84HDRbD2pdqZ6zzD14X5+i6QOSR29vb1jad3MzM6g5DCQ9HHgJ8A3IuK3Zxo6TC3GUT+9GNEWEbmIyDU0NIzWspmZlaikMJB0HoUgeCwiNqfysbSKh3T/eqr3AAuLZl8AHBmlvmCYupmZTZJS9iYS8BBwICK+V/TUVmBwj6DVwJai+m1pr6KlwIm0GmkbcI2kOWnD8TXAtvTc25KWpp91W9FrmZnZJJhRwpgrga8CL0vam2r3A38BPCHpDuA14CvpuaeBFUAn8C5wO0BEHJe0HtiVxq2LiONp+mvAI0At8LN0MzOzSaLCDjxTTy6Xi46OjqzbMDObUiTtjojc0LqPQDYzM4eBmZk5DMzMDIeBmZnhMDAzMxwGZmaGw8DMzHAYmJkZDgMzM8NhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZjgMzMwMh4GZmVFCGEh6WNLrkvYV1f5M0m8k7U23FUXP3SepU9Krkq4tqi9PtU5J9xbVL5L0gqSDkh6XNHMi36CZTW35vj6W7dnD0b6+rFuZ1kpZMngEWD5M/fsRsSTdngaQdAmwCrg0zfOgpGpJ1cAG4DrgEuDmNBbgu+m1FgNvAneczRsys+llfXc3z584wbru7qxbmdZGDYOIaAeOl/h6K4FNEdEXEYeATuCKdOuMiK6I6Ac2ASslCbgaeDLNvxG4aYzvwcymodr2drRjBz/dt49n77mHzfv3ox07qG1vz7q1aelsthncLemltBppTqrNBw4XjelJtZHqnwDeiogPhtSHJalFUoekjt7e3rNo3czKXVdzM7c0NvLtH/6Q//Tyy6x79FFubWzkUHNz1q1NS+MNg1bgU8ASIA/8VaprmLExjvqwIqItInIRkWtoaBhbx2Y2pTTNns1jl15Ky5YtVEfQsmULP7r0UubOnp11a9PSuMIgIo5FxIcRMQD8LYXVQFD4Zr+waOgC4MgZ6m8AsyXNGFI3s0rX1UX7ihX01dQA0FdTwz9dfz0cOpRxY9PTuMJAUlPRwy8Bg3sabQVWSZol6SJgMfAisAtYnPYcmklhI/PWiAjgOeDLaf7VwJbx9GRm00xTE1ddeCGz+vuhpoZZ/f0su/BCmDs3686mpRmjDZD0Y+DzwAWSeoC1wOclLaGwSqcbuBMgIvZLegJ4BfgAuCsiPkyvczewDagGHo6I/elHfAvYJOk7wB7goQl7d2Y2tR07BmvWQEsLtLVBPp91R9OWCl/Op55cLhcdHR1Zt2FmNqVI2h0RuaF1H4FsZmYOAzMzcxiYmRkOAzMzw2FgZmY4DMzMDIeBmZnhMDA7JZ+HZcvg6NGsOzGbdA4Ds0Hr18Pzz8O6dVl3YjbpHAZmtbUgQWsrDAwU7qVC3axCOAzMurrgllugrq7wuK4Obr3VZ8e0iuIwMGtqgvp6OHkSamoK9/X1PjumVRSHgRmcOjvmzp2Fe29Etgoz6imszSrC5s2npjdsyK4Ps4x4ycDMzBwGZmbmMDAzMxwGZmaGw8DMzHAYmJkZDgMzM6OEMJD0sKTXJe0rqp0vabukg+l+TqpL0gOSOiW9JOnyonlWp/EHJa0uqn9O0stpngckaaLfpJmZnVkpSwaPAMuH1O4FnomIxcAz6THAdcDidGsBWqEQHsBaoBm4Alg7GCBpTEvRfEN/lpmZnWOjhkFEtAPHh5RXAhvT9EbgpqL6o1GwE5gtqQm4FtgeEccj4k1gO7A8PVcfET+PiAAeLXqtc8PnrLcR5Pv6WLZnD0f7+rJuxWzSjXebwScjIg+Q7htTfT5wuGhcT6qdqd4zTH1YklokdUjq6O3tHV/nPme9jWB9dzfPnzjBuu7urFsxm3QTfW6i4db3xzjqw4qINqANIJfLjThuWLW1hbNRDmptLdxqauC998b0Uja91La3c3Jg4PePW/N5WvN5aqqqeO+qqzLszGzyjHfJ4FhaxUO6fz3Ve4CFReMWAEdGqS8Ypj7x0jnr+2pqAAr3Pme9AV3NzdzS2EhdVeG/Q11VFbc2NnKouTnjzswmz3jDYCswuEfQamBLUf22tFfRUuBEWo20DbhG0py04fgaYFt67m1JS9NeRLcVvdaEqj14kNZ33mFGXx/vzZzJjL4+Hnz7bWp/9atz8eNsCmmaNYv66mpODgxQU1XFyYEB6qurmTtrVtatmU2aUVcTSfox8HngAkk9FPYK+gvgCUl3AK8BX0nDnwZWAJ3Au8DtABFxXNJ6YFcaty4iBjdKf43CHku1wM/SbcJ1NTdz+N13+cGNN/LgDTfw9aee4o9/9zt/+zMAjr3/PmvmzaNl3jzajhwh39+fdUtmk0qFnXimnlwuFx0dHWOa52uvvkpbPs/Mqir6Bwa4s6mJBy+++Bx1aGZWfiTtjojc0HpFXdzG3/7MzIZXUWGw+bLLfj+94dOfzrATM7Py4nMTmZmZw8DMzBwGZmaGw8DMzHAYmJkZDgMzM8NhYGZmOAzMzAyHgZmZ4TDIjq+4ZmZjdQ7/bjgMsuIrrpnZWJ3DvxsVddbSsjD0imuDfMU1MxvJBP7dGOmspV4ymGzpimvU1RUe19X5imtmdmaT8HfDYTDZmpqgvr6Q8jU1hfv6epg7N+vOzKxcTcLfDYdBFo4dgzVrYOfOwr03IpvZaM7x3w1vMzAzqyDeZmBmZiNyGJiZ2dmFgaRuSS9L2iupI9XOl7Rd0sF0PyfVJekBSZ2SXpJ0edHrrE7jD0pafXZvyczMxmoilgz+c0QsKVoHdS/wTEQsBp5JjwGuAxanWwvQCoXwANYCzcAVwNrBADEzs8lxLlYTrQQ2pumNwE1F9UejYCcwW1ITcC2wPSKOR8SbwHZg+Tnoq6zk+/pYtmcPR/v6sm7FzOyswyCAf5S0W1JLqn0yIvIA6b4x1ecDh4vm7Um1keqnkdQiqUNSR29v71m2nq313d08f+IE67q7s27FzEZTAecSm3GW818ZEUckNQLbJf3yDGM1TC3OUD+9GNEGtEFh19KxNlsOatvbOTkw8PvHrfk8rfk8NVVVvHfVVRl2ZmYjKj4n0IMPZt3NOXFWSwYRcSTdvw78lMI6/2Np9Q/p/vU0vAdYWDT7AuDIGerTUldzM7c0NlJXVfjo66qquLWxkUPNzRl3Zmanqa0FCVpbYWCgcC8V6tPMuMNA0sck/ZvBaeAaYB+wFRjcI2g1sCVNbwVuS3sVLQVOpNVI24BrJM1JG46vSbVpqWnWLOqrqzk5MEBNVRUnBwaor65m7qxZWbdmZkNV0LnEzmY10SeBn0oafJ2/j4h/kLQLeELSHcBrwFfS+KeBFUAn8C5wO0BEHJe0HtiVxq2LiONn0VfZO/b++6yZN4+WefNoO3KEfH9/1i1ZOcnnYdUqePxxn7MqaxV0LjGfjsKs3Hz96/A3fwN33jlt109PKX/yJ4VQaGmBtrZCWG/enHVX4zbS6SgcBmblwte6sEngcxOZlbu0fnogbZyM2tpM10/7WJjycy7/TRwGZuWiaP30ezNnEhmvn/axMOXnXP6bnO1xBmY2QWrb2/nR/v0cvfFG2m64gZannmLuvn38aXv7pB6DMngszNx//VeeXbeO/7p2rY+FydhkHJ/kbQZmZSLf18f//PWv+X9vvMG7AwPUVVXxpQsu4C8/9alJ3fV4sI9l99/PHVu38tCNN9L+538+6X3YKRP5uzHSNgMvGZiViXI5BqVp9mweK9qQ3bJlCy1btnhDdoYm43fD2wzMysjgMSg7L7+cNfPmcfT99ye/ia4u2lesoK+mBoC+mhr+6frrp+WBVlPJuf7d8JKBWRnZfNllv5/e8OlPZ9NEUxNXXXgh9PdDTQ2z+vtZduGF0/JAq6nkXP9ueMmgwnn3QRvWOb74upUfLxlUuOJd1R68+OKs27FyUXyE7YYN2fVhk8ZhUKF8Km0zK+bVRBXKp9I2K10lrE51GFSoctmN0WwqqISjsb2aqIL5VNpmZ1ZJq1MdBhWsLHZjNCtjXc3NIx75O914NVGlq4ALfZuNVyWtTnUYVLriC32b2WnK4qjwSeAT1VUqX0jFrCL54jb2URV0oW8zG53DoFJV0IW+zWx0ZRMGkpZLelVSp6R7s+6nIvj8M2aWlMU2A0nVwK+A/wL0ALuAmyPilZHm8TYDM7OxK/dtBlcAnRHRFRH9wCZgZcY9mZlVjHIJg/nA4aLHPalmZmaToFzCQMPUTlt/JalFUoekjt7e3kloy8ysMpRLGPQAC4seLwCODB0UEW0RkYuIXENDw6Q1Z2Y23ZVLGOwCFku6SNJMYBWwNeOezMwqRlmcqC4iPpB0N7ANqAYejoj9GbdlZlYxymLX0vGQ1Av8yzhnvwB4YwLbmer8eZziz+Kj/HmcMl0+i38XEaetZ5+yYXA2JHUMt59tpfLncYo/i4/y53HKdP8symWbgZmZZchhYGZmFRsGbVk3UGb8eZziz+Kj/HmcMq0/i4rcZmBmZh9VqUsGZmZWxGFgZmaVFQa+ZsIpkhZKek7SAUn7Jd2TdU/lQFK1pD2Snsq6lyxJmi3pSUm/TL8j/yHrnrIk6X+k/yf7JP1YUk3WPU20igmDdM2EDcB1wCXAzZIuybarTH0AfDMiPgMsBe6q8M9j0D3AgaybKAN/DfxDRPwh8EdU8GciaT7w34FcRFxG4SwJq7LtauJVTBjgayZ8RETkI+IXafptCv/ZK/q04ZIWANcDP8i6lyxJqgeuAh4CiIj+iHgr264yNwOolTQDqGOYE2lOdZUUBr5mwggkLQI+C7yQbSeZ+7/A/wYGsm4kY/8e6AX+Lq0y+4Gkj2XdVFYi4jfAXwKvAXngRET8Y7ZdTbxKCoOSrplQaSR9HPgJ8I2I+G3W/WRF0g3A6xGxO+teysAM4HKgNSI+C/wOqNhtbJLmUFiLcBEwD/iYpD/NtquJV0lhUNI1EyqJpPMoBMFjEbE5634ydiVwo6RuCqsQr5b0o2xbykwP0BMRg0uKT1IIh0r1ReBQRPRGxPvAZuA/ZtzThKukMPA1E4pIEoV1wgci4ntZ95O1iLgvIhZExCIKvxvPRsS0+/ZXiog4ChyWdHEqfQF4JcOWsvYasFRSXfp/8wWm4Qb1sriewWTwNRNOcyXwVeBlSXtT7f6IeDrDnqx8/DfgsfTFqQu4PeN+MhMRL0h6EvgFhb3w9jANT03h01GYmVlFrSYyM7MROAzMzMxhYGZmDgMzM8NhYGZmOAzMzAyHgZmZAf8frojQR8GA5/IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test.values[:10], '*c')\n",
    "plt.plot(predicton[:10], '*r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1333</td>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1334</td>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1335</td>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1336</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1337</td>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region\n",
       "0      19  female  27.900         0    yes  southwest\n",
       "1      18    male  33.770         1     no  southeast\n",
       "2      28    male  33.000         3     no  southeast\n",
       "3      33    male  22.705         0     no  northwest\n",
       "4      32    male  28.880         0     no  northwest\n",
       "...   ...     ...     ...       ...    ...        ...\n",
       "1333   50    male  30.970         3     no  northwest\n",
       "1334   18  female  31.920         0     no  northeast\n",
       "1335   18  female  36.850         0     no  southeast\n",
       "1336   21  female  25.800         0     no  southwest\n",
       "1337   61  female  29.070         0    yes  northwest\n",
       "\n",
       "[1338 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.drop('charges', axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       16884.92400\n",
       "1        1725.55230\n",
       "2        4449.46200\n",
       "3       21984.47061\n",
       "4        3866.85520\n",
       "           ...     \n",
       "1333    10600.54830\n",
       "1334     2205.98080\n",
       "1335     1629.83350\n",
       "1336     2007.94500\n",
       "1337    29141.36030\n",
       "Name: charges, Length: 1338, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = df['charges']\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column('age')\n",
    "bmi = tf.feature_column.numeric_column('bmi')\n",
    "children = tf.feature_column.numeric_column('children')\n",
    "\n",
    "sex = tf.feature_column.categorical_column_with_hash_bucket('sex', hash_bucket_size=len(df['sex'].unique()))\n",
    "smoker = tf.feature_column.categorical_column_with_hash_bucket('smoker', hash_bucket_size=len(df['smoker'].unique()))\n",
    "region = tf.feature_column.categorical_column_with_hash_bucket('region', hash_bucket_size=len(df['region'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [age, bmi,children, sex, smoker, region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(936, 6)\n",
      "(402, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data,\n",
    "                                                    label,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=2020)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(X_train,\n",
    "                                                y_train,\n",
    "                                                num_epochs=5000,\n",
    "                                                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0602 14:17:08.697241 17688 estimator.py:1790] Using default config.\n",
      "W0602 14:17:08.698239 17688 estimator.py:1811] Using temporary folder as model directory: C:\\Users\\LENOVO\\AppData\\Local\\Temp\\tmpszmaf8za\n",
      "I0602 14:17:08.699237 17688 estimator.py:209] Using config: {'_model_dir': 'C:\\\\Users\\\\LENOVO\\\\AppData\\\\Local\\\\Temp\\\\tmpszmaf8za', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001F8E3CC0BC8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.LinearRegressor(feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0602 14:17:17.002321 17688 deprecation.py:323] From C:\\Users\\LENOVO\\Anaconda3\\envs\\fhadli\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0602 14:17:17.045203 17688 deprecation.py:323] From C:\\Users\\LENOVO\\Anaconda3\\envs\\fhadli\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0602 14:17:17.051219 17688 deprecation.py:323] From C:\\Users\\LENOVO\\Anaconda3\\envs\\fhadli\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "I0602 14:17:17.081109 17688 estimator.py:1145] Calling model_fn.\n",
      "W0602 14:17:17.745332 17688 deprecation.py:323] From C:\\Users\\LENOVO\\Anaconda3\\envs\\fhadli\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2655: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0602 14:17:18.043533 17688 deprecation.py:323] From C:\\Users\\LENOVO\\Anaconda3\\envs\\fhadli\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "I0602 14:17:18.646958 17688 estimator.py:1147] Done calling model_fn.\n",
      "I0602 14:17:18.647950 17688 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0602 14:17:20.420183 17688 monitored_session.py:240] Graph was finalized.\n",
      "I0602 14:17:20.652558 17688 session_manager.py:500] Running local_init_op.\n",
      "I0602 14:17:20.678499 17688 session_manager.py:502] Done running local_init_op.\n",
      "W0602 14:17:20.752324 17688 deprecation.py:323] From C:\\Users\\LENOVO\\Anaconda3\\envs\\fhadli\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "I0602 14:17:23.249674 17688 basic_session_run_hooks.py:606] Saving checkpoints for 0 into C:\\Users\\LENOVO\\AppData\\Local\\Temp\\tmpszmaf8za\\model.ckpt.\n",
      "I0602 14:17:24.952085 17688 basic_session_run_hooks.py:262] loss = 47903860000.0, step = 1\n",
      "I0602 14:17:25.649224 17688 basic_session_run_hooks.py:692] global_step/sec: 143.444\n",
      "I0602 14:17:25.652213 17688 basic_session_run_hooks.py:260] loss = 39709573000.0, step = 101 (0.700 sec)\n",
      "I0602 14:17:25.969340 17688 basic_session_run_hooks.py:692] global_step/sec: 311.389\n",
      "I0602 14:17:25.978349 17688 basic_session_run_hooks.py:260] loss = 38556360000.0, step = 201 (0.326 sec)\n",
      "I0602 14:17:26.369270 17688 basic_session_run_hooks.py:692] global_step/sec: 250.669\n",
      "I0602 14:17:26.378257 17688 basic_session_run_hooks.py:260] loss = 40760795000.0, step = 301 (0.400 sec)\n",
      "I0602 14:17:26.759245 17688 basic_session_run_hooks.py:692] global_step/sec: 257.088\n",
      "I0602 14:17:26.768203 17688 basic_session_run_hooks.py:260] loss = 42309583000.0, step = 401 (0.390 sec)\n",
      "I0602 14:17:27.162149 17688 basic_session_run_hooks.py:692] global_step/sec: 246.971\n",
      "I0602 14:17:27.165142 17688 basic_session_run_hooks.py:260] loss = 51498950000.0, step = 501 (0.397 sec)\n",
      "I0602 14:17:27.481296 17688 basic_session_run_hooks.py:692] global_step/sec: 313.336\n",
      "I0602 14:17:27.484288 17688 basic_session_run_hooks.py:260] loss = 41015830000.0, step = 601 (0.319 sec)\n",
      "I0602 14:17:27.853311 17688 basic_session_run_hooks.py:692] global_step/sec: 269.536\n",
      "I0602 14:17:27.863275 17688 basic_session_run_hooks.py:260] loss = 46520877000.0, step = 701 (0.379 sec)\n",
      "I0602 14:17:28.181424 17688 basic_session_run_hooks.py:692] global_step/sec: 303.841\n",
      "I0602 14:17:28.185415 17688 basic_session_run_hooks.py:260] loss = 43737170000.0, step = 801 (0.322 sec)\n",
      "I0602 14:17:28.529494 17688 basic_session_run_hooks.py:692] global_step/sec: 288.124\n",
      "I0602 14:17:28.533484 17688 basic_session_run_hooks.py:260] loss = 35289220000.0, step = 901 (0.348 sec)\n",
      "I0602 14:17:29.021198 17688 basic_session_run_hooks.py:692] global_step/sec: 203.379\n",
      "I0602 14:17:29.029158 17688 basic_session_run_hooks.py:260] loss = 24937562000.0, step = 1001 (0.496 sec)\n",
      "I0602 14:17:29.396176 17688 basic_session_run_hooks.py:692] global_step/sec: 266.671\n",
      "I0602 14:17:29.399197 17688 basic_session_run_hooks.py:260] loss = 34811208000.0, step = 1101 (0.370 sec)\n",
      "I0602 14:17:29.715326 17688 basic_session_run_hooks.py:692] global_step/sec: 312.362\n",
      "I0602 14:17:29.718315 17688 basic_session_run_hooks.py:260] loss = 37593997000.0, step = 1201 (0.319 sec)\n",
      "I0602 14:17:30.025495 17688 basic_session_run_hooks.py:692] global_step/sec: 322.405\n",
      "I0602 14:17:30.030480 17688 basic_session_run_hooks.py:260] loss = 50722790000.0, step = 1301 (0.312 sec)\n",
      "I0602 14:17:30.346635 17688 basic_session_run_hooks.py:692] global_step/sec: 311.39\n",
      "I0602 14:17:30.348629 17688 basic_session_run_hooks.py:260] loss = 28548555000.0, step = 1401 (0.318 sec)\n",
      "I0602 14:17:30.664784 17688 basic_session_run_hooks.py:692] global_step/sec: 314.319\n",
      "I0602 14:17:30.666778 17688 basic_session_run_hooks.py:260] loss = 36274598000.0, step = 1501 (0.318 sec)\n",
      "I0602 14:17:30.997893 17688 basic_session_run_hooks.py:692] global_step/sec: 300.202\n",
      "I0602 14:17:30.999888 17688 basic_session_run_hooks.py:260] loss = 29248756000.0, step = 1601 (0.333 sec)\n",
      "I0602 14:17:31.318039 17688 basic_session_run_hooks.py:692] global_step/sec: 312.358\n",
      "I0602 14:17:31.326051 17688 basic_session_run_hooks.py:260] loss = 33077830000.0, step = 1701 (0.325 sec)\n",
      "I0602 14:17:31.648154 17688 basic_session_run_hooks.py:692] global_step/sec: 302.924\n",
      "I0602 14:17:31.651146 17688 basic_session_run_hooks.py:260] loss = 36142730000.0, step = 1801 (0.326 sec)\n",
      "I0602 14:17:31.979303 17688 basic_session_run_hooks.py:692] global_step/sec: 301.979\n",
      "I0602 14:17:31.983258 17688 basic_session_run_hooks.py:260] loss = 36625375000.0, step = 1901 (0.332 sec)\n",
      "I0602 14:17:32.316367 17688 basic_session_run_hooks.py:692] global_step/sec: 296.68\n",
      "I0602 14:17:32.319360 17688 basic_session_run_hooks.py:260] loss = 43743166000.0, step = 2001 (0.336 sec)\n",
      "I0602 14:17:32.652470 17688 basic_session_run_hooks.py:692] global_step/sec: 298.415\n",
      "I0602 14:17:32.660454 17688 basic_session_run_hooks.py:260] loss = 33749608000.0, step = 2101 (0.341 sec)\n",
      "I0602 14:17:32.975609 17688 basic_session_run_hooks.py:692] global_step/sec: 308.511\n",
      "I0602 14:17:32.979594 17688 basic_session_run_hooks.py:260] loss = 36197343000.0, step = 2201 (0.319 sec)\n",
      "I0602 14:17:33.365563 17688 basic_session_run_hooks.py:692] global_step/sec: 256.44\n",
      "I0602 14:17:33.369551 17688 basic_session_run_hooks.py:260] loss = 46677170000.0, step = 2301 (0.390 sec)\n",
      "I0602 14:17:33.682714 17688 basic_session_run_hooks.py:692] global_step/sec: 316.302\n",
      "I0602 14:17:33.686707 17688 basic_session_run_hooks.py:260] loss = 28368247000.0, step = 2401 (0.317 sec)\n",
      "I0602 14:17:33.985903 17688 basic_session_run_hooks.py:692] global_step/sec: 328.746\n",
      "I0602 14:17:33.992886 17688 basic_session_run_hooks.py:260] loss = 35738706000.0, step = 2501 (0.306 sec)\n",
      "I0602 14:17:34.383841 17688 basic_session_run_hooks.py:692] global_step/sec: 251.295\n",
      "I0602 14:17:34.386859 17688 basic_session_run_hooks.py:260] loss = 43172303000.0, step = 2601 (0.394 sec)\n",
      "I0602 14:17:34.715953 17688 basic_session_run_hooks.py:692] global_step/sec: 302.007\n",
      "I0602 14:17:34.719941 17688 basic_session_run_hooks.py:260] loss = 28482425000.0, step = 2701 (0.333 sec)\n",
      "I0602 14:17:35.036094 17688 basic_session_run_hooks.py:692] global_step/sec: 311.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:17:35.044074 17688 basic_session_run_hooks.py:260] loss = 36224080000.0, step = 2801 (0.324 sec)\n",
      "I0602 14:17:35.335296 17688 basic_session_run_hooks.py:692] global_step/sec: 334.223\n",
      "I0602 14:17:35.343276 17688 basic_session_run_hooks.py:260] loss = 28076659000.0, step = 2901 (0.299 sec)\n",
      "I0602 14:17:35.651451 17688 basic_session_run_hooks.py:692] global_step/sec: 316.3\n",
      "I0602 14:17:35.660425 17688 basic_session_run_hooks.py:260] loss = 39399793000.0, step = 3001 (0.317 sec)\n",
      "I0602 14:17:35.997524 17688 basic_session_run_hooks.py:692] global_step/sec: 288.956\n",
      "I0602 14:17:36.000545 17688 basic_session_run_hooks.py:260] loss = 35480680000.0, step = 3101 (0.340 sec)\n",
      "I0602 14:17:36.344598 17688 basic_session_run_hooks.py:692] global_step/sec: 288.954\n",
      "I0602 14:17:36.346590 17688 basic_session_run_hooks.py:260] loss = 33001790000.0, step = 3201 (0.346 sec)\n",
      "I0602 14:17:36.681696 17688 basic_session_run_hooks.py:692] global_step/sec: 295.774\n",
      "I0602 14:17:36.685686 17688 basic_session_run_hooks.py:260] loss = 36714370000.0, step = 3301 (0.339 sec)\n",
      "I0602 14:17:36.982889 17688 basic_session_run_hooks.py:692] global_step/sec: 332.013\n",
      "I0602 14:17:36.985882 17688 basic_session_run_hooks.py:260] loss = 27826375000.0, step = 3401 (0.300 sec)\n",
      "I0602 14:17:37.274119 17688 basic_session_run_hooks.py:692] global_step/sec: 344.533\n",
      "I0602 14:17:37.279097 17688 basic_session_run_hooks.py:260] loss = 30245415000.0, step = 3501 (0.293 sec)\n",
      "I0602 14:17:37.583284 17688 basic_session_run_hooks.py:692] global_step/sec: 322.428\n",
      "I0602 14:17:37.586277 17688 basic_session_run_hooks.py:260] loss = 40360120000.0, step = 3601 (0.307 sec)\n",
      "I0602 14:17:37.887483 17688 basic_session_run_hooks.py:692] global_step/sec: 329.827\n",
      "I0602 14:17:37.896446 17688 basic_session_run_hooks.py:260] loss = 35753603000.0, step = 3701 (0.310 sec)\n",
      "I0602 14:17:38.184676 17688 basic_session_run_hooks.py:692] global_step/sec: 335.343\n",
      "I0602 14:17:38.191658 17688 basic_session_run_hooks.py:260] loss = 39275340000.0, step = 3801 (0.295 sec)\n",
      "I0602 14:17:38.483876 17688 basic_session_run_hooks.py:692] global_step/sec: 335.343\n",
      "I0602 14:17:38.485870 17688 basic_session_run_hooks.py:260] loss = 47707726000.0, step = 3901 (0.294 sec)\n",
      "I0602 14:17:38.781082 17688 basic_session_run_hooks.py:692] global_step/sec: 335.342\n",
      "I0602 14:17:38.785071 17688 basic_session_run_hooks.py:260] loss = 38566070000.0, step = 4001 (0.299 sec)\n",
      "I0602 14:17:39.116185 17688 basic_session_run_hooks.py:692] global_step/sec: 298.416\n",
      "I0602 14:17:39.119177 17688 basic_session_run_hooks.py:260] loss = 43981136000.0, step = 4101 (0.334 sec)\n",
      "I0602 14:17:39.415385 17688 basic_session_run_hooks.py:692] global_step/sec: 334.224\n",
      "I0602 14:17:39.419374 17688 basic_session_run_hooks.py:260] loss = 40859290000.0, step = 4201 (0.300 sec)\n",
      "I0602 14:17:39.711593 17688 basic_session_run_hooks.py:692] global_step/sec: 337.601\n",
      "I0602 14:17:39.714585 17688 basic_session_run_hooks.py:260] loss = 27726119000.0, step = 4301 (0.295 sec)\n",
      "I0602 14:17:40.033732 17688 basic_session_run_hooks.py:692] global_step/sec: 310.425\n",
      "I0602 14:17:40.037757 17688 basic_session_run_hooks.py:260] loss = 37509360000.0, step = 4401 (0.323 sec)\n",
      "I0602 14:17:40.333929 17688 basic_session_run_hooks.py:692] global_step/sec: 333.115\n",
      "I0602 14:17:40.340917 17688 basic_session_run_hooks.py:260] loss = 36862650000.0, step = 4501 (0.303 sec)\n",
      "I0602 14:17:40.619168 17688 basic_session_run_hooks.py:692] global_step/sec: 351.814\n",
      "I0602 14:17:40.628143 17688 basic_session_run_hooks.py:260] loss = 31263850000.0, step = 4601 (0.287 sec)\n",
      "I0602 14:17:40.929337 17688 basic_session_run_hooks.py:692] global_step/sec: 321.37\n",
      "I0602 14:17:40.932329 17688 basic_session_run_hooks.py:260] loss = 43552680000.0, step = 4701 (0.304 sec)\n",
      "I0602 14:17:41.214575 17688 basic_session_run_hooks.py:692] global_step/sec: 350.584\n",
      "I0602 14:17:41.216570 17688 basic_session_run_hooks.py:260] loss = 36058444000.0, step = 4801 (0.284 sec)\n",
      "I0602 14:17:41.503805 17688 basic_session_run_hooks.py:692] global_step/sec: 345.745\n",
      "I0602 14:17:41.511803 17688 basic_session_run_hooks.py:260] loss = 37227200000.0, step = 4901 (0.295 sec)\n",
      "I0602 14:17:41.799012 17688 basic_session_run_hooks.py:692] global_step/sec: 338.746\n",
      "I0602 14:17:41.803003 17688 basic_session_run_hooks.py:260] loss = 39350456000.0, step = 5001 (0.291 sec)\n",
      "I0602 14:17:42.093225 17688 basic_session_run_hooks.py:692] global_step/sec: 339.89\n",
      "I0602 14:17:42.096216 17688 basic_session_run_hooks.py:260] loss = 24796443000.0, step = 5101 (0.293 sec)\n",
      "I0602 14:17:42.393423 17688 basic_session_run_hooks.py:692] global_step/sec: 333.114\n",
      "I0602 14:17:42.398410 17688 basic_session_run_hooks.py:260] loss = 34569425000.0, step = 5201 (0.301 sec)\n",
      "I0602 14:17:42.745482 17688 basic_session_run_hooks.py:692] global_step/sec: 284.043\n",
      "I0602 14:17:42.747476 17688 basic_session_run_hooks.py:260] loss = 35555500000.0, step = 5301 (0.350 sec)\n",
      "I0602 14:17:43.065625 17688 basic_session_run_hooks.py:692] global_step/sec: 313.337\n",
      "I0602 14:17:43.069613 17688 basic_session_run_hooks.py:260] loss = 38617747000.0, step = 5401 (0.321 sec)\n",
      "I0602 14:17:43.356851 17688 basic_session_run_hooks.py:692] global_step/sec: 343.372\n",
      "I0602 14:17:43.365858 17688 basic_session_run_hooks.py:260] loss = 34035069000.0, step = 5501 (0.297 sec)\n",
      "I0602 14:17:43.703930 17688 basic_session_run_hooks.py:692] global_step/sec: 288.131\n",
      "I0602 14:17:43.711898 17688 basic_session_run_hooks.py:260] loss = 31838282000.0, step = 5601 (0.346 sec)\n",
      "I0602 14:17:43.978186 17688 basic_session_run_hooks.py:692] global_step/sec: 363.286\n",
      "I0602 14:17:43.981203 17688 basic_session_run_hooks.py:260] loss = 37421044000.0, step = 5701 (0.269 sec)\n",
      "I0602 14:17:44.249460 17688 basic_session_run_hooks.py:692] global_step/sec: 369.991\n",
      "I0602 14:17:44.252451 17688 basic_session_run_hooks.py:260] loss = 41246270000.0, step = 5801 (0.271 sec)\n",
      "I0602 14:17:44.530706 17688 basic_session_run_hooks.py:692] global_step/sec: 354.304\n",
      "I0602 14:17:44.534698 17688 basic_session_run_hooks.py:260] loss = 19192295000.0, step = 5901 (0.282 sec)\n",
      "I0602 14:17:44.867808 17688 basic_session_run_hooks.py:692] global_step/sec: 296.646\n",
      "I0602 14:17:44.877779 17688 basic_session_run_hooks.py:260] loss = 36502897000.0, step = 6001 (0.343 sec)\n",
      "I0602 14:17:45.196924 17688 basic_session_run_hooks.py:692] global_step/sec: 303.843\n",
      "I0602 14:17:45.198920 17688 basic_session_run_hooks.py:260] loss = 32367423000.0, step = 6101 (0.321 sec)\n",
      "I0602 14:17:45.569930 17688 basic_session_run_hooks.py:692] global_step/sec: 268.812\n",
      "I0602 14:17:45.604984 17688 basic_session_run_hooks.py:260] loss = 36837323000.0, step = 6201 (0.406 sec)\n",
      "I0602 14:17:46.434337 17688 basic_session_run_hooks.py:692] global_step/sec: 115.686\n",
      "I0602 14:17:46.438335 17688 basic_session_run_hooks.py:260] loss = 29827359000.0, step = 6301 (0.833 sec)\n",
      "I0602 14:17:46.777421 17688 basic_session_run_hooks.py:692] global_step/sec: 290.629\n",
      "I0602 14:17:46.781433 17688 basic_session_run_hooks.py:260] loss = 26523218000.0, step = 6401 (0.343 sec)\n",
      "I0602 14:17:47.111527 17688 basic_session_run_hooks.py:692] global_step/sec: 299.306\n",
      "I0602 14:17:47.115550 17688 basic_session_run_hooks.py:260] loss = 25481880000.0, step = 6501 (0.334 sec)\n",
      "I0602 14:17:47.428679 17688 basic_session_run_hooks.py:692] global_step/sec: 315.305\n",
      "I0602 14:17:47.432668 17688 basic_session_run_hooks.py:260] loss = 41817604000.0, step = 6601 (0.317 sec)\n",
      "I0602 14:17:47.717906 17688 basic_session_run_hooks.py:692] global_step/sec: 345.75\n",
      "I0602 14:17:47.726883 17688 basic_session_run_hooks.py:260] loss = 43827870000.0, step = 6701 (0.293 sec)\n",
      "I0602 14:17:48.114846 17688 basic_session_run_hooks.py:692] global_step/sec: 251.927\n",
      "I0602 14:17:48.118834 17688 basic_session_run_hooks.py:260] loss = 28579764000.0, step = 6801 (0.393 sec)\n",
      "I0602 14:17:48.379139 17688 basic_session_run_hooks.py:692] global_step/sec: 379.803\n",
      "I0602 14:17:48.381163 17688 basic_session_run_hooks.py:260] loss = 44080697000.0, step = 6901 (0.262 sec)\n",
      "I0602 14:17:48.631464 17688 basic_session_run_hooks.py:692] global_step/sec: 394.751\n",
      "I0602 14:17:48.634480 17688 basic_session_run_hooks.py:260] loss = 31168860000.0, step = 7001 (0.253 sec)\n",
      "I0602 14:17:48.948617 17688 basic_session_run_hooks.py:692] global_step/sec: 315.305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:17:48.951607 17688 basic_session_run_hooks.py:260] loss = 27757169000.0, step = 7101 (0.317 sec)\n",
      "I0602 14:17:49.385449 17688 basic_session_run_hooks.py:692] global_step/sec: 228.921\n",
      "I0602 14:17:49.393431 17688 basic_session_run_hooks.py:260] loss = 32998187000.0, step = 7201 (0.442 sec)\n",
      "I0602 14:17:49.722555 17688 basic_session_run_hooks.py:692] global_step/sec: 297.52\n",
      "I0602 14:17:49.730524 17688 basic_session_run_hooks.py:260] loss = 30699323000.0, step = 7301 (0.337 sec)\n",
      "I0602 14:17:50.044723 17688 basic_session_run_hooks.py:692] global_step/sec: 309.443\n",
      "I0602 14:17:50.048675 17688 basic_session_run_hooks.py:260] loss = 36530487000.0, step = 7401 (0.318 sec)\n",
      "I0602 14:17:50.315994 17688 basic_session_run_hooks.py:692] global_step/sec: 368.635\n",
      "I0602 14:17:50.319950 17688 basic_session_run_hooks.py:260] loss = 34039298000.0, step = 7501 (0.271 sec)\n",
      "I0602 14:17:50.567288 17688 basic_session_run_hooks.py:692] global_step/sec: 397.94\n",
      "I0602 14:17:50.574270 17688 basic_session_run_hooks.py:260] loss = 43099610000.0, step = 7601 (0.253 sec)\n",
      "I0602 14:17:50.839564 17688 basic_session_run_hooks.py:692] global_step/sec: 368.621\n",
      "I0602 14:17:50.844545 17688 basic_session_run_hooks.py:260] loss = 43172573000.0, step = 7701 (0.271 sec)\n",
      "I0602 14:17:51.127787 17688 basic_session_run_hooks.py:692] global_step/sec: 345.76\n",
      "I0602 14:17:51.132774 17688 basic_session_run_hooks.py:260] loss = 25427930000.0, step = 7801 (0.288 sec)\n",
      "I0602 14:17:51.428982 17688 basic_session_run_hooks.py:692] global_step/sec: 332.011\n",
      "I0602 14:17:51.433970 17688 basic_session_run_hooks.py:260] loss = 30398335000.0, step = 7901 (0.301 sec)\n",
      "I0602 14:17:51.769074 17688 basic_session_run_hooks.py:692] global_step/sec: 294.038\n",
      "I0602 14:17:51.777051 17688 basic_session_run_hooks.py:260] loss = 41444966000.0, step = 8001 (0.343 sec)\n",
      "I0602 14:17:52.057306 17688 basic_session_run_hooks.py:692] global_step/sec: 348.128\n",
      "I0602 14:17:52.061291 17688 basic_session_run_hooks.py:260] loss = 38104723000.0, step = 8101 (0.284 sec)\n",
      "I0602 14:17:52.331602 17688 basic_session_run_hooks.py:692] global_step/sec: 363.27\n",
      "I0602 14:17:52.335560 17688 basic_session_run_hooks.py:260] loss = 32402274000.0, step = 8201 (0.274 sec)\n",
      "I0602 14:17:52.598856 17688 basic_session_run_hooks.py:692] global_step/sec: 374.176\n",
      "I0602 14:17:52.601846 17688 basic_session_run_hooks.py:260] loss = 44616730000.0, step = 8301 (0.266 sec)\n",
      "I0602 14:17:52.877110 17688 basic_session_run_hooks.py:692] global_step/sec: 359.383\n",
      "I0602 14:17:52.880103 17688 basic_session_run_hooks.py:260] loss = 39394152000.0, step = 8401 (0.278 sec)\n",
      "I0602 14:17:53.159357 17688 basic_session_run_hooks.py:692] global_step/sec: 355.505\n",
      "I0602 14:17:53.161386 17688 basic_session_run_hooks.py:260] loss = 32261007000.0, step = 8501 (0.281 sec)\n",
      "I0602 14:17:53.432626 17688 basic_session_run_hooks.py:692] global_step/sec: 365.996\n",
      "I0602 14:17:53.435619 17688 basic_session_run_hooks.py:260] loss = 31437935000.0, step = 8601 (0.274 sec)\n",
      "I0602 14:17:53.808623 17688 basic_session_run_hooks.py:692] global_step/sec: 265.255\n",
      "I0602 14:17:53.811613 17688 basic_session_run_hooks.py:260] loss = 32449864000.0, step = 8701 (0.376 sec)\n",
      "I0602 14:17:54.083884 17688 basic_session_run_hooks.py:692] global_step/sec: 364.613\n",
      "I0602 14:17:54.089913 17688 basic_session_run_hooks.py:260] loss = 24527751000.0, step = 8801 (0.278 sec)\n",
      "I0602 14:17:54.374109 17688 basic_session_run_hooks.py:692] global_step/sec: 344.548\n",
      "I0602 14:17:54.380091 17688 basic_session_run_hooks.py:260] loss = 34485410000.0, step = 8901 (0.290 sec)\n",
      "I0602 14:17:54.646379 17688 basic_session_run_hooks.py:692] global_step/sec: 365.956\n",
      "I0602 14:17:54.648404 17688 basic_session_run_hooks.py:260] loss = 31039095000.0, step = 9001 (0.268 sec)\n",
      "I0602 14:17:54.898706 17688 basic_session_run_hooks.py:692] global_step/sec: 396.31\n",
      "I0602 14:17:54.900700 17688 basic_session_run_hooks.py:260] loss = 31507153000.0, step = 9101 (0.252 sec)\n",
      "I0602 14:17:55.181947 17688 basic_session_run_hooks.py:692] global_step/sec: 353.056\n",
      "I0602 14:17:55.185935 17688 basic_session_run_hooks.py:260] loss = 32255777000.0, step = 9201 (0.285 sec)\n",
      "I0602 14:17:55.447238 17688 basic_session_run_hooks.py:692] global_step/sec: 376.945\n",
      "I0602 14:17:55.451263 17688 basic_session_run_hooks.py:260] loss = 30281617000.0, step = 9301 (0.265 sec)\n",
      "I0602 14:17:55.718511 17688 basic_session_run_hooks.py:692] global_step/sec: 368.632\n",
      "I0602 14:17:55.725530 17688 basic_session_run_hooks.py:260] loss = 37947180000.0, step = 9401 (0.274 sec)\n",
      "I0602 14:17:55.997766 17688 basic_session_run_hooks.py:692] global_step/sec: 358.096\n",
      "I0602 14:17:55.999785 17688 basic_session_run_hooks.py:260] loss = 29162365000.0, step = 9501 (0.274 sec)\n",
      "I0602 14:17:56.298960 17688 basic_session_run_hooks.py:692] global_step/sec: 332.012\n",
      "I0602 14:17:56.303957 17688 basic_session_run_hooks.py:260] loss = 34726900000.0, step = 9601 (0.304 sec)\n",
      "I0602 14:17:56.582202 17688 basic_session_run_hooks.py:692] global_step/sec: 353.055\n",
      "I0602 14:17:56.584196 17688 basic_session_run_hooks.py:260] loss = 25313636000.0, step = 9701 (0.280 sec)\n",
      "I0602 14:17:56.851484 17688 basic_session_run_hooks.py:692] global_step/sec: 371.359\n",
      "I0602 14:17:56.859462 17688 basic_session_run_hooks.py:260] loss = 30894645000.0, step = 9801 (0.275 sec)\n",
      "I0602 14:17:57.125750 17688 basic_session_run_hooks.py:692] global_step/sec: 364.609\n",
      "I0602 14:17:57.128741 17688 basic_session_run_hooks.py:260] loss = 29467790000.0, step = 9901 (0.269 sec)\n",
      "I0602 14:17:57.424955 17688 basic_session_run_hooks.py:692] global_step/sec: 334.219\n",
      "I0602 14:17:57.430934 17688 basic_session_run_hooks.py:260] loss = 25872378000.0, step = 10001 (0.302 sec)\n",
      "I0602 14:17:57.709191 17688 basic_session_run_hooks.py:692] global_step/sec: 353.052\n",
      "I0602 14:17:57.713178 17688 basic_session_run_hooks.py:260] loss = 29781955000.0, step = 10101 (0.282 sec)\n",
      "I0602 14:17:57.985451 17688 basic_session_run_hooks.py:692] global_step/sec: 360.682\n",
      "I0602 14:17:57.993433 17688 basic_session_run_hooks.py:260] loss = 31343165000.0, step = 10201 (0.280 sec)\n",
      "I0602 14:17:58.289649 17688 basic_session_run_hooks.py:692] global_step/sec: 329.784\n",
      "I0602 14:17:58.294622 17688 basic_session_run_hooks.py:260] loss = 26982384000.0, step = 10301 (0.301 sec)\n",
      "I0602 14:17:58.563905 17688 basic_session_run_hooks.py:692] global_step/sec: 363.34\n",
      "I0602 14:17:58.565900 17688 basic_session_run_hooks.py:260] loss = 29642640000.0, step = 10401 (0.271 sec)\n",
      "I0602 14:17:58.826204 17688 basic_session_run_hooks.py:692] global_step/sec: 381.245\n",
      "I0602 14:17:58.829195 17688 basic_session_run_hooks.py:260] loss = 21259985000.0, step = 10501 (0.263 sec)\n",
      "I0602 14:17:59.099471 17688 basic_session_run_hooks.py:692] global_step/sec: 365.941\n",
      "I0602 14:17:59.102525 17688 basic_session_run_hooks.py:260] loss = 33114431000.0, step = 10601 (0.273 sec)\n",
      "I0602 14:17:59.379724 17688 basic_session_run_hooks.py:692] global_step/sec: 356.821\n",
      "I0602 14:17:59.382714 17688 basic_session_run_hooks.py:260] loss = 33680028000.0, step = 10701 (0.280 sec)\n",
      "I0602 14:17:59.663963 17688 basic_session_run_hooks.py:692] global_step/sec: 351.816\n",
      "I0602 14:17:59.668949 17688 basic_session_run_hooks.py:260] loss = 30513103000.0, step = 10801 (0.286 sec)\n",
      "I0602 14:17:59.949200 17688 basic_session_run_hooks.py:692] global_step/sec: 350.585\n",
      "I0602 14:17:59.952224 17688 basic_session_run_hooks.py:260] loss = 36775380000.0, step = 10901 (0.283 sec)\n",
      "I0602 14:18:00.246406 17688 basic_session_run_hooks.py:692] global_step/sec: 336.468\n",
      "I0602 14:18:00.249397 17688 basic_session_run_hooks.py:260] loss = 32804155000.0, step = 11001 (0.297 sec)\n",
      "I0602 14:18:00.591492 17688 basic_session_run_hooks.py:692] global_step/sec: 289.783\n",
      "I0602 14:18:00.599461 17688 basic_session_run_hooks.py:260] loss = 27083960000.0, step = 11101 (0.350 sec)\n",
      "I0602 14:18:00.932570 17688 basic_session_run_hooks.py:692] global_step/sec: 293.188\n",
      "I0602 14:18:00.935560 17688 basic_session_run_hooks.py:260] loss = 23279038000.0, step = 11201 (0.336 sec)\n",
      "I0602 14:18:01.419810 17688 basic_session_run_hooks.py:692] global_step/sec: 205.658\n",
      "I0602 14:18:01.448745 17688 basic_session_run_hooks.py:260] loss = 35864720000.0, step = 11301 (0.513 sec)\n",
      "I0602 14:18:01.897525 17688 basic_session_run_hooks.py:692] global_step/sec: 208.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:18:01.900516 17688 basic_session_run_hooks.py:260] loss = 29411211000.0, step = 11401 (0.452 sec)\n",
      "I0602 14:18:02.185754 17688 basic_session_run_hooks.py:692] global_step/sec: 346.946\n",
      "I0602 14:18:02.194731 17688 basic_session_run_hooks.py:260] loss = 35127136000.0, step = 11501 (0.294 sec)\n",
      "I0602 14:18:02.494930 17688 basic_session_run_hooks.py:692] global_step/sec: 323.44\n",
      "I0602 14:18:02.499915 17688 basic_session_run_hooks.py:260] loss = 36557746000.0, step = 11601 (0.305 sec)\n",
      "I0602 14:18:02.818063 17688 basic_session_run_hooks.py:692] global_step/sec: 309.469\n",
      "I0602 14:18:02.823055 17688 basic_session_run_hooks.py:260] loss = 34786570000.0, step = 11701 (0.323 sec)\n",
      "I0602 14:18:03.156162 17688 basic_session_run_hooks.py:692] global_step/sec: 295.771\n",
      "I0602 14:18:03.161146 17688 basic_session_run_hooks.py:260] loss = 32918374000.0, step = 11801 (0.338 sec)\n",
      "I0602 14:18:03.487286 17688 basic_session_run_hooks.py:692] global_step/sec: 302.926\n",
      "I0602 14:18:03.494256 17688 basic_session_run_hooks.py:260] loss = 30881120000.0, step = 11901 (0.333 sec)\n",
      "I0602 14:18:03.797445 17688 basic_session_run_hooks.py:692] global_step/sec: 321.369\n",
      "I0602 14:18:03.801437 17688 basic_session_run_hooks.py:260] loss = 31614423000.0, step = 12001 (0.307 sec)\n",
      "I0602 14:18:04.084678 17688 basic_session_run_hooks.py:692] global_step/sec: 349.365\n",
      "I0602 14:18:04.090687 17688 basic_session_run_hooks.py:260] loss = 33112150000.0, step = 12101 (0.289 sec)\n",
      "I0602 14:18:04.366924 17688 basic_session_run_hooks.py:692] global_step/sec: 353.051\n",
      "I0602 14:18:04.373908 17688 basic_session_run_hooks.py:260] loss = 31496327000.0, step = 12201 (0.283 sec)\n",
      "I0602 14:18:04.697040 17688 basic_session_run_hooks.py:692] global_step/sec: 302.924\n",
      "I0602 14:18:04.700031 17688 basic_session_run_hooks.py:260] loss = 27103445000.0, step = 12301 (0.326 sec)\n",
      "I0602 14:18:04.985269 17688 basic_session_run_hooks.py:692] global_step/sec: 346.946\n",
      "I0602 14:18:04.992274 17688 basic_session_run_hooks.py:260] loss = 18697470000.0, step = 12401 (0.292 sec)\n",
      "I0602 14:18:05.276524 17688 basic_session_run_hooks.py:692] global_step/sec: 343.342\n",
      "I0602 14:18:05.279481 17688 basic_session_run_hooks.py:260] loss = 32323780000.0, step = 12501 (0.287 sec)\n",
      "I0602 14:18:05.546767 17688 basic_session_run_hooks.py:692] global_step/sec: 370.037\n",
      "I0602 14:18:05.548763 17688 basic_session_run_hooks.py:260] loss = 26806673000.0, step = 12601 (0.269 sec)\n",
      "I0602 14:18:05.908806 17688 basic_session_run_hooks.py:692] global_step/sec: 277.739\n",
      "I0602 14:18:05.925760 17688 basic_session_run_hooks.py:260] loss = 39099482000.0, step = 12701 (0.377 sec)\n",
      "I0602 14:18:06.342647 17688 basic_session_run_hooks.py:692] global_step/sec: 229.971\n",
      "I0602 14:18:06.347625 17688 basic_session_run_hooks.py:260] loss = 24411308000.0, step = 12801 (0.422 sec)\n",
      "I0602 14:18:06.659793 17688 basic_session_run_hooks.py:692] global_step/sec: 315.312\n",
      "I0602 14:18:06.662785 17688 basic_session_run_hooks.py:260] loss = 31779010000.0, step = 12901 (0.315 sec)\n",
      "I0602 14:18:06.929072 17688 basic_session_run_hooks.py:692] global_step/sec: 369.999\n",
      "I0602 14:18:06.932063 17688 basic_session_run_hooks.py:260] loss = 33405483000.0, step = 13001 (0.269 sec)\n",
      "I0602 14:18:07.218299 17688 basic_session_run_hooks.py:692] global_step/sec: 345.749\n",
      "I0602 14:18:07.227287 17688 basic_session_run_hooks.py:260] loss = 27853324000.0, step = 13101 (0.295 sec)\n",
      "I0602 14:18:07.518495 17688 basic_session_run_hooks.py:692] global_step/sec: 333.116\n",
      "I0602 14:18:07.527472 17688 basic_session_run_hooks.py:260] loss = 26939032000.0, step = 13201 (0.300 sec)\n",
      "I0602 14:18:07.918014 17688 basic_session_run_hooks.py:692] global_step/sec: 250.926\n",
      "I0602 14:18:07.946950 17688 basic_session_run_hooks.py:260] loss = 26820133000.0, step = 13301 (0.419 sec)\n",
      "I0602 14:18:08.541290 17688 basic_session_run_hooks.py:692] global_step/sec: 160.444\n",
      "I0602 14:18:08.547261 17688 basic_session_run_hooks.py:260] loss = 30663543000.0, step = 13401 (0.600 sec)\n",
      "I0602 14:18:08.869399 17688 basic_session_run_hooks.py:692] global_step/sec: 303.851\n",
      "I0602 14:18:08.876381 17688 basic_session_run_hooks.py:260] loss = 36115034000.0, step = 13501 (0.329 sec)\n",
      "I0602 14:18:09.279304 17688 basic_session_run_hooks.py:692] global_step/sec: 243.959\n",
      "I0602 14:18:09.281298 17688 basic_session_run_hooks.py:260] loss = 32455678000.0, step = 13601 (0.405 sec)\n",
      "I0602 14:18:09.576511 17688 basic_session_run_hooks.py:692] global_step/sec: 336.467\n",
      "I0602 14:18:09.579500 17688 basic_session_run_hooks.py:260] loss = 32924727000.0, step = 13701 (0.298 sec)\n",
      "I0602 14:18:09.851773 17688 basic_session_run_hooks.py:692] global_step/sec: 363.29\n",
      "I0602 14:18:09.862746 17688 basic_session_run_hooks.py:260] loss = 29617037000.0, step = 13801 (0.282 sec)\n",
      "I0602 14:18:10.151970 17688 basic_session_run_hooks.py:692] global_step/sec: 333.114\n",
      "I0602 14:18:10.159949 17688 basic_session_run_hooks.py:260] loss = 29760303000.0, step = 13901 (0.298 sec)\n",
      "I0602 14:18:10.428233 17688 basic_session_run_hooks.py:692] global_step/sec: 363.286\n",
      "I0602 14:18:10.431258 17688 basic_session_run_hooks.py:260] loss = 25776787000.0, step = 14001 (0.271 sec)\n",
      "I0602 14:18:10.717458 17688 basic_session_run_hooks.py:692] global_step/sec: 344.562\n",
      "I0602 14:18:10.726437 17688 basic_session_run_hooks.py:260] loss = 35165030000.0, step = 14101 (0.294 sec)\n",
      "I0602 14:18:11.019650 17688 basic_session_run_hooks.py:692] global_step/sec: 332.011\n",
      "I0602 14:18:11.027628 17688 basic_session_run_hooks.py:260] loss = 29922873000.0, step = 14201 (0.302 sec)\n",
      "I0602 14:18:11.300899 17688 basic_session_run_hooks.py:692] global_step/sec: 354.3\n",
      "I0602 14:18:11.310873 17688 basic_session_run_hooks.py:260] loss = 40834638000.0, step = 14301 (0.283 sec)\n",
      "I0602 14:18:11.578158 17688 basic_session_run_hooks.py:692] global_step/sec: 360.674\n",
      "I0602 14:18:11.582145 17688 basic_session_run_hooks.py:260] loss = 26309493000.0, step = 14401 (0.271 sec)\n",
      "I0602 14:18:11.916254 17688 basic_session_run_hooks.py:692] global_step/sec: 295.774\n",
      "I0602 14:18:11.920248 17688 basic_session_run_hooks.py:260] loss = 22021378000.0, step = 14501 (0.338 sec)\n",
      "I0602 14:18:12.218445 17688 basic_session_run_hooks.py:692] global_step/sec: 330.916\n",
      "I0602 14:18:12.228421 17688 basic_session_run_hooks.py:260] loss = 28278127000.0, step = 14601 (0.308 sec)\n",
      "I0602 14:18:12.579480 17688 basic_session_run_hooks.py:692] global_step/sec: 277.745\n",
      "I0602 14:18:12.584465 17688 basic_session_run_hooks.py:260] loss = 34944434000.0, step = 14701 (0.356 sec)\n",
      "I0602 14:18:12.918573 17688 basic_session_run_hooks.py:692] global_step/sec: 294.044\n",
      "I0602 14:18:12.926552 17688 basic_session_run_hooks.py:260] loss = 32582430000.0, step = 14801 (0.342 sec)\n",
      "I0602 14:18:13.192841 17688 basic_session_run_hooks.py:692] global_step/sec: 364.606\n",
      "I0602 14:18:13.196828 17688 basic_session_run_hooks.py:260] loss = 24248656000.0, step = 14901 (0.270 sec)\n",
      "I0602 14:18:13.482065 17688 basic_session_run_hooks.py:692] global_step/sec: 345.753\n",
      "I0602 14:18:13.485057 17688 basic_session_run_hooks.py:260] loss = 37284405000.0, step = 15001 (0.288 sec)\n",
      "I0602 14:18:13.769298 17688 basic_session_run_hooks.py:692] global_step/sec: 349.333\n",
      "I0602 14:18:13.777276 17688 basic_session_run_hooks.py:260] loss = 32616595000.0, step = 15101 (0.292 sec)\n",
      "I0602 14:18:14.053541 17688 basic_session_run_hooks.py:692] global_step/sec: 350.612\n",
      "I0602 14:18:14.062513 17688 basic_session_run_hooks.py:260] loss = 27778562000.0, step = 15201 (0.285 sec)\n",
      "I0602 14:18:14.366700 17688 basic_session_run_hooks.py:692] global_step/sec: 319.326\n",
      "I0602 14:18:14.373695 17688 basic_session_run_hooks.py:260] loss = 39874600000.0, step = 15301 (0.311 sec)\n",
      "I0602 14:18:14.695822 17688 basic_session_run_hooks.py:692] global_step/sec: 303.84\n",
      "I0602 14:18:14.698813 17688 basic_session_run_hooks.py:260] loss = 30969242000.0, step = 15401 (0.325 sec)\n",
      "I0602 14:18:14.984051 17688 basic_session_run_hooks.py:692] global_step/sec: 346.946\n",
      "I0602 14:18:14.990038 17688 basic_session_run_hooks.py:260] loss = 25897525000.0, step = 15501 (0.291 sec)\n",
      "I0602 14:18:15.320154 17688 basic_session_run_hooks.py:692] global_step/sec: 297.527\n",
      "I0602 14:18:15.329128 17688 basic_session_run_hooks.py:260] loss = 38124683000.0, step = 15601 (0.339 sec)\n",
      "I0602 14:18:15.581453 17688 basic_session_run_hooks.py:692] global_step/sec: 382.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:18:15.584445 17688 basic_session_run_hooks.py:260] loss = 26857413000.0, step = 15701 (0.255 sec)\n",
      "I0602 14:18:15.855766 17688 basic_session_run_hooks.py:692] global_step/sec: 364.547\n",
      "I0602 14:18:15.861737 17688 basic_session_run_hooks.py:260] loss = 30467723000.0, step = 15801 (0.277 sec)\n",
      "I0602 14:18:16.126994 17688 basic_session_run_hooks.py:692] global_step/sec: 368.693\n",
      "I0602 14:18:16.129985 17688 basic_session_run_hooks.py:260] loss = 39148920000.0, step = 15901 (0.268 sec)\n",
      "I0602 14:18:16.432178 17688 basic_session_run_hooks.py:692] global_step/sec: 327.671\n",
      "I0602 14:18:16.435171 17688 basic_session_run_hooks.py:260] loss = 29441990000.0, step = 16001 (0.305 sec)\n",
      "I0602 14:18:16.730380 17688 basic_session_run_hooks.py:692] global_step/sec: 335.343\n",
      "I0602 14:18:16.732394 17688 basic_session_run_hooks.py:260] loss = 30426255000.0, step = 16101 (0.297 sec)\n",
      "I0602 14:18:17.001656 17688 basic_session_run_hooks.py:692] global_step/sec: 369.99\n",
      "I0602 14:18:17.009633 17688 basic_session_run_hooks.py:260] loss = 33281575000.0, step = 16201 (0.277 sec)\n",
      "I0602 14:18:17.283905 17688 basic_session_run_hooks.py:692] global_step/sec: 353.049\n",
      "I0602 14:18:17.292879 17688 basic_session_run_hooks.py:260] loss = 31532188000.0, step = 16301 (0.283 sec)\n",
      "I0602 14:18:17.577118 17688 basic_session_run_hooks.py:692] global_step/sec: 341.049\n",
      "I0602 14:18:17.581105 17688 basic_session_run_hooks.py:260] loss = 38118285000.0, step = 16401 (0.288 sec)\n",
      "I0602 14:18:17.935158 17688 basic_session_run_hooks.py:692] global_step/sec: 279.298\n",
      "I0602 14:18:17.944134 17688 basic_session_run_hooks.py:260] loss = 35617698000.0, step = 16501 (0.363 sec)\n",
      "I0602 14:18:18.206436 17688 basic_session_run_hooks.py:692] global_step/sec: 369.975\n",
      "I0602 14:18:18.211418 17688 basic_session_run_hooks.py:260] loss = 31581184000.0, step = 16601 (0.267 sec)\n",
      "I0602 14:18:18.484722 17688 basic_session_run_hooks.py:692] global_step/sec: 358.069\n",
      "I0602 14:18:18.491705 17688 basic_session_run_hooks.py:260] loss = 34343617000.0, step = 16701 (0.280 sec)\n",
      "I0602 14:18:19.583366 17688 basic_session_run_hooks.py:692] global_step/sec: 91.0213\n",
      "I0602 14:18:19.594337 17688 basic_session_run_hooks.py:260] loss = 26642117000.0, step = 16801 (1.103 sec)\n",
      "I0602 14:18:19.877581 17688 basic_session_run_hooks.py:692] global_step/sec: 341.046\n",
      "I0602 14:18:19.881571 17688 basic_session_run_hooks.py:260] loss = 33277624000.0, step = 16901 (0.287 sec)\n",
      "I0602 14:18:20.167802 17688 basic_session_run_hooks.py:692] global_step/sec: 343.383\n",
      "I0602 14:18:20.175783 17688 basic_session_run_hooks.py:260] loss = 32030908000.0, step = 17001 (0.294 sec)\n",
      "I0602 14:18:20.449052 17688 basic_session_run_hooks.py:692] global_step/sec: 355.556\n",
      "I0602 14:18:20.452044 17688 basic_session_run_hooks.py:260] loss = 33025872000.0, step = 17101 (0.276 sec)\n",
      "I0602 14:18:20.732295 17688 basic_session_run_hooks.py:692] global_step/sec: 353.054\n",
      "I0602 14:18:20.738292 17688 basic_session_run_hooks.py:260] loss = 20946842000.0, step = 17201 (0.286 sec)\n",
      "I0602 14:18:21.048450 17688 basic_session_run_hooks.py:692] global_step/sec: 316.301\n",
      "I0602 14:18:21.051441 17688 basic_session_run_hooks.py:260] loss = 34052753000.0, step = 17301 (0.313 sec)\n",
      "I0602 14:18:21.701702 17688 basic_session_run_hooks.py:692] global_step/sec: 153.08\n",
      "I0602 14:18:21.710679 17688 basic_session_run_hooks.py:260] loss = 22861780000.0, step = 17401 (0.659 sec)\n",
      "I0602 14:18:22.074712 17688 basic_session_run_hooks.py:692] global_step/sec: 269.53\n",
      "I0602 14:18:22.080688 17688 basic_session_run_hooks.py:260] loss = 28136071000.0, step = 17501 (0.370 sec)\n",
      "I0602 14:18:22.577220 17688 basic_session_run_hooks.py:692] global_step/sec: 198.607\n",
      "I0602 14:18:22.603161 17688 basic_session_run_hooks.py:260] loss = 30712285000.0, step = 17601 (0.522 sec)\n",
      "I0602 14:18:23.114771 17688 basic_session_run_hooks.py:692] global_step/sec: 185.685\n",
      "I0602 14:18:23.117763 17688 basic_session_run_hooks.py:260] loss = 28653971000.0, step = 17701 (0.515 sec)\n",
      "I0602 14:18:24.101426 17688 basic_session_run_hooks.py:692] global_step/sec: 101.353\n",
      "I0602 14:18:24.110403 17688 basic_session_run_hooks.py:260] loss = 28770095000.0, step = 17801 (0.993 sec)\n",
      "I0602 14:18:24.435533 17688 basic_session_run_hooks.py:692] global_step/sec: 299.305\n",
      "I0602 14:18:24.437531 17688 basic_session_run_hooks.py:260] loss = 41504070000.0, step = 17901 (0.327 sec)\n",
      "I0602 14:18:24.716781 17688 basic_session_run_hooks.py:692] global_step/sec: 355.558\n",
      "I0602 14:18:24.722779 17688 basic_session_run_hooks.py:260] loss = 23575280000.0, step = 18001 (0.285 sec)\n",
      "I0602 14:18:25.029946 17688 basic_session_run_hooks.py:692] global_step/sec: 319.321\n",
      "I0602 14:18:25.032937 17688 basic_session_run_hooks.py:260] loss = 27237118000.0, step = 18101 (0.310 sec)\n",
      "I0602 14:18:25.302217 17688 basic_session_run_hooks.py:692] global_step/sec: 367.281\n",
      "I0602 14:18:25.309197 17688 basic_session_run_hooks.py:260] loss = 26594736000.0, step = 18201 (0.276 sec)\n",
      "I0602 14:18:25.614382 17688 basic_session_run_hooks.py:692] global_step/sec: 320.343\n",
      "I0602 14:18:25.629342 17688 basic_session_run_hooks.py:260] loss = 27016827000.0, step = 18301 (0.320 sec)\n",
      "I0602 14:18:26.011321 17688 basic_session_run_hooks.py:692] global_step/sec: 251.928\n",
      "I0602 14:18:26.014313 17688 basic_session_run_hooks.py:260] loss = 31475675000.0, step = 18401 (0.385 sec)\n",
      "I0602 14:18:26.314510 17688 basic_session_run_hooks.py:692] global_step/sec: 329.827\n",
      "I0602 14:18:26.317501 17688 basic_session_run_hooks.py:260] loss = 25360667000.0, step = 18501 (0.303 sec)\n",
      "I0602 14:18:26.633656 17688 basic_session_run_hooks.py:692] global_step/sec: 313.337\n",
      "I0602 14:18:26.641636 17688 basic_session_run_hooks.py:260] loss = 33639186000.0, step = 18601 (0.323 sec)\n",
      "I0602 14:18:26.964769 17688 basic_session_run_hooks.py:692] global_step/sec: 302.923\n",
      "I0602 14:18:26.966765 17688 basic_session_run_hooks.py:260] loss = 21920178000.0, step = 18701 (0.326 sec)\n",
      "I0602 14:18:27.295916 17688 basic_session_run_hooks.py:692] global_step/sec: 301.075\n",
      "I0602 14:18:27.300872 17688 basic_session_run_hooks.py:260] loss = 37839270000.0, step = 18801 (0.334 sec)\n",
      "I0602 14:18:27.612041 17688 basic_session_run_hooks.py:692] global_step/sec: 316.331\n",
      "I0602 14:18:27.616028 17688 basic_session_run_hooks.py:260] loss = 35061390000.0, step = 18901 (0.315 sec)\n",
      "I0602 14:18:27.977071 17688 basic_session_run_hooks.py:692] global_step/sec: 273.95\n",
      "I0602 14:18:27.998018 17688 basic_session_run_hooks.py:260] loss = 24254489000.0, step = 19001 (0.382 sec)\n",
      "I0602 14:18:28.398936 17688 basic_session_run_hooks.py:692] global_step/sec: 237.043\n",
      "I0602 14:18:28.402924 17688 basic_session_run_hooks.py:260] loss = 23241224000.0, step = 19101 (0.405 sec)\n",
      "I0602 14:18:28.743016 17688 basic_session_run_hooks.py:692] global_step/sec: 290.63\n",
      "I0602 14:18:28.748002 17688 basic_session_run_hooks.py:260] loss = 32057180000.0, step = 19201 (0.345 sec)\n",
      "I0602 14:18:29.015287 17688 basic_session_run_hooks.py:692] global_step/sec: 367.281\n",
      "I0602 14:18:29.018279 17688 basic_session_run_hooks.py:260] loss = 28714226000.0, step = 19301 (0.270 sec)\n",
      "I0602 14:18:29.285565 17688 basic_session_run_hooks.py:692] global_step/sec: 369.99\n",
      "I0602 14:18:29.293543 17688 basic_session_run_hooks.py:260] loss = 29971048000.0, step = 19401 (0.275 sec)\n",
      "I0602 14:18:29.631641 17688 basic_session_run_hooks.py:692] global_step/sec: 288.954\n",
      "I0602 14:18:29.635629 17688 basic_session_run_hooks.py:260] loss = 38220490000.0, step = 19501 (0.342 sec)\n",
      "I0602 14:18:29.944802 17688 basic_session_run_hooks.py:692] global_step/sec: 319.324\n",
      "I0602 14:18:29.948791 17688 basic_session_run_hooks.py:260] loss = 35484496000.0, step = 19601 (0.313 sec)\n",
      "I0602 14:18:30.249987 17688 basic_session_run_hooks.py:692] global_step/sec: 328.746\n",
      "I0602 14:18:30.252005 17688 basic_session_run_hooks.py:260] loss = 23956216000.0, step = 19701 (0.303 sec)\n",
      "I0602 14:18:30.615011 17688 basic_session_run_hooks.py:692] global_step/sec: 273.207\n",
      "I0602 14:18:30.618003 17688 basic_session_run_hooks.py:260] loss = 25524933000.0, step = 19801 (0.366 sec)\n",
      "I0602 14:18:30.928173 17688 basic_session_run_hooks.py:692] global_step/sec: 319.323\n",
      "I0602 14:18:30.931165 17688 basic_session_run_hooks.py:260] loss = 27771589000.0, step = 19901 (0.313 sec)\n",
      "I0602 14:18:31.277240 17688 basic_session_run_hooks.py:692] global_step/sec: 287.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:18:31.282226 17688 basic_session_run_hooks.py:260] loss = 28103782000.0, step = 20001 (0.351 sec)\n",
      "I0602 14:18:32.001262 17688 basic_session_run_hooks.py:692] global_step/sec: 137.927\n",
      "I0602 14:18:32.007249 17688 basic_session_run_hooks.py:260] loss = 37672346000.0, step = 20101 (0.725 sec)\n",
      "I0602 14:18:32.282510 17688 basic_session_run_hooks.py:692] global_step/sec: 355.558\n",
      "I0602 14:18:32.290498 17688 basic_session_run_hooks.py:260] loss = 34181020000.0, step = 20201 (0.283 sec)\n",
      "I0602 14:18:32.663492 17688 basic_session_run_hooks.py:692] global_step/sec: 262.48\n",
      "I0602 14:18:32.667481 17688 basic_session_run_hooks.py:260] loss = 25988436000.0, step = 20301 (0.377 sec)\n",
      "I0602 14:18:32.984634 17688 basic_session_run_hooks.py:692] global_step/sec: 312.36\n",
      "I0602 14:18:32.989627 17688 basic_session_run_hooks.py:260] loss = 35064520000.0, step = 20401 (0.322 sec)\n",
      "I0602 14:18:33.663316 17688 basic_session_run_hooks.py:692] global_step/sec: 147.128\n",
      "I0602 14:18:33.666309 17688 basic_session_run_hooks.py:260] loss = 33649893000.0, step = 20501 (0.677 sec)\n",
      "I0602 14:18:33.965510 17688 basic_session_run_hooks.py:692] global_step/sec: 332.011\n",
      "I0602 14:18:33.968500 17688 basic_session_run_hooks.py:260] loss = 27985818000.0, step = 20601 (0.302 sec)\n",
      "I0602 14:18:34.243767 17688 basic_session_run_hooks.py:692] global_step/sec: 358.094\n",
      "I0602 14:18:34.247754 17688 basic_session_run_hooks.py:260] loss = 27243016000.0, step = 20701 (0.279 sec)\n",
      "I0602 14:18:34.531994 17688 basic_session_run_hooks.py:692] global_step/sec: 346.949\n",
      "I0602 14:18:34.535985 17688 basic_session_run_hooks.py:260] loss = 23831585000.0, step = 20801 (0.288 sec)\n",
      "I0602 14:18:34.816236 17688 basic_session_run_hooks.py:692] global_step/sec: 351.813\n",
      "I0602 14:18:34.819227 17688 basic_session_run_hooks.py:260] loss = 32810762000.0, step = 20901 (0.283 sec)\n",
      "I0602 14:18:35.100474 17688 basic_session_run_hooks.py:692] global_step/sec: 353.057\n",
      "I0602 14:18:35.104483 17688 basic_session_run_hooks.py:260] loss = 26714423000.0, step = 21001 (0.285 sec)\n",
      "I0602 14:18:35.416628 17688 basic_session_run_hooks.py:692] global_step/sec: 315.306\n",
      "I0602 14:18:35.421619 17688 basic_session_run_hooks.py:260] loss = 21985108000.0, step = 21101 (0.317 sec)\n",
      "I0602 14:18:35.742760 17688 basic_session_run_hooks.py:692] global_step/sec: 306.625\n",
      "I0602 14:18:35.746747 17688 basic_session_run_hooks.py:260] loss = 31893672000.0, step = 21201 (0.325 sec)\n",
      "I0602 14:18:36.047941 17688 basic_session_run_hooks.py:692] global_step/sec: 327.675\n",
      "I0602 14:18:36.051928 17688 basic_session_run_hooks.py:260] loss = 29203128000.0, step = 21301 (0.305 sec)\n",
      "I0602 14:18:36.381049 17688 basic_session_run_hooks.py:692] global_step/sec: 300.203\n",
      "I0602 14:18:36.386038 17688 basic_session_run_hooks.py:260] loss = 30893523000.0, step = 21401 (0.334 sec)\n",
      "I0602 14:18:36.689229 17688 basic_session_run_hooks.py:692] global_step/sec: 324.486\n",
      "I0602 14:18:36.695237 17688 basic_session_run_hooks.py:260] loss = 29081018000.0, step = 21501 (0.309 sec)\n",
      "I0602 14:18:37.018347 17688 basic_session_run_hooks.py:692] global_step/sec: 304.767\n",
      "I0602 14:18:37.027323 17688 basic_session_run_hooks.py:260] loss = 26052227000.0, step = 21601 (0.332 sec)\n",
      "I0602 14:18:37.382372 17688 basic_session_run_hooks.py:692] global_step/sec: 274.706\n",
      "I0602 14:18:37.385367 17688 basic_session_run_hooks.py:260] loss = 24054602000.0, step = 21701 (0.358 sec)\n",
      "I0602 14:18:37.964815 17688 basic_session_run_hooks.py:692] global_step/sec: 171.397\n",
      "I0602 14:18:37.966809 17688 basic_session_run_hooks.py:260] loss = 25539572000.0, step = 21801 (0.581 sec)\n",
      "I0602 14:18:38.297923 17688 basic_session_run_hooks.py:692] global_step/sec: 300.203\n",
      "I0602 14:18:38.299947 17688 basic_session_run_hooks.py:260] loss = 27300293000.0, step = 21901 (0.333 sec)\n",
      "I0602 14:18:38.598121 17688 basic_session_run_hooks.py:692] global_step/sec: 333.114\n",
      "I0602 14:18:38.601113 17688 basic_session_run_hooks.py:260] loss = 20136182000.0, step = 22001 (0.301 sec)\n",
      "I0602 14:18:38.876380 17688 basic_session_run_hooks.py:692] global_step/sec: 359.377\n",
      "I0602 14:18:38.880391 17688 basic_session_run_hooks.py:260] loss = 21147455000.0, step = 22101 (0.279 sec)\n",
      "I0602 14:18:39.180566 17688 basic_session_run_hooks.py:692] global_step/sec: 328.747\n",
      "I0602 14:18:39.183589 17688 basic_session_run_hooks.py:260] loss = 21771448000.0, step = 22201 (0.303 sec)\n",
      "I0602 14:18:39.469791 17688 basic_session_run_hooks.py:692] global_step/sec: 346.946\n",
      "I0602 14:18:39.477769 17688 basic_session_run_hooks.py:260] loss = 30817250000.0, step = 22301 (0.294 sec)\n",
      "I0602 14:18:39.780960 17688 basic_session_run_hooks.py:692] global_step/sec: 320.343\n",
      "I0602 14:18:39.783950 17688 basic_session_run_hooks.py:260] loss = 28087360000.0, step = 22401 (0.306 sec)\n",
      "I0602 14:18:40.080159 17688 basic_session_run_hooks.py:692] global_step/sec: 334.226\n",
      "I0602 14:18:40.084184 17688 basic_session_run_hooks.py:260] loss = 20465263000.0, step = 22501 (0.300 sec)\n",
      "I0602 14:18:40.393321 17688 basic_session_run_hooks.py:692] global_step/sec: 319.323\n",
      "I0602 14:18:40.397310 17688 basic_session_run_hooks.py:260] loss = 25621848000.0, step = 22601 (0.313 sec)\n",
      "I0602 14:18:40.728425 17688 basic_session_run_hooks.py:692] global_step/sec: 299.306\n",
      "I0602 14:18:40.731437 17688 basic_session_run_hooks.py:260] loss = 34446717000.0, step = 22701 (0.334 sec)\n",
      "I0602 14:18:41.043584 17688 basic_session_run_hooks.py:692] global_step/sec: 316.298\n",
      "I0602 14:18:41.047573 17688 basic_session_run_hooks.py:260] loss = 20734153000.0, step = 22801 (0.316 sec)\n",
      "I0602 14:18:41.351758 17688 basic_session_run_hooks.py:692] global_step/sec: 325.543\n",
      "I0602 14:18:41.359742 17688 basic_session_run_hooks.py:260] loss = 29472002000.0, step = 22901 (0.311 sec)\n",
      "I0602 14:18:41.645970 17688 basic_session_run_hooks.py:692] global_step/sec: 338.745\n",
      "I0602 14:18:41.649960 17688 basic_session_run_hooks.py:260] loss = 31811990000.0, step = 23001 (0.291 sec)\n",
      "I0602 14:18:41.932205 17688 basic_session_run_hooks.py:692] global_step/sec: 349.363\n",
      "I0602 14:18:41.935198 17688 basic_session_run_hooks.py:260] loss = 19648522000.0, step = 23101 (0.285 sec)\n",
      "I0602 14:18:42.302216 17688 basic_session_run_hooks.py:692] global_step/sec: 270.263\n",
      "I0602 14:18:42.312190 17688 basic_session_run_hooks.py:260] loss = 28993872000.0, step = 23201 (0.377 sec)\n",
      "I0602 14:18:42.644308 17688 basic_session_run_hooks.py:692] global_step/sec: 292.318\n",
      "I0602 14:18:42.647293 17688 basic_session_run_hooks.py:260] loss = 29891314000.0, step = 23301 (0.335 sec)\n",
      "I0602 14:18:42.917570 17688 basic_session_run_hooks.py:692] global_step/sec: 365.949\n",
      "I0602 14:18:42.921569 17688 basic_session_run_hooks.py:260] loss = 23985201000.0, step = 23401 (0.274 sec)\n",
      "I0602 14:18:43.247688 17688 basic_session_run_hooks.py:692] global_step/sec: 302.922\n",
      "I0602 14:18:43.250680 17688 basic_session_run_hooks.py:260] loss = 31404980000.0, step = 23501 (0.329 sec)\n",
      "I0602 14:18:43.594761 17688 basic_session_run_hooks.py:692] global_step/sec: 288.124\n",
      "I0602 14:18:43.597751 17688 basic_session_run_hooks.py:260] loss = 23585149000.0, step = 23601 (0.347 sec)\n",
      "I0602 14:18:43.864041 17688 basic_session_run_hooks.py:692] global_step/sec: 372.742\n",
      "I0602 14:18:43.867032 17688 basic_session_run_hooks.py:260] loss = 26029838000.0, step = 23701 (0.269 sec)\n",
      "I0602 14:18:44.166231 17688 basic_session_run_hooks.py:692] global_step/sec: 329.828\n",
      "I0602 14:18:44.169224 17688 basic_session_run_hooks.py:260] loss = 22704083000.0, step = 23801 (0.302 sec)\n",
      "I0602 14:18:44.459449 17688 basic_session_run_hooks.py:692] global_step/sec: 341.044\n",
      "I0602 14:18:44.463446 17688 basic_session_run_hooks.py:260] loss = 33477143000.0, step = 23901 (0.294 sec)\n",
      "I0602 14:18:44.750670 17688 basic_session_run_hooks.py:692] global_step/sec: 343.381\n",
      "I0602 14:18:44.752663 17688 basic_session_run_hooks.py:260] loss = 31665598000.0, step = 24001 (0.289 sec)\n",
      "I0602 14:18:45.061839 17688 basic_session_run_hooks.py:692] global_step/sec: 322.404\n",
      "I0602 14:18:45.065828 17688 basic_session_run_hooks.py:260] loss = 33878178000.0, step = 24101 (0.312 sec)\n",
      "I0602 14:18:45.349070 17688 basic_session_run_hooks.py:692] global_step/sec: 346.946\n",
      "I0602 14:18:45.353059 17688 basic_session_run_hooks.py:260] loss = 32913424000.0, step = 24201 (0.288 sec)\n",
      "I0602 14:18:45.634356 17688 basic_session_run_hooks.py:692] global_step/sec: 350.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:18:45.639300 17688 basic_session_run_hooks.py:260] loss = 24321536000.0, step = 24301 (0.286 sec)\n",
      "I0602 14:18:45.935500 17688 basic_session_run_hooks.py:692] global_step/sec: 332.067\n",
      "I0602 14:18:45.944479 17688 basic_session_run_hooks.py:260] loss = 27071185000.0, step = 24401 (0.305 sec)\n",
      "I0602 14:18:46.272614 17688 basic_session_run_hooks.py:692] global_step/sec: 297.522\n",
      "I0602 14:18:46.279581 17688 basic_session_run_hooks.py:260] loss = 26384409000.0, step = 24501 (0.335 sec)\n",
      "I0602 14:18:46.576786 17688 basic_session_run_hooks.py:692] global_step/sec: 327.679\n",
      "I0602 14:18:46.582771 17688 basic_session_run_hooks.py:260] loss = 24683080000.0, step = 24601 (0.303 sec)\n",
      "I0602 14:18:46.882967 17688 basic_session_run_hooks.py:692] global_step/sec: 326.603\n",
      "I0602 14:18:46.886960 17688 basic_session_run_hooks.py:260] loss = 24440887000.0, step = 24701 (0.304 sec)\n",
      "I0602 14:18:47.199150 17688 basic_session_run_hooks.py:692] global_step/sec: 316.273\n",
      "I0602 14:18:47.201116 17688 basic_session_run_hooks.py:260] loss = 24269510000.0, step = 24801 (0.314 sec)\n",
      "I0602 14:18:47.480372 17688 basic_session_run_hooks.py:692] global_step/sec: 356.86\n",
      "I0602 14:18:47.482365 17688 basic_session_run_hooks.py:260] loss = 27914912000.0, step = 24901 (0.281 sec)\n",
      "I0602 14:18:47.766605 17688 basic_session_run_hooks.py:692] global_step/sec: 348.149\n",
      "I0602 14:18:47.769598 17688 basic_session_run_hooks.py:260] loss = 30483616000.0, step = 25001 (0.287 sec)\n",
      "I0602 14:18:48.042868 17688 basic_session_run_hooks.py:692] global_step/sec: 363.283\n",
      "I0602 14:18:48.047852 17688 basic_session_run_hooks.py:260] loss = 17265535000.0, step = 25101 (0.278 sec)\n",
      "I0602 14:18:48.318130 17688 basic_session_run_hooks.py:692] global_step/sec: 361.982\n",
      "I0602 14:18:48.328104 17688 basic_session_run_hooks.py:260] loss = 26115897000.0, step = 25201 (0.279 sec)\n",
      "I0602 14:18:48.637282 17688 basic_session_run_hooks.py:692] global_step/sec: 314.317\n",
      "I0602 14:18:48.647249 17688 basic_session_run_hooks.py:260] loss = 24439454000.0, step = 25301 (0.320 sec)\n",
      "I0602 14:18:48.928499 17688 basic_session_run_hooks.py:692] global_step/sec: 342.209\n",
      "I0602 14:18:48.931489 17688 basic_session_run_hooks.py:260] loss = 27415718000.0, step = 25401 (0.284 sec)\n",
      "I0602 14:18:49.237706 17688 basic_session_run_hooks.py:692] global_step/sec: 324.483\n",
      "I0602 14:18:49.245649 17688 basic_session_run_hooks.py:260] loss = 28148010000.0, step = 25501 (0.314 sec)\n",
      "I0602 14:18:49.521922 17688 basic_session_run_hooks.py:692] global_step/sec: 351.822\n",
      "I0602 14:18:49.531886 17688 basic_session_run_hooks.py:260] loss = 33645373000.0, step = 25601 (0.286 sec)\n",
      "I0602 14:18:49.846044 17688 basic_session_run_hooks.py:692] global_step/sec: 307.571\n",
      "I0602 14:18:49.850033 17688 basic_session_run_hooks.py:260] loss = 19581710000.0, step = 25701 (0.318 sec)\n",
      "I0602 14:18:50.196110 17688 basic_session_run_hooks.py:692] global_step/sec: 286.478\n",
      "I0602 14:18:50.198134 17688 basic_session_run_hooks.py:260] loss = 28040464000.0, step = 25801 (0.348 sec)\n",
      "I0602 14:18:50.520243 17688 basic_session_run_hooks.py:692] global_step/sec: 308.516\n",
      "I0602 14:18:50.528220 17688 basic_session_run_hooks.py:260] loss = 25685352000.0, step = 25901 (0.330 sec)\n",
      "I0602 14:18:51.249134 17688 basic_session_run_hooks.py:692] global_step/sec: 137.007\n",
      "I0602 14:18:51.252127 17688 basic_session_run_hooks.py:260] loss = 21615043000.0, step = 26001 (0.724 sec)\n",
      "I0602 14:18:51.628122 17688 basic_session_run_hooks.py:692] global_step/sec: 263.861\n",
      "I0602 14:18:51.635102 17688 basic_session_run_hooks.py:260] loss = 31655420000.0, step = 26101 (0.383 sec)\n",
      "I0602 14:18:52.032043 17688 basic_session_run_hooks.py:692] global_step/sec: 247.573\n",
      "I0602 14:18:52.036032 17688 basic_session_run_hooks.py:260] loss = 23661982000.0, step = 26201 (0.401 sec)\n",
      "I0602 14:18:52.375126 17688 basic_session_run_hooks.py:692] global_step/sec: 292.316\n",
      "I0602 14:18:52.382106 17688 basic_session_run_hooks.py:260] loss = 29502218000.0, step = 26301 (0.346 sec)\n",
      "I0602 14:18:52.680309 17688 basic_session_run_hooks.py:692] global_step/sec: 326.616\n",
      "I0602 14:18:52.684299 17688 basic_session_run_hooks.py:260] loss = 29381902000.0, step = 26401 (0.302 sec)\n",
      "I0602 14:18:53.381094 17688 basic_session_run_hooks.py:692] global_step/sec: 142.697\n",
      "I0602 14:18:53.385081 17688 basic_session_run_hooks.py:260] loss = 22083017000.0, step = 26501 (0.701 sec)\n",
      "I0602 14:18:53.772070 17688 basic_session_run_hooks.py:692] global_step/sec: 257.095\n",
      "I0602 14:18:53.794001 17688 basic_session_run_hooks.py:260] loss = 39519020000.0, step = 26601 (0.409 sec)\n",
      "I0602 14:18:54.348283 17688 basic_session_run_hooks.py:692] global_step/sec: 173.242\n",
      "I0602 14:18:54.350276 17688 basic_session_run_hooks.py:260] loss = 20093194000.0, step = 26701 (0.556 sec)\n",
      "I0602 14:18:54.622554 17688 basic_session_run_hooks.py:692] global_step/sec: 363.28\n",
      "I0602 14:18:54.628532 17688 basic_session_run_hooks.py:260] loss = 26152663000.0, step = 26801 (0.278 sec)\n",
      "I0602 14:18:54.898811 17688 basic_session_run_hooks.py:692] global_step/sec: 361.982\n",
      "I0602 14:18:54.902799 17688 basic_session_run_hooks.py:260] loss = 22005527000.0, step = 26901 (0.274 sec)\n",
      "I0602 14:18:55.201999 17688 basic_session_run_hooks.py:692] global_step/sec: 329.829\n",
      "I0602 14:18:55.209980 17688 basic_session_run_hooks.py:260] loss = 22390065000.0, step = 27001 (0.307 sec)\n",
      "I0602 14:18:55.531121 17688 basic_session_run_hooks.py:692] global_step/sec: 303.838\n",
      "I0602 14:18:55.535108 17688 basic_session_run_hooks.py:260] loss = 28242588000.0, step = 27101 (0.325 sec)\n",
      "I0602 14:18:55.829323 17688 basic_session_run_hooks.py:692] global_step/sec: 335.344\n",
      "I0602 14:18:55.833311 17688 basic_session_run_hooks.py:260] loss = 29697694000.0, step = 27201 (0.298 sec)\n",
      "I0602 14:18:56.215290 17688 basic_session_run_hooks.py:692] global_step/sec: 259.09\n",
      "I0602 14:18:56.217284 17688 basic_session_run_hooks.py:260] loss = 26133869000.0, step = 27301 (0.384 sec)\n",
      "I0602 14:18:56.531444 17688 basic_session_run_hooks.py:692] global_step/sec: 316.301\n",
      "I0602 14:18:56.534436 17688 basic_session_run_hooks.py:260] loss = 25671946000.0, step = 27401 (0.317 sec)\n",
      "I0602 14:18:56.931375 17688 basic_session_run_hooks.py:692] global_step/sec: 250.668\n",
      "I0602 14:18:56.933369 17688 basic_session_run_hooks.py:260] loss = 26213816000.0, step = 27501 (0.399 sec)\n",
      "I0602 14:18:57.297395 17688 basic_session_run_hooks.py:692] global_step/sec: 272.467\n",
      "I0602 14:18:57.300387 17688 basic_session_run_hooks.py:260] loss = 20341830000.0, step = 27601 (0.367 sec)\n",
      "I0602 14:18:57.629508 17688 basic_session_run_hooks.py:692] global_step/sec: 301.103\n",
      "I0602 14:18:57.633497 17688 basic_session_run_hooks.py:260] loss = 28692756000.0, step = 27701 (0.333 sec)\n",
      "I0602 14:18:57.951646 17688 basic_session_run_hooks.py:692] global_step/sec: 310.425\n",
      "I0602 14:18:57.958638 17688 basic_session_run_hooks.py:260] loss = 23295025000.0, step = 27801 (0.325 sec)\n",
      "I0602 14:18:58.289747 17688 basic_session_run_hooks.py:692] global_step/sec: 295.77\n",
      "I0602 14:18:58.294764 17688 basic_session_run_hooks.py:260] loss = 18072950000.0, step = 27901 (0.336 sec)\n",
      "I0602 14:18:58.599915 17688 basic_session_run_hooks.py:692] global_step/sec: 322.406\n",
      "I0602 14:18:58.601907 17688 basic_session_run_hooks.py:260] loss = 29812713000.0, step = 28001 (0.307 sec)\n",
      "I0602 14:18:58.919061 17688 basic_session_run_hooks.py:692] global_step/sec: 313.336\n",
      "I0602 14:18:58.926045 17688 basic_session_run_hooks.py:260] loss = 27659647000.0, step = 28101 (0.324 sec)\n",
      "I0602 14:18:59.213273 17688 basic_session_run_hooks.py:692] global_step/sec: 339.891\n",
      "I0602 14:18:59.217264 17688 basic_session_run_hooks.py:260] loss = 21880078000.0, step = 28201 (0.291 sec)\n",
      "I0602 14:18:59.492567 17688 basic_session_run_hooks.py:692] global_step/sec: 358.046\n",
      "I0602 14:18:59.497515 17688 basic_session_run_hooks.py:260] loss = 27715117000.0, step = 28301 (0.280 sec)\n",
      "I0602 14:18:59.787744 17688 basic_session_run_hooks.py:692] global_step/sec: 339.936\n",
      "I0602 14:18:59.795717 17688 basic_session_run_hooks.py:260] loss = 36977810000.0, step = 28401 (0.298 sec)\n",
      "I0602 14:19:00.111870 17688 basic_session_run_hooks.py:692] global_step/sec: 308.516\n",
      "I0602 14:19:00.114861 17688 basic_session_run_hooks.py:260] loss = 31977173000.0, step = 28501 (0.319 sec)\n",
      "I0602 14:19:00.561674 17688 basic_session_run_hooks.py:692] global_step/sec: 222.316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:19:00.565659 17688 basic_session_run_hooks.py:260] loss = 22031884000.0, step = 28601 (0.451 sec)\n",
      "I0602 14:19:00.877826 17688 basic_session_run_hooks.py:692] global_step/sec: 315.314\n",
      "I0602 14:19:00.882811 17688 basic_session_run_hooks.py:260] loss = 31680170000.0, step = 28701 (0.317 sec)\n",
      "I0602 14:19:01.194975 17688 basic_session_run_hooks.py:692] global_step/sec: 316.305\n",
      "I0602 14:19:01.197966 17688 basic_session_run_hooks.py:260] loss = 21188506000.0, step = 28801 (0.315 sec)\n",
      "I0602 14:19:01.469240 17688 basic_session_run_hooks.py:692] global_step/sec: 363.289\n",
      "I0602 14:19:01.479214 17688 basic_session_run_hooks.py:260] loss = 31253957000.0, step = 28901 (0.281 sec)\n",
      "I0602 14:19:01.783402 17688 basic_session_run_hooks.py:692] global_step/sec: 318.307\n",
      "I0602 14:19:01.786394 17688 basic_session_run_hooks.py:260] loss = 32182735000.0, step = 29001 (0.307 sec)\n",
      "I0602 14:19:02.069635 17688 basic_session_run_hooks.py:692] global_step/sec: 350.546\n",
      "I0602 14:19:02.075631 17688 basic_session_run_hooks.py:260] loss = 16534217000.0, step = 29101 (0.289 sec)\n",
      "I0602 14:19:02.382832 17688 basic_session_run_hooks.py:692] global_step/sec: 318.309\n",
      "I0602 14:19:02.388786 17688 basic_session_run_hooks.py:260] loss = 30208090000.0, step = 29201 (0.313 sec)\n",
      "I0602 14:19:02.697957 17688 basic_session_run_hooks.py:692] global_step/sec: 317.334\n",
      "I0602 14:19:02.699951 17688 basic_session_run_hooks.py:260] loss = 28249694000.0, step = 29301 (0.311 sec)\n",
      "I0602 14:19:03.000147 17688 basic_session_run_hooks.py:692] global_step/sec: 330.917\n",
      "I0602 14:19:03.004141 17688 basic_session_run_hooks.py:260] loss = 28433310000.0, step = 29401 (0.303 sec)\n",
      "I0602 14:19:03.315304 17688 basic_session_run_hooks.py:692] global_step/sec: 318.31\n",
      "I0602 14:19:03.319293 17688 basic_session_run_hooks.py:260] loss = 30252052000.0, step = 29501 (0.316 sec)\n",
      "I0602 14:19:03.627472 17688 basic_session_run_hooks.py:692] global_step/sec: 319.319\n",
      "I0602 14:19:03.631458 17688 basic_session_run_hooks.py:260] loss = 23803429000.0, step = 29601 (0.312 sec)\n",
      "I0602 14:19:03.927669 17688 basic_session_run_hooks.py:692] global_step/sec: 333.116\n",
      "I0602 14:19:03.930660 17688 basic_session_run_hooks.py:260] loss = 27708936000.0, step = 29701 (0.299 sec)\n",
      "I0602 14:19:04.207953 17688 basic_session_run_hooks.py:692] global_step/sec: 356.781\n",
      "I0602 14:19:04.212903 17688 basic_session_run_hooks.py:260] loss = 25146650000.0, step = 29801 (0.282 sec)\n",
      "I0602 14:19:04.544020 17688 basic_session_run_hooks.py:692] global_step/sec: 297.56\n",
      "I0602 14:19:04.549006 17688 basic_session_run_hooks.py:260] loss = 24492569000.0, step = 29901 (0.336 sec)\n",
      "I0602 14:19:04.884109 17688 basic_session_run_hooks.py:692] global_step/sec: 294.041\n",
      "I0602 14:19:04.894092 17688 basic_session_run_hooks.py:260] loss = 30549600000.0, step = 30001 (0.345 sec)\n",
      "I0602 14:19:05.235170 17688 basic_session_run_hooks.py:692] global_step/sec: 284.851\n",
      "I0602 14:19:05.244148 17688 basic_session_run_hooks.py:260] loss = 34060500000.0, step = 30101 (0.350 sec)\n",
      "I0602 14:19:05.566286 17688 basic_session_run_hooks.py:692] global_step/sec: 302.009\n",
      "I0602 14:19:05.574278 17688 basic_session_run_hooks.py:260] loss = 30709268000.0, step = 30201 (0.330 sec)\n",
      "I0602 14:19:05.910371 17688 basic_session_run_hooks.py:692] global_step/sec: 291.473\n",
      "I0602 14:19:05.914356 17688 basic_session_run_hooks.py:260] loss = 29876191000.0, step = 30301 (0.340 sec)\n",
      "I0602 14:19:06.227517 17688 basic_session_run_hooks.py:692] global_step/sec: 314.321\n",
      "I0602 14:19:06.230511 17688 basic_session_run_hooks.py:260] loss = 31716643000.0, step = 30401 (0.316 sec)\n",
      "I0602 14:19:06.516743 17688 basic_session_run_hooks.py:692] global_step/sec: 346.946\n",
      "I0602 14:19:06.518738 17688 basic_session_run_hooks.py:260] loss = 34693018000.0, step = 30501 (0.288 sec)\n",
      "I0602 14:19:06.841892 17688 basic_session_run_hooks.py:692] global_step/sec: 306.611\n",
      "I0602 14:19:06.846894 17688 basic_session_run_hooks.py:260] loss = 35351970000.0, step = 30601 (0.328 sec)\n",
      "I0602 14:19:07.150099 17688 basic_session_run_hooks.py:692] global_step/sec: 325.561\n",
      "I0602 14:19:07.162023 17688 basic_session_run_hooks.py:260] loss = 30034506000.0, step = 30701 (0.315 sec)\n",
      "I0602 14:19:07.442305 17688 basic_session_run_hooks.py:692] global_step/sec: 341.006\n",
      "I0602 14:19:07.450251 17688 basic_session_run_hooks.py:260] loss = 24680710000.0, step = 30801 (0.288 sec)\n",
      "I0602 14:19:07.735492 17688 basic_session_run_hooks.py:692] global_step/sec: 341.079\n",
      "I0602 14:19:07.749460 17688 basic_session_run_hooks.py:260] loss = 20937791000.0, step = 30901 (0.299 sec)\n",
      "I0602 14:19:08.132425 17688 basic_session_run_hooks.py:692] global_step/sec: 251.932\n",
      "I0602 14:19:08.140406 17688 basic_session_run_hooks.py:260] loss = 29992937000.0, step = 31001 (0.391 sec)\n",
      "I0602 14:19:08.532355 17688 basic_session_run_hooks.py:692] global_step/sec: 250.043\n",
      "I0602 14:19:08.535379 17688 basic_session_run_hooks.py:260] loss = 33231438000.0, step = 31101 (0.395 sec)\n",
      "I0602 14:19:08.847511 17688 basic_session_run_hooks.py:692] global_step/sec: 317.303\n",
      "I0602 14:19:08.851502 17688 basic_session_run_hooks.py:260] loss = 28312540000.0, step = 31201 (0.316 sec)\n",
      "I0602 14:19:09.134745 17688 basic_session_run_hooks.py:692] global_step/sec: 349.364\n",
      "I0602 14:19:09.137741 17688 basic_session_run_hooks.py:260] loss = 25794118000.0, step = 31301 (0.286 sec)\n",
      "I0602 14:19:09.404033 17688 basic_session_run_hooks.py:692] global_step/sec: 371.358\n",
      "I0602 14:19:09.411005 17688 basic_session_run_hooks.py:260] loss = 25263225000.0, step = 31401 (0.273 sec)\n",
      "I0602 14:19:09.719180 17688 basic_session_run_hooks.py:692] global_step/sec: 317.302\n",
      "I0602 14:19:09.727160 17688 basic_session_run_hooks.py:260] loss = 27783131000.0, step = 31501 (0.316 sec)\n",
      "I0602 14:19:10.002422 17688 basic_session_run_hooks.py:692] global_step/sec: 351.817\n",
      "I0602 14:19:10.010438 17688 basic_session_run_hooks.py:260] loss = 30119719000.0, step = 31601 (0.283 sec)\n",
      "I0602 14:19:10.291655 17688 basic_session_run_hooks.py:692] global_step/sec: 345.742\n",
      "I0602 14:19:10.296638 17688 basic_session_run_hooks.py:260] loss = 27662563000.0, step = 31701 (0.286 sec)\n",
      "I0602 14:19:10.552953 17688 basic_session_run_hooks.py:692] global_step/sec: 382.706\n",
      "I0602 14:19:10.560932 17688 basic_session_run_hooks.py:260] loss = 27320277000.0, step = 31801 (0.264 sec)\n",
      "I0602 14:19:10.865116 17688 basic_session_run_hooks.py:692] global_step/sec: 320.346\n",
      "I0602 14:19:10.867110 17688 basic_session_run_hooks.py:260] loss = 25933120000.0, step = 31901 (0.306 sec)\n",
      "I0602 14:19:11.205259 17688 basic_session_run_hooks.py:692] global_step/sec: 293.994\n",
      "I0602 14:19:11.211191 17688 basic_session_run_hooks.py:260] loss = 26783260000.0, step = 32001 (0.344 sec)\n",
      "I0602 14:19:11.512399 17688 basic_session_run_hooks.py:692] global_step/sec: 325.584\n",
      "I0602 14:19:11.516374 17688 basic_session_run_hooks.py:260] loss = 30029100000.0, step = 32101 (0.305 sec)\n",
      "I0602 14:19:11.817599 17688 basic_session_run_hooks.py:692] global_step/sec: 327.654\n",
      "I0602 14:19:11.827545 17688 basic_session_run_hooks.py:260] loss = 27440210000.0, step = 32201 (0.311 sec)\n",
      "I0602 14:19:12.158661 17688 basic_session_run_hooks.py:692] global_step/sec: 293.202\n",
      "I0602 14:19:12.165641 17688 basic_session_run_hooks.py:260] loss = 14990089000.0, step = 32301 (0.338 sec)\n",
      "I0602 14:19:12.476806 17688 basic_session_run_hooks.py:692] global_step/sec: 314.322\n",
      "I0602 14:19:12.480795 17688 basic_session_run_hooks.py:260] loss = 29217667000.0, step = 32401 (0.315 sec)\n",
      "I0602 14:19:12.759057 17688 basic_session_run_hooks.py:692] global_step/sec: 354.296\n",
      "I0602 14:19:12.763041 17688 basic_session_run_hooks.py:260] loss = 28692726000.0, step = 32501 (0.282 sec)\n",
      "I0602 14:19:13.051271 17688 basic_session_run_hooks.py:692] global_step/sec: 342.214\n",
      "I0602 14:19:13.058260 17688 basic_session_run_hooks.py:260] loss = 23771843000.0, step = 32601 (0.294 sec)\n",
      "I0602 14:19:13.348477 17688 basic_session_run_hooks.py:692] global_step/sec: 336.467\n",
      "I0602 14:19:13.351468 17688 basic_session_run_hooks.py:260] loss = 24962212000.0, step = 32701 (0.294 sec)\n",
      "I0602 14:19:13.633714 17688 basic_session_run_hooks.py:692] global_step/sec: 350.585\n",
      "I0602 14:19:13.638746 17688 basic_session_run_hooks.py:260] loss = 23908905000.0, step = 32801 (0.287 sec)\n",
      "I0602 14:19:13.933912 17688 basic_session_run_hooks.py:692] global_step/sec: 334.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:19:13.935905 17688 basic_session_run_hooks.py:260] loss = 26691777000.0, step = 32901 (0.297 sec)\n",
      "I0602 14:19:14.219149 17688 basic_session_run_hooks.py:692] global_step/sec: 350.586\n",
      "I0602 14:19:14.226131 17688 basic_session_run_hooks.py:260] loss = 23631815000.0, step = 33001 (0.290 sec)\n",
      "I0602 14:19:14.519346 17688 basic_session_run_hooks.py:692] global_step/sec: 333.113\n",
      "I0602 14:19:14.527344 17688 basic_session_run_hooks.py:260] loss = 24923701000.0, step = 33101 (0.301 sec)\n",
      "I0602 14:19:14.814557 17688 basic_session_run_hooks.py:692] global_step/sec: 338.742\n",
      "I0602 14:19:14.816550 17688 basic_session_run_hooks.py:260] loss = 18422260000.0, step = 33201 (0.289 sec)\n",
      "I0602 14:19:15.098796 17688 basic_session_run_hooks.py:692] global_step/sec: 350.584\n",
      "I0602 14:19:15.101786 17688 basic_session_run_hooks.py:260] loss = 23116386000.0, step = 33301 (0.285 sec)\n",
      "I0602 14:19:15.387066 17688 basic_session_run_hooks.py:692] global_step/sec: 348.152\n",
      "I0602 14:19:15.396998 17688 basic_session_run_hooks.py:260] loss = 26947797000.0, step = 33401 (0.295 sec)\n",
      "I0602 14:19:15.671295 17688 basic_session_run_hooks.py:692] global_step/sec: 351.807\n",
      "I0602 14:19:15.678246 17688 basic_session_run_hooks.py:260] loss = 28646638000.0, step = 33501 (0.281 sec)\n",
      "I0602 14:19:15.967474 17688 basic_session_run_hooks.py:692] global_step/sec: 337.608\n",
      "I0602 14:19:15.973472 17688 basic_session_run_hooks.py:260] loss = 32595976000.0, step = 33601 (0.295 sec)\n",
      "I0602 14:19:16.248721 17688 basic_session_run_hooks.py:692] global_step/sec: 354.3\n",
      "I0602 14:19:16.252711 17688 basic_session_run_hooks.py:260] loss = 23038927000.0, step = 33701 (0.278 sec)\n",
      "I0602 14:19:16.531965 17688 basic_session_run_hooks.py:692] global_step/sec: 353.054\n",
      "I0602 14:19:16.534988 17688 basic_session_run_hooks.py:260] loss = 21965523000.0, step = 33801 (0.283 sec)\n",
      "I0602 14:19:16.832162 17688 basic_session_run_hooks.py:692] global_step/sec: 334.227\n",
      "I0602 14:19:16.835155 17688 basic_session_run_hooks.py:260] loss = 23846498000.0, step = 33901 (0.300 sec)\n",
      "I0602 14:19:17.142338 17688 basic_session_run_hooks.py:692] global_step/sec: 321.361\n",
      "I0602 14:19:17.145323 17688 basic_session_run_hooks.py:260] loss = 28878539000.0, step = 34001 (0.310 sec)\n",
      "I0602 14:19:17.487416 17688 basic_session_run_hooks.py:692] global_step/sec: 290.635\n",
      "I0602 14:19:17.494390 17688 basic_session_run_hooks.py:260] loss = 21513755000.0, step = 34101 (0.349 sec)\n",
      "I0602 14:19:17.810545 17688 basic_session_run_hooks.py:692] global_step/sec: 308.515\n",
      "I0602 14:19:17.813535 17688 basic_session_run_hooks.py:260] loss = 24299311000.0, step = 34201 (0.319 sec)\n",
      "I0602 14:19:18.102762 17688 basic_session_run_hooks.py:692] global_step/sec: 342.212\n",
      "I0602 14:19:18.112736 17688 basic_session_run_hooks.py:260] loss = 28082240000.0, step = 34301 (0.299 sec)\n",
      "I0602 14:19:18.415926 17688 basic_session_run_hooks.py:692] global_step/sec: 320.343\n",
      "I0602 14:19:18.418920 17688 basic_session_run_hooks.py:260] loss = 23847490000.0, step = 34401 (0.306 sec)\n",
      "I0602 14:19:18.743057 17688 basic_session_run_hooks.py:692] global_step/sec: 304.758\n",
      "I0602 14:19:18.746044 17688 basic_session_run_hooks.py:260] loss = 33694978000.0, step = 34501 (0.327 sec)\n",
      "I0602 14:19:19.213792 17688 basic_session_run_hooks.py:692] global_step/sec: 212.434\n",
      "I0602 14:19:19.216784 17688 basic_session_run_hooks.py:260] loss = 25402430000.0, step = 34601 (0.470 sec)\n",
      "I0602 14:19:19.492052 17688 basic_session_run_hooks.py:692] global_step/sec: 359.377\n",
      "I0602 14:19:19.498031 17688 basic_session_run_hooks.py:260] loss = 26492359000.0, step = 34701 (0.282 sec)\n",
      "I0602 14:19:19.800223 17688 basic_session_run_hooks.py:692] global_step/sec: 325.548\n",
      "I0602 14:19:19.804267 17688 basic_session_run_hooks.py:260] loss = 29438579000.0, step = 34801 (0.306 sec)\n",
      "I0602 14:19:20.135329 17688 basic_session_run_hooks.py:692] global_step/sec: 297.527\n",
      "I0602 14:19:20.145331 17688 basic_session_run_hooks.py:260] loss = 31649956000.0, step = 34901 (0.341 sec)\n",
      "I0602 14:19:20.463451 17688 basic_session_run_hooks.py:692] global_step/sec: 304.765\n",
      "I0602 14:19:20.466480 17688 basic_session_run_hooks.py:260] loss = 39582024000.0, step = 35001 (0.321 sec)\n",
      "I0602 14:19:21.234735 17688 basic_session_run_hooks.py:692] global_step/sec: 129.99\n",
      "I0602 14:19:21.254678 17688 basic_session_run_hooks.py:260] loss = 31672392000.0, step = 35101 (0.788 sec)\n",
      "I0602 14:19:22.198785 17688 basic_session_run_hooks.py:692] global_step/sec: 103.515\n",
      "I0602 14:19:22.200780 17688 basic_session_run_hooks.py:260] loss = 23523164000.0, step = 35201 (0.946 sec)\n",
      "I0602 14:19:22.510951 17688 basic_session_run_hooks.py:692] global_step/sec: 320.342\n",
      "I0602 14:19:22.512945 17688 basic_session_run_hooks.py:260] loss = 31745622000.0, step = 35301 (0.312 sec)\n",
      "I0602 14:19:22.817131 17688 basic_session_run_hooks.py:692] global_step/sec: 326.605\n",
      "I0602 14:19:22.821130 17688 basic_session_run_hooks.py:260] loss = 24758640000.0, step = 35401 (0.308 sec)\n",
      "I0602 14:19:23.512882 17688 basic_session_run_hooks.py:692] global_step/sec: 143.73\n",
      "I0602 14:19:23.516872 17688 basic_session_run_hooks.py:260] loss = 32343216000.0, step = 35501 (0.696 sec)\n",
      "I0602 14:19:23.803106 17688 basic_session_run_hooks.py:692] global_step/sec: 344.561\n",
      "I0602 14:19:23.811085 17688 basic_session_run_hooks.py:260] loss = 28223844000.0, step = 35601 (0.294 sec)\n",
      "I0602 14:19:24.119259 17688 basic_session_run_hooks.py:692] global_step/sec: 317.302\n",
      "I0602 14:19:24.128237 17688 basic_session_run_hooks.py:260] loss = 31703040000.0, step = 35701 (0.317 sec)\n",
      "I0602 14:19:24.417464 17688 basic_session_run_hooks.py:692] global_step/sec: 335.341\n",
      "I0602 14:19:24.424456 17688 basic_session_run_hooks.py:260] loss = 26708710000.0, step = 35801 (0.296 sec)\n",
      "I0602 14:19:24.750573 17688 basic_session_run_hooks.py:692] global_step/sec: 299.305\n",
      "I0602 14:19:24.755609 17688 basic_session_run_hooks.py:260] loss = 16673628000.0, step = 35901 (0.331 sec)\n",
      "I0602 14:19:25.081686 17688 basic_session_run_hooks.py:692] global_step/sec: 302.012\n",
      "I0602 14:19:25.085675 17688 basic_session_run_hooks.py:260] loss = 24023177000.0, step = 36001 (0.330 sec)\n",
      "I0602 14:19:25.420789 17688 basic_session_run_hooks.py:692] global_step/sec: 295.774\n",
      "I0602 14:19:25.429757 17688 basic_session_run_hooks.py:260] loss = 23958622000.0, step = 36101 (0.344 sec)\n",
      "I0602 14:19:25.733944 17688 basic_session_run_hooks.py:692] global_step/sec: 319.323\n",
      "I0602 14:19:25.739938 17688 basic_session_run_hooks.py:260] loss = 24591050000.0, step = 36201 (0.310 sec)\n",
      "I0602 14:19:26.064061 17688 basic_session_run_hooks.py:692] global_step/sec: 302.923\n",
      "I0602 14:19:26.068049 17688 basic_session_run_hooks.py:260] loss = 22852493000.0, step = 36301 (0.328 sec)\n",
      "I0602 14:19:26.363260 17688 basic_session_run_hooks.py:692] global_step/sec: 333.112\n",
      "I0602 14:19:26.367250 17688 basic_session_run_hooks.py:260] loss = 28011012000.0, step = 36401 (0.299 sec)\n",
      "I0602 14:19:26.668444 17688 basic_session_run_hooks.py:692] global_step/sec: 327.671\n",
      "I0602 14:19:26.677425 17688 basic_session_run_hooks.py:260] loss = 23074836000.0, step = 36501 (0.310 sec)\n",
      "I0602 14:19:26.928779 17688 basic_session_run_hooks.py:606] Saving checkpoints for 36563 into C:\\Users\\LENOVO\\AppData\\Local\\Temp\\tmpszmaf8za\\model.ckpt.\n",
      "I0602 14:19:27.967969 17688 estimator.py:368] Loss for final step: 9214477000.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressor at 0x1f8e3cc0548>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.train(input_fn=input_func, steps=5000)\n",
    "model.train(input_fn=input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_input_func = tf.estimator.inputs.pandas_input_fn(X_test,\n",
    "                                                     shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:19:46.652038 17688 estimator.py:1145] Calling model_fn.\n",
      "I0602 14:19:47.262402 17688 estimator.py:1147] Done calling model_fn.\n",
      "I0602 14:19:47.440948 17688 monitored_session.py:240] Graph was finalized.\n",
      "W0602 14:19:47.443892 17688 deprecation.py:323] From C:\\Users\\LENOVO\\Anaconda3\\envs\\fhadli\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I0602 14:19:47.448877 17688 saver.py:1280] Restoring parameters from C:\\Users\\LENOVO\\AppData\\Local\\Temp\\tmpszmaf8za\\model.ckpt-36563\n",
      "I0602 14:19:47.566595 17688 session_manager.py:500] Running local_init_op.\n",
      "I0602 14:19:47.580526 17688 session_manager.py:502] Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "reg_prediction = []\n",
    "\n",
    "for pred in model.predict(input_fn=pred_input_func):\n",
    "    reg_prediction.append(pred['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.393047797280456"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_result = r2_score(y_test, reg_prediction)\n",
    "r2_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f8e632a908>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test.values[:10], '*c')\n",
    "plt.plot(reg_prediction[:10], '*r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DNN Linear Combiner Regresson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_sex = tf.feature_column.embedding_column(sex, dimension=len(df['sex'].unique()))\n",
    "embedded_smoker = tf.feature_column.embedding_column(smoker, dimension=len(df['smoker'].unique()))\n",
    "embedded_region = tf.feature_column.embedding_column(region, dimension=len(df['region'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [age,\n",
    "            bmi,\n",
    "            children,\n",
    "            embedded_sex,\n",
    "            embedded_smoker,\n",
    "            embedded_region]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
    "             learning_rate_init=0.001, max_fun=15000, max_iter=10000,\n",
    "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
    "             power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
    "             tol=0.0001, validation_fraction=0.1, verbose=True,\n",
    "             warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(X_train,\n",
    "                                                y_train,\n",
    "                                                num_epochs=5000,\n",
    "                                                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.compat.v1.train.AdamOptimizer(\n",
    "    learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, name='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:24:37.530687 17688 estimator.py:1790] Using default config.\n",
      "W0602 14:24:37.532684 17688 estimator.py:1811] Using temporary folder as model directory: C:\\Users\\LENOVO\\AppData\\Local\\Temp\\tmp9xr1hi4y\n",
      "I0602 14:24:37.533679 17688 estimator.py:209] Using config: {'_model_dir': 'C:\\\\Users\\\\LENOVO\\\\AppData\\\\Local\\\\Temp\\\\tmp9xr1hi4y', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001F8E79460C8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "dnn_model = tf.estimator.DNNLinearCombinedRegressor(dnn_hidden_units=[100, ],\n",
    "                                                   dnn_feature_columns=feat_cols,\n",
    "                                                   dnn_optimizer=opt\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:25:00.335084 17688 estimator.py:1145] Calling model_fn.\n",
      "W0602 14:25:00.344064 17688 deprecation.py:506] From C:\\Users\\LENOVO\\Anaconda3\\envs\\fhadli\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0602 14:25:00.663207 17688 deprecation.py:323] From C:\\Users\\LENOVO\\Anaconda3\\envs\\fhadli\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:3038: HashedCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "I0602 14:25:02.584069 17688 estimator.py:1147] Done calling model_fn.\n",
      "I0602 14:25:02.585067 17688 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0602 14:25:04.733792 17688 monitored_session.py:240] Graph was finalized.\n",
      "I0602 14:25:04.902341 17688 session_manager.py:500] Running local_init_op.\n",
      "I0602 14:25:04.929267 17688 session_manager.py:502] Done running local_init_op.\n",
      "I0602 14:25:07.374776 17688 basic_session_run_hooks.py:606] Saving checkpoints for 0 into C:\\Users\\LENOVO\\AppData\\Local\\Temp\\tmp9xr1hi4y\\model.ckpt.\n",
      "I0602 14:25:08.959491 17688 basic_session_run_hooks.py:262] loss = 47120867000.0, step = 1\n",
      "I0602 14:25:10.062541 17688 basic_session_run_hooks.py:692] global_step/sec: 90.5762\n",
      "I0602 14:25:10.065533 17688 basic_session_run_hooks.py:260] loss = 33354301000.0, step = 101 (1.106 sec)\n",
      "I0602 14:25:10.563203 17688 basic_session_run_hooks.py:692] global_step/sec: 199.736\n",
      "I0602 14:25:10.566195 17688 basic_session_run_hooks.py:260] loss = 45498155000.0, step = 201 (0.501 sec)\n",
      "I0602 14:25:11.181557 17688 basic_session_run_hooks.py:692] global_step/sec: 161.719\n",
      "I0602 14:25:11.191523 17688 basic_session_run_hooks.py:260] loss = 30743230000.0, step = 301 (0.625 sec)\n",
      "I0602 14:25:11.783938 17688 basic_session_run_hooks.py:692] global_step/sec: 165.734\n",
      "I0602 14:25:11.787932 17688 basic_session_run_hooks.py:260] loss = 24601580000.0, step = 401 (0.596 sec)\n",
      "I0602 14:25:12.268642 17688 basic_session_run_hooks.py:692] global_step/sec: 206.312\n",
      "I0602 14:25:12.274627 17688 basic_session_run_hooks.py:260] loss = 24810349000.0, step = 501 (0.487 sec)\n",
      "I0602 14:25:12.726419 17688 basic_session_run_hooks.py:692] global_step/sec: 218.918\n",
      "I0602 14:25:12.728413 17688 basic_session_run_hooks.py:260] loss = 33959040000.0, step = 601 (0.454 sec)\n",
      "I0602 14:25:13.194168 17688 basic_session_run_hooks.py:692] global_step/sec: 213.341\n",
      "I0602 14:25:13.197159 17688 basic_session_run_hooks.py:260] loss = 21881256000.0, step = 701 (0.469 sec)\n",
      "I0602 14:25:13.683858 17688 basic_session_run_hooks.py:692] global_step/sec: 204.628\n",
      "I0602 14:25:13.685853 17688 basic_session_run_hooks.py:260] loss = 19837317000.0, step = 801 (0.489 sec)\n",
      "I0602 14:25:14.356065 17688 basic_session_run_hooks.py:692] global_step/sec: 148.543\n",
      "I0602 14:25:14.362051 17688 basic_session_run_hooks.py:260] loss = 24764754000.0, step = 901 (0.676 sec)\n",
      "I0602 14:25:14.945485 17688 basic_session_run_hooks.py:692] global_step/sec: 169.658\n",
      "I0602 14:25:14.948477 17688 basic_session_run_hooks.py:260] loss = 18191364000.0, step = 1001 (0.586 sec)\n",
      "I0602 14:25:15.415228 17688 basic_session_run_hooks.py:692] global_step/sec: 212.882\n",
      "I0602 14:25:15.418220 17688 basic_session_run_hooks.py:260] loss = 18931436000.0, step = 1101 (0.470 sec)\n",
      "I0602 14:25:15.881980 17688 basic_session_run_hooks.py:692] global_step/sec: 214.705\n",
      "I0602 14:25:15.883975 17688 basic_session_run_hooks.py:260] loss = 12382280000.0, step = 1201 (0.466 sec)\n",
      "I0602 14:25:16.575127 17688 basic_session_run_hooks.py:692] global_step/sec: 144.269\n",
      "I0602 14:25:16.579116 17688 basic_session_run_hooks.py:260] loss = 22818474000.0, step = 1301 (0.695 sec)\n",
      "I0602 14:25:17.050855 17688 basic_session_run_hooks.py:692] global_step/sec: 209.765\n",
      "I0602 14:25:17.054848 17688 basic_session_run_hooks.py:260] loss = 20766589000.0, step = 1401 (0.476 sec)\n",
      "I0602 14:25:17.684161 17688 basic_session_run_hooks.py:692] global_step/sec: 157.901\n",
      "I0602 14:25:17.694144 17688 basic_session_run_hooks.py:260] loss = 17900868000.0, step = 1501 (0.639 sec)\n",
      "I0602 14:25:18.210753 17688 basic_session_run_hooks.py:692] global_step/sec: 190.261\n",
      "I0602 14:25:18.213746 17688 basic_session_run_hooks.py:260] loss = 20723427000.0, step = 1601 (0.520 sec)\n",
      "I0602 14:25:18.687484 17688 basic_session_run_hooks.py:692] global_step/sec: 209.324\n",
      "I0602 14:25:18.692465 17688 basic_session_run_hooks.py:260] loss = 14785436000.0, step = 1701 (0.479 sec)\n",
      "I0602 14:25:19.147249 17688 basic_session_run_hooks.py:692] global_step/sec: 217.502\n",
      "I0602 14:25:19.150241 17688 basic_session_run_hooks.py:260] loss = 17758308000.0, step = 1801 (0.458 sec)\n",
      "I0602 14:25:19.624983 17688 basic_session_run_hooks.py:692] global_step/sec: 209.764\n",
      "I0602 14:25:19.628961 17688 basic_session_run_hooks.py:260] loss = 16101628000.0, step = 1901 (0.479 sec)\n",
      "I0602 14:25:20.085739 17688 basic_session_run_hooks.py:692] global_step/sec: 217.03\n",
      "I0602 14:25:20.089735 17688 basic_session_run_hooks.py:260] loss = 17943163000.0, step = 2001 (0.461 sec)\n",
      "I0602 14:25:20.532544 17688 basic_session_run_hooks.py:692] global_step/sec: 223.811\n",
      "I0602 14:25:20.535537 17688 basic_session_run_hooks.py:260] loss = 15838274000.0, step = 2101 (0.446 sec)\n",
      "I0602 14:25:20.983340 17688 basic_session_run_hooks.py:692] global_step/sec: 221.34\n",
      "I0602 14:25:20.988331 17688 basic_session_run_hooks.py:260] loss = 11477906000.0, step = 2201 (0.453 sec)\n",
      "I0602 14:25:21.437127 17688 basic_session_run_hooks.py:692] global_step/sec: 220.368\n",
      "I0602 14:25:21.442114 17688 basic_session_run_hooks.py:260] loss = 13259062000.0, step = 2301 (0.454 sec)\n",
      "I0602 14:25:21.881936 17688 basic_session_run_hooks.py:692] global_step/sec: 224.815\n",
      "I0602 14:25:21.885926 17688 basic_session_run_hooks.py:260] loss = 12291938000.0, step = 2401 (0.444 sec)\n",
      "I0602 14:25:22.328741 17688 basic_session_run_hooks.py:692] global_step/sec: 224.312\n",
      "I0602 14:25:22.331734 17688 basic_session_run_hooks.py:260] loss = 10142760000.0, step = 2501 (0.446 sec)\n",
      "I0602 14:25:22.787514 17688 basic_session_run_hooks.py:692] global_step/sec: 217.973\n",
      "I0602 14:25:22.792507 17688 basic_session_run_hooks.py:260] loss = 14629087000.0, step = 2601 (0.461 sec)\n",
      "I0602 14:25:23.245290 17688 basic_session_run_hooks.py:692] global_step/sec: 217.973\n",
      "I0602 14:25:23.248282 17688 basic_session_run_hooks.py:260] loss = 9894144000.0, step = 2701 (0.456 sec)\n",
      "I0602 14:25:23.727004 17688 basic_session_run_hooks.py:692] global_step/sec: 208.022\n",
      "I0602 14:25:23.729995 17688 basic_session_run_hooks.py:260] loss = 9327662000.0, step = 2801 (0.482 sec)\n",
      "I0602 14:25:24.218688 17688 basic_session_run_hooks.py:692] global_step/sec: 202.972\n",
      "I0602 14:25:24.227666 17688 basic_session_run_hooks.py:260] loss = 8545762300.0, step = 2901 (0.497 sec)\n",
      "I0602 14:25:24.703395 17688 basic_session_run_hooks.py:692] global_step/sec: 206.737\n",
      "I0602 14:25:24.708382 17688 basic_session_run_hooks.py:260] loss = 12130566000.0, step = 3001 (0.482 sec)\n",
      "I0602 14:25:25.163163 17688 basic_session_run_hooks.py:692] global_step/sec: 217.029\n",
      "I0602 14:25:25.167152 17688 basic_session_run_hooks.py:260] loss = 11811428000.0, step = 3101 (0.459 sec)\n",
      "I0602 14:25:25.642881 17688 basic_session_run_hooks.py:692] global_step/sec: 208.456\n",
      "I0602 14:25:25.646869 17688 basic_session_run_hooks.py:260] loss = 10726190000.0, step = 3201 (0.480 sec)\n",
      "I0602 14:25:26.113620 17688 basic_session_run_hooks.py:692] global_step/sec: 212.432\n",
      "I0602 14:25:26.117610 17688 basic_session_run_hooks.py:260] loss = 9687327000.0, step = 3301 (0.470 sec)\n",
      "I0602 14:25:26.574392 17688 basic_session_run_hooks.py:692] global_step/sec: 217.499\n",
      "I0602 14:25:26.578378 17688 basic_session_run_hooks.py:260] loss = 6478355500.0, step = 3401 (0.462 sec)\n",
      "I0602 14:25:27.032165 17688 basic_session_run_hooks.py:692] global_step/sec: 217.973\n",
      "I0602 14:25:27.035156 17688 basic_session_run_hooks.py:260] loss = 6961172500.0, step = 3501 (0.457 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:25:27.481962 17688 basic_session_run_hooks.py:692] global_step/sec: 222.816\n",
      "I0602 14:25:27.484954 17688 basic_session_run_hooks.py:260] loss = 4809092000.0, step = 3601 (0.450 sec)\n",
      "I0602 14:25:27.928767 17688 basic_session_run_hooks.py:692] global_step/sec: 223.812\n",
      "I0602 14:25:27.931759 17688 basic_session_run_hooks.py:260] loss = 6793786000.0, step = 3701 (0.447 sec)\n",
      "I0602 14:25:28.380560 17688 basic_session_run_hooks.py:692] global_step/sec: 220.853\n",
      "I0602 14:25:28.384548 17688 basic_session_run_hooks.py:260] loss = 5887471600.0, step = 3801 (0.453 sec)\n",
      "I0602 14:25:28.836340 17688 basic_session_run_hooks.py:692] global_step/sec: 219.404\n",
      "I0602 14:25:28.842324 17688 basic_session_run_hooks.py:260] loss = 7631759400.0, step = 3901 (0.458 sec)\n",
      "I0602 14:25:29.332015 17688 basic_session_run_hooks.py:692] global_step/sec: 201.745\n",
      "I0602 14:25:29.336004 17688 basic_session_run_hooks.py:260] loss = 5087498000.0, step = 4001 (0.494 sec)\n",
      "I0602 14:25:29.787801 17688 basic_session_run_hooks.py:692] global_step/sec: 219.401\n",
      "I0602 14:25:29.792783 17688 basic_session_run_hooks.py:260] loss = 5104377000.0, step = 4101 (0.457 sec)\n",
      "I0602 14:25:30.238592 17688 basic_session_run_hooks.py:692] global_step/sec: 221.832\n",
      "I0602 14:25:30.243577 17688 basic_session_run_hooks.py:260] loss = 5216379000.0, step = 4201 (0.451 sec)\n",
      "I0602 14:25:30.694372 17688 basic_session_run_hooks.py:692] global_step/sec: 219.404\n",
      "I0602 14:25:30.697363 17688 basic_session_run_hooks.py:260] loss = 6353379300.0, step = 4301 (0.454 sec)\n",
      "I0602 14:25:31.158134 17688 basic_session_run_hooks.py:692] global_step/sec: 216.093\n",
      "I0602 14:25:31.163122 17688 basic_session_run_hooks.py:260] loss = 4279542300.0, step = 4401 (0.466 sec)\n",
      "I0602 14:25:31.627876 17688 basic_session_run_hooks.py:692] global_step/sec: 212.432\n",
      "I0602 14:25:31.631865 17688 basic_session_run_hooks.py:260] loss = 2779291600.0, step = 4501 (0.469 sec)\n",
      "I0602 14:25:32.108591 17688 basic_session_run_hooks.py:692] global_step/sec: 208.023\n",
      "I0602 14:25:32.112580 17688 basic_session_run_hooks.py:260] loss = 4641180700.0, step = 4601 (0.481 sec)\n",
      "I0602 14:25:32.559386 17688 basic_session_run_hooks.py:692] global_step/sec: 221.83\n",
      "I0602 14:25:32.563374 17688 basic_session_run_hooks.py:260] loss = 4828411000.0, step = 4701 (0.451 sec)\n",
      "I0602 14:25:33.042100 17688 basic_session_run_hooks.py:692] global_step/sec: 207.162\n",
      "I0602 14:25:33.046084 17688 basic_session_run_hooks.py:260] loss = 5225292000.0, step = 4801 (0.483 sec)\n",
      "I0602 14:25:33.541765 17688 basic_session_run_hooks.py:692] global_step/sec: 200.537\n",
      "I0602 14:25:33.544751 17688 basic_session_run_hooks.py:260] loss = 3955706400.0, step = 4901 (0.499 sec)\n",
      "I0602 14:25:34.057381 17688 basic_session_run_hooks.py:692] global_step/sec: 193.566\n",
      "I0602 14:25:34.061369 17688 basic_session_run_hooks.py:260] loss = 4411618300.0, step = 5001 (0.517 sec)\n",
      "I0602 14:25:34.506183 17688 basic_session_run_hooks.py:692] global_step/sec: 223.313\n",
      "I0602 14:25:34.511166 17688 basic_session_run_hooks.py:260] loss = 4040180500.0, step = 5101 (0.449 sec)\n",
      "I0602 14:25:35.176387 17688 basic_session_run_hooks.py:692] global_step/sec: 148.986\n",
      "I0602 14:25:35.180376 17688 basic_session_run_hooks.py:260] loss = 3277884400.0, step = 5201 (0.670 sec)\n",
      "I0602 14:25:35.612222 17688 basic_session_run_hooks.py:692] global_step/sec: 229.971\n",
      "I0602 14:25:35.615214 17688 basic_session_run_hooks.py:260] loss = 3486655500.0, step = 5301 (0.435 sec)\n",
      "I0602 14:25:36.231568 17688 basic_session_run_hooks.py:692] global_step/sec: 161.201\n",
      "I0602 14:25:36.239554 17688 basic_session_run_hooks.py:260] loss = 3932437200.0, step = 5401 (0.623 sec)\n",
      "I0602 14:25:36.724253 17688 basic_session_run_hooks.py:692] global_step/sec: 202.97\n",
      "I0602 14:25:36.728237 17688 basic_session_run_hooks.py:260] loss = 5772289000.0, step = 5501 (0.490 sec)\n",
      "I0602 14:25:37.184018 17688 basic_session_run_hooks.py:692] global_step/sec: 217.502\n",
      "I0602 14:25:37.190009 17688 basic_session_run_hooks.py:260] loss = 6210889700.0, step = 5601 (0.462 sec)\n",
      "I0602 14:25:37.621849 17688 basic_session_run_hooks.py:692] global_step/sec: 228.919\n",
      "I0602 14:25:37.625838 17688 basic_session_run_hooks.py:260] loss = 3493774800.0, step = 5701 (0.436 sec)\n",
      "I0602 14:25:38.064664 17688 basic_session_run_hooks.py:692] global_step/sec: 225.829\n",
      "I0602 14:25:38.067656 17688 basic_session_run_hooks.py:260] loss = 4105120800.0, step = 5801 (0.442 sec)\n",
      "I0602 14:25:38.552359 17688 basic_session_run_hooks.py:692] global_step/sec: 204.628\n",
      "I0602 14:25:38.557349 17688 basic_session_run_hooks.py:260] loss = 4087764000.0, step = 5901 (0.490 sec)\n",
      "I0602 14:25:39.009139 17688 basic_session_run_hooks.py:692] global_step/sec: 218.924\n",
      "I0602 14:25:39.013128 17688 basic_session_run_hooks.py:260] loss = 4449150500.0, step = 6001 (0.456 sec)\n",
      "I0602 14:25:39.459933 17688 basic_session_run_hooks.py:692] global_step/sec: 221.83\n",
      "I0602 14:25:39.463923 17688 basic_session_run_hooks.py:260] loss = 5265411000.0, step = 6101 (0.450 sec)\n",
      "I0602 14:25:39.891779 17688 basic_session_run_hooks.py:692] global_step/sec: 231.564\n",
      "I0602 14:25:39.895768 17688 basic_session_run_hooks.py:260] loss = 4579247000.0, step = 6201 (0.433 sec)\n",
      "I0602 14:25:40.345565 17688 basic_session_run_hooks.py:692] global_step/sec: 220.368\n",
      "I0602 14:25:40.349554 17688 basic_session_run_hooks.py:260] loss = 6674368500.0, step = 6301 (0.454 sec)\n",
      "I0602 14:25:40.941973 17688 basic_session_run_hooks.py:692] global_step/sec: 167.951\n",
      "I0602 14:25:40.947957 17688 basic_session_run_hooks.py:260] loss = 3542758000.0, step = 6401 (0.598 sec)\n",
      "I0602 14:25:41.929338 17688 basic_session_run_hooks.py:692] global_step/sec: 101.28\n",
      "I0602 14:25:41.935315 17688 basic_session_run_hooks.py:260] loss = 3646242600.0, step = 6501 (0.987 sec)\n",
      "I0602 14:25:42.958584 17688 basic_session_run_hooks.py:692] global_step/sec: 97.1582\n",
      "I0602 14:25:42.963564 17688 basic_session_run_hooks.py:260] loss = 3472601000.0, step = 6601 (1.028 sec)\n",
      "I0602 14:25:43.805314 17688 basic_session_run_hooks.py:692] global_step/sec: 117.962\n",
      "I0602 14:25:43.810300 17688 basic_session_run_hooks.py:260] loss = 4700388000.0, step = 6701 (0.847 sec)\n",
      "I0602 14:25:44.456573 17688 basic_session_run_hooks.py:692] global_step/sec: 153.784\n",
      "I0602 14:25:44.460561 17688 basic_session_run_hooks.py:260] loss = 4314183000.0, step = 6801 (0.650 sec)\n",
      "I0602 14:25:44.931303 17688 basic_session_run_hooks.py:692] global_step/sec: 210.205\n",
      "I0602 14:25:44.935292 17688 basic_session_run_hooks.py:260] loss = 5301506000.0, step = 6901 (0.475 sec)\n",
      "I0602 14:25:45.422990 17688 basic_session_run_hooks.py:692] global_step/sec: 203.794\n",
      "I0602 14:25:45.427974 17688 basic_session_run_hooks.py:260] loss = 4772189000.0, step = 7001 (0.493 sec)\n",
      "I0602 14:25:45.926642 17688 basic_session_run_hooks.py:692] global_step/sec: 198.158\n",
      "I0602 14:25:45.930630 17688 basic_session_run_hooks.py:260] loss = 6396399600.0, step = 7101 (0.503 sec)\n",
      "I0602 14:25:46.419324 17688 basic_session_run_hooks.py:692] global_step/sec: 202.971\n",
      "I0602 14:25:46.424315 17688 basic_session_run_hooks.py:260] loss = 5369142300.0, step = 7201 (0.494 sec)\n",
      "I0602 14:25:46.886076 17688 basic_session_run_hooks.py:692] global_step/sec: 214.706\n",
      "I0602 14:25:46.891064 17688 basic_session_run_hooks.py:260] loss = 3322725400.0, step = 7301 (0.466 sec)\n",
      "I0602 14:25:47.357815 17688 basic_session_run_hooks.py:692] global_step/sec: 211.534\n",
      "I0602 14:25:47.362800 17688 basic_session_run_hooks.py:260] loss = 4436077600.0, step = 7401 (0.473 sec)\n",
      "I0602 14:25:47.835537 17688 basic_session_run_hooks.py:692] global_step/sec: 209.765\n",
      "I0602 14:25:47.840524 17688 basic_session_run_hooks.py:260] loss = 5119560700.0, step = 7501 (0.478 sec)\n",
      "I0602 14:25:48.656118 17688 basic_session_run_hooks.py:692] global_step/sec: 121.717\n",
      "I0602 14:25:48.665099 17688 basic_session_run_hooks.py:260] loss = 4102366200.0, step = 7601 (0.825 sec)\n",
      "I0602 14:25:49.191685 17688 basic_session_run_hooks.py:692] global_step/sec: 186.718\n",
      "I0602 14:25:49.196671 17688 basic_session_run_hooks.py:260] loss = 3648269800.0, step = 7701 (0.532 sec)\n",
      "I0602 14:25:49.664420 17688 basic_session_run_hooks.py:692] global_step/sec: 211.535\n",
      "I0602 14:25:49.668408 17688 basic_session_run_hooks.py:260] loss = 5170042000.0, step = 7801 (0.472 sec)\n",
      "I0602 14:25:50.134164 17688 basic_session_run_hooks.py:692] global_step/sec: 213.335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:25:50.138161 17688 basic_session_run_hooks.py:260] loss = 3666629600.0, step = 7901 (0.470 sec)\n",
      "I0602 14:25:50.617870 17688 basic_session_run_hooks.py:692] global_step/sec: 206.312\n",
      "I0602 14:25:50.621860 17688 basic_session_run_hooks.py:260] loss = 4034347800.0, step = 8001 (0.484 sec)\n",
      "I0602 14:25:51.039744 17688 basic_session_run_hooks.py:692] global_step/sec: 237.037\n",
      "I0602 14:25:51.044729 17688 basic_session_run_hooks.py:260] loss = 3587180800.0, step = 8101 (0.423 sec)\n",
      "I0602 14:25:51.567331 17688 basic_session_run_hooks.py:692] global_step/sec: 189.542\n",
      "I0602 14:25:51.573323 17688 basic_session_run_hooks.py:260] loss = 3587097000.0, step = 8201 (0.528 sec)\n",
      "I0602 14:25:52.099907 17688 basic_session_run_hooks.py:692] global_step/sec: 187.767\n",
      "I0602 14:25:52.103903 17688 basic_session_run_hooks.py:260] loss = 5442754600.0, step = 8301 (0.532 sec)\n",
      "I0602 14:25:52.592589 17688 basic_session_run_hooks.py:692] global_step/sec: 202.971\n",
      "I0602 14:25:52.596578 17688 basic_session_run_hooks.py:260] loss = 4939664400.0, step = 8401 (0.493 sec)\n",
      "I0602 14:25:53.142121 17688 basic_session_run_hooks.py:692] global_step/sec: 181.973\n",
      "I0602 14:25:53.146110 17688 basic_session_run_hooks.py:260] loss = 3848439300.0, step = 8501 (0.550 sec)\n",
      "I0602 14:25:53.619846 17688 basic_session_run_hooks.py:692] global_step/sec: 209.765\n",
      "I0602 14:25:53.626824 17688 basic_session_run_hooks.py:260] loss = 3521179100.0, step = 8601 (0.481 sec)\n",
      "I0602 14:25:54.156413 17688 basic_session_run_hooks.py:692] global_step/sec: 186.368\n",
      "I0602 14:25:54.160397 17688 basic_session_run_hooks.py:260] loss = 4743122000.0, step = 8701 (0.534 sec)\n",
      "I0602 14:25:54.617176 17688 basic_session_run_hooks.py:692] global_step/sec: 216.564\n",
      "I0602 14:25:54.623176 17688 basic_session_run_hooks.py:260] loss = 3545086700.0, step = 8801 (0.462 sec)\n",
      "I0602 14:25:55.095906 17688 basic_session_run_hooks.py:692] global_step/sec: 209.324\n",
      "I0602 14:25:55.100883 17688 basic_session_run_hooks.py:260] loss = 3267596000.0, step = 8901 (0.479 sec)\n",
      "I0602 14:25:55.564643 17688 basic_session_run_hooks.py:692] global_step/sec: 212.884\n",
      "I0602 14:25:55.568632 17688 basic_session_run_hooks.py:260] loss = 3677095000.0, step = 9001 (0.468 sec)\n",
      "I0602 14:25:56.046354 17688 basic_session_run_hooks.py:692] global_step/sec: 207.593\n",
      "I0602 14:25:56.050344 17688 basic_session_run_hooks.py:260] loss = 5183970300.0, step = 9101 (0.482 sec)\n",
      "I0602 14:25:56.511111 17688 basic_session_run_hooks.py:692] global_step/sec: 215.166\n",
      "I0602 14:25:56.515101 17688 basic_session_run_hooks.py:260] loss = 2711298000.0, step = 9201 (0.465 sec)\n",
      "I0602 14:25:56.984845 17688 basic_session_run_hooks.py:692] global_step/sec: 211.089\n",
      "I0602 14:25:56.989839 17688 basic_session_run_hooks.py:260] loss = 3161652200.0, step = 9301 (0.475 sec)\n",
      "I0602 14:25:57.383778 17688 basic_session_run_hooks.py:692] global_step/sec: 250.669\n",
      "I0602 14:25:57.388775 17688 basic_session_run_hooks.py:260] loss = 3535602700.0, step = 9401 (0.399 sec)\n",
      "I0602 14:25:57.905387 17688 basic_session_run_hooks.py:692] global_step/sec: 191.714\n",
      "I0602 14:25:57.910370 17688 basic_session_run_hooks.py:260] loss = 4167738600.0, step = 9501 (0.522 sec)\n",
      "I0602 14:25:58.380114 17688 basic_session_run_hooks.py:692] global_step/sec: 210.648\n",
      "I0602 14:25:58.384103 17688 basic_session_run_hooks.py:260] loss = 4128095500.0, step = 9601 (0.474 sec)\n",
      "I0602 14:25:59.245802 17688 basic_session_run_hooks.py:692] global_step/sec: 115.515\n",
      "I0602 14:25:59.249788 17688 basic_session_run_hooks.py:260] loss = 4257295400.0, step = 9701 (0.866 sec)\n",
      "I0602 14:25:59.940942 17688 basic_session_run_hooks.py:692] global_step/sec: 143.856\n",
      "I0602 14:25:59.944930 17688 basic_session_run_hooks.py:260] loss = 3871127600.0, step = 9801 (0.695 sec)\n",
      "I0602 14:26:00.407700 17688 basic_session_run_hooks.py:692] global_step/sec: 214.701\n",
      "I0602 14:26:00.417667 17688 basic_session_run_hooks.py:260] loss = 2910307300.0, step = 9901 (0.473 sec)\n",
      "I0602 14:26:00.862476 17688 basic_session_run_hooks.py:692] global_step/sec: 219.409\n",
      "I0602 14:26:00.866466 17688 basic_session_run_hooks.py:260] loss = 4531058000.0, step = 10001 (0.449 sec)\n",
      "I0602 14:26:01.329228 17688 basic_session_run_hooks.py:692] global_step/sec: 214.246\n",
      "I0602 14:26:01.332221 17688 basic_session_run_hooks.py:260] loss = 5200376300.0, step = 10101 (0.466 sec)\n",
      "I0602 14:26:01.787004 17688 basic_session_run_hooks.py:692] global_step/sec: 218.448\n",
      "I0602 14:26:01.791991 17688 basic_session_run_hooks.py:260] loss = 4697989600.0, step = 10201 (0.460 sec)\n",
      "I0602 14:26:02.281682 17688 basic_session_run_hooks.py:692] global_step/sec: 202.152\n",
      "I0602 14:26:02.287675 17688 basic_session_run_hooks.py:260] loss = 4802133000.0, step = 10301 (0.496 sec)\n",
      "I0602 14:26:02.759403 17688 basic_session_run_hooks.py:692] global_step/sec: 209.764\n",
      "I0602 14:26:02.762396 17688 basic_session_run_hooks.py:260] loss = 4282052400.0, step = 10401 (0.475 sec)\n",
      "I0602 14:26:03.226156 17688 basic_session_run_hooks.py:692] global_step/sec: 213.79\n",
      "I0602 14:26:03.230145 17688 basic_session_run_hooks.py:260] loss = 3827316700.0, step = 10501 (0.468 sec)\n",
      "I0602 14:26:03.902347 17688 basic_session_run_hooks.py:692] global_step/sec: 147.887\n",
      "I0602 14:26:03.910327 17688 basic_session_run_hooks.py:260] loss = 4196970200.0, step = 10601 (0.680 sec)\n",
      "I0602 14:26:04.391042 17688 basic_session_run_hooks.py:692] global_step/sec: 204.627\n",
      "I0602 14:26:04.395030 17688 basic_session_run_hooks.py:260] loss = 2650172000.0, step = 10701 (0.485 sec)\n",
      "I0602 14:26:04.896689 17688 basic_session_run_hooks.py:692] global_step/sec: 197.767\n",
      "I0602 14:26:04.901675 17688 basic_session_run_hooks.py:260] loss = 4363186000.0, step = 10801 (0.507 sec)\n",
      "I0602 14:26:05.371422 17688 basic_session_run_hooks.py:692] global_step/sec: 211.089\n",
      "I0602 14:26:05.376406 17688 basic_session_run_hooks.py:260] loss = 4273949200.0, step = 10901 (0.475 sec)\n",
      "I0602 14:26:05.846150 17688 basic_session_run_hooks.py:692] global_step/sec: 210.205\n",
      "I0602 14:26:05.850140 17688 basic_session_run_hooks.py:260] loss = 5285933600.0, step = 11001 (0.474 sec)\n",
      "I0602 14:26:06.330854 17688 basic_session_run_hooks.py:692] global_step/sec: 206.737\n",
      "I0602 14:26:06.333846 17688 basic_session_run_hooks.py:260] loss = 4621817000.0, step = 11101 (0.484 sec)\n",
      "I0602 14:26:06.819547 17688 basic_session_run_hooks.py:692] global_step/sec: 204.627\n",
      "I0602 14:26:06.826529 17688 basic_session_run_hooks.py:260] loss = 3630480000.0, step = 11201 (0.493 sec)\n",
      "I0602 14:26:07.297270 17688 basic_session_run_hooks.py:692] global_step/sec: 208.891\n",
      "I0602 14:26:07.300261 17688 basic_session_run_hooks.py:260] loss = 3661526000.0, step = 11301 (0.474 sec)\n",
      "I0602 14:26:07.914621 17688 basic_session_run_hooks.py:692] global_step/sec: 161.982\n",
      "I0602 14:26:07.920617 17688 basic_session_run_hooks.py:260] loss = 4399495000.0, step = 11401 (0.620 sec)\n",
      "I0602 14:26:08.436224 17688 basic_session_run_hooks.py:692] global_step/sec: 191.717\n",
      "I0602 14:26:08.445203 17688 basic_session_run_hooks.py:260] loss = 4712362000.0, step = 11501 (0.525 sec)\n",
      "I0602 14:26:09.217136 17688 basic_session_run_hooks.py:692] global_step/sec: 128.055\n",
      "I0602 14:26:09.222125 17688 basic_session_run_hooks.py:260] loss = 3941902300.0, step = 11601 (0.777 sec)\n",
      "I0602 14:26:09.974112 17688 basic_session_run_hooks.py:692] global_step/sec: 132.104\n",
      "I0602 14:26:09.978101 17688 basic_session_run_hooks.py:260] loss = 3026145500.0, step = 11701 (0.756 sec)\n",
      "I0602 14:26:10.667259 17688 basic_session_run_hooks.py:692] global_step/sec: 144.27\n",
      "I0602 14:26:10.671252 17688 basic_session_run_hooks.py:260] loss = 4672648000.0, step = 11801 (0.693 sec)\n",
      "I0602 14:26:11.351428 17688 basic_session_run_hooks.py:692] global_step/sec: 146.163\n",
      "I0602 14:26:11.360407 17688 basic_session_run_hooks.py:260] loss = 3236200000.0, step = 11901 (0.689 sec)\n",
      "I0602 14:26:12.164410 17688 basic_session_run_hooks.py:692] global_step/sec: 123.004\n",
      "I0602 14:26:12.168399 17688 basic_session_run_hooks.py:260] loss = 3027636000.0, step = 12001 (0.808 sec)\n",
      "I0602 14:26:12.644127 17688 basic_session_run_hooks.py:692] global_step/sec: 208.456\n",
      "I0602 14:26:12.648117 17688 basic_session_run_hooks.py:260] loss = 3970233000.0, step = 12101 (0.480 sec)\n",
      "I0602 14:26:13.117861 17688 basic_session_run_hooks.py:692] global_step/sec: 211.535\n",
      "I0602 14:26:13.121851 17688 basic_session_run_hooks.py:260] loss = 4217532400.0, step = 12201 (0.474 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:26:13.607553 17688 basic_session_run_hooks.py:692] global_step/sec: 203.795\n",
      "I0602 14:26:13.612538 17688 basic_session_run_hooks.py:260] loss = 4472019000.0, step = 12301 (0.491 sec)\n",
      "I0602 14:26:14.082281 17688 basic_session_run_hooks.py:692] global_step/sec: 210.647\n",
      "I0602 14:26:14.087275 17688 basic_session_run_hooks.py:260] loss = 3891430000.0, step = 12401 (0.475 sec)\n",
      "I0602 14:26:14.701628 17688 basic_session_run_hooks.py:692] global_step/sec: 161.722\n",
      "I0602 14:26:14.712601 17688 basic_session_run_hooks.py:260] loss = 5957966000.0, step = 12501 (0.625 sec)\n",
      "I0602 14:26:15.229215 17688 basic_session_run_hooks.py:692] global_step/sec: 189.183\n",
      "I0602 14:26:15.233204 17688 basic_session_run_hooks.py:260] loss = 2793756700.0, step = 12601 (0.520 sec)\n",
      "I0602 14:26:15.690984 17688 basic_session_run_hooks.py:692] global_step/sec: 216.559\n",
      "I0602 14:26:15.694969 17688 basic_session_run_hooks.py:260] loss = 4039676000.0, step = 12701 (0.463 sec)\n",
      "I0602 14:26:16.145763 17688 basic_session_run_hooks.py:692] global_step/sec: 219.887\n",
      "I0602 14:26:16.149753 17688 basic_session_run_hooks.py:260] loss = 4375229400.0, step = 12801 (0.455 sec)\n",
      "I0602 14:26:16.649417 17688 basic_session_run_hooks.py:692] global_step/sec: 198.943\n",
      "I0602 14:26:16.652409 17688 basic_session_run_hooks.py:260] loss = 3829384200.0, step = 12901 (0.503 sec)\n",
      "I0602 14:26:17.111182 17688 basic_session_run_hooks.py:692] global_step/sec: 216.094\n",
      "I0602 14:26:17.115171 17688 basic_session_run_hooks.py:260] loss = 3514792000.0, step = 13001 (0.463 sec)\n",
      "I0602 14:26:17.572949 17688 basic_session_run_hooks.py:692] global_step/sec: 217.029\n",
      "I0602 14:26:17.576937 17688 basic_session_run_hooks.py:260] loss = 3582971600.0, step = 13101 (0.462 sec)\n",
      "I0602 14:26:18.046681 17688 basic_session_run_hooks.py:692] global_step/sec: 211.09\n",
      "I0602 14:26:18.050670 17688 basic_session_run_hooks.py:260] loss = 3720305200.0, step = 13201 (0.474 sec)\n",
      "I0602 14:26:18.521414 17688 basic_session_run_hooks.py:692] global_step/sec: 210.203\n",
      "I0602 14:26:18.526398 17688 basic_session_run_hooks.py:260] loss = 3263385000.0, step = 13301 (0.476 sec)\n",
      "I0602 14:26:19.004121 17688 basic_session_run_hooks.py:692] global_step/sec: 207.594\n",
      "I0602 14:26:19.009109 17688 basic_session_run_hooks.py:260] loss = 3456193000.0, step = 13401 (0.483 sec)\n",
      "I0602 14:26:19.453922 17688 basic_session_run_hooks.py:692] global_step/sec: 222.322\n",
      "I0602 14:26:19.460899 17688 basic_session_run_hooks.py:260] loss = 2599193900.0, step = 13501 (0.452 sec)\n",
      "I0602 14:26:19.925657 17688 basic_session_run_hooks.py:692] global_step/sec: 211.982\n",
      "I0602 14:26:19.928648 17688 basic_session_run_hooks.py:260] loss = 3958356500.0, step = 13601 (0.468 sec)\n",
      "I0602 14:26:20.398392 17688 basic_session_run_hooks.py:692] global_step/sec: 211.535\n",
      "I0602 14:26:20.401384 17688 basic_session_run_hooks.py:260] loss = 4515077600.0, step = 13701 (0.473 sec)\n",
      "I0602 14:26:20.857167 17688 basic_session_run_hooks.py:692] global_step/sec: 217.499\n",
      "I0602 14:26:20.861154 17688 basic_session_run_hooks.py:260] loss = 3623080400.0, step = 13801 (0.460 sec)\n",
      "I0602 14:26:21.361816 17688 basic_session_run_hooks.py:692] global_step/sec: 198.157\n",
      "I0602 14:26:21.365805 17688 basic_session_run_hooks.py:260] loss = 2653585400.0, step = 13901 (0.505 sec)\n",
      "I0602 14:26:21.834552 17688 basic_session_run_hooks.py:692] global_step/sec: 211.981\n",
      "I0602 14:26:21.838544 17688 basic_session_run_hooks.py:260] loss = 3136155000.0, step = 14001 (0.472 sec)\n",
      "I0602 14:26:22.297314 17688 basic_session_run_hooks.py:692] global_step/sec: 215.629\n",
      "I0602 14:26:22.301304 17688 basic_session_run_hooks.py:260] loss = 2849512200.0, step = 14101 (0.464 sec)\n",
      "I0602 14:26:22.764067 17688 basic_session_run_hooks.py:692] global_step/sec: 214.246\n",
      "I0602 14:26:22.768056 17688 basic_session_run_hooks.py:260] loss = 4606481400.0, step = 14201 (0.467 sec)\n",
      "I0602 14:26:23.275698 17688 basic_session_run_hooks.py:692] global_step/sec: 195.453\n",
      "I0602 14:26:23.279687 17688 basic_session_run_hooks.py:260] loss = 3970377700.0, step = 14301 (0.512 sec)\n",
      "I0602 14:26:23.713528 17688 basic_session_run_hooks.py:692] global_step/sec: 228.399\n",
      "I0602 14:26:23.717517 17688 basic_session_run_hooks.py:260] loss = 3516531200.0, step = 14401 (0.438 sec)\n",
      "I0602 14:26:24.186264 17688 basic_session_run_hooks.py:692] global_step/sec: 211.535\n",
      "I0602 14:26:24.192248 17688 basic_session_run_hooks.py:260] loss = 4147133400.0, step = 14501 (0.475 sec)\n",
      "I0602 14:26:24.665980 17688 basic_session_run_hooks.py:692] global_step/sec: 208.456\n",
      "I0602 14:26:24.669970 17688 basic_session_run_hooks.py:260] loss = 4853700600.0, step = 14601 (0.478 sec)\n",
      "I0602 14:26:25.127746 17688 basic_session_run_hooks.py:692] global_step/sec: 216.56\n",
      "I0602 14:26:25.133730 17688 basic_session_run_hooks.py:260] loss = 4242348000.0, step = 14701 (0.464 sec)\n",
      "I0602 14:26:25.587520 17688 basic_session_run_hooks.py:692] global_step/sec: 217.498\n",
      "I0602 14:26:25.593502 17688 basic_session_run_hooks.py:260] loss = 4204696800.0, step = 14801 (0.460 sec)\n",
      "I0602 14:26:26.083191 17688 basic_session_run_hooks.py:692] global_step/sec: 201.747\n",
      "I0602 14:26:26.087180 17688 basic_session_run_hooks.py:260] loss = 3531143400.0, step = 14901 (0.494 sec)\n",
      "I0602 14:26:26.543960 17688 basic_session_run_hooks.py:692] global_step/sec: 217.029\n",
      "I0602 14:26:26.547948 17688 basic_session_run_hooks.py:260] loss = 3444524500.0, step = 15001 (0.461 sec)\n",
      "I0602 14:26:27.027666 17688 basic_session_run_hooks.py:692] global_step/sec: 207.164\n",
      "I0602 14:26:27.030658 17688 basic_session_run_hooks.py:260] loss = 4129576200.0, step = 15101 (0.483 sec)\n",
      "I0602 14:26:27.524340 17688 basic_session_run_hooks.py:692] global_step/sec: 200.936\n",
      "I0602 14:26:27.529324 17688 basic_session_run_hooks.py:260] loss = 2773190700.0, step = 15201 (0.499 sec)\n",
      "I0602 14:26:28.000066 17688 basic_session_run_hooks.py:692] global_step/sec: 210.647\n",
      "I0602 14:26:28.003057 17688 basic_session_run_hooks.py:260] loss = 3473093000.0, step = 15301 (0.474 sec)\n",
      "I0602 14:26:28.486764 17688 basic_session_run_hooks.py:692] global_step/sec: 205.466\n",
      "I0602 14:26:28.491753 17688 basic_session_run_hooks.py:260] loss = 4287811600.0, step = 15401 (0.489 sec)\n",
      "I0602 14:26:29.356440 17688 basic_session_run_hooks.py:692] global_step/sec: 114.985\n",
      "I0602 14:26:29.361429 17688 basic_session_run_hooks.py:260] loss = 2253097500.0, step = 15501 (0.870 sec)\n",
      "I0602 14:26:29.995729 17688 basic_session_run_hooks.py:692] global_step/sec: 156.181\n",
      "I0602 14:26:30.000716 17688 basic_session_run_hooks.py:260] loss = 3371380700.0, step = 15601 (0.639 sec)\n",
      "I0602 14:26:30.648982 17688 basic_session_run_hooks.py:692] global_step/sec: 153.08\n",
      "I0602 14:26:30.652972 17688 basic_session_run_hooks.py:260] loss = 3499502600.0, step = 15701 (0.652 sec)\n",
      "I0602 14:26:31.172586 17688 basic_session_run_hooks.py:692] global_step/sec: 190.984\n",
      "I0602 14:26:31.177568 17688 basic_session_run_hooks.py:260] loss = 3261127200.0, step = 15801 (0.525 sec)\n",
      "I0602 14:26:31.670255 17688 basic_session_run_hooks.py:692] global_step/sec: 200.937\n",
      "I0602 14:26:31.676236 17688 basic_session_run_hooks.py:260] loss = 2973125600.0, step = 15901 (0.499 sec)\n",
      "I0602 14:26:32.165925 17688 basic_session_run_hooks.py:692] global_step/sec: 201.747\n",
      "I0602 14:26:32.170923 17688 basic_session_run_hooks.py:260] loss = 2904811000.0, step = 16001 (0.495 sec)\n",
      "I0602 14:26:32.638669 17688 basic_session_run_hooks.py:692] global_step/sec: 211.98\n",
      "I0602 14:26:32.645643 17688 basic_session_run_hooks.py:260] loss = 2688291300.0, step = 16101 (0.475 sec)\n",
      "I0602 14:26:33.120375 17688 basic_session_run_hooks.py:692] global_step/sec: 207.595\n",
      "I0602 14:26:33.126358 17688 basic_session_run_hooks.py:260] loss = 4163332900.0, step = 16201 (0.481 sec)\n",
      "I0602 14:26:33.645968 17688 basic_session_run_hooks.py:692] global_step/sec: 189.901\n",
      "I0602 14:26:33.649957 17688 basic_session_run_hooks.py:260] loss = 3907389000.0, step = 16301 (0.524 sec)\n",
      "I0602 14:26:34.118704 17688 basic_session_run_hooks.py:692] global_step/sec: 211.982\n",
      "I0602 14:26:34.123693 17688 basic_session_run_hooks.py:260] loss = 2637019100.0, step = 16401 (0.474 sec)\n",
      "I0602 14:26:34.618368 17688 basic_session_run_hooks.py:692] global_step/sec: 199.736\n",
      "I0602 14:26:34.625356 17688 basic_session_run_hooks.py:260] loss = 3679899100.0, step = 16501 (0.502 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:26:35.128005 17688 basic_session_run_hooks.py:692] global_step/sec: 196.218\n",
      "I0602 14:26:35.131995 17688 basic_session_run_hooks.py:260] loss = 3750615000.0, step = 16601 (0.507 sec)\n",
      "I0602 14:26:35.647616 17688 basic_session_run_hooks.py:692] global_step/sec: 192.822\n",
      "I0602 14:26:35.650608 17688 basic_session_run_hooks.py:260] loss = 3514200600.0, step = 16701 (0.519 sec)\n",
      "I0602 14:26:36.167228 17688 basic_session_run_hooks.py:692] global_step/sec: 192.083\n",
      "I0602 14:26:36.172225 17688 basic_session_run_hooks.py:260] loss = 4228797700.0, step = 16801 (0.522 sec)\n",
      "I0602 14:26:36.755656 17688 basic_session_run_hooks.py:692] global_step/sec: 170.233\n",
      "I0602 14:26:36.760640 17688 basic_session_run_hooks.py:260] loss = 4124462800.0, step = 16901 (0.588 sec)\n",
      "I0602 14:26:37.255319 17688 basic_session_run_hooks.py:692] global_step/sec: 200.133\n",
      "I0602 14:26:37.260303 17688 basic_session_run_hooks.py:260] loss = 4482618400.0, step = 17001 (0.500 sec)\n",
      "I0602 14:26:37.714090 17688 basic_session_run_hooks.py:692] global_step/sec: 217.976\n",
      "I0602 14:26:37.718079 17688 basic_session_run_hooks.py:260] loss = 4256367600.0, step = 17101 (0.458 sec)\n",
      "I0602 14:26:38.180841 17688 basic_session_run_hooks.py:692] global_step/sec: 213.79\n",
      "I0602 14:26:38.184831 17688 basic_session_run_hooks.py:260] loss = 3147027500.0, step = 17201 (0.467 sec)\n",
      "I0602 14:26:38.694468 17688 basic_session_run_hooks.py:692] global_step/sec: 194.694\n",
      "I0602 14:26:38.697460 17688 basic_session_run_hooks.py:260] loss = 3277407200.0, step = 17301 (0.513 sec)\n",
      "I0602 14:26:39.173190 17688 basic_session_run_hooks.py:692] global_step/sec: 208.89\n",
      "I0602 14:26:39.179173 17688 basic_session_run_hooks.py:260] loss = 2810240000.0, step = 17401 (0.482 sec)\n",
      "I0602 14:26:39.636950 17688 basic_session_run_hooks.py:692] global_step/sec: 216.094\n",
      "I0602 14:26:39.641936 17688 basic_session_run_hooks.py:260] loss = 2680366800.0, step = 17501 (0.463 sec)\n",
      "I0602 14:26:40.105697 17688 basic_session_run_hooks.py:692] global_step/sec: 212.881\n",
      "I0602 14:26:40.110681 17688 basic_session_run_hooks.py:260] loss = 2742188500.0, step = 17601 (0.469 sec)\n",
      "I0602 14:26:40.584414 17688 basic_session_run_hooks.py:692] global_step/sec: 208.892\n",
      "I0602 14:26:40.588406 17688 basic_session_run_hooks.py:260] loss = 3362242000.0, step = 17701 (0.478 sec)\n",
      "I0602 14:26:40.996313 17688 basic_session_run_hooks.py:692] global_step/sec: 242.778\n",
      "I0602 14:26:41.000303 17688 basic_session_run_hooks.py:260] loss = 4030903800.0, step = 17801 (0.412 sec)\n",
      "I0602 14:26:41.497972 17688 basic_session_run_hooks.py:692] global_step/sec: 199.736\n",
      "I0602 14:26:41.500964 17688 basic_session_run_hooks.py:260] loss = 4153685000.0, step = 17901 (0.501 sec)\n",
      "I0602 14:26:41.976692 17688 basic_session_run_hooks.py:692] global_step/sec: 208.456\n",
      "I0602 14:26:41.980681 17688 basic_session_run_hooks.py:260] loss = 4921471000.0, step = 18001 (0.480 sec)\n",
      "I0602 14:26:42.475361 17688 basic_session_run_hooks.py:692] global_step/sec: 200.936\n",
      "I0602 14:26:42.479348 17688 basic_session_run_hooks.py:260] loss = 4952019000.0, step = 18101 (0.499 sec)\n",
      "I0602 14:26:42.962057 17688 basic_session_run_hooks.py:692] global_step/sec: 205.047\n",
      "I0602 14:26:42.965049 17688 basic_session_run_hooks.py:260] loss = 1600200400.0, step = 18201 (0.486 sec)\n",
      "I0602 14:26:43.417838 17688 basic_session_run_hooks.py:692] global_step/sec: 219.404\n",
      "I0602 14:26:43.421830 17688 basic_session_run_hooks.py:260] loss = 4098511400.0, step = 18301 (0.457 sec)\n",
      "I0602 14:26:43.864643 17688 basic_session_run_hooks.py:692] global_step/sec: 224.312\n",
      "I0602 14:26:43.870629 17688 basic_session_run_hooks.py:260] loss = 4616890000.0, step = 18401 (0.449 sec)\n",
      "I0602 14:26:44.333389 17688 basic_session_run_hooks.py:692] global_step/sec: 212.882\n",
      "I0602 14:26:44.338379 17688 basic_session_run_hooks.py:260] loss = 3956243700.0, step = 18501 (0.468 sec)\n",
      "I0602 14:26:44.800141 17688 basic_session_run_hooks.py:692] global_step/sec: 214.705\n",
      "I0602 14:26:44.804132 17688 basic_session_run_hooks.py:260] loss = 2085219200.0, step = 18601 (0.466 sec)\n",
      "I0602 14:26:45.307788 17688 basic_session_run_hooks.py:692] global_step/sec: 196.601\n",
      "I0602 14:26:45.311774 17688 basic_session_run_hooks.py:260] loss = 4000032300.0, step = 18701 (0.508 sec)\n",
      "I0602 14:26:45.766558 17688 basic_session_run_hooks.py:692] global_step/sec: 217.974\n",
      "I0602 14:26:45.770550 17688 basic_session_run_hooks.py:260] loss = 4031746600.0, step = 18801 (0.459 sec)\n",
      "I0602 14:26:46.230318 17688 basic_session_run_hooks.py:692] global_step/sec: 216.093\n",
      "I0602 14:26:46.233310 17688 basic_session_run_hooks.py:260] loss = 3365815800.0, step = 18901 (0.463 sec)\n",
      "I0602 14:26:46.687097 17688 basic_session_run_hooks.py:692] global_step/sec: 218.447\n",
      "I0602 14:26:46.692084 17688 basic_session_run_hooks.py:260] loss = 2051585900.0, step = 19001 (0.459 sec)\n",
      "I0602 14:26:47.143878 17688 basic_session_run_hooks.py:692] global_step/sec: 218.923\n",
      "I0602 14:26:47.147865 17688 basic_session_run_hooks.py:260] loss = 3629885200.0, step = 19101 (0.456 sec)\n",
      "I0602 14:26:47.626584 17688 basic_session_run_hooks.py:692] global_step/sec: 207.594\n",
      "I0602 14:26:47.629576 17688 basic_session_run_hooks.py:260] loss = 4393683000.0, step = 19201 (0.482 sec)\n",
      "I0602 14:26:48.397524 17688 basic_session_run_hooks.py:692] global_step/sec: 129.544\n",
      "I0602 14:26:48.402509 17688 basic_session_run_hooks.py:260] loss = 3588089300.0, step = 19301 (0.773 sec)\n",
      "I0602 14:26:49.192397 17688 basic_session_run_hooks.py:692] global_step/sec: 125.806\n",
      "I0602 14:26:49.196386 17688 basic_session_run_hooks.py:260] loss = 2339145000.0, step = 19401 (0.794 sec)\n",
      "I0602 14:26:49.669123 17688 basic_session_run_hooks.py:692] global_step/sec: 209.764\n",
      "I0602 14:26:49.675107 17688 basic_session_run_hooks.py:260] loss = 3264388600.0, step = 19501 (0.479 sec)\n",
      "I0602 14:26:50.191725 17688 basic_session_run_hooks.py:692] global_step/sec: 191.35\n",
      "I0602 14:26:50.195714 17688 basic_session_run_hooks.py:260] loss = 3343571200.0, step = 19601 (0.521 sec)\n",
      "I0602 14:26:50.664461 17688 basic_session_run_hooks.py:692] global_step/sec: 211.535\n",
      "I0602 14:26:50.668450 17688 basic_session_run_hooks.py:260] loss = 3945868000.0, step = 19701 (0.473 sec)\n",
      "I0602 14:26:51.130215 17688 basic_session_run_hooks.py:692] global_step/sec: 214.706\n",
      "I0602 14:26:51.134204 17688 basic_session_run_hooks.py:260] loss = 2870090800.0, step = 19801 (0.466 sec)\n",
      "I0602 14:26:51.843309 17688 basic_session_run_hooks.py:692] global_step/sec: 140.234\n",
      "I0602 14:26:51.847298 17688 basic_session_run_hooks.py:260] loss = 3535617500.0, step = 19901 (0.713 sec)\n",
      "I0602 14:26:52.494571 17688 basic_session_run_hooks.py:692] global_step/sec: 153.784\n",
      "I0602 14:26:52.503550 17688 basic_session_run_hooks.py:260] loss = 2927244800.0, step = 20001 (0.656 sec)\n",
      "I0602 14:26:53.092967 17688 basic_session_run_hooks.py:692] global_step/sec: 167.113\n",
      "I0602 14:26:53.095959 17688 basic_session_run_hooks.py:260] loss = 4234387000.0, step = 20101 (0.592 sec)\n",
      "I0602 14:26:53.639508 17688 basic_session_run_hooks.py:692] global_step/sec: 182.968\n",
      "I0602 14:26:53.644492 17688 basic_session_run_hooks.py:260] loss = 3602205400.0, step = 20201 (0.549 sec)\n",
      "I0602 14:26:54.231921 17688 basic_session_run_hooks.py:692] global_step/sec: 168.518\n",
      "I0602 14:26:54.235911 17688 basic_session_run_hooks.py:260] loss = 3678152400.0, step = 20301 (0.591 sec)\n",
      "I0602 14:26:54.743553 17688 basic_session_run_hooks.py:692] global_step/sec: 195.453\n",
      "I0602 14:26:54.747542 17688 basic_session_run_hooks.py:260] loss = 3011142400.0, step = 20401 (0.512 sec)\n",
      "I0602 14:26:55.172408 17688 basic_session_run_hooks.py:692] global_step/sec: 233.179\n",
      "I0602 14:26:55.177393 17688 basic_session_run_hooks.py:260] loss = 3739573500.0, step = 20501 (0.430 sec)\n",
      "I0602 14:26:55.659107 17688 basic_session_run_hooks.py:692] global_step/sec: 205.466\n",
      "I0602 14:26:55.663095 17688 basic_session_run_hooks.py:260] loss = 3408643300.0, step = 20601 (0.486 sec)\n",
      "I0602 14:26:56.130844 17688 basic_session_run_hooks.py:692] global_step/sec: 212.432\n",
      "I0602 14:26:56.133836 17688 basic_session_run_hooks.py:260] loss = 3499308000.0, step = 20701 (0.471 sec)\n",
      "I0602 14:26:56.599591 17688 basic_session_run_hooks.py:692] global_step/sec: 212.882\n",
      "I0602 14:26:56.603581 17688 basic_session_run_hooks.py:260] loss = 2705953800.0, step = 20801 (0.470 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:26:57.065345 17688 basic_session_run_hooks.py:692] global_step/sec: 214.706\n",
      "I0602 14:26:57.069334 17688 basic_session_run_hooks.py:260] loss = 2931114500.0, step = 20901 (0.466 sec)\n",
      "I0602 14:26:57.535089 17688 basic_session_run_hooks.py:692] global_step/sec: 212.882\n",
      "I0602 14:26:57.540082 17688 basic_session_run_hooks.py:260] loss = 2426858000.0, step = 21001 (0.471 sec)\n",
      "I0602 14:26:58.009819 17688 basic_session_run_hooks.py:692] global_step/sec: 210.646\n",
      "I0602 14:26:58.013809 17688 basic_session_run_hooks.py:260] loss = 2546831400.0, step = 21101 (0.474 sec)\n",
      "I0602 14:26:58.433686 17688 basic_session_run_hooks.py:692] global_step/sec: 236.479\n",
      "I0602 14:26:58.440669 17688 basic_session_run_hooks.py:260] loss = 4105649400.0, step = 21201 (0.427 sec)\n",
      "I0602 14:26:58.906423 17688 basic_session_run_hooks.py:692] global_step/sec: 211.533\n",
      "I0602 14:26:58.910411 17688 basic_session_run_hooks.py:260] loss = 2549268000.0, step = 21301 (0.470 sec)\n",
      "I0602 14:26:59.398107 17688 basic_session_run_hooks.py:692] global_step/sec: 202.972\n",
      "I0602 14:26:59.401099 17688 basic_session_run_hooks.py:260] loss = 4361379300.0, step = 21401 (0.491 sec)\n",
      "I0602 14:26:59.862864 17688 basic_session_run_hooks.py:692] global_step/sec: 215.629\n",
      "I0602 14:26:59.865856 17688 basic_session_run_hooks.py:260] loss = 3207655200.0, step = 21501 (0.465 sec)\n",
      "I0602 14:27:00.289724 17688 basic_session_run_hooks.py:692] global_step/sec: 233.723\n",
      "I0602 14:27:00.294710 17688 basic_session_run_hooks.py:260] loss = 4211444200.0, step = 21601 (0.429 sec)\n",
      "I0602 14:27:00.801355 17688 basic_session_run_hooks.py:692] global_step/sec: 195.453\n",
      "I0602 14:27:00.808342 17688 basic_session_run_hooks.py:260] loss = 2660072700.0, step = 21701 (0.514 sec)\n",
      "I0602 14:27:01.314981 17688 basic_session_run_hooks.py:692] global_step/sec: 195.073\n",
      "I0602 14:27:01.317973 17688 basic_session_run_hooks.py:260] loss = 3320310300.0, step = 21801 (0.510 sec)\n",
      "I0602 14:27:01.780736 17688 basic_session_run_hooks.py:692] global_step/sec: 214.246\n",
      "I0602 14:27:01.784726 17688 basic_session_run_hooks.py:260] loss = 3595972000.0, step = 21901 (0.467 sec)\n",
      "I0602 14:27:02.658394 17688 basic_session_run_hooks.py:692] global_step/sec: 114.069\n",
      "I0602 14:27:02.662378 17688 basic_session_run_hooks.py:260] loss = 3112049200.0, step = 22001 (0.878 sec)\n",
      "I0602 14:27:03.120154 17688 basic_session_run_hooks.py:692] global_step/sec: 216.563\n",
      "I0602 14:27:03.125144 17688 basic_session_run_hooks.py:260] loss = 3076277800.0, step = 22101 (0.463 sec)\n",
      "I0602 14:27:03.600869 17688 basic_session_run_hooks.py:692] global_step/sec: 207.593\n",
      "I0602 14:27:03.617824 17688 basic_session_run_hooks.py:260] loss = 1667468900.0, step = 22201 (0.493 sec)\n",
      "I0602 14:27:04.126464 17688 basic_session_run_hooks.py:692] global_step/sec: 190.261\n",
      "I0602 14:27:04.130453 17688 basic_session_run_hooks.py:260] loss = 2944870400.0, step = 22301 (0.513 sec)\n",
      "I0602 14:27:04.706914 17688 basic_session_run_hooks.py:692] global_step/sec: 172.28\n",
      "I0602 14:27:04.712903 17688 basic_session_run_hooks.py:260] loss = 1954691300.0, step = 22401 (0.582 sec)\n",
      "I0602 14:27:05.234500 17688 basic_session_run_hooks.py:692] global_step/sec: 189.543\n",
      "I0602 14:27:05.240485 17688 basic_session_run_hooks.py:260] loss = 3916472800.0, step = 22501 (0.528 sec)\n",
      "I0602 14:27:05.736159 17688 basic_session_run_hooks.py:692] global_step/sec: 199.736\n",
      "I0602 14:27:05.743141 17688 basic_session_run_hooks.py:260] loss = 4022606800.0, step = 22601 (0.502 sec)\n",
      "I0602 14:27:06.225849 17688 basic_session_run_hooks.py:692] global_step/sec: 204.209\n",
      "I0602 14:27:06.228842 17688 basic_session_run_hooks.py:260] loss = 2860439000.0, step = 22701 (0.487 sec)\n",
      "I0602 14:27:06.702575 17688 basic_session_run_hooks.py:692] global_step/sec: 209.328\n",
      "I0602 14:27:06.708560 17688 basic_session_run_hooks.py:260] loss = 2509716700.0, step = 22801 (0.480 sec)\n",
      "I0602 14:27:07.189274 17688 basic_session_run_hooks.py:692] global_step/sec: 205.466\n",
      "I0602 14:27:07.194260 17688 basic_session_run_hooks.py:260] loss = 2560223700.0, step = 22901 (0.486 sec)\n",
      "I0602 14:27:07.886409 17688 basic_session_run_hooks.py:692] global_step/sec: 143.444\n",
      "I0602 14:27:07.892394 17688 basic_session_run_hooks.py:260] loss = 3483343400.0, step = 23001 (0.698 sec)\n",
      "I0602 14:27:08.623450 17688 basic_session_run_hooks.py:692] global_step/sec: 135.862\n",
      "I0602 14:27:08.630424 17688 basic_session_run_hooks.py:260] loss = 3157660700.0, step = 23101 (0.737 sec)\n",
      "I0602 14:27:09.159006 17688 basic_session_run_hooks.py:692] global_step/sec: 186.374\n",
      "I0602 14:27:09.162996 17688 basic_session_run_hooks.py:260] loss = 3876727000.0, step = 23201 (0.534 sec)\n",
      "I0602 14:27:09.624762 17688 basic_session_run_hooks.py:692] global_step/sec: 214.705\n",
      "I0602 14:27:09.627753 17688 basic_session_run_hooks.py:260] loss = 2761879800.0, step = 23301 (0.465 sec)\n",
      "I0602 14:27:10.093508 17688 basic_session_run_hooks.py:692] global_step/sec: 213.79\n",
      "I0602 14:27:10.096500 17688 basic_session_run_hooks.py:260] loss = 2626005000.0, step = 23401 (0.469 sec)\n",
      "I0602 14:27:10.559262 17688 basic_session_run_hooks.py:692] global_step/sec: 214.247\n",
      "I0602 14:27:10.563252 17688 basic_session_run_hooks.py:260] loss = 2755116500.0, step = 23501 (0.467 sec)\n",
      "I0602 14:27:10.998089 17688 basic_session_run_hooks.py:692] global_step/sec: 227.88\n",
      "I0602 14:27:11.003076 17688 basic_session_run_hooks.py:260] loss = 2770148400.0, step = 23601 (0.440 sec)\n",
      "I0602 14:27:11.464840 17688 basic_session_run_hooks.py:692] global_step/sec: 214.247\n",
      "I0602 14:27:11.468830 17688 basic_session_run_hooks.py:260] loss = 3242880800.0, step = 23701 (0.466 sec)\n",
      "I0602 14:27:11.935582 17688 basic_session_run_hooks.py:692] global_step/sec: 212.431\n",
      "I0602 14:27:11.941567 17688 basic_session_run_hooks.py:260] loss = 2965760500.0, step = 23801 (0.473 sec)\n",
      "I0602 14:27:12.388374 17688 basic_session_run_hooks.py:692] global_step/sec: 220.852\n",
      "I0602 14:27:12.393358 17688 basic_session_run_hooks.py:260] loss = 4040837600.0, step = 23901 (0.452 sec)\n",
      "I0602 14:27:12.865097 17688 basic_session_run_hooks.py:692] global_step/sec: 209.765\n",
      "I0602 14:27:12.869086 17688 basic_session_run_hooks.py:260] loss = 2829466000.0, step = 24001 (0.476 sec)\n",
      "I0602 14:27:13.302926 17688 basic_session_run_hooks.py:692] global_step/sec: 228.4\n",
      "I0602 14:27:13.308910 17688 basic_session_run_hooks.py:260] loss = 5438182000.0, step = 24101 (0.439 sec)\n",
      "I0602 14:27:13.799598 17688 basic_session_run_hooks.py:692] global_step/sec: 201.34\n",
      "I0602 14:27:13.806588 17688 basic_session_run_hooks.py:260] loss = 2747955700.0, step = 24201 (0.499 sec)\n",
      "I0602 14:27:14.273334 17688 basic_session_run_hooks.py:692] global_step/sec: 211.534\n",
      "I0602 14:27:14.277320 17688 basic_session_run_hooks.py:260] loss = 4477849600.0, step = 24301 (0.471 sec)\n",
      "I0602 14:27:14.734098 17688 basic_session_run_hooks.py:692] global_step/sec: 216.561\n",
      "I0602 14:27:14.738092 17688 basic_session_run_hooks.py:260] loss = 2033636400.0, step = 24401 (0.461 sec)\n",
      "I0602 14:27:15.199853 17688 basic_session_run_hooks.py:692] global_step/sec: 215.166\n",
      "I0602 14:27:15.202846 17688 basic_session_run_hooks.py:260] loss = 3581837800.0, step = 24501 (0.465 sec)\n",
      "I0602 14:27:15.663614 17688 basic_session_run_hooks.py:692] global_step/sec: 215.166\n",
      "I0602 14:27:15.667603 17688 basic_session_run_hooks.py:260] loss = 3874718700.0, step = 24601 (0.465 sec)\n",
      "I0602 14:27:16.137347 17688 basic_session_run_hooks.py:692] global_step/sec: 211.535\n",
      "I0602 14:27:16.142334 17688 basic_session_run_hooks.py:260] loss = 3387457500.0, step = 24701 (0.475 sec)\n",
      "I0602 14:27:16.618061 17688 basic_session_run_hooks.py:692] global_step/sec: 207.593\n",
      "I0602 14:27:16.623053 17688 basic_session_run_hooks.py:260] loss = 2423446800.0, step = 24801 (0.481 sec)\n",
      "I0602 14:27:17.091795 17688 basic_session_run_hooks.py:692] global_step/sec: 211.532\n",
      "I0602 14:27:17.094786 17688 basic_session_run_hooks.py:260] loss = 2130657500.0, step = 24901 (0.472 sec)\n",
      "I0602 14:27:17.558547 17688 basic_session_run_hooks.py:692] global_step/sec: 214.248\n",
      "I0602 14:27:17.561538 17688 basic_session_run_hooks.py:260] loss = 2345105000.0, step = 25001 (0.467 sec)\n",
      "I0602 14:27:18.021311 17688 basic_session_run_hooks.py:692] global_step/sec: 215.629\n",
      "I0602 14:27:18.027293 17688 basic_session_run_hooks.py:260] loss = 2677995000.0, step = 25101 (0.465 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:27:18.498034 17688 basic_session_run_hooks.py:692] global_step/sec: 209.766\n",
      "I0602 14:27:18.502023 17688 basic_session_run_hooks.py:260] loss = 2723729400.0, step = 25201 (0.476 sec)\n",
      "I0602 14:27:18.956812 17688 basic_session_run_hooks.py:692] global_step/sec: 217.97\n",
      "I0602 14:27:18.960796 17688 basic_session_run_hooks.py:260] loss = 3732040200.0, step = 25301 (0.459 sec)\n",
      "I0602 14:27:19.364717 17688 basic_session_run_hooks.py:692] global_step/sec: 245.155\n",
      "I0602 14:27:19.368706 17688 basic_session_run_hooks.py:260] loss = 3113502700.0, step = 25401 (0.408 sec)\n",
      "I0602 14:27:19.817505 17688 basic_session_run_hooks.py:692] global_step/sec: 220.854\n",
      "I0602 14:27:19.821497 17688 basic_session_run_hooks.py:260] loss = 3482463700.0, step = 25501 (0.453 sec)\n",
      "I0602 14:27:20.278273 17688 basic_session_run_hooks.py:692] global_step/sec: 217.029\n",
      "I0602 14:27:20.282263 17688 basic_session_run_hooks.py:260] loss = 3127436800.0, step = 25601 (0.461 sec)\n",
      "I0602 14:27:20.741041 17688 basic_session_run_hooks.py:692] global_step/sec: 216.091\n",
      "I0602 14:27:20.745025 17688 basic_session_run_hooks.py:260] loss = 3180712000.0, step = 25701 (0.463 sec)\n",
      "I0602 14:27:21.207790 17688 basic_session_run_hooks.py:692] global_step/sec: 214.248\n",
      "I0602 14:27:21.211778 17688 basic_session_run_hooks.py:260] loss = 2724611000.0, step = 25801 (0.467 sec)\n",
      "I0602 14:27:21.669553 17688 basic_session_run_hooks.py:692] global_step/sec: 217.03\n",
      "I0602 14:27:21.674542 17688 basic_session_run_hooks.py:260] loss = 3745468700.0, step = 25901 (0.463 sec)\n",
      "I0602 14:27:22.134310 17688 basic_session_run_hooks.py:692] global_step/sec: 214.705\n",
      "I0602 14:27:22.139302 17688 basic_session_run_hooks.py:260] loss = 3148511200.0, step = 26001 (0.465 sec)\n",
      "I0602 14:27:22.602060 17688 basic_session_run_hooks.py:692] global_step/sec: 213.79\n",
      "I0602 14:27:22.607049 17688 basic_session_run_hooks.py:260] loss = 2429642200.0, step = 26101 (0.468 sec)\n",
      "I0602 14:27:23.095740 17688 basic_session_run_hooks.py:692] global_step/sec: 202.56\n",
      "I0602 14:27:23.099730 17688 basic_session_run_hooks.py:260] loss = 3280491000.0, step = 26201 (0.493 sec)\n",
      "I0602 14:27:23.564486 17688 basic_session_run_hooks.py:692] global_step/sec: 213.335\n",
      "I0602 14:27:23.567478 17688 basic_session_run_hooks.py:260] loss = 3377133000.0, step = 26301 (0.468 sec)\n",
      "I0602 14:27:23.972397 17688 basic_session_run_hooks.py:692] global_step/sec: 245.75\n",
      "I0602 14:27:23.979377 17688 basic_session_run_hooks.py:260] loss = 3235111200.0, step = 26401 (0.412 sec)\n",
      "I0602 14:27:24.370332 17688 basic_session_run_hooks.py:692] global_step/sec: 250.671\n",
      "I0602 14:27:24.378310 17688 basic_session_run_hooks.py:260] loss = 2495174100.0, step = 26501 (0.399 sec)\n",
      "I0602 14:27:24.840076 17688 basic_session_run_hooks.py:692] global_step/sec: 212.882\n",
      "I0602 14:27:24.845062 17688 basic_session_run_hooks.py:260] loss = 2779654700.0, step = 26601 (0.467 sec)\n",
      "I0602 14:27:25.300843 17688 basic_session_run_hooks.py:692] global_step/sec: 217.029\n",
      "I0602 14:27:25.305836 17688 basic_session_run_hooks.py:260] loss = 2629271000.0, step = 26701 (0.461 sec)\n",
      "I0602 14:27:25.777568 17688 basic_session_run_hooks.py:692] global_step/sec: 210.204\n",
      "I0602 14:27:25.780561 17688 basic_session_run_hooks.py:260] loss = 2455108600.0, step = 26801 (0.475 sec)\n",
      "I0602 14:27:26.475703 17688 basic_session_run_hooks.py:692] global_step/sec: 143.035\n",
      "I0602 14:27:26.479691 17688 basic_session_run_hooks.py:260] loss = 3843434000.0, step = 26901 (0.699 sec)\n",
      "I0602 14:27:26.947440 17688 basic_session_run_hooks.py:692] global_step/sec: 211.982\n",
      "I0602 14:27:26.951429 17688 basic_session_run_hooks.py:260] loss = 3372404200.0, step = 27001 (0.472 sec)\n",
      "I0602 14:27:27.422172 17688 basic_session_run_hooks.py:692] global_step/sec: 211.089\n",
      "I0602 14:27:27.426161 17688 basic_session_run_hooks.py:260] loss = 3652778800.0, step = 27101 (0.475 sec)\n",
      "I0602 14:27:28.168607 17688 basic_session_run_hooks.py:692] global_step/sec: 133.791\n",
      "I0602 14:27:28.179581 17688 basic_session_run_hooks.py:260] loss = 3385659400.0, step = 27201 (0.752 sec)\n",
      "I0602 14:27:28.948516 17688 basic_session_run_hooks.py:692] global_step/sec: 128.22\n",
      "I0602 14:27:28.951508 17688 basic_session_run_hooks.py:260] loss = 3647439600.0, step = 27301 (0.773 sec)\n",
      "I0602 14:27:29.612741 17688 basic_session_run_hooks.py:692] global_step/sec: 150.551\n",
      "I0602 14:27:29.616730 17688 basic_session_run_hooks.py:260] loss = 2384673300.0, step = 27401 (0.665 sec)\n",
      "I0602 14:27:30.084480 17688 basic_session_run_hooks.py:692] global_step/sec: 211.982\n",
      "I0602 14:27:30.088472 17688 basic_session_run_hooks.py:260] loss = 2062311600.0, step = 27501 (0.472 sec)\n",
      "I0602 14:27:30.517322 17688 basic_session_run_hooks.py:692] global_step/sec: 231.031\n",
      "I0602 14:27:30.524307 17688 basic_session_run_hooks.py:260] loss = 3023279900.0, step = 27601 (0.436 sec)\n",
      "I0602 14:27:31.166586 17688 basic_session_run_hooks.py:692] global_step/sec: 154.021\n",
      "I0602 14:27:31.171583 17688 basic_session_run_hooks.py:260] loss = 4359049000.0, step = 27701 (0.647 sec)\n",
      "I0602 14:27:31.852751 17688 basic_session_run_hooks.py:692] global_step/sec: 145.738\n",
      "I0602 14:27:31.858735 17688 basic_session_run_hooks.py:260] loss = 2701862100.0, step = 27801 (0.687 sec)\n",
      "I0602 14:27:32.553876 17688 basic_session_run_hooks.py:692] global_step/sec: 142.831\n",
      "I0602 14:27:32.558865 17688 basic_session_run_hooks.py:260] loss = 2580451600.0, step = 27901 (0.700 sec)\n",
      "I0602 14:27:33.067506 17688 basic_session_run_hooks.py:692] global_step/sec: 194.694\n",
      "I0602 14:27:33.077484 17688 basic_session_run_hooks.py:260] loss = 2555688400.0, step = 28001 (0.518 sec)\n",
      "I0602 14:27:33.687850 17688 basic_session_run_hooks.py:692] global_step/sec: 160.941\n",
      "I0602 14:27:33.694826 17688 basic_session_run_hooks.py:260] loss = 2175323600.0, step = 28101 (0.618 sec)\n",
      "I0602 14:27:34.341101 17688 basic_session_run_hooks.py:692] global_step/sec: 153.549\n",
      "I0602 14:27:34.349079 17688 basic_session_run_hooks.py:260] loss = 1583085400.0, step = 28201 (0.654 sec)\n",
      "I0602 14:27:34.854735 17688 basic_session_run_hooks.py:692] global_step/sec: 194.316\n",
      "I0602 14:27:34.862705 17688 basic_session_run_hooks.py:260] loss = 3434965500.0, step = 28301 (0.514 sec)\n",
      "I0602 14:27:35.551860 17688 basic_session_run_hooks.py:692] global_step/sec: 143.24\n",
      "I0602 14:27:35.557845 17688 basic_session_run_hooks.py:260] loss = 2673523200.0, step = 28401 (0.695 sec)\n",
      "I0602 14:27:36.041550 17688 basic_session_run_hooks.py:692] global_step/sec: 204.211\n",
      "I0602 14:27:36.045539 17688 basic_session_run_hooks.py:260] loss = 3397787100.0, step = 28501 (0.488 sec)\n",
      "I0602 14:27:36.520273 17688 basic_session_run_hooks.py:692] global_step/sec: 208.889\n",
      "I0602 14:27:36.526254 17688 basic_session_run_hooks.py:260] loss = 3367635500.0, step = 28601 (0.481 sec)\n",
      "I0602 14:27:37.218404 17688 basic_session_run_hooks.py:692] global_step/sec: 143.24\n",
      "I0602 14:27:37.225392 17688 basic_session_run_hooks.py:260] loss = 1867794700.0, step = 28701 (0.699 sec)\n",
      "I0602 14:27:37.700115 17688 basic_session_run_hooks.py:692] global_step/sec: 208.024\n",
      "I0602 14:27:37.703108 17688 basic_session_run_hooks.py:260] loss = 2656604700.0, step = 28801 (0.478 sec)\n",
      "I0602 14:27:38.184819 17688 basic_session_run_hooks.py:692] global_step/sec: 205.888\n",
      "I0602 14:27:38.189810 17688 basic_session_run_hooks.py:260] loss = 4217803800.0, step = 28901 (0.487 sec)\n",
      "I0602 14:27:38.835080 17688 basic_session_run_hooks.py:692] global_step/sec: 153.784\n",
      "I0602 14:27:38.839072 17688 basic_session_run_hooks.py:260] loss = 3916296400.0, step = 29001 (0.649 sec)\n",
      "I0602 14:27:39.318787 17688 basic_session_run_hooks.py:692] global_step/sec: 207.164\n",
      "I0602 14:27:39.323778 17688 basic_session_run_hooks.py:260] loss = 2694660600.0, step = 29101 (0.485 sec)\n",
      "I0602 14:27:39.795512 17688 basic_session_run_hooks.py:692] global_step/sec: 209.326\n",
      "I0602 14:27:39.798504 17688 basic_session_run_hooks.py:260] loss = 2492098000.0, step = 29201 (0.475 sec)\n",
      "I0602 14:27:40.301160 17688 basic_session_run_hooks.py:692] global_step/sec: 198.157\n",
      "I0602 14:27:40.304156 17688 basic_session_run_hooks.py:260] loss = 2618723300.0, step = 29301 (0.506 sec)\n",
      "I0602 14:27:40.754947 17688 basic_session_run_hooks.py:692] global_step/sec: 219.885\n",
      "I0602 14:27:40.759934 17688 basic_session_run_hooks.py:260] loss = 2026754400.0, step = 29401 (0.456 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:27:41.232669 17688 basic_session_run_hooks.py:692] global_step/sec: 209.327\n",
      "I0602 14:27:41.235661 17688 basic_session_run_hooks.py:260] loss = 2345551400.0, step = 29501 (0.476 sec)\n",
      "I0602 14:27:41.682466 17688 basic_session_run_hooks.py:692] global_step/sec: 222.322\n",
      "I0602 14:27:41.687455 17688 basic_session_run_hooks.py:260] loss = 4887218000.0, step = 29601 (0.452 sec)\n",
      "I0602 14:27:42.188117 17688 basic_session_run_hooks.py:692] global_step/sec: 198.156\n",
      "I0602 14:27:42.193100 17688 basic_session_run_hooks.py:260] loss = 5068238000.0, step = 29701 (0.506 sec)\n",
      "I0602 14:27:42.677805 17688 basic_session_run_hooks.py:692] global_step/sec: 203.796\n",
      "I0602 14:27:42.681794 17688 basic_session_run_hooks.py:260] loss = 2207847000.0, step = 29801 (0.489 sec)\n",
      "I0602 14:27:43.175475 17688 basic_session_run_hooks.py:692] global_step/sec: 200.936\n",
      "I0602 14:27:43.179463 17688 basic_session_run_hooks.py:260] loss = 2679883800.0, step = 29901 (0.498 sec)\n",
      "I0602 14:27:43.647212 17688 basic_session_run_hooks.py:692] global_step/sec: 211.982\n",
      "I0602 14:27:43.650205 17688 basic_session_run_hooks.py:260] loss = 1602459800.0, step = 30001 (0.471 sec)\n",
      "I0602 14:27:44.109975 17688 basic_session_run_hooks.py:692] global_step/sec: 216.56\n",
      "I0602 14:27:44.112967 17688 basic_session_run_hooks.py:260] loss = 2092712700.0, step = 30101 (0.463 sec)\n",
      "I0602 14:27:44.598669 17688 basic_session_run_hooks.py:692] global_step/sec: 204.211\n",
      "I0602 14:27:44.601660 17688 basic_session_run_hooks.py:260] loss = 4177664300.0, step = 30201 (0.489 sec)\n",
      "I0602 14:27:45.076391 17688 basic_session_run_hooks.py:692] global_step/sec: 209.326\n",
      "I0602 14:27:45.079382 17688 basic_session_run_hooks.py:260] loss = 4069254400.0, step = 30301 (0.478 sec)\n",
      "I0602 14:27:45.679777 17688 basic_session_run_hooks.py:692] global_step/sec: 165.731\n",
      "I0602 14:27:45.683767 17688 basic_session_run_hooks.py:260] loss = 3654360000.0, step = 30401 (0.604 sec)\n",
      "I0602 14:27:46.210360 17688 basic_session_run_hooks.py:692] global_step/sec: 188.472\n",
      "I0602 14:27:46.215345 17688 basic_session_run_hooks.py:260] loss = 1293574700.0, step = 30501 (0.532 sec)\n",
      "I0602 14:27:46.731964 17688 basic_session_run_hooks.py:692] global_step/sec: 192.084\n",
      "I0602 14:27:46.734956 17688 basic_session_run_hooks.py:260] loss = 2833698800.0, step = 30601 (0.520 sec)\n",
      "I0602 14:27:47.197719 17688 basic_session_run_hooks.py:692] global_step/sec: 214.246\n",
      "I0602 14:27:47.200711 17688 basic_session_run_hooks.py:260] loss = 2566167000.0, step = 30701 (0.466 sec)\n",
      "I0602 14:27:47.645521 17688 basic_session_run_hooks.py:692] global_step/sec: 223.313\n",
      "I0602 14:27:47.649510 17688 basic_session_run_hooks.py:260] loss = 1810358500.0, step = 30801 (0.449 sec)\n",
      "I0602 14:27:48.104295 17688 basic_session_run_hooks.py:692] global_step/sec: 217.972\n",
      "I0602 14:27:48.112272 17688 basic_session_run_hooks.py:260] loss = 5673220600.0, step = 30901 (0.463 sec)\n",
      "I0602 14:27:48.562070 17688 basic_session_run_hooks.py:692] global_step/sec: 218.448\n",
      "I0602 14:27:48.566060 17688 basic_session_run_hooks.py:260] loss = 2641162800.0, step = 31001 (0.454 sec)\n",
      "I0602 14:27:49.027825 17688 basic_session_run_hooks.py:692] global_step/sec: 214.705\n",
      "I0602 14:27:49.030817 17688 basic_session_run_hooks.py:260] loss = 1258995000.0, step = 31101 (0.465 sec)\n",
      "I0602 14:27:49.494577 17688 basic_session_run_hooks.py:692] global_step/sec: 214.703\n",
      "I0602 14:27:49.497569 17688 basic_session_run_hooks.py:260] loss = 2408894000.0, step = 31201 (0.467 sec)\n",
      "I0602 14:27:50.201685 17688 basic_session_run_hooks.py:692] global_step/sec: 141.223\n",
      "I0602 14:27:50.207675 17688 basic_session_run_hooks.py:260] loss = 1869830400.0, step = 31301 (0.710 sec)\n",
      "I0602 14:27:50.667440 17688 basic_session_run_hooks.py:692] global_step/sec: 215.166\n",
      "I0602 14:27:50.671435 17688 basic_session_run_hooks.py:260] loss = 2169027800.0, step = 31401 (0.464 sec)\n",
      "I0602 14:27:51.132198 17688 basic_session_run_hooks.py:692] global_step/sec: 214.706\n",
      "I0602 14:27:51.136187 17688 basic_session_run_hooks.py:260] loss = 2263380700.0, step = 31501 (0.465 sec)\n",
      "I0602 14:27:51.715637 17688 basic_session_run_hooks.py:692] global_step/sec: 171.397\n",
      "I0602 14:27:51.721642 17688 basic_session_run_hooks.py:260] loss = 2256148500.0, step = 31601 (0.584 sec)\n",
      "I0602 14:27:52.221290 17688 basic_session_run_hooks.py:692] global_step/sec: 197.764\n",
      "I0602 14:27:52.226272 17688 basic_session_run_hooks.py:260] loss = 2734151700.0, step = 31701 (0.506 sec)\n",
      "I0602 14:27:52.725937 17688 basic_session_run_hooks.py:692] global_step/sec: 198.158\n",
      "I0602 14:27:52.729925 17688 basic_session_run_hooks.py:260] loss = 3766792200.0, step = 31801 (0.503 sec)\n",
      "I0602 14:27:53.209643 17688 basic_session_run_hooks.py:692] global_step/sec: 206.737\n",
      "I0602 14:27:53.213633 17688 basic_session_run_hooks.py:260] loss = 2279643400.0, step = 31901 (0.485 sec)\n",
      "I0602 14:27:53.673408 17688 basic_session_run_hooks.py:692] global_step/sec: 216.089\n",
      "I0602 14:27:53.678389 17688 basic_session_run_hooks.py:260] loss = 2194153700.0, step = 32001 (0.465 sec)\n",
      "I0602 14:27:54.211962 17688 basic_session_run_hooks.py:692] global_step/sec: 185.341\n",
      "I0602 14:27:54.215952 17688 basic_session_run_hooks.py:260] loss = 3609686300.0, step = 32101 (0.538 sec)\n",
      "I0602 14:27:54.652784 17688 basic_session_run_hooks.py:692] global_step/sec: 226.849\n",
      "I0602 14:27:54.660763 17688 basic_session_run_hooks.py:260] loss = 1834014500.0, step = 32201 (0.445 sec)\n",
      "I0602 14:27:55.150453 17688 basic_session_run_hooks.py:692] global_step/sec: 201.34\n",
      "I0602 14:27:55.154451 17688 basic_session_run_hooks.py:260] loss = 2652640500.0, step = 32301 (0.494 sec)\n",
      "I0602 14:27:55.637156 17688 basic_session_run_hooks.py:692] global_step/sec: 205.466\n",
      "I0602 14:27:55.642138 17688 basic_session_run_hooks.py:260] loss = 3340229400.0, step = 32401 (0.488 sec)\n",
      "I0602 14:27:56.113877 17688 basic_session_run_hooks.py:692] global_step/sec: 209.327\n",
      "I0602 14:27:56.116868 17688 basic_session_run_hooks.py:260] loss = 3811083000.0, step = 32501 (0.475 sec)\n",
      "I0602 14:27:56.612543 17688 basic_session_run_hooks.py:692] global_step/sec: 200.937\n",
      "I0602 14:27:56.616533 17688 basic_session_run_hooks.py:260] loss = 3171213800.0, step = 32601 (0.500 sec)\n",
      "I0602 14:27:57.098245 17688 basic_session_run_hooks.py:692] global_step/sec: 205.466\n",
      "I0602 14:27:57.101236 17688 basic_session_run_hooks.py:260] loss = 2013599200.0, step = 32701 (0.485 sec)\n",
      "I0602 14:27:57.569983 17688 basic_session_run_hooks.py:692] global_step/sec: 211.982\n",
      "I0602 14:27:57.576965 17688 basic_session_run_hooks.py:260] loss = 3040378600.0, step = 32801 (0.475 sec)\n",
      "I0602 14:27:58.043717 17688 basic_session_run_hooks.py:692] global_step/sec: 211.089\n",
      "I0602 14:27:58.047706 17688 basic_session_run_hooks.py:260] loss = 2567626800.0, step = 32901 (0.472 sec)\n",
      "I0602 14:27:58.527426 17688 basic_session_run_hooks.py:692] global_step/sec: 206.736\n",
      "I0602 14:27:58.531412 17688 basic_session_run_hooks.py:260] loss = 2996155100.0, step = 33001 (0.484 sec)\n",
      "I0602 14:27:58.997167 17688 basic_session_run_hooks.py:692] global_step/sec: 212.883\n",
      "I0602 14:27:59.001156 17688 basic_session_run_hooks.py:260] loss = 2579676200.0, step = 33101 (0.470 sec)\n",
      "I0602 14:27:59.465913 17688 basic_session_run_hooks.py:692] global_step/sec: 213.335\n",
      "I0602 14:27:59.469902 17688 basic_session_run_hooks.py:260] loss = 2637470200.0, step = 33201 (0.469 sec)\n",
      "I0602 14:27:59.952612 17688 basic_session_run_hooks.py:692] global_step/sec: 205.466\n",
      "I0602 14:27:59.957602 17688 basic_session_run_hooks.py:260] loss = 2288078800.0, step = 33301 (0.488 sec)\n",
      "I0602 14:28:00.448286 17688 basic_session_run_hooks.py:692] global_step/sec: 202.152\n",
      "I0602 14:28:00.451279 17688 basic_session_run_hooks.py:260] loss = 2630540800.0, step = 33401 (0.494 sec)\n",
      "I0602 14:28:00.917033 17688 basic_session_run_hooks.py:692] global_step/sec: 212.882\n",
      "I0602 14:28:00.921029 17688 basic_session_run_hooks.py:260] loss = 2714164000.0, step = 33501 (0.470 sec)\n",
      "I0602 14:28:01.419689 17688 basic_session_run_hooks.py:692] global_step/sec: 198.943\n",
      "I0602 14:28:01.425674 17688 basic_session_run_hooks.py:260] loss = 1408497900.0, step = 33601 (0.504 sec)\n",
      "I0602 14:28:01.898409 17688 basic_session_run_hooks.py:692] global_step/sec: 208.89\n",
      "I0602 14:28:01.902398 17688 basic_session_run_hooks.py:260] loss = 2175010000.0, step = 33701 (0.478 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:28:02.365161 17688 basic_session_run_hooks.py:692] global_step/sec: 214.705\n",
      "I0602 14:28:02.369150 17688 basic_session_run_hooks.py:260] loss = 2237602300.0, step = 33801 (0.467 sec)\n",
      "I0602 14:28:02.767086 17688 basic_session_run_hooks.py:692] global_step/sec: 248.187\n",
      "I0602 14:28:02.777060 17688 basic_session_run_hooks.py:260] loss = 3024977700.0, step = 33901 (0.408 sec)\n",
      "I0602 14:28:03.228851 17688 basic_session_run_hooks.py:692] global_step/sec: 216.56\n",
      "I0602 14:28:03.232841 17688 basic_session_run_hooks.py:260] loss = 2769045500.0, step = 34001 (0.456 sec)\n",
      "I0602 14:28:03.699593 17688 basic_session_run_hooks.py:692] global_step/sec: 212.431\n",
      "I0602 14:28:03.704585 17688 basic_session_run_hooks.py:260] loss = 2901396000.0, step = 34101 (0.472 sec)\n",
      "I0602 14:28:04.184297 17688 basic_session_run_hooks.py:692] global_step/sec: 206.737\n",
      "I0602 14:28:04.188287 17688 basic_session_run_hooks.py:260] loss = 2567043000.0, step = 34201 (0.484 sec)\n",
      "I0602 14:28:04.736819 17688 basic_session_run_hooks.py:692] global_step/sec: 180.662\n",
      "I0602 14:28:04.741806 17688 basic_session_run_hooks.py:260] loss = 1875257300.0, step = 34301 (0.554 sec)\n",
      "I0602 14:28:05.220528 17688 basic_session_run_hooks.py:692] global_step/sec: 207.164\n",
      "I0602 14:28:05.225513 17688 basic_session_run_hooks.py:260] loss = 2476116000.0, step = 34401 (0.484 sec)\n",
      "I0602 14:28:05.710221 17688 basic_session_run_hooks.py:692] global_step/sec: 204.21\n",
      "I0602 14:28:05.716201 17688 basic_session_run_hooks.py:260] loss = 2042020400.0, step = 34501 (0.491 sec)\n",
      "I0602 14:28:06.338537 17688 basic_session_run_hooks.py:692] global_step/sec: 159.155\n",
      "I0602 14:28:06.354496 17688 basic_session_run_hooks.py:260] loss = 1911955800.0, step = 34601 (0.637 sec)\n",
      "I0602 14:28:06.916989 17688 basic_session_run_hooks.py:692] global_step/sec: 172.578\n",
      "I0602 14:28:06.920987 17688 basic_session_run_hooks.py:260] loss = 2498167800.0, step = 34701 (0.567 sec)\n",
      "I0602 14:28:07.391725 17688 basic_session_run_hooks.py:692] global_step/sec: 210.643\n",
      "I0602 14:28:07.395709 17688 basic_session_run_hooks.py:260] loss = 1865661700.0, step = 34801 (0.475 sec)\n",
      "I0602 14:28:07.879416 17688 basic_session_run_hooks.py:692] global_step/sec: 205.468\n",
      "I0602 14:28:07.882408 17688 basic_session_run_hooks.py:260] loss = 3021640700.0, step = 34901 (0.487 sec)\n",
      "I0602 14:28:08.353151 17688 basic_session_run_hooks.py:692] global_step/sec: 210.645\n",
      "I0602 14:28:08.359134 17688 basic_session_run_hooks.py:260] loss = 2593357300.0, step = 35001 (0.477 sec)\n",
      "I0602 14:28:08.827880 17688 basic_session_run_hooks.py:692] global_step/sec: 210.646\n",
      "I0602 14:28:08.831869 17688 basic_session_run_hooks.py:260] loss = 4510366700.0, step = 35101 (0.473 sec)\n",
      "I0602 14:28:09.517037 17688 basic_session_run_hooks.py:692] global_step/sec: 145.105\n",
      "I0602 14:28:09.521029 17688 basic_session_run_hooks.py:260] loss = 2820986000.0, step = 35201 (0.689 sec)\n",
      "I0602 14:28:09.998748 17688 basic_session_run_hooks.py:692] global_step/sec: 207.593\n",
      "I0602 14:28:10.001741 17688 basic_session_run_hooks.py:260] loss = 2714322000.0, step = 35301 (0.481 sec)\n",
      "I0602 14:28:10.514370 17688 basic_session_run_hooks.py:692] global_step/sec: 193.94\n",
      "I0602 14:28:10.519358 17688 basic_session_run_hooks.py:260] loss = 3211299300.0, step = 35401 (0.518 sec)\n",
      "I0602 14:28:10.998076 17688 basic_session_run_hooks.py:692] global_step/sec: 206.737\n",
      "I0602 14:28:11.001068 17688 basic_session_run_hooks.py:260] loss = 2856354800.0, step = 35501 (0.482 sec)\n",
      "I0602 14:28:11.484776 17688 basic_session_run_hooks.py:692] global_step/sec: 205.888\n",
      "I0602 14:28:11.488766 17688 basic_session_run_hooks.py:260] loss = 3209129500.0, step = 35601 (0.488 sec)\n",
      "I0602 14:28:12.102124 17688 basic_session_run_hooks.py:692] global_step/sec: 161.722\n",
      "I0602 14:28:12.109112 17688 basic_session_run_hooks.py:260] loss = 3126258400.0, step = 35701 (0.619 sec)\n",
      "I0602 14:28:12.521006 17688 basic_session_run_hooks.py:692] global_step/sec: 238.731\n",
      "I0602 14:28:12.529980 17688 basic_session_run_hooks.py:260] loss = 1589718300.0, step = 35801 (0.422 sec)\n",
      "I0602 14:28:12.994738 17688 basic_session_run_hooks.py:692] global_step/sec: 211.535\n",
      "I0602 14:28:12.997729 17688 basic_session_run_hooks.py:260] loss = 1920689300.0, step = 35901 (0.468 sec)\n",
      "I0602 14:28:13.460492 17688 basic_session_run_hooks.py:692] global_step/sec: 214.247\n",
      "I0602 14:28:13.464482 17688 basic_session_run_hooks.py:260] loss = 3193784000.0, step = 36001 (0.467 sec)\n",
      "I0602 14:28:13.871395 17688 basic_session_run_hooks.py:692] global_step/sec: 243.959\n",
      "I0602 14:28:13.876381 17688 basic_session_run_hooks.py:260] loss = 4665349000.0, step = 36101 (0.412 sec)\n",
      "I0602 14:28:14.335153 17688 basic_session_run_hooks.py:692] global_step/sec: 215.629\n",
      "I0602 14:28:14.339145 17688 basic_session_run_hooks.py:260] loss = 3255464200.0, step = 36201 (0.463 sec)\n",
      "I0602 14:28:14.796919 17688 basic_session_run_hooks.py:692] global_step/sec: 216.093\n",
      "I0602 14:28:14.800907 17688 basic_session_run_hooks.py:260] loss = 3010362000.0, step = 36301 (0.462 sec)\n",
      "I0602 14:28:15.298577 17688 basic_session_run_hooks.py:692] global_step/sec: 199.339\n",
      "I0602 14:28:15.301568 17688 basic_session_run_hooks.py:260] loss = 1392081700.0, step = 36401 (0.501 sec)\n",
      "I0602 14:28:15.760342 17688 basic_session_run_hooks.py:692] global_step/sec: 216.56\n",
      "I0602 14:28:15.764332 17688 basic_session_run_hooks.py:260] loss = 3331387400.0, step = 36501 (0.463 sec)\n",
      "I0602 14:28:16.108413 17688 basic_session_run_hooks.py:606] Saving checkpoints for 36563 into C:\\Users\\LENOVO\\AppData\\Local\\Temp\\tmp9xr1hi4y\\model.ckpt.\n",
      "I0602 14:28:19.280928 17688 estimator.py:368] Loss for final step: 965466900.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn_linear_combined.DNNLinearCombinedRegressor at 0x1f8e8593a08>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.train(input_fn=input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 14:29:33.586837 17688 estimator.py:1145] Calling model_fn.\n",
      "I0602 14:29:35.300256 17688 estimator.py:1147] Done calling model_fn.\n",
      "I0602 14:29:35.753044 17688 monitored_session.py:240] Graph was finalized.\n",
      "I0602 14:29:35.765012 17688 saver.py:1280] Restoring parameters from C:\\Users\\LENOVO\\AppData\\Local\\Temp\\tmp9xr1hi4y\\model.ckpt-36563\n",
      "I0602 14:29:36.035350 17688 session_manager.py:500] Running local_init_op.\n",
      "I0602 14:29:36.078233 17688 session_manager.py:502] Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "dnnreg_prediction = []\n",
    "\n",
    "for pred in dnn_model.predict(input_fn=pred_input_func):\n",
    "    dnnreg_prediction.append(pred['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8194067093812948"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_result = r2_score(y_test, dnnreg_prediction)\n",
    "r2_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f8893ee808>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test.values, '*c')\n",
    "plt.plot(dnnreg_prediction, '*r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
